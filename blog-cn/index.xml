<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog-cns on PingCAP Site</title>
    <link>https://pingcap.com/blog-cn/</link>
    <description>Recent content in Blog-cns on PingCAP Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://pingcap.com/blog-cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TiDB 在西山居实时舆情监控系统中的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-xishanju/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-xishanju/</guid>
      <description>公司简介 西山居创建 1995 年初夏，在美丽的海滨小城珠海，西山居工作室孕育而生，一群西山居居士们十年如一日尅勊业业的奋斗。&amp;rdquo;创造快乐，传递快乐！&amp;rdquo; 一直是西山居居士们的创作宗旨。西山居以领先的技术作为坚实的基础以独特的本土化产品为玩家提供时尚化服务。在未来，西山居仍以娱乐软件为主导产品，不断进行研发和市场活动，逐步发展成为国内最优秀的集制作、发行于一体的数字化互动娱乐公司。
业务背景 由于公司产品的社交属性都非常强，对相关舆情进行分析与了解就显得很有必要，在此背景下，舆情监控系统应运而生。该系统利用算法组提供的分词算法，对文本进行解析与分类，打上各类标记后再通过计算产生中间结果。舆情系统直接查询这些中间结果，产生各类报表与趋势图，为及时掌握各类舆情趋势提供便利。用户可以自由组合舆情关注点，从而对平台有很严格的实时交互性查询要求，是典型的实时 HTAP 类业务。
存储技术选型 舆情系统之前我们曾经实现过一个客服系统，这个系统要求能实时查询，但面对是海量的玩家行为记录。在当时情况下（2016 年），可以选择的对象只有 MyCAT 这类数据库中间件，通过综合压力测试后，我们选定了 KingShard 这一款由公司前同事开发的中间件，KingShard 虽然没有 MyCAT 丰富的周边功能，但它在满足我们业务需求的核心功能上有更快的表现。但正因为有了这一次中间件的使用，我们对中间件有了比较全面的了解，它们在查询优化上有着天生的弱点，无法满足更复杂的查询或者表现极不友好，为此我们还不得不砍掉了客服系统的部分业务功能，所以在那时我已开始寻找更优的技术方案，其中分布式数据库是我们考察的重点方向。
BigTable、GFS、MapReduce 是谷歌在分布式存储与查询领域的探索成果，他们没有公开具体实现代码，但却发布了相应论文，对分布式文件系统、大数据挖掘和 NoSQL 发展起了重大促进作用。开源界根据这一成果开发出对应产品是 HBase、HDFS、Hadoop，这三个产品红极一时，相关周边产品更是百花齐放，很多细分领域都同时出现了多个产品竞争，让整个生态非常繁荣但也变得复杂，提高了我们的学习与使用成本。那么，在一些领域中有没有更加简单、直接、具有较强融合能力的解决方案呢？此时距谷歌这三篇论文发表已近 10 年，谷歌内部早已在尝试融合 NoSQL 和 SQL，并对它们进行了多次更新换代，Spanner、F1 两篇论文便是谷歌在这一方向的探索成果。开源分布式数据库 TiDB 便是受论文启发而设计的 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL，具有支持分布式事务、无限的水平扩展、数据强一致性保证等核心 NewSQL 特性。
当时，舆情系统接入的第一个游戏平均每天入库数据量就已达到 8500 万条，并且还需要支持各种实时交互性查询，显然中间件已不能满足要求，传统的关系型数据库则更加不可能了。考虑到以后还会有其它游戏接入，我们果断选择了分布式数据库。 随着互联网经济的发展，数据量跟并发数也在飞速增长，单机数据库已越来越不能满足要求了，为此谷歌、阿里等大厂都有了自研的分布式数据库，但都没有开源，而 MySQL 的 MGR 及相关功能进展的步子太小，TiDB 的出现很好的弥补了市场空白，成为我们的唯一选择。
服务器配置 舆情系统是内部孵化项目，服务器具体如下：
新购物理机器 6 台：
旧物理机 4 台：
我们将对资源使用相对较小的 PD、监控服务分别放在旧物理机上，TiDB、TiKV 和 TiSpark 则分配在新机器上，详细如下：
其中每个 TiKV 分配 CPU 10C / 内存 64G / 硬盘 2T，每个 TiSpark 分配 CPU 20C / 内存 64G。在资源有限情况下，结合数据量及舆情系统的 AP 业务属性，我们设计了这样相对复杂的架构，目的是为了充分利用好服务器资源，让它们能承担更极限的压力，事后有多次历史数据的导入也证明了我们这样设计的必要性，多谢 TiDB 的兄弟全程耐心指导及帮助。</description>
    </item>
    
    <item>
      <title>TiDB 分布式数据库在转转公司的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</guid>
      <description>公司及业务架构介绍 转转二手交易网 —— 把家里不用的东西卖了变成钱，一个帮你赚钱的网站。由腾讯与 58 集团共同投资。为海量用户提供一个有担保、便捷的二手交易平台。转转是 2015 年 11 月 12 日正式推出的 APP，遵循“用户第一”的核心价值观，以“让资源重新配置，让人与人更信任”为企业愿景，提倡真实个人交易。
转转二手交易涵盖手机、3C 数码、母婴用品等三十余个品类。在系统设计上，转转整体架构采用微服务架构，首先按照业务领域模型垂直拆分成用户、商品、交易、搜索、推荐微服务。对每一个功能单元（商品等），继续进行水平拆分，分为商品网关层、商品业务逻辑层、商品数据访问层、商品 DB / Cache，如下图所示： 项目背景 1. 面临的问题 转转后端业务现阶段主要使用 MySQL 数据库存储数据，还有少部分业务使用 MongoDB。虽然目前情况下使用这两种存储基本可以满足我们的需求，但随着业务的增长，公司的数据规模逐渐变大，为了应对大数据量下业务服务访问的性能问题，MySQL 数据库常用的分库、分表方案会随着 MySQL Sharding（分片）的增多，业务访问数据库逻辑会越来越复杂。而且对于某些有多维度查询需求的表，我们总需要引入额外的存储或牺牲性能来满足我们的查询需求，这样会使业务逻辑越来越重，不利于产品的快速迭代。
从数据库运维角度讲，大数据量的情况下，MySQL 数据库在每次 DDL 都会对运维人员造成很大的工作量，当节点故障后，由于数据量较大，恢复时间较长。但这种 M - S 架构只能通过主从切换并且需要额外的高可用组件来保障高可用，同时在切换过程由于需要确定主库状态、新主库选举、新路由下发等原因，还是会存在短暂的业务访问中断的情况。 综上所述，我们面临的主要问题可归纳为：
 数据量大，如何快速水平扩展存储；
 大数据量下，如何快速 DDL；
 分库分表造成业务逻辑非常复杂；
 常规 MySQL 主从故障转移会导致业务访问短暂不可用。
  2. 为什么选择 TiDB 针对上章提到的问题，转转基础架构部和 DBA 团队考虑转转业务数据增速，定位简化业务团队数据库使用方案，更好的助力业务发展，决定启动新型存储服务（NewSQL）的选型调研工作。 TiDB 数据库，结合了关系库与 KV 存储的优点，对于使用方，完全可以当做 MySQL 来用，而且不用考虑数据量大了后的分库分表以及为了支持分库分表后的多维度查询而建立的 Mapping 表，可以把精力全部放在业务需求上。所以我们把 TiDB 作为选型的首选对象展开了测试和试用。
TiDB 测试 1. 功能测试 TiDB 支持绝大多数 MySQL 语法，业务可以将基于 MySQL 的开发，无缝迁移至 TiDB。不过目前 TiDB 不支持部分 MySQL 特性，如：存储过程、自定义函数、触发器等。</description>
    </item>
    
    <item>
      <title>北京银行企业级 NewSQL 数据库赋能金融科技建设</title>
      <link>https://pingcap.com/cases-cn/user-case-beijing-bank/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-beijing-bank/</guid>
      <description> 近年来，国家不断提高对信息技术安全可控的战略要求，银行业希望在快速发展业务的同时不断降低经营成本。这不仅促使商业银行积极提升自主掌控能力，也促使商业银行对基础软件的服务能力、软硬件升级成本控制提出新的要求。与此同时，面对互联网金融带来的交易复杂度及交易频次的大幅提升，商业银行信息系统采用的传统数据库一体化解决方案，在应对此类场景时遇到了明显的性能瓶颈，而提升系统性能只靠替换式的硬件升级，成本昂贵。在这种背景下，引入一种高性能、可弹性扩展、能够支持OLTP场景的数据库成为我行系统建设的优先选择方案。
一、 分布式数据库的价值与应用场景 分布式事务数据库采用多种模式实现数据的分散存储，将数据库压力分散到不同服务器上。与集中式数据库相比，分布式数据库可以均衡交易负载，并采用高并发的架构提升系统的交易处理能力，而其统一的资源管理机制也使得数据库的性能扩展不再是设备的替换式升级，而是通过增加存储或计算节点来实现弹性升级，极大地节约了升级成本。
虽然分布式事务数据库在互联网应用场景下的探索取得了良好的成效和大量的实战经验，积累了很多成熟的技术，但相比互联网企业，金融行业对风险控制的要求更高，所以在面对高复杂度交易场景、业务实时一致性等方面的需求时，需要更为完善的技术方案支持。目前绝大部分分布式数据库解决方案都是基于 MySQL 主从复制结合分库分表中间件方式进行改造和集成，无法提供商业银行交易场景中的强一致性和完整的分布式事务要求，对业务和应用有侵入性，需要做一定的技术调整和事务妥协，并且此类架构离银行业务场景中的高可用和多中心容灾及多活的高级别安全要求也有一定距离。
所以，我行在选型前先确定了六个需要特别关注的特性：ACID 特性、横向扩展能力、可用性、可维护性、透明性、兼容性。需要特别说明的是透明性和兼容性，区域银行等体量的金融机构相比互联网企业来说科技资源有限，所以希望新的分布式数据库对架构、开发、运维的影响能够降到最低，同时能够支持传统系统的迁移。
新一代分布式 NewSQL 数据库对应用透明，像一个单机数据库一样使用，支持水平扩展的同时保证分布式事务和数据的强一致性，从而避免传统分库分表、事务补偿等方案对上层应用及业务流程的影响，另一方面如果能兼容传统单机数据库，传统应用平移时不需要人工改写代码，就能极大减少迁移成本。
二、具有北京银行特色的选型方案 由于金融行业对风险控制的严格要求，以及在交易复杂度、业务实时一致性等方面诉求不同于互联网企业。所以，我行对于分布式数据库的选择也比较谨慎,利用两轮专项POC评测来探索分布式数据库的适用场景及性能指标，稳步推进由传统数据库向分布式数据库的迁移。
在第一轮 POC 测试中，主要进行了多场景的性能测试。由于 Sysbench 等开源测试工具对 OLTP 的性能测试存在较大的局限性，于是我行提出了“标准化交易组”的概念，用银行真实交易逻辑，模拟多表跨节点事务，最大程度的还原银行实际应用场景，检验数据库产品的实际交易性能。
第二轮 POC 测试关注更为全面的数据库产品特性。在当前数据库主流评测指标的基础上，结合银行的关注要点，我行自主提出了一套“分布式事务数据库评测指标”（见图），将分布式事务数据库能力进行了分解，形成具体的指标项，使得评测标准更加标准化，评测结果更加客观。
图1：分布式事务数据库评测指标
选型过程中，从多维度考察了多家厂商的产品，包括 TPS、QPS 等性能指标，和算法性能、可靠性、安全备份、数据库兼容性、产品化程度等功能指标。同时，我行也得到了 Intel 实验室的大力支持，提供最新架构的计算和存储设备进行对比测试。
结合两轮 POC 结果，TiDB 分布式数据库产品表现出了架构的先进性和高效的性能，水平扩展能力、交易处理能力和功能指标均符合我行对分布式数据库产品的要求。其采用的 Raft 算法保证了数据的强一致性，同时可以实现两地三中心多活的部署方式，以上特性在应用中具备较大优势。除了优秀的开源社区环境，其背后的团队在开发支持、技术培训、运维服务、成本控制等方面也表现出了优秀的素质。
三、NewSQL 数据库平台的建设进展 我行在进行分布式事务数据库选型之初，就将目标定为可以承载银行核心系统与核心业务，所以选型过程和应用迁移都是基于这一目标，在数据库投产后将首先应用于互联网支付业务，之后迁移部分核心系统功能模块，并进一步扩展到其他场景的使用。其他感兴趣的用户也可以从非核心业务用起，或先作为备份数据系统。
为了更好满足应用端的需求以及业务的扩展，对业务的交易量和数据量进行了预估。结合预估结果以及行内系统建设要求，北京银行率先采用了两地三中心五副本的高可用部署架构方案，支持同城两中心多活，并具备服务器级、机柜级、数据中心级容灾能力。
随着业务不断发展，客户数量、账户数量、业务交易量都会上升，这对我行信息系统的数据存储能力、运算能力等方面提出了更高的要求。我行也对系统架构进行了长远规划，利用分布式 NewSQL 数据库集群的横向水平扩展能力，通过增加存储或计算节点来实现弹性升级，节约成本与实施难度。
2018 年 3 月 22 日，北京银行分布式 NewSQL 数据库集群正式投产，成为国内首家采用同类方案应用于核心交易场景的银行。在数据库投产后，将进行生产环境多活和灾备的验证，并开始应用切换。
四、对开源软件的一些理解 银行在开展技术能力转型建设的过程中，必然会应用越来越多的开源技术。开源软件是当前软件发展的趋势，互联网企业的大规模应用和快速迭代使开源软件成为先进技术事实上的代表。传统银行业使用开源软件的初衷是希望快速获得互联网企业同样的能力，但是否存在困难与阻碍呢？
第一、大部分银行的科技资源状况使之不具备源代码级的掌控能力和基于开源组件的架构设计能力。大多选择采用由国外社区控制的软件或是直接购买国内互联网公司封装好的全家桶解决方案，很难做到真正意义的自主、安全、可控。
第二、开源软件变化快、分支多、依赖“试错”的创新，跟银行追求稳健、长期的内部机制存在差异甚至冲突，反映在选型、测试、变更、运维等各个环节。
第三、开源软件的极客思维更多面向开发者，而非使用者，灾备、监控、审计等企业级功能经常落后于核心功能，在培训、ISV 持、维保服务上跟传统企业的需求还有差距。
所以银行业采用开源软件并取得成功的成本可能会比原有模式更高。值得欣慰的是，随着多年的技术积累，国内越来越多的类似 PingCAP 这样专注于底层核心基础软件研发的团队开始崭露头角，通过全球开源协作的方式极大的提升软件的迭代速度和成熟度，且愿意倾听传统行业的客户需求，有一颗做好产品与服务的诚心。不同于部分银行在新兴业务上采用互联网公司提供的整体外包解决方案，北京银行寻求自主可控能力，主动在模式和管理上创新，与互联网思维和技术不断切磋、碰撞、融合。通过研究、评测、应用、部署等工作，在实践中做到了自主掌控。双方在合作中互惠互利，利用双方优势，实现了信息系统服务能力的快速提升，打造出具有北京银行特色的创新驱动力。
五、结语 今后我行会尝试将更多高频高并发、对可扩展性和可用性有较高要求的业务场景迁移到分布式系统上。充分发挥分布式数据库的优势，探索和开辟创新发展的新路径。同时也希望我行在分布式数据库建设过程中的经验可以分享给更多的金融机构。借此北京银行愿与各同业机构和互联网企业携手并进，为推动银行数据库应用升级贡献自己的一份力量！
 作者简介
于振华，北京银行软件开发部，核心系统架构管理，长期从事银行核心系统研发、规划，当前主要研发方向集中在构建先进、高效、面向OLTP的银行交易系统，提升银行信息系统服务能力。
张小龙，北京银行软件开发部，核心系统架构设计，长期从事银行核心系统对公业务、中间业务模型研发、规划，软件项目管理。参与构建新型面向OLTP的银行交易系统架构设计。
 </description>
    </item>
    
    <item>
      <title>TiDB 在海航易建科技与香港航空研发收益支持系统过程中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ekingtech/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ekingtech/</guid>
      <description>背景介绍 收益支持系统（Revenue Support System，简称 RSS）是海航易建科技与香港航空共同研发的基于大数据实时分析处理的航空业务支持和决策系统。RSS 的目标在于根据顾客需求进行市场细分和定价，在科学分析的基础上通过价格和座位库存控制手段平衡需求和供给的关系，将产品销售给合适的旅客，其核心价值在于支撑和帮助航空公司业务人员和决策者进行业务管理和科学决策。 RSS 在航空公司角色和定位，决定了该系统对 OLAP 和 OLTP 的操作在准确性和实时性方面具有很高的要求，并且由于航空公司每天产生海量的订票、值机、离港和财务数据，使得要求系统在数据存储方面要有很好的水平扩展能力。
前期方案 前期我们主要使用 MySQL 数据库,但是单表记录大于 2000 万行时，现有的业务报表查询和导出操作明显变慢，通过各种 sql 调优和代码优化手段，也无法继续满足服务等级协议，只能通过分库分表来解决，但是这会增加的后续业务逻辑开发复杂度与数据库运维困难。后来，随着业务的深入和数据的积累，代理人在全球各个全球分销系统（Global Distribution System，GDS）中的订座数据数据（Marketing Information Data Tapes，MIDT）就近2年的数据就超过 3.8 亿行，后续会同步近 10 年的数据，初步预估单表数据量将突破10亿条数据，并且后续每年的正常量可能会突破 2 亿条，如果继续使用 MySQL，必然面临着更细粒度分库、分表的难题，而且当前业界很多分表分库的中间件对 OLAP 支持的并不完美,而且很难满足复杂的 OLAP 需求，并且需要进行分表策略的额外配置。这样必然加大了开发和运维的难度和降低了开发的灵活性。
在这个过程中，我们曾经使用 HDFS + Hive + Spark + Kylin 作为大数据解决方案，但是这个方案对于实时的OLTP却满足不了。
为了满足两者的需求，我们需要把一份大数据存储两份，MySQL + 分表中间件做 OLTP 操作，HDFS + Hive + Spark + Kylin 做 OLAP 分析。
茅塞顿开 在业务遇到不可妥协的技术瓶颈后，我们重新评估业务模型，发现对于数据库的选型必须满足：
 支持业务弹性的水平扩容与缩容；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL 和复杂的查询，尽量少的改动代码；</description>
    </item>
    
    <item>
      <title>TiDB 在威锐达 WindRDS 远程诊断及运维中心的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-weiruida/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-weiruida/</guid>
      <description>公司简介 西安锐益达风电技术有限公司成立于 2012 年 1 月 4 日，是一家专业化的工业测量仪器系统、机电产品和计算机软件研发、设计和制造公司，是北京威锐达测控系统有限公司在西安成立的全资子公司。依托大学的科研实力，矢志不渝地从事仪器仪表及测量系统的研究和应用开发，积累了丰富的专业知识和实践经验，具备自主开发高端仪器系统和工程实施的完整技术能力。
为了适应我国大型风电运营商设备维护管理的需求，破解风电监测技术难题，经过多年艰苦研发，研制了一种具有完全自主知识产权的网络化、模块化、集成化的风电机组状态监测与故障诊断系统，为风电机组全生命周期的运行维护管理提供一套完整的解决方案。
业务描述 威锐达 WindRDS 远程诊断与运维中心，是以设备健康监测为核心，实现企业设备全生命周期的健康监测和基于状态的预知性设备运营维护的管理平台。
本平台以多维、丰富的数据为基础，结合传统的诊断分析方法，并充分发挥利用大数据智能化的技术手段，快速及时的发现、分析定位设备运转及企业运维过程中的问题，并以流程化、自动化的软件系统辅助用户高效的跟踪、处理问题，目标提升企业设备运维管理的能力，节约运维成本，为企业创造价值。
图 1：WindRDS 系统交互图
痛点、选型指标 痛点  WindRDS 的数据平台，对于数据的存储当前选用流行的 MySQL 数据库，面对每年 T 级的数据增长量，以及随着数据量的快速增长导致访问性能的急剧下降，目前也只是通过传统的分表、分库等解决方案进行优化，但性能提升未达到预期，且后续维护升级复杂麻烦，不能很好的满足存储和性能弹性水平扩展的需求。
 本项目同时具有 OLTP 和 OLAP 应用需求，也曾设计构建混合型的数据存储方案（MySQL+ HDFS + Hive + Kylin + HBase + Spark），功能上可同时满足 OLTP 和 OLAP 应用需求，但问题也很明显，如：
 要满足一定程度的实时在线分析，还需要做一些数据迁移同步工作，需要开发实时同步 ETL 中间件，实时从存储事务数据的关系数据库向存储面向分析的 Hive、HBase 数据库同步数据，实时性及可靠性不能保证；
 对于基于 SQL 数据访问的应用程序的切换到该数据平台构成很大挑战，应用程序的数据访问层都需要进行修改适配，工作量大，切换成本高；
 对于面向大数据的的分布式数据库产品（Hive、HBase 等）投入成本高且维护复杂，容易出错，可维护性差。
   选型指标  支持容量及性能的水平弹性扩缩；
 支持对使用 MySQL 协议的应用程序的便捷稳定的迁移，无需修改程序；
 满足业务故障自恢复的高可用，且易维护；</description>
    </item>
    
    <item>
      <title>TiDB 在 Ping&#43;&#43; 金融聚合支付业务中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</guid>
      <description>Ping++ 介绍 Ping++ 是国内领先的支付解决方案 SaaS 服务商。自 2014 年正式推出聚合支付产品，Ping++ 便凭借“7 行代码接入支付”的极致产品体验获得了广大企业客户的认可。
如今，Ping++ 在持续拓展泛支付领域的服务范围，旗下拥有聚合支付、账户系统、商户系统三大核心产品，已累计为近 25000 家企业客户解决支付难题，遍布零售、电商、企业服务、O2O、游戏、直播、教育、旅游、交通、金融、房产等等 70 多个细分领域。
Ping++ 连续两年入选毕马威中国领先金融科技 50 强，并于 2017 成功上榜 CB Insights 全球 Fintech 250 强。从支付接入、交易处理、业务分析到业务运营，Ping++ 以定制化全流程的解决方案来帮助企业应对在商业变现环节可能面临的诸多问题。
TiDB 在 Ping++ 的应用场景 - 数据仓库整合优化 Ping++ 数据支撑系统主要由流计算类、报表统计类、日志类、数据挖掘类组成。其中报表统计类对应的数据仓库系统，承载着数亿交易数据的实时汇总、分析统计、流水下载等重要业务:
随着业务和需求的扩展，数仓系统历经了多次发展迭代过程：
 由于业务需求中关联维度大部分是灵活多变的，所以起初直接沿用了关系型数据库 RDS 作为数据支撑，数据由自研的数据订阅平台从 OLTP 系统订阅而来。
 随着业务扩大，过大的单表已不足以支撑复杂的查询场景，因此引入了两个方案同时提供数据服务：ADS，阿里云的 OLAP 解决方案，用来解决复杂关系型多维分析场景。ES，用分布式解决海量数据的搜索场景。
 以上两个方案基本满足业务需求，但是都仍存在一些问题：
 ADS：一是数据服务稳定性，阿里云官方会不定期进行版本升级，升级过程会导致数据数小时滞后，实时业务根本无法保证。二是扩容成本，ADS 为按计算核数付费，如果扩容就必须购买对应的核数，成本不是那么灵活可控。
 ES：单业务搜索能力较强，但是不适合对复杂多变的场景查询。且研发运维代价相对较高，没有关系型数据库兼容各类新业务的优势。
   所以需要做出进一步的迭代整合，我们属于金融数据类业务，重要性安全性不能忽视、性能也得要有保障，经过我们漫长的调研过程，最终，由 PingCAP 研发的 TiDB 数据库成为我们的目标选型。
TiDB 具备的以下核心特征是我们选择其作为实时数仓的主要原因：
 高度兼容 MySQL 语法；</description>
    </item>
    
    <item>
      <title>TiDB 在游族网络平台部的深度应用</title>
      <link>https://pingcap.com/cases-cn/user-case-youzu/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-youzu/</guid>
      <description>公司介绍 游族网络股份有限公司（SZ.002174）成立于 2009 年，是全球领先的互动娱乐供应商。公司以“大数据”、“全球化”、“精品化”为战略方向，立足全球化游戏研发与发行，知名 IP 管理，大数据与智能化，泛娱乐产业投资四大业务板块全面发展。
背景 2017 年初的时候，游族的用户中心体系面临迭代和重构，当时数据库有数亿多的核心数据，通过 hash key 分为了 1024 张表在 64 个数据库中来存储，使用自研的代码框架来进行对应 hash key 的 seek 操作。这时，非 hash key 的查询、DDL 变更等业务需求，分表分库逻辑代码框架的局限，让研发和运维都面临较高的数据库使用成本，数据库不能灵活高效的支撑业务需求。
图 1：分库分表方案架构图
为了解决上述问题，游族的技术团队急需一套同时满足如下的条件的数据库分布式集群：
 能够提供实时的 OLTP 的一致性数据存储服务；
 弹性的分布式架构；
 配套的监控备份方案；
 稳定的高可用性；
 较低的迁移重构成本。
  前期选择 最开始先考察了几个方案，但都有相对来说的不足：
 方案一，将整个分表分库逻辑剥离到开源分表分库中间件上：
 基于 2PC 的 XA 弱事务的一致性保证不尽如人意；
 高可用架构更加复杂，单分片的局部不可用会对全局产生影响；
 备份恢复的复杂度高；
 这些方案引入了新的 sharding key 和 join key 的设计问题，整体的迁移难度不降反升。
  方案二，官方的 MySQL cluster 集群：</description>
    </item>
    
    <item>
      <title>TiDB 在摩拜单车在线数据业务的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobike/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobike/</guid>
      <description>背景 摩拜单车于 2015 年 1 月成立，2016 年 4 月 22 日地球日当天正式推出智能共享单车服务，截至 2017 年 11 月中旬，已先后进入国内外超过 180 个城市，运营着超过 700 万辆摩拜单车，为全球超过 2 亿用户提供着智能出行服务，日订单量超过 3000 万，成为全球最大的智能共享单车运营平台和移动物联网平台。摩拜每天产生的骑行数据超过 30TB，在全球拥有最为全面的骑行大数据，飞速增长的业务使摩拜面临数据库扩展与运维的巨大挑战。
面对飞速增长的并发数与数据量，单机数据库终将因无法支撑业务压力而罢工。在摩拜正式上线以来，我们就在不断思考数据库扩展和运维的未来，近年来业内对数据库进行扩展的常见的方案是通过中间件把数据库表进行水平拆分，将表内数据按照规则拆分到多个物理数据库中。使用这样的中间件方案，在数据库扩容时需要先停下业务，再重构代码，之后进行数据迁移，对于摩拜这样与时间赛跑的创业公司来讲代价巨大，中间件方案对业务过强的侵入性，不支持跨分片的分布式事务，无法保证强一致性事务的特性都使我们望而却步。
摩拜单车于 2017 年初开始使用 TiDB，从最早的 RC3、RC4、PreGA、到现在的 1.0 正式版，一步步见证了 TiDB 的成熟和稳定。目前支撑着摩拜内部的实时分析和部分线上业务，同时正在规划迁移更多的线上业务至 TiDB。
目前，TiDB 在摩拜部署了数套集群，近百个节点，承载着数十 TB 的各类数据。
TiDB 在摩拜的角色和主要应用场景 在摩拜，TiDB 是一个核心的数据交易与存储支撑平台，引入它的主要目的是用来解决海量数据的在线存储、大规模实时数据分析和处理。
在我们看来，TiDB 的好处主要有：
 弹性扩容。具有 NoSQL 类似的扩容能力，在数据量和访问流量持续增长的情况下能够通过水平扩容提高系统的业务支撑能力，并且响应延迟稳定； 简单易用。兼容 MySQL 协议，基本上开箱即用，完全不用担心传统分库分表方案带来的心智负担和复杂的维护成本，而且用户界面友好，常规的技术技术人员都可以很高地进行维护和管理； 响应及时。因为和 PingCAP 团队有非常深入的合作关系，所以有任何问题都可以第一时间和 PingCAP 团队直接沟通交流，遇到问题都能很快的处理和解决。  下面介绍 TiDB 的应用场景：
场景一：开关锁日志成功率统计 开关锁成功率是摩拜业务监控的重点指标之一。
在每次开、关锁过程中，用户和锁信息会在关键业务节点产生海量日志，通过对线上日志的汇总分析，我们把用户的行为规整为人和车两个维度，通过分布式、持久化消息队列，导入并存放到 TiDB 里。在此过程中，通过对不同的实体添加不同的标签，我们就能方便地按照地域、应用版本、终端类型、用户、自行车等不同的维度，分别统计各个类别的开锁成功率。
按照我们的估计，这个业务一年的量在数百亿，所以使用单机的 MySQL 库需要频繁的进行归档，特别是遇到单机数据库瓶颈的情况下，扩容更是带来了非常大的挑战，这在我们有限的人力情况下，完全是个灾难。所以要支撑整个 Mobike 的后端数据库，我们必须要寻找简单易用的方案，极大地减少在单个业务上的人力成本开销。其次，根据我们之前使用分库分表的经验，对于这类需要频繁更新表结构进行 DDL 操作的业务，一旦数据量过大，很很容易出现数据库假死的情况，不仅影响服务的可用性，更严重的是很可能导致数据不一致的情况出现。最后，我们希望不管今后的业务量如何激增，业务需求如何变化，都可以保持业务逻辑可以很方便地升级支持。</description>
    </item>
    
    <item>
      <title>TiDB / TiSpark 在易果集团实时数仓中的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yiguo/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yiguo/</guid>
      <description>项目背景 目前企业大多数的数据分析场景的解决方案底层都是围绕 Hadoop 大数据生态展开的，常见的如 HDFS + Hive + Spark + Presto + Kylin，在易果集团，我们初期也是采取这种思路，但是随着业务规模的快速增长和需求的不断变化，一些实时或者准实时的需求变得越来越多，这类业务除了有实时的 OLTP 需求，还伴随着一些有一定复杂度的 OLAP 的需求，单纯地使用 Hadoop 已经无法满足需求。
现有的准实时系统运行在 SQL Server 之上，通过开发人员编写和维护相应的存储过程来实现。由于数据量不大，SQL Server 能够满足需求，但是随着业务的发展，数据量随之增长，SQL Server 越来越不能满足需求，当数据量到达一定的阶段，性能便会出现拐点。这个时候，这套方案已完全无法支撑业务，不得不重新设计新的方案。
选型评估 在评估初期，Greenplum、Kudu、TiDB 都进入了我们的视野，对于新的实时系统，我们有主要考虑点：
 首先，系统既要满足 OLAP 还要满足 OLTP 的基本需求；
 其次，新系统要尽量降低业务的使用要求；
 最后，新系统最好能够与现有的 Hadoop 体系相结合。
  Greenplum 是一套基于 PostgreSQL 分析为主的 MPP 引擎，大多用在并发度不高的离线分析场景，但在 OLTP 方面，我们的初步测试发现其对比 TiDB 的性能差很多。
再说说 Kudu。Kudu 是 CDH 2015年发布的一套介于 Hbase 和 HDFS 中间的一套存储系统，目前在国内主要是小米公司应用的较多，在测试中，我们发现其在 OLTP 表现大致与 TiDB 相当，但是一些中等数据量下，其分析性能相比 TiDB 有一定差距。另外我们的查询目前主要以 Presto 为主，Presto 对接 Kudu 和 PostgreSQL 都是需要考虑兼容性的问题，而 TiDB 兼容 MySQL 协议，在应用初期可以直接使用 Presto-MySQL 进行统一查询，下一步再考虑专门开发 Presto-TiDB。</description>
    </item>
    
    <item>
      <title>TiDB 帮助万达网络科技集团实现高性能高质量的实时风控平台</title>
      <link>https://pingcap.com/cases-cn/user-case-wanda/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-wanda/</guid>
      <description>万达网络科技集团 是中国唯一的实业+互联网大型开放型平台公司，拥有飞凡信息、快钱支付、征信、网络信贷、大数据等公司，运用大数据、云计算、人工智能、场景应用等技术为实体产业实现数字化升级，为消费者提供生活圈的全新消费服务。
万达网络科技集团的技术团队，建设和维护着一套实时风控平台。这套实时风控平台，承担着各种关键交易的在线风控数据的写入和查询服务。实时风控平台后端的数据库系统在高性能，可靠性，可扩展性上有很高的要求，并且需要满足如下核心功能和业务要求：
 风控相关业务数据实时入库
 实时风控规则计算
 通过 BI 工具分析风控历史数据
 ETL 入库到 Hadoop 数据仓库
 应用开发侧需要兼容 MySQL，降低应用改造门槛
  为实现上述业务目标，万达网络科技集团的技术团队在实时风控数据库选型的早期阶段，首先选择了 MySQL Galera Cluster 作为数据库集群的技术架构。这套 MySQL 数据库架构通过不同于 MySQL 主流复制技术的复制机制，实现在多个 MySQL 节点间建立强同步关系，实现数据的副本和高可用。但经过业务实践，发现这套方案有诸多问题，其中比较突出的有以下几点：
 MySQL Galera Cluster 自身的强同步机制以大幅度降低集群整体性能为代价，集群整体性能比单节点 MySQL 还差。所以不能很好的满足“风控相关业务数据实时入库”的业务需求。
 同时，MySQL Galera Cluster 的 JOIN 支持非常弱，不足以支持 BI 相关的复杂分析。
 集群整体性能的短板加上对 JOIN 支持的薄弱，使得要在业务上实现大并发高性能的风控规则计算变的很困难。
  万达的技术团队还考察了市场上用的比较多的 MySQL 主从复制以及通过 MySQL Proxy 中间件实现分库分表的方案。但这些方案，无论是高可用安全性，强一致性，还是对业务应用所需要的复杂事务／JOIN 操作以及横向扩展能力上，都无法满足实时风控平台的业务要求。这些问题集中反映在以下几个方面：
 基于 MySQL 主从复制方式的高可用方案，容易出现诸如接入层脑裂和数据不一致的风险。
 基于 MySQL Proxy 中间件的方案，缺少对分库分表后的跨库跨表的分布式事务支持以及对复杂 JOIN 的良好支持，因此也无法满足业务上风控规则实时计算和复杂查询的需求以及对业务团队的 BI 需求的支持。</description>
    </item>
    
    <item>
      <title>盖娅互娱 | 日均数据量千万级，MySQL、TiDB 两种存储方案的落地对比</title>
      <link>https://pingcap.com/cases-cn/user-case-gaea-ad/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-gaea-ad/</guid>
      <description>背景介绍 盖娅广告匹配系统（GaeaAD）用于支撑盖娅互娱全平台实时广告投放系统，需要将广告数据和游戏 SDK 上报的信息进行近实时匹配，本质上来说需要实时的根据各个渠道的广告投放与相应渠道带来的游戏玩家数据进行计算，实现广告转化效果分钟级别的展现及优化。
初期的 MySQL 存储方案 在系统设计之初，基于对数据量的预估以及简化实现方案考虑，我们选用了高可用的 MySQL RDS 存储方案，当时的匹配逻辑主要通过 SQL 语句来实现，包含了很多联表查询和聚合操作。当数据量在千万级别左右，系统运行良好，基本响应还在一分钟内。
图 1 MySQL RDS 存储方案架构图
遭遇瓶颈，寻找解决方案 然而随着业务的发展，越来越多游戏的接入，盖娅广告系统系统接收数据很快突破千万/日，高峰期每次参与匹配的数据量更是需要翻几个番，数据库成为了业务的瓶颈。由于此时，整个技术架构出现了一些问题：
1. 单次匹配耗时已从原本的 10 秒左右增加到 2 分钟以上，最慢的聚合查询甚至达到 20 分钟，时效性受到严重挑战。而且 MySQL 的问题是查询的时间随着数据量的增长而增长，以至于数据量越大的情况下查询越慢。
2. 随着历史数据的积累，单表数据很快达到亿级别，此时单表的读写压力已经接近极限。
3. 由于第一点提到的查询性能问题以及单机的容量限制，需要定时删除数据，对于一些时间跨度较长的业务查询需求没法满足。
根据数据量的增长情况来看，分布式数据库会是很好的解决方案。首先考虑的是业务的垂直及水平拆分或者基于 MySQL 的数据库中间件方案和一些主流的 NoSQL 方案。
但是仔细评估后，最先排除掉的是业务水平拆分的方案，因为业务逻辑中包含大量的关联查询和子查询，如果拆表后这些查询逻辑就没有办法透明的兼容，而且是比较核心的业务系统，时间精力的关系也不允许整体做大的重构。中间件的问题和分库分表的问题类似，虽然解决了大容量存储和实时写入的问题，但是查询的灵活度受限，而且多个 MySQL 实例的维护成本也需要考虑。
第二个方案就是采用 NoSQL，因为此系统需要接收业务端并发的实时写入和实时查询，所以使用类似 Greenplum，Hive 或者 SparkSQL 这样的系统不太合适，因为这几个系统并不是针对实时写入设计的， MongoDB 的问题是文档型的查询访问接口对业务的修改太大，而且 MongoDB 是否能满足在这么大数据量下高效的聚合分析可能是一个问题。
所以很明显，我们当时的诉求就是能有一款数据库既能像 MySQL 一样便于使用，最好能让业务几乎不用做任何修改，又能满足分布式的存储需求，还要保证很高的复杂查询性能。
当时调研了一下社区的分布式数据库解决方案，找到了 TiDB 这个项目，因为协议层兼容 MySQL，而且对于复杂查询的支持不错，业务代码完全不用修改直接就能使用，使迁移使用成本降到极低。
技术转身，使用 TiDB 在部署测试的过程中，我们使用 TiDB 提供的 Syncer 工具将 TiDB 作为 MySQL Slave 接在原业务的 MySQL 主库后边观察，确保读写的兼容性以及稳定性，经过一段时间观察后，确认读写没有任何问题，业务层的读请求切换至 TiDB，随后把写的流量也切换至 TiDB 集群，完成平滑的上线。</description>
    </item>
    
    <item>
      <title>TiDB 在特来电的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-telaidian/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-telaidian/</guid>
      <description>背景介绍 特来电新能源有限公司是创业板第一股特锐德（300001）的全资子公司，主要从事新能源汽车充电网的建设、运营及互联网的增值服务。特来电颠覆了传统充电桩的模式，世界首创了电动汽车群智能充电系统，获得 336 项技术专利，以“无桩充电、无电插头、群管群控、模块结构、主动防护、柔性充电”的特点引领世界新能源汽车充电的发展，系统的鉴定结论为：“产品世界首创、技术水平国际领先。主动柔性充电对电池寿命可以延长 30% 左右，电池充电的安全性可以提升 100 倍以上。”
特来电采用互联网思维，依靠国际领先的汽车群智能充电技术和系统，创新电动汽车充电商业模式，建设全国最大的汽车充电网，通过大系统卖电、大平台卖车、大共享租车、大数据修车、大支付金融、大客户电商，打造让客户满意、政府放心的中国最大汽车充电网生态公司，引领充电网、车联网、互联网“三网融合”的新能源互联网。
为什么研究 TiDB 特来电大数据平台通过开源与自研相结合的方式，目前已经上线多套集群满足不同的业务需求。目前在大数据存储和计算方面主要使用了 HBase、Elasticsearch、Druid、Spark、Flink。大数据技术可谓是百花齐放、百家争鸣，不同的技术都有针对性的场景。结合实际情况，选择合适的技术不是一件容易的事情。
随着接入大数据平台的核心业务的增加，我们在 OLAP 上主要遇到以下痛点问题：
 随着基于大数据分析计算的深入应用，使用 SQL 进行分析的需求越来越旺盛，但目前已经上线的大数据集群（HBase、Elasticsearch、Druid、Spark、Flink）对 SQL 的支持度都比较弱。
 目前进入大数据集群的数据主要以宽表方式进行，导致在数据归集和后期基础数据放生变化时应用成本较高。
 数据仓库业务有些还是基于复杂的 T+1 模式的 ETL 过程，延时较高，不能实时的反映业务变化。
 由于每个大数据集群主要针对特定的场景，数据重复存储的情况较多，这就造成了存储成本的增加，同时也会导致数据的不一致性。
 目前进入 HDFS / Druid / ES 的数据，在历史数据更新时，成本较高，灵活性降低。
  大数据技术发展迅速，我们也一直希望采用新的技术可以解决我们以上问题，我们关注到目前 NewSQL 技术已经有落地产品，并且不少企业在使用，所以决定在我们平台内尝试引入 NewSQL 技术解决我们的痛点问题。
我们先了解一下 NewSQL。
图 1 数据库发展史
如图 1 所示，数据库的发展经历了 RDBMS、NoSQL 以及现在的 NewSQL，每种不同的技术都有对应的产品，每种数据库的技术背后，都有典型的理论支撑。2003 年 Google GFS 开创了分布式文件系统、2006 年的 BigTable 论文催生了 Hadoop 生态，在 2012 年的 Spanner 和 2013 年的 F1 论文发表后，被业界认为指明了未来关系型数据库的发展。</description>
    </item>
    
    <item>
      <title>支撑百亿级应用的 NewSQL——TiDB 在同程旅游的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-tongcheng/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-tongcheng/</guid>
      <description>项目背景 初次接触 TiDB，是通过同程网首席架构师王晓波先生的分享，当时同程网正在使开发和数据库全面往开源方向转型，由于业务需要，很多在线业务数据量和访问量都非常的大，而 MySQL 无法满足大数据量下的复杂查询需求，为了使数据库分片对开发透明，同程自研了 DBrouter。但分片后的合并、实时汇总统计及全量数据的监控仍然是困扰我们的一个难点。一直没有特别好的办法解决。
急速增长的业务 2016 年国庆前，同程的票务项目（微信九宫格中的火车票、机票等票务业务背后是同程在提供）由于流量激增，订单库压力越来越大，同时相关业务需求也在增加，开发不断的在订单库上新增各种查询，例如为了及时定位异常而增加的限定各类条件的分钟级订单量监控（每分钟执行根据不同的条件进行汇总的订单量）。这样的功能越来越多，同时订单库总大小数 T 左右。对此，公司内部决定将票务订单库进行分片来降低单库压力，应对即将到来的国庆高峰订单爆发。
引入 TiDB 经过评估，发现公司自研的分片可以满足绝大多数的查询需求，但是部分复杂条件的查询将会影响整个分片集群的性能，少量的全片扫描 SQL 经常会占用 80% 以上的 IO 资源，导致其他的查询性能下降。这时，刚好我们的首席架构师提议，使用 TiDB 试试，经过中间件组和 DBA 组的配合测试，我们尝试将 TiDB 作为所有数据的集合库提供复杂查询，分片集群则提供简单查询，同时由于 TiDB 高度兼容 MySQL 的连接协议，我们基于 PingCAP 提供的数据同步工具 Syncer 进行了二次开发，可以自定义库名和表名（后来同 TiDB 工程师交流，他们最新的 Wormhole &amp;amp; Syncer 也都已经支持了自定义选项），同时新增了同步状态监控，如 TPS、延迟等，如果出现异常，会通过微信告警。从 MySQL 将数据实时同步到 TiDB 来确保数据的一致。
确定方案后，我们连夜安排压测同事和开发同事协作，紧急测试，发现这套分片集群 + TiDB 的方案能够满足我们的功能和性能方面的需求，于是迅速调整了该项目的架构，我们将数千个 MySQL 分片汇总到一个 TiDB 集群，保障了 2016 年国庆的高峰平稳渡过。当时的流量达到了我们平时流量的 2 倍，然而并没有出现异常。
该实时同步查询系统架构如下所示： 在该项目实施成功后，我们加深了对于 TiDB 的使用。并根据 PingCAP 的建议和协助部署了各类监控。
同时，为了更好的关注数据库的情况，第一时间发现异常，我们将 TiDB 的异常报警接入了公司的监控系统和自愈系统。当发生异常的时候，监控系统会第一时间发现，然后自愈系统会依据提前制定的愈合逻辑处理对应异常，在第一时间恢复应用的可用。
更大规模的使用 业务上线以后，我们很快又迁移了机票业务实时同步业务到 TiDB。至本文截稿时，在同程内部，目前共有数套 TiDB 集群，部署服务器数量近百台，总数据量数十 TB。其中最大的一个集群 10 多个数据节点，近十 TB 数据，数据量过百亿，支撑了每天过亿的访问，并提供千万级别的数据监控服务，平均 QPS 在 5000，高峰 QPS 过万。</description>
    </item>
    
    <item>
      <title>TiDB 在株式会社 FUNYOURS JAPAN 的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-funyours-japan/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-funyours-japan/</guid>
      <description>背景 株式会社 FUNYOURS JAPAN 自 2014 在日本成立以来，营运多款颇受好评的页游跟手游，如：剣戟のソティラス、九十九姬 等，对于营运游戏来说，能够了解游戏中的玩家在做什么，喜欢的偏好是什么，关卡的设计是否平衡，都是相当重要的，所以随着营运时间的增长，资料库数据在亿笔以上也是寻常的。
所以我们的技术单位也一直不断在评估市面上的各种资料库以及如何改进目前现有系统与架构，近年来最热门的资料库系统可以说是 NoSQL 了，不论 MongoDB，Cassandra，Redis，HBase 等等都占有一片天，具有读写快速，容易扩展等特性。经过初步了解后，采用 NoSQL 方式，需要对于目前的资料储存架构整个重新设计，并且需要配合采用的该套 NoSQL 资料库进行业务改造设计，那么该采用哪一套 NoSQL 资料库又是一个需要慎重考虑的课题。先回过头来看当前最需要处理改进的项目：
1. 储存空间扩展不易
2. 单台资料库效能有限
初期方案 在处理储存空间不足的部分，一开始我们先采用了 MySQL innoDB 提供的压缩表格格式，对于需要时常读写更新的部分使用了 8K page size，过往的日志部分采用 4K page size，效果非常令人满意，释放了大量的储存空间，并且对于效能来说没有造成可察觉的影响。这部分网路上的测试比较多，就不在此多做说明。但是很快的压缩表格节省的空间毕竟是有限的，接下来只能增加 volume 容量以及将没有需要更新的过往日志移动到其他资料库上，虽然造成维护工作跟时间的繁复与负担，但是问题解决了。
基于 MySQL 资料库架构单台的性能限制上，我们采用了多组的资料库伺服器，来满足所需的效能。当然不同组之间资料是不共通的，也就是无法直接使用 SQL 来做跨组间的操作，需要额外的程式来作业。而当然为了大量的资料存取上的效能，分表分库对表格进行 partition 这些作业都少不了。
初识 TiDB 使用 NoSQL 式资料库看似可以完美的提供出一个解法，但需要付出的成本也是高昂的。于是我们把眼光落到了 MySQL Cluster 上，这时看到了 Google 发布 Cloud Spanner beta 的新闻，NewSQL？这是什么? 很快的引起了我们浓厚的兴趣，然后经过多方调研，我们发现了 TiDB：一个开源在 GitHub 上的 NewSQL 资料库。官方也持续不断发布了很多相关的文章，随着对 TiDB 的认识，认为对于目前现况是很合适的最佳化方案，相容于 MySQL，高可用性，容易水平扩展。
在可行性评估与测试的时候，一开始采用了 TiKV 3 台搭配 PD 3 台，TiDB 2 台混搭 PD 的架构，使用了文件建议的 ansible 安装，这时遇到两个困难，第一个是在 ansible 检查机器效能的时候会因为硬碟读写效能而无法安装。由于是使用云端机器，所以对硬体方面没有太大的弹性，只好自己手动去修改脚本才能顺利安装。第二个也是在 ansible 里面会检查 ntp 同步服务是否启动，但是 centos7 预设的时间同步服务是 chrony，所以也是修改了脚本（后来的版本有提供 flag 能切换，也有自动安装 ntp 的选项），总之是顺利安装了。这时因为 PingCAP 才刚发布了 ansible 安装的方式，所以文件对于水平扩展部分，如新增 TiKV、 PD 、TiDB 机器，或者移除机器，官方 doc 没有详细说明，于是就写了封 mail 联系 PingCAP，发完信出去吃午餐回来，官方已经回复并且邀请加入 wechat，提供更即时的沟通跟支援，实在是很令人惊艳。</description>
    </item>
    
    <item>
      <title>TiDB 在 360 金融贷款实时风控场景应用</title>
      <link>https://pingcap.com/cases-cn/user-case-360/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-360/</guid>
      <description>背景 近几年来基于互联网渠道的现金贷业务发展十分迅猛，无论是新兴的互联网企业还是传统的金融机构，都想在这个领域快速占领市场，攫取客户。然而在线贷款业务与其他互联网业务有着明显的不同，源自金融的基因决定了重视风险的必要性，这不仅关系到产品的收益，也直接影响了产品是否可以成功。
将业务推到线上意味着无法准确的获取客户信息，只能通过有限的渠道验证客户的真实性和偿还能力，极大的增加了风险成本。如果申请步骤过于繁琐则降低了用户体验，不利于产品的推广和客户的使用。因此对于互联网贷款风控的一项挑战就是能够在尽可能短的时间内，有限数据的情况下，给出明确的风险判断。
应用 建立风险策略的过程中，使用各种风险变量以及相关的衍生变量，通过专家模型进行评分，是一种较为典型的方法。实际应用中，我们发现除了已经被广泛使用的消费行为数据，基本收入数据等，基于特定维度的用户间社交关系也是比较有效的模型变量。
在使用这些变量的过程中，我们面临最直接的问题是数据量。如果考虑将用户手机通讯录中出现的电话号码作为一项关系关联的形式，假设每位用户通讯录中联系人的个数平均为 100 个，那 100 万个注册用户就有对应大约 1 亿个联系人。事实上，在系统上线大约 1 年不到的时间内，我们几张存储社交关系的表已经达到了大约 50 亿左右的规模。
相对于数据存储，变量的衍生加工和查询匹配是个更加有挑战性的工作。一个人的社交关系是个很典型的「图」数据结构。而很多专家模型中的规则是需要匹配某个用户 3 层以上关系的，最简单的就是匹配用户通过联系人关系，跃进 3 层后，命中系统黑名单的人数。我们还是按照平均 100 个联系人来估算，跃进 3 层后，需要匹配的关联人数为 100 * 100 * 100，即 100 万。而类似计算量的规则不在少数，需要调用这些计算规则的业务场景也较为频繁，同时对响应时间的要求也高。
V1.0 版本的解决方案 在评估阶段，我们考虑了几种方案，各有利弊。首先被淘汰的是使用 MySQL 的解决方案。使用关系型数据库的优势是在查询方面的便捷性。在开发效率上，SQL 是开发人员和数据分析人员的必备技能，能够较快的在功能上实现需求。但是在数据存储和计算层面，MySQL 的表现则差强人意。在面对大数据量时，MySQL 能采取的水平扩展策略无非是分库分表，这样的后果就是查询逻辑变的非常复杂，不易维护，且性能下降的较为严重。
另一个方案是把 HBase 作为数据存储的解决方案。它的优点很明显，可以水平扩展，数据量不再是瓶颈。但是它的缺点也同样明显，即对开发人员不友好，查询的 API 功能性较差，只能通过 key 来获取单条数据，或是通过 scan API 来批量读取。更关键的是 HBase 对图这样的数据结构支持的不好，只能通过使用 tall table 和存储冗余数据的形式来模拟。
第三个方案是使用纯粹的图数据库。首先我们考察了开源的 Titan，发现这个项目已经废弃了，主力团队貌似研发了一个新的商业图数据库，并成立了公司。而且 Titan 的存储引擎也是使用了 HBase 和 Cassandra(根据需求两者选一)，性能并不能满足我们的要求。接着我们考察了两款开源的商业产品 Neo4j 和 OrientDB。他们两者都提供了免费的社区版本，当然在功能上比商业版少了些。其中 Neo4j 的社区版不支持 HA，只能在单机上运行。而 OrientDB 的数据版支持 HA 和 Sharding。在编程接口上两者都支持各种主流的编程语言。Neo4j 提供了自家独创的，基于模式匹配的查询语言 cypher。OrientDB 则提供了类 SQL 的语法 API，可谓各有所长。</description>
    </item>
    
    <item>
      <title>TiDB 在爱奇艺的应用及实践</title>
      <link>https://pingcap.com/cases-cn/user-case-iqiyi/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-iqiyi/</guid>
      <description>背景介绍 爱奇艺，中国高品质视频娱乐服务提供者，2010 年 4 月 22 日正式上线，推崇品质、青春、时尚的品牌内涵如今已深入人心，网罗了全球广大的年轻用户群体，积极推动产品、技术、内容、营销等全方位创新。企业愿景为做一家以科技创新为驱动的伟大娱乐公司。我们在前沿技术领域也保持一定的关注度。
随着公司业务的快速发展，原来普遍使用的 MySQL 集群遇到了很多瓶颈，比如单机 MySQL 实例支撑的数据量有限，只能通过不停删除较旧的数据来维持数据库的运转。同时单表的数据行数不断增大导致查询速度变慢。急需一种可扩展、高可用同时又兼容 MySQL 访问方式的数据库来支撑业务的高速发展。
我司从 2017 年年中开始调研 TiDB，并且在数据库云部门内部系统中使用了 TiDB 集群。从今年 TiDB 推出 2.0 之后，TiDB 愈发成熟，稳定性与查询效率都有很大提升。今年陆续接入了边控中心、视频转码、用户登录信息等几个业务，这几个业务背景和接入方式如下详述。
项目介绍 1. 边控中心 边控中心存储的是机器的安全统计信息，包括根据 DC、IP、PORT 等不同维度统计的流量信息。上层业务会不定期做统计查询，其业务页面如下：
图 1 边控中心上层业务页面（一）
图 2 边控中心上层业务页面（二）
在选型过程中，也考虑过时序型数据库 Apache Druid（http://druid.io），但是 Druid 聚合查询不够灵活，最终放弃 Druid 选择了 TiDB 数据库。TiDB 几乎完全兼容 MySQL 的访问协议，可以使用现有的 MySQL 连接池组件访问 TiDB，业务迁移成本低，开发效率高。
边控中心是爱奇艺第一个在线业务使用 TiDB 的项目，所以我们制定了详细的上线计划。
 第一，部署单独的 TiDB 集群。然后，为了数据安全，部署了 TokuDB 集群，用作 TiDB 集群的备份数据库。
 第二，我们通过 TiDB-Binlog 将 TiDB 集群的数据变更实时同步到 TokuDB 集群中，作为 TiDB 的灾备方案。</description>
    </item>
    
    <item>
      <title>Qunar 高速发展下数据库的创新与发展 - TiDB 篇</title>
      <link>https://pingcap.com/cases-cn/user-case-qunar/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-qunar/</guid>
      <description>目前互联网公司数据存储主要依赖于 MySQL 为代表的关系型数据库，但是随着业务量的增长，使用场景更加多样，传统的关系型数据库不能很好的满足业务需求，主要是在两个维度：一是随着数据量爆炸式增长，性能急剧下降，而且很难在单机内存储；二是一些场景下业务对响应速度要求较高，数据库无法及时返回结果，而传统的 memcached 缓存又存在无法持久化数据，存储容量受限于内存等问题。针对这两个问题，去哪儿的 DBA 团队分别调研了 TiDB 和 InnoDB memcached 以满足业务需求，为用户提供更多的选择方案。
接下来的文章系列，我们将陆续为大家带来 TiDB 和 InnoDB memcached 在去哪儿的调研和实践，本篇文章先介绍 TiDB。
分布式数据库诞生背景 随着互联网的飞速发展，业务量可能在短短的时间内爆发式地增长，对应的数据量可能快速地从几百 GB 涨到几百个 TB，传统的单机数据库提供的服务，在系统的可扩展性、性价比方面已经不再适用。随着业界相关分布式数据库论文的发布，分布式数据库应运而生，可以预见分布式数据库必将成为海量数据处理技术发展的又一个核心。
目前业界最流行的分布式数据库有两类，一个是以 Google Spanner 为代表，一个是以 AWS Auraro 为代表。 Spanner 是 shared nothing 的架构，内部维护了自动分片、分布式事务、弹性扩展能力，数据存储还是需要 sharding，plan 计算也需要涉及多台机器，也就涉及了分布式计算和分布式事务。主要产品代表为 TiDB、CockroachDB、OceanBase 等。 Auraro 主要思想是计算和存储分离架构，使用共享存储技术，这样就提高了容灾和总容量的扩展。但是在协议层，只要是不涉及到存储的部分，本质还是单机实例的 MySQL，不涉及分布式存储和分布式计算，这样就和 MySQL 兼容性非常高。主要产品代表为 PolarDB。
去哪儿数据存储方案现状 在去哪儿的 DBA 团队，主要有三种数据存储方案，分别是 MySQL、Redis 和 HBase。
MySQL 是去哪儿的最主要的数据存储方案，绝大部分核心的数据都存储在 MySQL 中。MySQL 的优点不用多说，缺点是没法做到水平扩展。MySQL 要想能做到水平扩展，唯一的方法就业务层的分库分表或者使用中间件等方案。因此几年前就出现了各大公司重复造轮子，不断涌现出中间层分库分表解决方案，比如百度的 DDBS，淘宝的 TDDL，360 的 Atlas 等。但是，这些中间层方案也有很大局限性，执行计划不是最优，分布式事务，跨节点 join，扩容复杂（这个心酸 DBA 应该相当清楚）等。Redis 主要作为缓存使用，针对读访问延时要求高的业务，使用场景有限。 HBase 因其分布式的特点，可以通过 RS 的增加线性提升系统的吞吐，HDFS 具有水平扩展容量的能力，主要用来进行大数据量的存储，如日志、历史数据、订单快照等。HBase 底层存储是 LSM-Tree 的数据结构，与 B+ Tree 比，LSM-Tree 牺牲了部分读性能，用来大幅提升写性能。 但在实际运维的过程中，HBase 也暴露了一些缺点： 1.</description>
    </item>
    
    <item>
      <title>TiKV 在饿了么的大规模应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-eleme-1/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-eleme-1/</guid>
      <description>背景介绍 饿了么从 2008 年创建以来，一直都是飞速的发展。目前，饿了么已覆盖了 2000 多个城市，拥有 2.6 亿的用户，130 万的商户，300万的骑手。饿了么在配送时间上追求卓越，目前饿了么的准时达订单平均配送时长已达到 28 分钟以内。从 2015 年开始，饿了么形成了 2 大业务，在线交易平台业务和即时配送平台业务。饿了么的用户量和订单量的快速增长，带来了数据量的快速增长，从而产生对大数据量存储的强烈需求，并且很多数据都是 KeyValue 格式的数据。之前饿了么没有统一的 Key-Value 存储系统，这部分数据被存储在 MySQL、Redis、Mongo、Cassandra 等不同的系统中，将数据存储在这些系统中，带来一些问题，比如数据扩容不方便、内存不可靠、性能不达标、运维不方便等。
我们希望用一套统一的 Key-Value 存储系统来存储这些 Key-Value 形式的数据，并且满足以下所有的技术要求：
 大数据量，可以存储至少数十 TB 级别的数据。
 高性能，在满足高 QPS 的同时，保证比较低的延时。
 高可靠，数据被可靠的持久化存储，少量机器的损坏不会导致数据的丢失。
 高可用，作为在线服务的底层依赖存储，要有非常完善的高可用性能力，外卖服务不同于电子商务，对实时性要求非常高，对系统的可用性的要求则是更高的。
 易运维，可以在不停服的基础上进行数据迁移，和集群扩容。
  从 2017 年下半年开始，饿了么开始基于 TiKV 构建饿了么的 Key-Value 存储系统，并且取得了很好的应用效果。饿了么对 Key-Value 系统的使用是在线系统，由离线计算集群生成数据，在线服务消费这些数据。这些在线服务覆盖了饿了么在线交易和即时配送 2 大平台，在线交易平台中的首页搜索、商品品类、商品排序、天降红包等等，即时配送平台中的物流旗手智能调度等，各种在线服务都在使用我们的 Key-Value 系统。 目前，TiKV 的应用会影响饿了么全平台 80% 的流量，包括从用户选餐下单到订单配送整个饿了么流程。
TiKV集群上线情况  目前已在饿了么部署了十几套 TiKV 集群，分别位于北京、上海、广州的四个机房，共计 100+ 机器节点，承载了数十 TB 的数据。
 配置了完备的监控告警系统，所有集群都已接入，可以在集群出现问题时及时发送告警信息，为集群的正常运行提供了保障。</description>
    </item>
    
    <item>
      <title>TiDB 在今日头条的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-toutiao/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-toutiao/</guid>
      <description>本文整理自今日头条数据库中间件/分布式数据库负责人吴镝（知乎 ID：吴镝）在 TiDB DevCon2018 上的分享内容。
 TiDB 主要应用在今日头条核心 OLTP 系统 - 对象存储系统中，存储其中一部分元数据，支持头条图片和视频相关业务，比如抖音等。
如今（数据截至发文），TiDB 支撑着今日头条 OLTP 系统里 QPS 比较高的场景：集群容量约几十 T，日常 QPS 峰值会达到几十万。
为什么我们需要用 TiDB 今日头条内部有一些业务数据量非常大，之前用的 MySQL 的单机盘是大概 2.8T 的 SSD 盘。我们做对象存储。因为头条不但做视频，还做图片，这些视频和图片当中基本上都是用我们自研的 S3 存储系统，这种存储系统需要一个元数据，比如一个图片存下来，它存在 S3 系统的哪个机器、哪个文件、哪个偏移里面的数据，还有比如一个大的视频，S3 会把它切成很多小的视频片段，每一个分片的位置，都会存在元数据里面。
用 TiDB 之前，元数据是存在 MySQL 里的一个 2.8TB 的盘，因为增长的特别快，所以导致磁盘不够用，只能用分库分表的方案。我们以前用的的分库分表方案是 MyCAT。但用这个方案的过程中我们有遇到了一些问题，比如丢数据。某一个数据我 commit 了之后，最后发现这个数据丢了。
再就是连接的问题，目前头条做分片是大概固定分 100 个片。如果你的业务是需要分库分表，那你这边搞 101 个分片，这样有些业务，他用了一个分片键，用分片键来做查询，那可能中间件只用一个连接就可以找到相关数据。但有些业务，确实有不带分片键的请求。会导致 select 语句过来的时候，下面会建 101 个对后端的连接，也就是说，因为有连接的限制，有一个没有带分片键的这种请求过来之后， MyCAT 可以启 101 个连接到后面的每一个 MySQL 库。那这样的话，有时候我给它 5 万个连接，他一下子就把一百万用掉了。这样会导致它在非分片键的 select 请求，它连接速度消耗非常快，经常在业务这边会抛出说，连接数不够。
头条的数据库主要用的是 MySQL 和 MongoDB，相对比较单一，所我们也想多尝试一些其他的数据库。</description>
    </item>
    
    <item>
      <title>TiDB 在 G7 的实践和未来</title>
      <link>https://pingcap.com/cases-cn/user-case-g7/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-g7/</guid>
      <description>背景 2010 年，G7 正式为物流运输行业提供面向车队管理的 SaaS 服务，经过持续创新，通过软硬一体化的产品技术能力，致力于数字化每一辆货车，以实时感知技术创造智慧物流新生态。G7 为客户提供全方位的数据服务、智能的安全和运营管理、手机管车、数字运力、以及 ETC、油和金融等增值服务。
目前，G7 连接了 600,000 辆货车，每天行驶 6500 万公里（可绕地球赤道 1625 圈），13.5 亿个轨迹点和 2,200 万次车辆事件触发，并且以直线速度飞速增长。G7 每天产生的车辆行驶、状态、消费等数据超过 2T，飞速增加的车辆、数据类型和复杂的金融业务，使得数据库的事务、分析、扩展和可用性面临巨大的挑战。
在大量的车辆信息和轨迹相关数据业务中，当前我们通过 Spark、Hive 等对大量原始数据进行分析后，存入阿里云 DRDS，对外提供基础数据接口服务。由于清洗后的数据量依然很大，使用 DRDS 的存储成本非常高，且面对很多 OLAP 的查询时，效率不如人意。
而在金融和支付这种复杂业务场景中，面临 CAP 中 C 和 P 的挑战。在以往的工作中，支付系统由于面临强一致性事务的高峰值写入问题，采用了 2PC+MySQLXA（单个 MySQL 作为参与者，上层增加 Proxy 作为协调者）完成了分布式事务数据库的方案。但是这种方案在 Partition 中，极为麻烦。同时，运营和风控系统经常需要做相对复杂的查询，要么通过 MySQL+ETL+OLAP 数据库（成本高），要么容忍查询的效率问题。
探索 G7 的技术团队一直在寻找一种能解决上述问题的数据库。要找到这样一种数据库，除了需要满足上述需求以外，还需要满足另一个需求：可维护性和易迁移性。这要求该数据库具体需要满足如下几个要求：
 兼容 MySQL 协议，使得数据库的变更对上层业务透明，这个有多重要，做过基础架构升级落地的同学应该深有感触。
 支持 MySQL 的主从同步机制，使得数据库的变更可以平滑逐步升级，降低变更风险。
 必须是开源的。数据库的稳定需要付出很大的精力和时间，在这个过程中，或多或少都出现问题。出现问题不可怕，可怕的是无法定位和解决问题，只能依赖“他人”。数据库的一个 BUG 对“他人”来说，可能是一个小问题，对 G7 业务而言，可能是一个巨大的灾难。当“屁股”不在同一个板凳上时，我们需要对数据库有很强的掌控力。
 开源的同时，背后一定需要有一个有实力的技术团队或商业公司的全力投入。在见识了不少“烂尾”和“政绩”的开源项目后，只有一个稳定全职投入的技术团队或商业公司，才能最终让这个数据库越来越好。
  在这么多限制和需求的情况下，TiDB+TiSpark 很快进入我们的视线，并且开始调研。通过和 TiDB 技术人员的交流，除了满足上述的需求外，如下技术细节使我们一致认为可以选择这样的方案：</description>
    </item>
    
    <item>
      <title>TiDB 在二维火餐饮管理实时报表中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-erweihuo/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-erweihuo/</guid>
      <description>二维火 SaaS 平台介绍 二维火作为餐饮商家管理标准化服务提供商，帮助商家节省经营成本、提升服务效果是我们的使命。在商家日常生产中，上游系统产生了很多数据，包括供应链采购系统（Support），门店收银系统（POS），食客排队系统（Queueing），智能厨房显示系统（KDS），电子菜谱系统等（E-Menu）， 一个实时、精准、可多维度分析的报表系统能充分利用这些数据，支持商家对经营决策进行优化，极大提升商家工作效率。主要服务于以下场景：
 收银员交接班需要通过收银软件、财务报表进行多维度对账，来保障收银员一天的辛苦劳动。
 商家运营人员需要时段性监控每个门店的经营状况，并通过监控数据实时调整运营策略。
 中小型店老板解放自我，不再需要时时刻刻呆在门店里，也能从原料变化到收入波动进行实时把控。
 大型门店连锁更有专门的指挥中心，实时了解每个门店的经营状况，实现一体化管理。
  二维火各类报表界面：
二维火实时报表的业务约束  要求实时或者准实时，数据延迟不超过 3 秒。
 数据量大、数据增速快，报表结果查询需要在 500 ms 之内返回结果。
 查询维度多，查询条件复杂，涉及十几个业务表，上百个维度汇总查询。
  随着业务范围扩大以及功能扩展，实时报表业务不光承担了报表业务，业务方同时希望这是一个数据实时、可多维度查询分析的数据平台工具，为业务进行各种数据支持。
二维火数据的特殊场景  商家门店连锁关系不是固定的，A 门店数据今天属于 AA 连锁，明天可能会变成 BB 连锁。
 数据展现多人多面，权限不同展现结果不同。
 数据变更非常频繁，一条数据最少也会经过五六次变更操作。
 实时报表展现的不仅是当天数据，涉及到挂帐、垮天营业、不结账等复杂状况，生产数据的生命周期往往会超过一个月以上。
  如果用 MySQL 作为报表存储引擎的话，一个门店所属连锁总部变更，相当于分库的路由值产生了变化，意味着需要对这家店的数据进行全量迁移，这是个灾难性的事情，我们希望连锁只是个属性，而不用受到 Sharding Key 的制约导致的一地鸡毛。
开始的解决方案 我们的业务数据是构建在 MySQL 之上，按照业务和商家维度进行分库。利用 Otter 订阅业务数据，进行数据整理归并到 Apache Solr[1] 中，输出分析、统计报表所需要的数据。然而随着业务的快速发展以及客户定制化需求不断增加，Solr 的瓶颈从一张白纸慢慢地被填充。
 不断的添加检索维度，需要不停的对索引进行 Full Build，Solr 的 Full Build 成本慢慢地高成了一座大山。</description>
    </item>
    
    <item>
      <title>TiDB 在饿了么归档环境的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-eleme-2/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-eleme-2/</guid>
      <description>背景 随着业务增长，公司数据规模不断膨胀，表变多、变大。一方面占用的磁盘、CPU 等物理资源疾速上涨，另一方面大表性能下降且变更困难。实际上，很多大表的数据无需保留很久，比如某些业务可能只需近 3 周或近 3 个月的数据。对此类表，可依据业务要求，在线上环境只保留指定天数的数据，其余超出时间范围的过期数据可予以删除。出于某些原因，比如对账，线上业务查冷数据等，从生产环境删除的数据不能直接丢弃，需要存档以备不时之需，所谓归档。
方案 目前我们公司主要使用的是 MySQL 数据库服务，那么我们使用大磁盘容量的机器搭建几套主从结构的 MySQL 集群，配上高可用机制，将生产环境指定库表、指定时间范围之外且满足其他指定条件的数据按照一定的顺序定期分批导入到这些目标集群，并在每批确认导入成功后对源生产环境的数据予以删除，下批再从上次结束的位点开始导入、删除，如此循环重复，使生产环境表的数据始终维持在指定的时间范围。至于归档目标环境的数据则可以根据公司的要求统一保留指定的时间，比如 1 年。对于归档目标环境过期的数据可以进行直接删除处理。
问题 上述是一个典型的归档系统需要完成的基本功能和基本的处理流程，如果数据规模不是很大且增幅稳定而且表结构固定，那么上述流程可以很好的运行的。但现实的情况是公司数据规模庞大、数据增长迅速，而且由于业务发生变化等原因，后端的表结构可能需要跟着变化。而且，还需要考虑归档对生产集群正常业务的影响、对主从延迟的影响和 DDL 的影响等（这部分内容不在本文讨论范围）。
对于表结构变更有两种处理方式，
 “温和型”：在发现源端表结构发生变更后，相应的在目标端的表上执行同样的变更，以确保两端表结构一致数据可以正常写入；
 “粗暴型”：一旦发现源端表结构发生了变更，则在目标端轮转一个新表（旧表重命名，然后按源表新的表结构在目标端重建表）以确保源和目标表结构统一。
  “粗暴型”的解决方式可以很好的处理结构不一致问题，但如前边所述，一些线上的业务可能需要查询归档环境的冷数据，比如，用户想要查询半年前的订单数据，对于这类表简单粗暴的将其重命名会对业务查询归档数据造成困难；“温和型”的解决方式不仅可以处理表结构不一致的问题，而且也可以避免轮转表导致的数据查询问题，但是，对于 MySQL 来说，当归档表变得很大的时候，DDL 通常会非常耗时。
对于数据规模大、数据增长快这一情况，尽管选用了大磁盘容量的机型来存储归档数据，但因表多且数据量大往往在运行几个月后磁盘空间即被写满。这部分数据因为还没超出指定的有效期，所以还不能从归档目标环境直接清理，而 MySQL 又不能方便的进行容量扩展，所以只能考虑将现有的归档作业迁移至新的归档目标集群进行归档，而这一迁移也会对需要访问归档环境数据的应用造成影响。
另外，尽管启用了高可用机制，因为归档环境数据量大，一旦归档目标集群发生了 Master 节点切换，要想重新同步一份数据搭建一个 Slave 节点会非常耗时。
上述问题可简要概括为三个主要痛点：
 快速 Online DDL；
 水平扩展存储容量；
 故障恢复后的数据自动同步。
  探索 弹性伸缩和快速 Online DDL 不是我们在归档环境遇到的个案问题，其实也是数据库业界普遍会遇到的两个问题，尤其是现如今各类海量数据的大背景下，也因此出现过诸多解决方案。比如，TokuDB 存储引擎就可以快速安全的处理 DDL，而且是作为 MySQL 插件的方式提供的，所以对于基于 MySQL 的应用几乎可以不用进行任何改造就可以在 TokuDB 引擎上运行。而且 TokuDB 引擎有很高的压缩比，这一点对很多资源敏感型的用户也很具吸引力。
美中不足的是，TokuDB 只是插件式的存储引擎，并不能解决弹性扩容问题。 MySQL Cluster、PXC 等具备弹性扩容能力，但它们只是扩展了计算能力，并不能扩展存储能力，且大表的 DDL 依然是个问题。Cassandra，Vertica 这类分布式列式存储可以对计算和存储方便的进行弹性伸缩，DDL 也可以快速安全的进行，但这类数据库是非关系型的，不支持分布式事务（对于归档应用不是什么问题），且对于基于 MySQL 的应用需要进行大量兼容性的改造才可能迁移至这些存储（对于 MySQL 的归档意味着我们要进行额外的大量的改造工作）。</description>
    </item>
    
    <item>
      <title>TiDB 助力客如云餐饮 SaaS 服务</title>
      <link>https://pingcap.com/cases-cn/user-case-keruyun/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-keruyun/</guid>
      <description>公司介绍 客如云成立于 2012 年，是全球领先、 国内最大的 SaaS 系统公司。 目前面向餐饮、 零售等服务业商家， 提供软硬一体的新一代智能化前台、收银等 SaaS 云服务，包括预订、排队、外卖、点餐、收银、会员管理、进销存等系统服务，并将数据实时传达云端。我们是客如云的大数据基础架构组，负责公司的大数据架构和建设工作，为公司提供大数据基础数据服务。
业务发展遇到的痛点 1. 随着公司业务架构越来越复杂，技术架构组需要在服务器端与应用端尽可能的通过微服务化实现业务解耦，同时需要第三方熔断服务机制来保证核心业务正常运行。数据库层面，为了保证高并发的实时写入、实时查询、实时统计分析，我们针对地做了很多工作，比如对实时要求较高的服务走缓存、对大表进行分库分表操作、对有冷热属性的大表进行归档、库分离，虽然用大量人力资源解决了部分问题，但是同时也带来了历史数据访问、跨库分表操作、多维度查询等问题。
2. 大数据量下，MySQL 稍微复杂的查询都会很慢，线上业务也存在单一复杂接口包含执行几十次 SQL 的情况，部分核心交易大库急需解决访问性能。
3. 餐饮行业有明显的业务访问高峰时间，高峰期期间数据库会出现高并发访问，而有些业务，比如收银，在高峰期出现任何 RDS 抖动都会严重影响业务和用户体验。
4. 传统的数仓业务往往有复杂的 T+1 的 ETL 过程，无法实时的对业务变化进行动态分析和及时决策。
业务描述 大数据的 ODS（Operational Data Store）以前选型的是 MongoDB，ODS 与支持 SaaS 服务的 RDS 进行数据同步。初期的设想是线上的复杂 SQL、分析 SQL，非核心业务 SQL 迁移到大数据的 ODS 层。同时 ODS 也作为大数据的数据源，可以进行增量和全量的数据处理需求。但是由于使用的 MongoDB，对业务有一定侵入，需要业务线修改相应查询语句，而这点基本上遭到业务线的同学不同程度的抵制。同时目前大数据使用的是 Hadoop + Hive 存储和访问方案，业务线需要把历史明细查询迁移到 Hadoop ，然后通过 Impala、Spark SQL、Hive SQL 进行查询，而这三个产品在并发度稍微高的情况下，响应时间都会很慢，所以大数据组在提供明细查询上就比较麻烦。 同时更为棘手的是，面对客户查询服务（历史细则、报表等），这类查询的并发会更高，而且客户对响应时间也更为敏感，我们首先将处理后的数据（历史细则等）放在了 MongoDB 上（当时 TiDB 1.0 还没有 GA，不然就使用 TiDB 了），然后针对 OLAP 查询使用了 Kylin ，先解决了明细查询的问题。 但是由于业务很复杂, 数据变更非常频繁，一条数据最少也会经过五六次变更操作。报表展现的不仅是当天数据，涉及到挂账、跨天营业、不结账、预定等复杂状况，生产数据的生命周期往往会超过一个月以上。所以当前的 OLAP 解决方案还有痛点，所以后续我们要把 OLAP 查询移植一部分到 TiDB 上面去，来减轻 Kylin 的压力并且支持更加灵活的查询需求，这个目前还在论证当中。 同时，我们发现 TiDB 有一个子项目 TiSpark， TiSpark 是建立在 Spark 引擎之上，Spark 在机器学习领域里有诸如 MLlib 等诸多成熟的项目，算法工程师们使用 TiSpark 去操作 TiDB 的门槛非常低，同时也会大大提升算法工程师们的效率。我们可以使用 TiSpark 做 ETL，这样我们就能做到批处理和实时数仓，再结合 CarbonData 可以做到非常灵活的业务分析和数据支持，后期根据情况来决定是否可以把一部分 Hive 的数据放在 TiDB 上。</description>
    </item>
    
    <item>
      <title>TiDB 在凤凰网新闻内容业务的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ifeng/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ifeng/</guid>
      <description>背景 凤凰网（纽交所上市公司，代码：FENG）是全球领先的跨平台网络新媒体公司，整合旗下综合门户凤凰网、手机凤凰网和凤凰视频三大平台，秉承&amp;rdquo;中华情怀，全球视野，兼容开放，进步力量&amp;rdquo;的媒体理念，为主流华人提供互联网、无线通信、电视网的三网融合无缝衔接的新媒体优质内容与服务。
在媒体行业，新闻内容就是核心的业务数据，我们需要一个稳定的、具有高可用的、易水平扩展的数据存储系统，来存放公司核心数据，在最早，我们采用比较流行的 MySQL 来存储各个业务模块的内容，通过主从切换的方式进行高可用，但随着数据量的增加，MySQL 单机容量成为了瓶颈，传统的基于 MySQL 分片方案在实现及运维都需要比较昂贵的成本，同时 MySQL 主流主从切换方案由于机制问题，在判断“主库真死”，“新主库选举”及“新路由信息广播”上都存在一些不足，整体时间消耗比较大，并不能达到公司核心业务的高可用要求。于是，我们不得不寻找新的解决方案。
选择 TiDB 前期方案选择
在选择评估初期，我们主要有以下几个考虑点：
 支持业务弹性的水平扩容与缩容；
 满足业务故障自恢复的高可用；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL，尽量少的改动代码；
 使用上、运维上要足够优化，最好支持在线 DDL。
  在寻找的道路中，我们惊喜的发现了 TiDB — 中国人研发主导的开源分布式数据库。
数据库容量及扩展
记得有这样一句话：“单机 MySQL 能解决的问题，不要使用 TiDB！”，我们原有的数据存储存放于多个 MySQL 数据库中。诚然，对于数据量小的库来说，一些常见的点查、范围查 MySQL 的性能要比 TiDB 的性能好，如果不考虑扩张的问题，短期内使用主从 MySQL 比使用 TiDB 更满足我们的线上需求，但是，即使如此，我们也不得不考虑成本问题。将多套线上的主从 MySQL 迁移到 TiDB，更能充分利用服务器资源，减少资源的浪费。而对于很多业务来说，扩张问题是不可能回避的，对数据日益增长的数据库来说，单表响应时间会越来越长，而分库分表的成本过高，代码需要改动和测试，即使业务上能接受这一次的操作，那下次扩容呢？TiDB 通过底层自动进行分片帮我们解决了这个问题，同时业务量的增加或减少可以通过添加减少节点来处理，代码上基本无改动，这也是我们所期望的。
高可用
对于原有的主从 MySQL，并没有配置高可用，我们也对 MHA 等第三方工具做过调研，在发生主从切换后，在新路由信息分发这块也依赖修改网络配置或者数据库中间件（DBproxy），有一定的时间成本，虽然业界有很多中间件方案，但也很多问题和技术成本，所以这个方向并不是我们首选，之前的方式是一旦 MySQL 主数据库宕机，我们通过内部的监控系统获知，再进行更改 Keepalived + HAproxy 配置，即使人为响应非常及时，其影响的时间也早已超过业务的容忍。而选择天然的多节点 TiDB 自然就避免了这一点，配合网络 HAproxy 完全实现了 DB 层面的高可用。前一段时间，我们内部监控系统升级，其中一台机器没有对 TiKV 添加监控，而该 TiKV 节点由于硬件原因服务宕了几天，我们业务上也未感知，当然这是我们的失误，但是也侧面反应了 TiDB 自身的高可用机制。</description>
    </item>
    
    <item>
      <title>TiDB 在零氪科技（LinkDoc）大数据医疗系统的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-linkdoc/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-linkdoc/</guid>
      <description>公司介绍 零氪科技作为全球领先的人工智能与医疗大数据平台，拥有国内最大规模、体量的医疗大数据资源库和最具优势的技术支撑服务体系。多年来，零氪科技凭借在医疗大数据整合、处理和分析上的核心技术优势，依托先进的人工智能技术，致力于为社会及行业、政府部门、各级医疗机构、国内外医疗器械厂商、药企等提供高质量医疗大数据整体解决方案，以及人工智能辅助决策系统（辅助管理决策、助力临床科研、AI 智能诊疗）、患者全流程管理、医院舆情监控及品牌建设、药械研发、保险控费等一体化服务。
LinkDoc 的主要应用场景 LinkDoc 通过将患者真实的病例数据和算法模型应用于肿瘤治疗，构建精准的诊疗模型并提供数据支持，从而辅助医院管理决策、辅助科研、辅助临床诊疗。目前 Hubble 系统“肺癌淋巴结跳跃转移风险预测”模块可避免肺癌病人由于误判而导致提前 8-10 个月的复发，每年能让近两万病人的生命再延长 8-10 个月。Hubble 系统“AI - 肺结节智能诊断”模块全自动地识别 CT 影像中所有的结节，识别率达 91.5%。LinkDoc 希望凭借医疗大数据整合、处理和分析上的核心技术优势，以互联网人工智能上的创新研发，提升中国医师的全球医学水准，并通过支持药物研发与医疗保险行业的发展，让每一位患者享有普惠、精准的医疗服务。
支撑 LinkDoc 业务的底层数据库平台也面临着医疗行业新领域的技术 &amp;amp; 业务挑战，如数据量的快速增长（亿级别）、大数据量下的清洗逻辑的数据擦写、分析型事物对数据库的读压力都要求我们在数据库平台进行重新探索，选择一款适合医疗大数据业务的数据库解决方案。
选择 TiDB 业务痛点  数据量大，单实例 MySQL 扩容操作复杂；
 写入量大，主从延时高，由于业务对数据有低延时的要求，所以传统的 MySQL 主从架构在该项目下不能满足需求，大量数据写入下主库成为性能瓶颈；
 随着数据量越来越大，部分统计查询速度慢；
 分库分表业务开发和维护成本高。
  业务需求  高可靠性 &amp;amp; 稳定性；
 可扩展性，可随数据量 &amp;amp; 请求量增长快速提升存储 &amp;amp; 请求处理能力；
 更低的延时。
  方案调研 未选择 TiDB 之前我们调研了 MyCAT、Cobar、Atlas 等中间件解决方案，这些中间件整体来说就是让使用者觉得很“拧巴”，从社区支持、MySQL 功能兼容、系统稳定性上都不尽人意，需要业务做大量改造，对于快速发展的公司来说切换成本太高。
在 LinkDoc 首席架构师王晓哲的推荐下我们调研了 TiDB, TiDB 的如下特性让我们眼前一亮：</description>
    </item>
    
    <item>
      <title>TiDB 助力一面数据实现消费领域的决策分析平台</title>
      <link>https://pingcap.com/cases-cn/user-case-yimian/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yimian/</guid>
      <description>公司介绍 深圳市一面网络技术有限公司（下称：一面数据）是一家为消费领域的领导企业提供实时、精准、全面的数据洞察和决策指导的创新型企业，利用人工智能和算法，进行自然语言处理，语义情感分析，回归预测模型等，帮助客户实现精准产品运营和预测市场变化。一面数据服务于国内外一流企业，包括世界最大的对冲基金、国际一线汽车品牌、快消品龙头厂商，以及时尚鞋服大牌等。
改造前系统架构 一面数据的核心 IT 系统覆盖了从数据获取、数据清洗处理、数据建模到数据可视化的全套数据分析流程。核心系统每天有海量从互联网采集的公开数据和来自企业内部的数据，对数据存储的容量、扩展性和可用性都有很高的要求。
起初，一面数据的核心系统采用的是多个 MySQL 实例和一个 Cassandra 集群。MySQL 多实例集群主要存储指定特征的爬虫数据，Cassandra 主要存储数据量大、不适合存储 MySQL 的全页面缓存的数据。在数据量/请求量小的时候系统运行正常。下图为一面数据改造前系统构架图：
随着数据量的增长，逐渐暴露出很多问题：
 MySQL：随着数据增长，存储容量接近单机的磁盘极限，单机的磁盘 IO 繁忙且易阻塞，查询性能难以满足业务增长的需求。数据量大了以后，传统的 MySQL 水平扩展能力弱，性能和稳定性容易产生问题，在数据量和访问量增长到一定阶段将无法满足常见的 OLAP 场景分析需求。技术团队通过诊断系统性能问题，认识到现有数据库已经成为瓶颈。
 Cassandra：Cassandra 对磁盘 IO 和内存要求高，添加一个实例，需要从其他实例迁数据，对网络带宽、 磁盘要求特别高。另外 CQL 支持的特性太少，业务开发麻烦，例如不能联表，不支持主键之外的索引，对主键以外的查询比较困难，虽然有 Secondary Index，但是使用限制大。生态圈不完善，例如很难找到好用的监控。
  改造后的系统架构 引入 TiDB 替换 MySQL 和 Cassandra 为从根本上解决以上问题，一面数据的技术团队决定通过增加部署一套高性能的数据库系统，以解决当前业务的痛点。 在评估和验证了 MySQL Sharding 和 MongoDB 等传统技术手段之后，团队认识到：基于 MySQL Sharding (即利用 MySQL 中间件分库分表) 架构在高可用安全能力，业务和查询的灵活支持以及运维管理难度和成本上都不尽如人意，有着诸多架构上和技术上的缺陷；而 MongoDB 比较适合存储爬虫数据，但迁移成本高，不管是数据还是应用程序都需要做侵入性修改和调整，难度和开发成本骤升。另外，作为 NoSQL 数据库，MongoDB 不支持 SQL 和 JOIN ，对 BI 工具的支持也不完善，数据分析师们无法直接使用。 最终从满足业务需求、降低切换成本和减少运维成本等角度考虑，一面数据选择了分布式关系型数据库－TiDB 作为业务的首选事务型数据库。</description>
    </item>
    
    <item>
      <title>TiDB 在 Mobikok 广告系统中的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobikok/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobikok/</guid>
      <description>公司介绍 Mobikok（可可网络）成立于 2013 年，是一家快速成长的移动互联网营销公司，专注于移动 eCPM 营销。总部在中国深圳，聚焦于订阅 offer 的海外流量变现业务。Mobikok 提供的接口方式支持各类手机端流量（API、SDK、Smartlink），RTB（实时竞价系统）对接海外的 DSP（Demand-Side Platform，需求方平台）高效优化客户的广告效果。截止目前，系统已对 2 亿用户进行广告优化，已接入上百家广告主以及上百家渠道，Mobikok 致力于高效，便捷，专业的帮助广告主以及渠道互惠共赢。
场景介绍：SSP 系统 订阅 SSP（Sell-Side-Platform）平台当前业务主要分为：SDK、Smartlink、Online API 以及 Offline API；在当前 SSP SDK 业务系统当中，累计用户已达到 2 亿，最初使用的是 MySQL 主从分表的方式存储用户数据，随着数据量的增加，MySQL 单机容量以及大数据量查询成为了瓶颈；当单表数据达到 2 千万以上时，单机 MySQL 的查询以及插入已经不能满足业务的需求，当访问量到一定阶段后，系统响应能力在数据库这一块是一个瓶颈。
一次很偶然的机会在 GitHub 上面了解到 TiDB，并且因为现在业务系统当中使用的 Redis 集群是 Codis，已在线上稳定使用两年，听闻 TiDB 创始团队就是之前 Codis 的作者，所以对 TiDB 有了极大的兴趣并且进行测试。通过测试单机 MySQL 和 TiDB 集群，当数据量达到数千万级别的时候发现 TiDB 效率明显高于 MySQL。所以就决定进行 MySQL 到 TiDB 迁移。
迁移后整体架构图：
引入 TiDB 在选择使用替换 MySQL 方案当中。我们主要考虑几点：
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 高度兼容 MySQL，少改动代码；</description>
    </item>
    
    <item>
      <title>TiDB 在猿辅导数据快速增长及复杂查询场景下的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yuanfudao/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yuanfudao/</guid>
      <description>猿辅导是国内拥有最多中小学生用户的在线教育机构，旗下有猿题库、小猿搜题、猿辅导三款在线教育 APP，为用户提供在线题库、拍照搜题、名师在线辅导相关的服务。其中，猿辅导 APP 已经有超过 116 万付费用户，提供小学英语、奥数，和初中高中全学科的直播辅导课程，全国任何地区的中小学生，都可以享受在家上北京名师辅导课的服务。
海量的题库、音视频答题资料、用户数据以及日志，对猿辅导后台数据存储和处理能力都提出了严峻的要求。
猿辅导的业务决定了其后台系统具有以下特点：
 数据体量大，增速快，存储系统需要能够灵活的水平扩展；
 有复杂查询，BI 方面的需求，可以根据索引，例如城市、渠道等，进行实时统计；
 数据存储要具备高可用、高可运维性，实现自动故障转移。
  在最初方案选型时，猿辅导初期考虑用单机 MySQL。但根据业务发展速度预估，数据存储容量和并发压力很快就会达到单机数据库的处理瓶颈。如果在 MySQL 上加入分库中间件方案，则一定要指定 sharding key，这样是无法支持跨 shard 的分布式事务。同时 proxy 的方案对业务层的侵入性较强，开发人员必须了解数据库的分区规则，无法做到透明。
除此之外，分库分表很难实现跨 shard 的聚合查询，例如全表的关联查询、子查询、分组聚合等业务场景，查询的复杂度需要转嫁给开发者。即使某些中间件能实现简单的 join 支持，但是仍然没有办法保证查询的正确性。另外广播是一个没有办法 Scale 的方案，当集群规模变大，广播的性能开销是很大的。同时，传统 RDBMS 上 DDL 锁表的问题，对于数据量较大的业务来说，锁定的时间会很长，如果使用 gh-ost 这样第三方工具来实现非阻塞 DDL，额外的空间开销会比较大，而且仍然需要人工的介入确保数据的一致性，最后切换的过程系统可能会有抖动。可以说，运维的复杂性是随着机器数量指数级增长，而扩容复杂度则是直接转嫁给了 DBA。
最终，猿辅导的后台开发同学决定寻求一个彻底的分布式存储解决方案。通过对社区方案的调研，猿辅导发现分布式关系型数据库 TiDB 项目。
TiDB 是一款定位于在线事务处理/在线分析处理（HTAP）的融合型数据库产品，具备在线弹性水平扩展、分布式强一致性事务、故障自恢复的高可用、跨数据中心多活等核心特性；对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案，并在此过程中保证了事务的 ACID 特性。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。用户可以把 TiDB 当作一个容量无限扩展的单机数据库，复杂的分布式事务和数据复制由底层存储引擎来支持，开发者只需要集中精力在业务逻辑的开发上面。
图为 TiDB 与传统的 MySQL 中间件方案的一些对比
TiDB 集群主要分为三个组件：TiDB Server、TiKV Server、PD Server。
TiDB 整体架构图
TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以企业在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。</description>
    </item>
    
    <item>
      <title>TiKV 是如何存取数据的</title>
      <link>https://pingcap.com/blog-cn/how-tikv-store-get-data/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-tikv-store-get-data/</guid>
      <description>本文会详细的介绍 TiKV 是如何处理读写请求的，通过该文档，同学们会知道 TiKV 是如何将一个写请求包含的数据更改存储到系统，并且能读出对应的数据的。
基础知识 在开始之前，我们需要介绍一些基础知识，便于大家去理解后面的流程。
Raft TiKV 使用 Raft 一致性算法来保证数据的安全，默认提供的是三个副本支持，这三个副本形成了一个 Raft Group。
当 Client 需要写入某个数据的时候，Client 会将操作发送给 Raft Leader，这个在 TiKV 里面我们叫做 Propose，Leader 会将操作编码成一个 entry，写入到自己的 Raft Log 里面，这个我们叫做 Append。
Leader 也会通过 Raft 算法将 entry 复制到其他的 Follower 上面，这个我们叫做 Replicate。Follower 收到这个 entry 之后也会同样进行 Append 操作，顺带告诉 Leader Append 成功。
当 Leader 发现这个 entry 已经被大多数节点 Append，就认为这个 entry 已经是 Committed 的了，然后就可以将 entry 里面的操作解码出来，执行并且应用到状态机里面，这个我们叫做 Apply。
在 TiKV 里面，我们提供了 Lease Read，对于 Read 请求，会直接发给 Leader，如果 Leader 确定自己的 lease 没有过期，那么就会直接提供 Read 服务，这样就不用走一次 Raft 了。如果 Leader 发现 lease 过期了，就会强制走一次 Raft 进行续租，然后在提供 Read 服务。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十九）tikv-client（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</guid>
      <description>上篇文章 中，我们介绍了数据读写过程中 tikv-client 需要解决的几个具体问题，本文将继续介绍 tikv-client 里的两个主要的模块——负责处理分布式计算的 copIterator 和执行二阶段提交的 twoPhaseCommitter。
copIterator copIterator 是什么 在介绍 copIterator 的概念之前，我们需要简单回顾一下前面 TiDB 源码阅读系列文章（六）中讲过的 distsql 和 coprocessor 的概念以及它们和 SQL 语句的关系。
tikv-server 通过 coprocessor 接口，支持部分 SQL 层的计算能力，大部分只涉及单表数据的常用的算子都可以下推到 tikv-server 上计算，计算下推以后，从存储引擎读取的数据虽然是一样的多，但是通过网络返回的数据会少很多，可以大幅节省序列化和网络传输的开销。
distsql 是位于 SQL 层和 coprocessor 之间的一层抽象，它把下层的 coprocessor 请求封装起来对上层提供一个简单的 Select 方法。执行一个单表的计算任务。最上层的 SQL 语句可能会包含 JOIN，SUBQUERY 等复杂算子，涉及很多的表，而 distsql 只涉及到单个表的数据。一个 distsql 请求会涉及到多个 region，我们要对涉及到的每一个 region 执行一次 coprocessor 请求。
所以它们的关系是这样的，一个 SQL 语句包含多个 distsql 请求，一个 distsql 请求包含多个 coprocessor 请求。
copIterator 的任务就是实现 distsql 请求，执行所有涉及到的 coprocessor 请求，并依次返回结果。</description>
    </item>
    
    <item>
      <title>TiKV 集群版本的安全迁移</title>
      <link>https://pingcap.com/blog-cn/tikv-cluster-migration/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-cluster-migration/</guid>
      <description>问题描述 在 TiDB 的产品迭代中，不免会碰到一些兼容性问题出现。通常协议上的兼容性 protobuf 已经能帮我们处理的很好，在进行功能开发，性能优化时，通常会保证版本是向后兼容的，但并不保证向前兼容性，因此，当集群中同时有新旧版本节点存在时，旧版本不能兼容新版本的特性，就有可能造成该节点崩溃，影响集群可用性，甚至丢失数据。目前在有不兼容的版本升级时，会要求进行离线升级，但这会影响到服务，我们需要一个适合的机制来进行不停服务的升级。因此我们需要在进行滚动升级时，让这些不能保证整个集群的向后兼容性的功能不被启用。只有在保证集群中所有节点都已经升级完成后，我们才安全的启用这些功能。
常见的当我们对引入新的 RaftCommand 的时候，旧版本的 TiKV 并不能识别新的添加的 RaftCommand，对于不能认知的 RaftCommand TiKV 有不同的处理，可能会报错退出或忽略。比如为了支持 Raft Learner, 在 raftpb 里对添加新的 ConfChange 类型。 当 PD 在进行 Region 调度时，会先发送 AddLearner 到 TiKV 上，接受到这个命令的肯定是这个 Region 的 Leader，在进行一系列检查后，会将该命令 Proposal, 而 Follwer 如果是旧版本的话，在 Apply 这条 Command 就会出错。而在滚动升级时，很有可能存在 Leader 是新版本，Follwer 是老版本的情况。
引入版本检查机制 TiDB 的版本定义是遵循 Semver 的版本规则的。版本格式一般由主版本号（Major），次版本号（Minor），修订号（Patch），版本号递增规则如下：
 主版本号：当进行了不兼容的 API 修改。 次版本号：当做了向下兼容的功能性新增。 修订号：当做了向下兼容的问题修正。  先行版本号（PreRelase）及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。比如 TiDB 目前的版本是 2.1.0-beta，先行版号为 beta 版。
在此之前，集群并没有版本的概念，虽然每个组件都有各自的版本信息，但各个节点的各自组件的版本都可以任意的。没有一个管理机制可以管理或查看所有组件的版本信息。为了解决滚动升级过程中存在多个版本的兼容性问题，这里引入集群版本的概念，并由 TiDB 集群的中心节点 PD 来进行管理和检查。
具体实现 1.</description>
    </item>
    
    <item>
      <title>使用 TiKV 构建分布式类 Redis 服务</title>
      <link>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</guid>
      <description>什么是 Redis Redis 是一个开源的，高性能的，支持多种数据结构的内存数据库，已经被广泛用于数据库，缓存，消息队列等领域。它有着丰富的数据结构支持，譬如 String，Hash，Set 和 Sorted Set，用户通过它们能构建自己的高性能应用。
Redis 非常快，没准是世界上最快的数据库了，它虽然使用内存，但也提供了一些持久化机制以及异步复制机制来保证数据的安全。
Redis 的不足 Redis 非常酷，但它也有一些问题：
 内存很贵，而且并不是无限容量的，所以我们不可能将大量的数据存放到一台机器。 异步复制并不能保证 Redis 的数据安全。 Redis 提供了 transaction mode，但其实并不满足 ACID 特性。 Redis 提供了集群支持，但也不能支持跨多个节点的分布式事务。  所以有时候，我们需要一个更强大的数据库，虽然在延迟上面可能赶不上 Redis，但也有足够多的特性，譬如：
 丰富的数据结构 高吞吐，能接受的延迟 强数据一致 水平扩展 分布式事务  为什么选择 TiKV 大约 4 年前，我开始解决上面提到的 Redis 遇到的一些问题。为了让数据持久化，最直观的做法就是将数据保存到硬盘上面，而不是在内存里面。所以我开发了 LedisDB，一个使用 Redis 协议，提供丰富数据结构，但将数据放在 RocksDB 的数据库。LedisDB 并不是完全兼容 Redis，所以后来，我和其他同事继续创建了 RebornDB，一个完全兼容 Redis 的数据库。 无论是 LedisDB 还是 RebornDB，因为他们都是将数据放在硬盘，所以能存储更大量的数据。但它们仍然不能提供 ACID 的支持，另外，虽然我们可以通过 codis 去提供集群的支持，我们也不能很好的支持全局的分布式事务。
所以我们需要另一种方式，幸运的是，我们有 TiKV。
TiKV 是一个高性能，支持分布式事务的 key-value 数据库。虽然它仅仅提供了简单的 key-value API，但基于 key-value，我们可以构造自己的逻辑去创建更强大的应用。譬如，我们就构建了 TiDB ，一个基于 TiKV 的，兼容 MySQL 的分布式关系型数据库。TiDB 通过将 database 的 schema 映射到 key-value 来支持了相关 SQL 特性。所以对于 Redis，我们也可以采用同样的办法 - 构建一个支持 Redis 协议的服务，将 Redis 的数据结构映射到 key-value 上面。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十八）tikv-client（上）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</guid>
      <description>在整个 SQL 执行过程中，需要经过 Parser，Optimizer，Executor，DistSQL 这几个主要的步骤，最终数据的读写是通过 tikv-client 与 TiKV 集群通讯来完成的。
为了完成数据读写的任务，tikv-client 需要解决以下几个具体问题：
 如何定位到某一个 key 或 key range 所在的 TiKV 地址？
 如何建立和维护和 tikv-server 之间的连接？
 如何发送 RPC 请求？
 如何处理各种错误？
 如何实现分布式读取多个 TiKV 节点的数据？
 如何实现 2PC 事务？
  我们接下来就对以上几个问题逐一解答，其中 5、6 会在下篇中介绍。
如何定位 key 所在的 tikv-server 我们需要回顾一下之前 《三篇文章了解 TiDB 技术内幕——说存储》 这篇文章中介绍过的一个重要的概念：Region。
TiDB 的数据分布是以 Region 为单位的，一个 Region 包含了一个范围内的数据，通常是 96MB 的大小，Region 的 meta 信息包含了 StartKey 和 EndKey 这两个属性。当某个 key &amp;gt;= StartKey &amp;amp;&amp;amp; key &amp;lt; EndKey 的时候，我们就知道了这个 key 所在的 Region，然后我们就可以通过查找该 Region 所在的 TiKV 地址，去这个地址读取这个 key 的数据。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十七）DDL 源码解析</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</guid>
      <description>DDL 是数据库非常核心的组件，其正确性和稳定性是整个 SQL 引擎的基石，在分布式数据库中，如何在保证数据一致性的前提下实现无锁的 DDL 操作是一件有挑战的事情。本文首先会介绍 TiDB DDL 组件的总体设计，介绍如何在分布式场景下支持无锁 shema 变更，描述这套算法的大致流程，然后详细介绍一些常见的 DDL 语句的源码实现，包括 create table、add index、drop column、drop table 这四种。
DDL in TiDB TiDB 的 DDL 通过实现 Google F1 的在线异步 schema 变更算法，来完成在分布式场景下的无锁，在线 schema 变更。为了简化设计，TiDB 在同一时刻，只允许一个节点执行 DDL 操作。用户可以把多个 DDL 请求发给任何 TiDB 节点，但是所有的 DDL 请求在 TiDB 内部是由 owner 节点的 worker 串行执行的。
 worker：每个节点都有一个 worker 用来处理 DDL 操作。 owner：整个集群中只有一个节点能当选 owner，每个节点都可能当选这个角色。当选 owner 后的节点 worker 才有处理 DDL 操作的权利。owner 节点的产生是用 Etcd 的选举功能从多个 TiDB 节点选举出 owner 节点。owner 是有任期的，owner 会主动维护自己的任期，即续约。当 owner 节点宕机后，其他节点可以通过 Etcd 感知到并且选举出新的 owner。  这里只是简单概述了 TiDB 的 DDL 设计，下两篇文章详细介绍了 TiDB DDL 的设计实现以及优化，推荐阅读：</description>
    </item>
    
    <item>
      <title>TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库</title>
      <link>https://pingcap.com/blog-cn/tidb-operator-introduction/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-operator-introduction/</guid>
      <description>TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（pingcap/tidb-operator）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。
要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。
TiDB 和 Kubernetes 简介 TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。  TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。
 TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。
 PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。
  上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</guid>
      <description>在之前的一篇文章 《TiDB 源码阅读系列文章（四）INSERT 语句概览》 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。
本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。
INSERT 语句的种类 从广义上讲，TiDB 有以下六种 INSERT 语句：
 Basic INSERT
 INSERT IGNORE
 INSERT ON DUPLICATE KEY UPDATE
 INSERT IGNORE ON DUPLICATE KEY UPDATE
 REPLACE
 LOAD DATA
  这六种语句理论上都属于 INSERT 语句。
第一种，Basic INSERT，即是最普通的 INSERT 语句，语法 INSERT INTO VALUES ()，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。
第二种，语法 INSERT IGNORE INTO VALUES ()，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 SHOW WARNINGS 看到哪些行没有被插入。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十五）Sort Merge Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</guid>
      <description>什么是 Sort Merge Join 在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 wikipedia。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。
TiDB Sort Merge Join 实现 执行过程 TiDB 的实现代码在 tidb/executor/merge_join.go 中 MergeJoinExec.NextChunk 是这个算子的入口。下面以 SELECT * FROM A JOIN B ON A.a = B.a 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：
 顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。
 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。</description>
    </item>
    
    <item>
      <title>三十分钟成为 Contributor | 为 TiKV 添加 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。
图 1
如图 1，当 TiDB 收到来自客户端的查询请求
select count(*) from t where a + b &amp;gt; 5
时，执行顺序如下：
 TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV
 TiKV 收到请求后，循环以下过程
 获取下一行完整数据，并按列解析
 使用参数中的 where 表达式对数据进行过滤
 若上一条件符合，进行聚合计算
  TiKV 向 TiDB 返回聚合计算结果
 TiDB 对所有涉及的结果进行二次聚合，返回给客户端
  这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</guid>
      <description>在 统计信息（上） 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。
文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。
数据结构定义 直方图的定义可以在 histograms.go 中找到，值得注意的是，对于桶的上下界，我们使用了在 《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。
CM Sketch 的定义可以在 cmsketch.go 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 table，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 table 中得到。
除此之外，对列和索引的统计信息，分别使用了 Column 和 Index 来记录，主要包含了直方图，CM Sketch 等。 统计信息创建 在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 builder.go 中切分成不同的任务，然后在 analyze.go 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。
列直方图的创建 在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。
在 collect 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</guid>
      <description>简述 在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 a = 1 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 a = 1 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。
索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。
关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：三篇文章了解 TiDB 技术内幕 - 说计算 ）。
这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：
CREATE TABLE t (a int primary key, b int, c int); select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5; 计算索引逻辑区间范围的流程如下：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十二）统计信息(上)</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</guid>
      <description>在 TiDB 里，SQL 优化的过程可以分为逻辑优化和物理优化两个部分，在物理优化阶段需要为逻辑查询计划中的算子估算运行代价，并选择其中代价最低的一条查询路径作为最终的查询计划。这里非常关键的一点是如何估算查询代价，本文所介绍的统计信息是这个估算过程的核心模块。
这部分内容非常复杂，所以会分成两篇文章来介绍。本篇文章介绍统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价。上篇侧重于介绍原理，下篇会结合原理介绍 TiDB 的源码实现。
统计信息是什么 为了得到查询路径的执行代价，最简单的办法就是实际执行这个查询计划，不过这样子做就失去了优化器的意义。不过，优化器并不需要知道准确的代价，只需要一个估算值，以便能够区分开代价差别较大的执行计划。因此，数据库常常会维护一些实际数据的概括信息，用以快速的估计代价，这便是统计信息。
在 TiDB 中，我们维护的统计信息包括表的总行数，列的等深直方图，Count-Min Sketch，Null 值的个数，平均长度，不同值的数目等等。下面会简单介绍一下直方图和 Count-Min Sketch。
直方图简介 直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。根据分桶策略的不同，常见的直方图可以分为等深直方图和等宽直方图。
在 TiDB 中，我们选择了等深直方图，于 1984 年在 Accurate estimation of the number of tuples satisfying a condition 文献中提出。相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差。所谓的等深直方图，就是落入每个桶里的值数量尽量相等。举个例子，比方说对于给定的集合 {1.6, 1.9, 1.9, 2.0, 2.4, 2.6, 2.7, 2.7, 2.8, 2.9, 3.4, 3.5}，并且生成 4 个桶，那么最终的等深直方图就会如下图所示，包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3。
Count-Min Sketch 简介 Count-Min Sketch 是一种可以处理等值查询，Join 大小估计等的数据结构，并且可以提供很强的准确性保证。自 2003 年在文献 An improved data stream summary: The count-min sketch and its applications 中提出以来，由于其创建和使用的简单性获得了广泛的使用。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十一）Index Lookup Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</guid>
      <description>什么是 Index Lookup Join Nested Loop Join 在介绍 Index Lookup Join 之前，我们首先看一下什么是 Nested Loop Join（NLJ）。 NLJ 的具体定义可以参考 Wikipedia。NLJ 是最为简单暴力的 Join 算法，其执行过程简述如下：
 遍历 Outer 表，取一条数据 r；
 遍历 Inner 表，对于 Inner 表中的每条数据，与 r 进行 join 操作并输出 join 结果；
 重复步骤 1，2 直至遍历完 Outer 表中的所有数据。
  NLJ 算法实现非常简单并且 join 结果的顺序与 Outer 表的数据顺序一致。
但是存在性能上的问题：执行过程中，对于每一条 OuterRow，我们都需要对 Inner 表进行一次全表扫操作，这将消耗大量时间。
为了减少对于 Inner 表的全表扫次数，我们可以将上述步骤 1 优化为每次从 Outer 表中读取一个 batch 的数据，优化后的算法即 Block Nested-Loop Join（BNJ），BNJ 的具体定义可以参考 Wikipedia。</description>
    </item>
    
    <item>
      <title>十问 TiDB ：关于架构设计的一些思考</title>
      <link>https://pingcap.com/blog-cn/10-questions-tidb-structure/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/10-questions-tidb-structure/</guid>
      <description>“我希望能够把 TiDB 的设计的一些理念能够更好的传达给大家，相信大家理解了背后原因后，就能够把 TiDB 用的更好。”
 做 TiDB 的缘起是从思考一个问题开始的：为什么在数据库领域有这么多永远也躲不开的坑？从 2015 年我们写下第一行代码，3 年以来我们迎面遇到无数个问题，一边思考一边做，尽量用最小的代价来快速奔跑。
作为一个开源项目，TiDB 是我们基础架构工程师和社区一起努力的结果，TiDB 已经发版到 2.0，有了一个比较稳定的形态，大量在生产环境使用的伙伴们。可以负责任的说，我们做的任何决定都经过了非常慎重的思考和实践，是经过内部和社区一起论证产生的结果。它未必是最好的，但是在这个阶段应该是最适合我们的，而且大家也可以看到 TiDB 在快速迭代进化。
这篇文章是关于 TiDB 代表性“为什么”的 TOP 10，希望大家在了解了我们这些背后的选择之后，能更加纯熟的使用 TiDB，让它在适合的环境里更好的发挥价值。
这个世界有很多人，感觉大于思想，疑问多于答案。感恩大家保持疑问，我们承诺回馈我们的思考过程，毕竟有时候很多思考也很有意思。
一、为什么分布式系统并不是银弹 其实并没有什么技术是完美和包治百病的，在存储领域更是如此，如果你的数据能够在一个 MySQL 装下并且服务器的压力不大，或者对复杂查询性能要求不高，其实分布式数据库并不是一个特别好的选择。 选用分布式的架构就意味着引入额外的维护成本，而且这个成本对于特别小的业务来说是不太划算的，即使你说需要高可用的能力，那 MySQL 的主从复制 + GTID 的方案可能也基本够用，这不够的话，还有最近引入的 Group Replication。而且 MySQL 的社区足够庞大，你能 Google 找到几乎一切常见问题的答案。
我们做 TiDB 的初衷并不是想要在小数据量下取代 MySQL，而是尝试去解决基于单机数据库解决不了的一些本质的问题。
有很多朋友问我选择分布式数据库的一个比较合适的时机是什么？我觉得对于每个公司或者每个业务都不太一样，我并不希望一刀切的给个普适的标准（也可能这个标准并不存在），但是有一些事件开始出现的时候：比如是当你发现你的数据库已经到了你每天开始绞尽脑汁思考数据备份迁移扩容，开始隔三差五的想着优化存储空间和复杂的慢查询，或者你开始不自觉的调研数据库中间件方案时，或者人肉在代码里面做 sharding 的时候，这时给自己提个醒，看看 TiDB 是否能够帮助你，我相信大多数时候应该是可以的。
而且另一方面，选择 TiDB 和选择 MySQL 并不是一刀切的有你没他的过程，我们为了能让 MySQL 的用户尽可能减小迁移和改造成本，做了大量的工具能让整个数据迁移和灰度上线变得平滑，甚至从 TiDB 无缝的迁移回来，而且有些小数据量的业务你仍然可以继续使用 MySQL。所以一开始如果你的业务和数据量还小，大胆放心的用 MySQL 吧，MySQL still rocks，TiDB 在未来等你。
二、为什么是 MySQL 和上面提到的一样，并不是 MySQL 不好我们要取代他，而是选择兼容 MySQL 的生态对我们来说是最贴近用户实际场景的选择：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十）Chunk 和执行框架简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</guid>
      <description>什么是 Chunk TiDB 2.0 中，我们引入了一个叫 Chunk 的数据结构用来在内存中存储内部数据，用于减小内存分配开销、降低内存占用以及实现内存使用量统计/控制，其特点如下：
 只读
 不支持随机写
 只支持追加写
 列存，同一列的数据连续的在内存中存放
  Chunk 本质上是 Column 的集合，它负责连续的在内存中存储同一列的数据，接下来我们看看 Column 的实现。
1. Column Column 的实现参考了 Apache Arrow，Column 的代码在 这里。根据所存储的数据类型，我们有两种 Column：
 定长 Column：存储定长类型的数据，比如 Double、Bigint、Decimal 等
 变长 Column：存储变长类型的数据，比如 Char、Varchar 等
  哪些数据类型用定长 Column，哪些数据类型用变长 Column 可以看函数 addColumnByFieldType 。
Column 里面的字段非常多，这里先简单介绍一下：
 length   用来表示这个 Column 有多少行数据。
 nullCount  用来表示这个 Column 中有多少 NULL 数据。
 nullBitmap  用来存储这个 Column 中每个元素是否是 NULL，需要特殊注意的是我们使用 0 表示 NULL，1 表示非 NULL，和 Apache Arrow 一样。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（九）Hash Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</guid>
      <description>什么是 Hash Join Hash Join 的基本定义可以参考维基百科：Hash join。简单来说，A 表和 B 表的 Hash Join 需要我们选择一个 Inner 表来构造哈希表，然后对 Outer 表的每一行数据都去这个哈希表中查找是否有匹配的数据。
我们不用 “小表” 和 “大表” 这两个术语是因为：对于类似 Left Outer Join 这种 Outer Join 来说，如果我们使用 Hash Join，不管 Left 表相对于 Right 表而言是大表还是小表，我们都只能使用 Right 表充当 Inner 表并在之上建哈希表，使用 Left 表来当 Outer 表，也就是我们的驱动表。使用 Inner 和 Outer 更准确，没有迷惑性。在 Build 阶段，对 Inner 表建哈希表，在 Probe 阶段，对由 Outer 表驱动执行 Join 过程。
TiDB Hash Join 实现 TiDB 的 Hash Join 是一个多线程版本的实现，主要任务有：
 Main Thread，一个，执行下列任务：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（八）基于代价的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</guid>
      <description>概述 本文是 TiDB 源码阅读系列文章的第八篇。内文会先简单介绍制定查询计划以及优化的过程，然后用较大篇幅详述在得到逻辑计划后，如何基于统计信息和不同的属性选择等生成各种不同代价的物理计划，通过比较物理计划的代价，最后选择一个代价最小的物理计划，即 Cost-Based Optimization（CBO）的过程。
优化器框架 一般优化器分两个阶段进行优化，即基于规则的优化（Rule-Based-Optimization，简称 RBO）和基于代价的优化（CBO）。
TiDB 主要分为两个模块对计划进行优化：
 逻辑优化，主要依据关系代数的等价交换规则做一些逻辑变换。
 物理优化，主要通过对查询的数据读取、表连接方式、表连接顺序、排序等技术进行优化。
  相比 RBO，CBO 依赖于统计信息的准确性与及时性，执行计划会及时的根据数据变换做对应的调整。
优化器流程 TiDB 一个查询语句的简单流程：一个语句经过 parser 后会得到一个抽象语法树（AST），首先用经过合法性检查后的 AST 生成一个逻辑计划，接着会进行去关联化、谓词下推、聚合下推等规则化优化，然后通过统计数据计算代价选择最优的物理计划，最后执行。流程如下图 1。
 图 1 
物理算子简介 通过之前介绍物理层优化的方式，我们可以知道同一个逻辑算子可能因为它的数据读取、计算方式等不同会生成多个不同的物理算子，例如逻辑上的 Join 算子转换成物理算子可以选择 HashJoin、SortMergeJoin、IndexLookupJoin。
这里会简单介绍一些逻辑算子可选择的物理算子。例如语句：select sum(*) from t join s on t.c = s.c group by a。此语句中逻辑算子有 DataSource、Aggregation、Join 和 Projection，接下来会对其中几个典型的逻辑算子对应的物理算子进行一个简单介绍，如下表：
CBO 流程 基于代价优化的的主要思路是计算所有可能的执行计划的代价，并挑选代价最小的执行计划的路径。那么可以倒推出，首先得到需要采集对应表的统计信息，那么就可以用来计算出每个算子的执行代价，最后将得到每条路径上算子的代价按路径各自累加获取代价最小的路径。具体的代码实现在 plan/optimizer.go 中 dagPhysicalOptimize 函数，本文介绍的流程基本上也都由此函数完成，代码如下： func dagPhysicalOptimize(logic LogicalPlan) (PhysicalPlan, error) { logic.preparePossibleProperties() logic.deriveStats() t, err := logic.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 GA Release</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</guid>
      <description>2018 年 4 月 27 日，TiDB 发布 2.0 GA 版。相比 1.0 版本，对 MySQL 兼容性、系统稳定性、优化器和执行器做了很多改进。
TiDB  SQL 优化器
 精简统计信息数据结构，减小内存占用
 加快进程启动时加载统计信息速度
 支持统计信息动态更新 [experimental]
 优化代价模型，对代价估算更精准
 使用 Count-Min Sketch 更精确地估算点查的代价
 支持分析更复杂的条件，尽可能充分的使用索引
 支持通过 STRAIGHT_JOIN 语法手动指定 Join 顺序
 GROUP BY子句为空时使用 Stream Aggregation 算子，提升性能
 支持使用索引计算 Max/Min 函数
 优化关联子查询处理算法，支持将更多类型的关联子查询解关联并转化成 Left Outer Join
 扩大 IndexLookupJoin 的使用范围，索引前缀匹配的场景也可以使用该算法
  SQL 执行引擎
 使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用，显著提升 TPC-H 结果</description>
    </item>
    
    <item>
      <title>详解 | TiDB 2.0 GA is here!</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</guid>
      <description>去年十月份的时候，我们发布了 TiDB 1.0 版本，为此我们日夜兼程奋斗了两年半时间，我们认为 1.0 版本达到了可在生产环境中使用的程度。在接下来的六个月中，我们一方面维护 1.0 版本的稳定性并且增加必要的新特性，另一方面马不停蹄的开发 2.0 版本。经过半年时间，6 个 RC 版本，今天 TiDB 2.0 GA 版本正式发布。
2.0 版本规划 在 2.0 版本的规划阶段，我们对“这个版本需要做什么”进行了深入思考，我们根据现有用户的情况、技术发展趋势以及社区的声音，认为 2.0 版本需要聚焦在以下几点：
 保证 TiDB 的稳定性以及正确性。这两点是一个数据库软件的基础功能，作为业务的基石，任何一点抖动或者错误都可能对业务造成巨大的影响。目前已经有大量的用户在线上使用 TiDB，这些用户的数据量在不断增加、业务也在不断演进。我们非常关注 TiDB 集群如何保持长期稳定运行、如何减小系统的抖动、如何进行智能的调度，为此做了大量的调研和分析。
 提升 TiDB 在大数据量下的查询性能。从我们接触下来的用户来看，很多客户都有少则上百 GB，多则上百 TB 的数据，一方面数据会持续增加，另一方面也希望能对这些数据做实时的查询。所以如果能提升大数据量下的查询性能，对用户会很有帮助。
 优化 TiDB 的易用性和可维护性。TiDB 整套系统的复杂性比较高，运维及使用的难度要大于单机数据库，所以我们希望能提供尽可能方便的方案帮助用户使用 TiDB。比如尽可能简化部署、升级、扩容方式，尽可能容易的定位系统中出现的异常状态。
  围绕上面三点原则，我们做了大量的改进，一些是对外可见（如 OLAP 性能的显著提升、监控项的大量增加以及运维工具的各项优化），还有更多的改进是隐藏在数据库背后，默默的提升整个数据库的稳定性以及正确性。
正确性和稳定性 在 1.0 版本发布之后，我们开始构建和完善自动化测试平台 Schrodinger，彻底告别了之前靠手工部署集群测试的方式。同时我们也新增了非常多的测试用例，做到测试从最底层 RocksDB，到 Raft，再到 Transaction，然后是 SQL 都能覆盖。
在 Chaos 测试上面，我们引入了更多的错误注入工具，例如使用 systemtap 对 I/O 进行 delay 等，也在代码特定的业务的逻辑进行错误注入测试，充分保证 TiDB 在异常条件下面也能稳定运行。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（七）基于规则的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</guid>
      <description>在 TiDB 里面，SQL 优化的过程可以分为逻辑优化和物理优化两个部分。逻辑优化主要是基于规则的优化，简称 RBO（rule based optimization）。物理优化会为逻辑查询计划中的算子选择某个具体的实现，需要用到一些统计信息，决定哪一种方式代价最低，所以是基于代价的优化 CBO（cost based optimization）。
本篇将主要关注逻辑优化。先介绍 TiDB 中的逻辑算子，然后介绍 TiDB 的逻辑优化规则，包括列裁剪、最大最小消除、投影消除、谓词下推等等。
逻辑算子介绍 在写具体的优化规则之前，先简单介绍查询计划里面的一些逻辑算子。
 DataSource 这个就是数据源，也就是表，select * from t 里面的 t
 Selection 选择，例如 select xxx from t where xx = 5 里面的 where 过滤条件
 Projection 投影， select c from t 里面的取 c 列是投影操作
 Join 连接， select xx from t1, t2 where t1.c = t2.c 就是把 t1 t2 两个表做 Join
  选择，投影，连接（简称 SPJ） 是最基本的算子。其中 Join 有内连接，左外右外连接等多种连接方式。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（六）Select 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</guid>
      <description>在先前的 TiDB 源码阅读系列文章（四） 中，我们介绍了 Insert 语句，想必大家已经了解了 TiDB 是如何写入数据，本篇文章介绍一下 Select 语句是如何执行。相比 Insert，Select 语句的执行流程会更复杂，本篇文章会第一次进入优化器、Coprocessor 模块进行介绍。
表结构和语句 表结构沿用上篇文章的：
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Select 语句只会讲解最简单的情况：全表扫描+过滤，暂时不考虑索引等复杂情况，更复杂的情况会在后续章节中介绍。语句为：
SELECT name FROM t WHERE age &amp;gt; 10; 语句处理流程 相比 Insert 的处理流程，Select 的处理流程中有 3 个明显的不同：
 需要经过 Optimize
Insert 是比较简单语句，在查询计划这块并不能做什么事情（对于 Insert into Select 语句这种，实际上只对 Select 进行优化），而 Select 语句可能会无比复杂，不同的查询计划之间性能天差地别，需要非常仔细的进行优化。
 需要和存储引擎中的计算模块交互
Insert 语句只涉及对 Key-Value 的 Set 操作，Select 语句可能要查询大量的数据，如果通过 KV 接口操作存储引擎，会过于低效，必须要通过计算下推的方式，将计算逻辑发送到存储节点，就近进行处理。</description>
    </item>
    
    <item>
      <title>刘寅：TiDB 工具链和生态</title>
      <link>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</guid>
      <description>本文为今年年初 PingCAP 商业产品团队负责人刘寅在 TiDB DevCon2018 上分享的 《 TiDB 工具链和生态》实录内容，文内详细介绍了 TiDB 的周边工具以及生态系统。enjoy~
 大家下午好，我叫刘寅。在 PingCAP 主要负责 TiDB 商业工具产品开发，也在做公司 SRE 方面的事情。今天下午我分享的主题是介绍下 TiDB 的周边工具以及生态系统。
今天要讲的内容主要包含这几方面，首先是关于 TiDB 的部署，这是很多使用 TiDB 的用户首先关心的事情。接下来会介绍 TiDB 的数据导入工具和数据迁移同步工具，以及管理配置，数据可视化相关的工具。
TiDB 的架构可能大家都比较清楚了。TiDB 是一个由若干模块组成的分布式系统。这些模块相互依赖协调工作组成一个集群，整体构成了 TiDB 数据库。这样一个架构，对于用户进行部署和运维，其复杂程度相对单机数据库比如 MySQL 来说不那么容易的事情。那让我们来看看如何快速部署一套 TiDB 集群实例。最近我们公开了一个项目 pingcap/tidb-docker-compose，这令我们在一个本地的开发和测试环境上跑一套 TiDB 变得非常简单。只需要用一个命令 docker-compose up 就能快速启动起来。docker-compose 是 Docker 生态中的一个非常便利的工具，它可以在本机方便的把 TiDB 的各个组件，包括它的监控，可视化工具，全部整合在一个 yaml 文件来描述，非常的方便。不仅可以通过我们官方 docker image 镜像启动，也可以支持从本地的 binary 启动。比如当我本机编译了一个特殊版本的 binary，我就可以直接构建本地镜像来启动，甚至还可以支持现场编译源码来启动。所以这对于我们自己开发和测试也是非常方便的。另外我们也做了一个很简化的配置文件，比如我不希望默认跑 3 个 TiKV，我想启 5 个或者更多，简单的改下配置就可以搞定。
对于生产环境的部署和运维，往往面对的是一个成规模的集群，docker-compose 的部署方式就不够了。我们建议采用提供的 Ansible 部署方式。用户首先在一个 Inventory 文件中描述和编排所需的 TiDB 集群拓扑，然后执行我们提供的 ansible-playbook 脚本，就可以快速部署和运维一个生产环境下的 TiDB 集群。我们现在很多的线上用户，也是用了这样的部署方式。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第五篇，主要对 SQL Parser 功能的实现进行了讲解，内容来自社区小伙伴——马震（GitHub ID：mz1999 ）的投稿。
TiDB 源码阅读系列文章的撰写初衷，就是希望能与数据库研究者、爱好者进行深入交流，我们欣喜于如此短的时间内就收到了来自社区的反馈。后续，也希望有更多小伙伴加入到与 TiDB 『坦诚相见』的阵列中来。
 PingCAP 发布了 TiDB 的源码阅读系列文章，让我们可以比较系统的去学习了解TiDB的内部实现。最近的一篇《SQL 的一生》，从整体上讲解了一条 SQL 语句的处理流程，从网络上接收数据，MySQL 协议解析和转换，SQL 语法解析，查询计划的制定和优化，查询计划执行，到最后返回结果。
其中，SQL Parser 的功能是把 SQL 语句按照 SQL 语法规则进行解析，将文本转换成抽象语法树（AST），这部分功能需要些背景知识才能比较容易理解，我尝试做下相关知识的介绍，希望能对读懂这部分代码有点帮助。
TiDB 是使用 goyacc 根据预定义的 SQL 语法规则文件 parser.y 生成 SQL 语法解析器。我们可以在 TiDB 的 Makefile 文件中看到这个过程，先 build goyacc 工具，然后使用 goyacc 根据 parser.y 生成解析器 parser.go：
goyacc: $(GOBUILD) -o bin/goyacc parser/goyacc/main.go parser: goyacc bin/goyacc -o /dev/null parser/parser.y bin/goyacc -o parser/parser.go parser/parser.y 2&amp;gt;&amp;amp;1 ... goyacc 是 yacc 的 Golang 版，所以要想看懂语法规则定义文件 parser.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（四）Insert 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第四篇。上一篇文章简单介绍了整体流程，无论什么语句，大体上是在这个框架下运行，DDL 语句也不例外。
本篇文章会以 Insert 语句为例进行讲解，帮助读者理解前一篇文章，下一篇文章会介绍 Select 语句的执行流程。这两条是最常用的读、写语句，其他的语句相信读者能触类旁通，可以自行研究或者是等待后续的文章。对于这两类语句，目前也只会针对核心流程进行说明，更复杂的 Join、Insert-Into-OnDuplicate-Update 等会等到后面的文章进行讲解。另外本文会重点介绍每个语句在执行框架下面的具体执行逻辑，请读者阅读前先了解 Insert 语句的行为。
表结构 这里先给一个表结构，下面介绍的 SQL 语句都是在这个表上的操作。
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Insert 语句 INSERT INTO t VALUES (&amp;quot;pingcap001&amp;quot;, &amp;quot;pingcap&amp;quot;, 3); 以这条语句为例，解释 Insert 是如何运行的。
语句处理流程 首先大家回忆一下上一篇文章介绍的框架，一条 SQL 语句经过协议层、Parser、Plan、Executor 这样几个模块处理后，变成可执行的结构，再通过 Next() 来驱动语句的真正执行。对于框架，每类语句都差不多；对于每个核心步骤，每个语句会有自己的处理逻辑。
语法解析 先看 Parser，对于 Insert 语句的解析逻辑在这里，可以看到这条语句会被解析成下面这个结构：
// InsertStmt is a statement to insert new rows into an existing table. // See https://dev.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（三）SQL 的一生</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</guid>
      <description>概述 上一篇文章讲解了 TiDB 项目的结构以及三个核心部分，本篇文章从 SQL 处理流程出发，介绍哪里是入口，对 SQL 需要做哪些操作，知道一个 SQL 是从哪里进来的，在哪里处理，并从哪里返回。
SQL 有很多种，比如读、写、修改、删除以及管理类的 SQL，每种 SQL 有自己的执行逻辑，不过大体上的流程是类似的，都在一个统一的框架下运转。
框架 我们先从整体上看一下，一条语句需要经过哪些方面的工作。如果大家还记得上一篇文章所说的三个核心部分，可以想到首先要经过协议解析和转换，拿到语句内容，然后经过 SQL 核心层逻辑处理，生成查询计划，最后去存储引擎中获取数据，进行计算，返回结果。这个就是一个粗略的处理框架，本篇文章会把这个框架不断细化。
对于第一部分，协议解析和转换，所有的逻辑都在 server 这个包中，主要逻辑分为两块：一是连接的建立和管理，每个连接对应于一个 Session；二是在单个连接上的处理逻辑。第一点本文暂时不涉及，感兴趣的同学可以翻翻代码，看看连接如何建立、如何握手、如何销毁，后面也会有专门的文章讲解。对于 SQL 的执行过程，更重要的是第二点，也就是已经建立了连接，在这个连接上的操作，本文会详细讲解这一点。
对于第二部分，SQL 层的处理是整个 TiDB 最复杂的部分。这部分为什么复杂？原因有三点：
 SQL 语言本身是一门复杂的语言，语句的种类多、数据类型多、操作符多、语法组合多，这些『多』经过排列组合会变成『很多』『非常多』，所以需要写大量的代码来处理。
 SQL 是一门表意的语言，只是说『要什么数据』，而不说『如何拿数据』，所以需要一些复杂的逻辑选择『如何拿数据』，也就是选择一个好的查询计划。
 底层是一个分布式存储引擎，会面临很多单机存储引擎不会遇到的问题，比如做查询计划的时候要考虑到下层的数据是分片的、网络不通了如何处理等情况，所以需要一些复杂的逻辑处理这些情况，并且需要一个很好的机制将这些处理逻辑封装起来。这些复杂性是看懂源码比较大的障碍，所以本篇文章会尽量排除这些干扰，给大家讲解核心的逻辑是什么。
  这一层有几个核心概念，掌握了这几个也就掌握了这一层的框架，请大家关注下面这几个接口：
 Session
 RecordSet
 Plan
 LogicalPlan
 PhysicalPlan
 Executor
  下面的详细内容中，会讲解这些接口，用这些接口理清楚整个逻辑。
对于第三部分可以认为两块，第一块是 KV 接口层，主要作用是将请求路由到正确的的 KV Server，接收返回消息传给 SQL 层，并在此过程中处理各种异常逻辑；第二块是 KV Server 的具体实现，由于 TiKV 比较复杂，我们可以先看 Mock-TiKV 的实现，这里有所有的 SQL 分布式计算相关的逻辑。 接下来的几节，会对上面的三块详细展开描述。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二）初识 TiDB 源码</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第二篇，第一篇文章介绍了 TiDB 整体的架构，知道 TiDB 有哪些模块，分别是做什么的，从哪里入手比较好，哪些可以忽略，哪些需要仔细阅读。
这篇文章是一篇入门文档，难度系数比较低，其中部分内容可能大家在其他渠道已经看过，不过为了内容完整性，我们还是会放在这里。
TiDB 架构 本次 TiDB 源码之旅从这幅简单的架构图开始，这幅图很多人都看过，我们可以用一句话来描述这个图：『TiDB 是一个支持 MySQL 协议，以某种支持事务的分布式 KV 存储引擎为底层存储的 SQL 引擎』。从这句话可以看出有三个重要的事情，第一是如何支持 MySQL 协议，与 Client 交互，第二是如何与底层的存储引擎打交道，存取数据，第三是如何实现 SQL 的功能。本篇文章会先介绍一些 TiDB 有哪些模块及其功能简要介绍，然后以这三点为线索，将这些模块串联起来。
代码简介 TiDB 源码完全托管在 Github 上，从项目主页可以看到所有信息。整个项目使用 Go 语言开发，按照功能模块分了很多 Package，通过一些依赖分析工具，可以看到项目内部包之间的依赖关系。
大部分包都以接口的形式对外提供服务，大部分功能也都集中在某个包中，不过有一些包提供了非常基础的功能，会被很多包依赖，这些包需要特别注意。
项目的 main 文件在 tidb-server/main.go，这里面定义了服务如何启动。整个项目的 Build 方法可以在 Makefile 中找到。
除了代码之外，还有很多测试用例，可以在 xx_test.go 中找到。另外 cmd 目录下面还有几个工具包，用来做性能测试或者是构造测试数据。
模块介绍 TiDB 的模块非常多，这里做一个整体介绍，大家可以看到每个模块大致是做什么用的，想看相关功能的代码是，可以直接找到对应的模块。
   Package Introduction     ast 抽象语法树的数据结构定义，例如 SelectStmt 定义了一条 Select 语句被解析成什么样的数据结构   cmd/benchdb 简单的 benchmark 工具，用于性能优化   cmd/benchfilesort 简单的 benchmark 工具，用于性能优化   cmd/benchkv Transactional KV API benchmark 工具，也可以看做 KV 接口的使用样例   cmd/benchraw Raw KV API benchmark 工具，也可以看做不带事务的 KV 接口的使用样例   cmd/importer 根据表结构以及统计信息伪造数据的工具，用于构造测试数据   config 配置文件相关逻辑   context 主要包括 Context 接口，提供一些基本的功能抽象，很多包以及函数都会依赖于这个接口，把这些功能抽象为接口是为了解决包之间的依赖关系   ddl DDL 的执行逻辑   distsql 对分布式计算接口的抽象，通过这个包把 Executor 和 TiKV Client 之间的逻辑做隔离   domain domain 可以认为是一个存储空间的抽象，可以在其中创建数据库、创建表，不同的 domain 之间，可以存在相同名称的数据库，有点像 Name Space。一般来说单个 TiDB 实例只会创建一个 Domain 实例，其中会持有 information schema 信息、统计信息等。   executor 执行器相关逻辑，可以认为大部分语句的执行逻辑都在这里，比较杂，后面会专门介绍   expression 表达式相关逻辑，包括各种运算符、内建函数   expression/aggregation 聚合表达式相关的逻辑，比如 Sum、Count 等函数   infoschema SQL 元信息管理模块，另外对于 Information Schema 的操作，都会访问这里   kv KV 引擎接口以及一些公用方法，底层的存储引擎需要实现这个包中定义的接口   meta 利用 structure 包提供的功能，管理存储引擎中存储的 SQL 元信息，infoschema/DDL 利用这个模块访问或者修改 SQL 元信息   meta/autoid 用于生成全局唯一自增 ID 的模块，除了用于给每个表的自增 ID 之外，还用于生成全局唯一的 Database ID 和 Table ID   metrics Metrics 相关信息，所有的模块的 Metrics 信息都在这里   model SQL 元信息数据结构，包括 DBInfo / TableInfo / ColumnInfo / IndexInfo 等   mysql MySQL 相关的常量定义   owner TiDB 集群中的一些任务只能由一个实例执行，比如异步 Schema 变更，这个模块用于多个 tidb-server 之间协调产生一个任务执行者。每种任务都会产生自己的执行者。   parser 语法解析模块，主要包括词法解析 (lexer.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（一）序</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</guid>
      <description>在 TiDB DevCon2018 上，我们对外宣布了 TiDB 源码阅读分享活动，承诺对外发布一系列文章以及视频帮助大家理解 TiDB 源码。大家一直很关心这项活动的时间，而我们忙于新版本的开发，一直不得闲。在春节放假期间，终于有时间开始动手写这个系列。
为什么我们要做这件事情？
事情的起因是随着 TiDB 项目逐渐发展，代码日渐复杂，我们发现新入职的同学越来越难上手修改代码。我们萌生了做内部培训的想法，通过录制视频、写教程的方式，加快新同事融入的速度，做了几次之后，我们发现效果不错，除了新同学有不少收获之外，老同志们也了解了之前自己并不熟悉的模块，大家都有收获。我们想到开源社区面临同样的问题，也可以通过这项工作收益，所以萌生了把这个活动做细做大的想法，于是有了这项活动。
TiDB 作为一个开源项目，在开发过程中得到了社区的广泛关注，很多人在试用或者已经在线用 TiDB，并给出了很多很好的建议或者是问题反馈，帮助我们把项目做的更好。对于项目开发是这样，那么对于数据库技术的研究，也是这样。我们非常希望能和对数据库研究者、爱好者交流，我们在过去的两年中组织过近百场技术 Meetup 或者 Talk，在和大家的交流过程中，我们发现国内的数据库技术水平非常好，在交流过程中总能碰撞出火花。通过这项活动，我们希望能和大家做更深入的交流，通过源码阅读，让 TiDB 与大家 『坦诚相见』。
前言 学习一种系统最好的方法是阅读一些经典著作并研究一个开源项目，数据库也不例外。单机数据库领域有很多好的开源项目，MySQL、PostgreSQL 是其中知名度最高的两个，不少人看过这两个项目的代码。我们在刚做数据库的时候也看过不少 MySQL、PG 的代码，从中受益良多。但是分布式数据库方面，好的开源项目并不多，有一些知名的系统并不开源，比如 F1/Spanner，还有一些系统疏于维护或者是从开源变成闭源，比如被 Apple 收购后闭源的 FoundationDB（还好当初 clone 了一份代码 :)，参见 这里，我们在内部或者外部也组织过一些开源系统代码阅读的 Talk，不过并不系统。
TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于整个系统的复杂性，很多人并不能很好的理解整个项目。我们希望通过这一系列文章自顶向下，由浅入深，讲述 TiDB 的技术原理以及实现细节，帮助大家掌握这个项目。
背景知识 本系列文章会聚焦在 TiDB 自身，读者需要有一些基本的知识，包括但不限于：
 Go 语言，不需要精通，但是至少要能读懂代码，知道 Goroutine、Channel、Sync 等组件的使用
 数据库基础知识，了解一个单机数据库由哪些功能、哪些组件
 SQL 基础知识，知道基本的 DDL、DML 语句，事务的基本常识
 基本的后端服务知识，比如如何启动一个后台进程、RPC 是如何工作的 一些网络、操作系统的常识
 总体而言，读者需要了解基本的数据库知识以及能看懂 Go 语言程序，我相信这一点对于大多数同学来说，并不是问题。
  除了上述比较通用的知识之外，还希望读者能够看一下我之前写过的三篇文章（说存储，讲计算，论调度），了解一些 TiDB 的基本原理。
读者可以有哪些收获 通过这一系列文章可以获得什么？首先是通过了解 TiDB 的基本原理，明白一个关系型数据库的基本原理；其次通过阅读 TiDB 的代码，知道一个数据库是如何实现的，将教科书中看到的数据库原理落地。第三，了解一个数据库的实现对其行为的影响，可以更好的理解数据库为什么是这样的，并推广到其他的数据库，相信对读者用好其他数据库也有帮助。第四，可以看到一个大型的分布式系统是如何设计、构建以及优化的。最后，大家理解了 TiDB 的代码后，如果后续工作中有需求，可以引用 TiDB 的代码，目前一些公司已经在自己的产品中用到了 TiDB 的部分模块，例如 Parser。</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</guid>
      <description>2018 年 2 月 24 日，TiDB 发布 1.1 Beta 版。该版本在 1.1 Alpha 版的基础上，对 MySQL 兼容性、系统稳定性做了很多改进。
TiDB  添加更多监控项, 优化日志
 兼容更多 MySQL 语法。
 在 information_schema 中支持显示建表时间
 提速包含 MaxOneRow 算子的查询
 控制 Join 产生的中间结果集大小，进一步减少 Join 的内存使用
 增加 tidb_config session 变量，输出当前 TiDB 配置
 修复 Union 和 Index Join 算子中遇到的 panic 问题
 修复 Sort Merge Join 算子在部分场景下结果错误的问题
 修复 Show Index 语句显示正在添加过程中的索引的问题
 修复 Drop Stats 语句失败的问题</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</guid>
      <description>2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确的估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT INGORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 region size Fix 了一些调度的 bug  TiKV  支持 Raft learner 优化 Raft Snapshot，减少 IO 开销 支持 TLS 优化 RocksDB 配置，提升性能 Coprocessor 支持更多下推操作 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 TiKV-CTL 的功能 region 支持按 table 进行分裂 支持 delete range 功能 支持设置 snapshot 导致的 IO 上限 完善流控机制  源码地址：https://github.</description>
    </item>
    
    <item>
      <title>使用 Rust 构建分布式 Key-Value Store</title>
      <link>https://pingcap.com/blog-cn/rust-key-value-store/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/rust-key-value-store/</guid>
      <description>引子 构建一个分布式 Key-Value Store 并不是一件容易的事情，我们需要考虑很多的问题，首先就是我们的系统到底需要提供什么样的功能，譬如：
 一致性：我们是否需要保证整个系统的线性一致性，还是能容忍短时间的数据不一致，只支持最终一致性。
 稳定性：我们能否保证系统 7 x 24 小时稳定运行。系统的可用性是 4 个 9，还有 5 个 9？如果出现了机器损坏等灾难情况，系统能否做的自动恢复。
 扩展性：当数据持续增多，能否通过添加机器就自动做到数据再次平衡，并且不影响外部服务。
 分布式事务：是否需要提供分布式事务支持，事务隔离等级需要支持到什么程度。
  上面的问题在系统设计之初，就需要考虑好，作为整个系统的设计目标。为了实现这些特性，我们就需要考虑到底采用哪一种实现方案，取舍各个方面的利弊等。
后面，我将以我们开发的分布式 Key-Value TiKV 作为实际例子，来说明下我们是如何取舍并实现的。
TiKV TiKV 是一个分布式 Key-Value store，它使用 Rust 开发，采用 Raft 一致性协议保证数据的强一致性，以及稳定性，同时通过 Raft 的 Configuration Change 机制实现了系统的可扩展性。
TiKV 提供了基本的 KV API 支持，也就是通常的 Get，Set，Delete，Scan 这样的 API。TiKV 也提供了支持 ACID 事务的 Transaction API，我们可以使用 Begin 开启一个事务，在事务里面对 Key 进行操作，最后再用 Commit 提交一个事务，TiKV 支持 SI 以及 SSI 事务隔离级别，用来满足用户的不同业务场景。
Rust 在规划好 TiKV 的特性之后，我们就要开始进行 TiKV 的开发。这时候，我们面临的第一个问题就是采用什么样的语言进行开发。当时，摆在我们眼前的有几个选择：</description>
    </item>
    
    <item>
      <title>写在 TiDB 1.0 发布之际 | 预测未来最好的方式就是创造未来</title>
      <link>https://pingcap.com/blog-cn/ga-1.0/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/ga-1.0/</guid>
      <description>如果只能用一个词来描述此刻的心情，我想说恍如隔世，这样说多少显得有几分矫情，或许内心还是想在能矫情的时候再矫情一次，毕竟当初做这一切的起因是为了梦想。还记得有人说预测未来最好的方式就是创造未来，以前看到这句话总觉得是废话，如今看到这一切在自己身上变成现实的一刻，感受是如此的真切，敲击键盘的手居然有点颤抖，是的，预测未来最好的方式就是创造未来。
还记得刚开始做的时候，只有很少的几个人相信这个事情可以做，毕竟难度比较高，就像有些户外旅行，只有方向，没有路。从零开始到发布 1.0 版本，历时 2 年 6 个月，终于还是做出来了。这是开源精神的胜利，是真正属于工程师们的荣耀。这个过程我们一直和用户保持沟通和密切协作，从最早纯粹的为 OLTP 场景的设计，到后来迭代为 HTAP 的设计，一共经历了 7 次重构，许多看得见的汗水，看不见的心跳，也许这就是相信相信的力量，总有那么一群人顶着世俗的压力，用自己的信念和力量在改变世界。在这个过程中，质疑的声音变少了，越来越多的人从观望，到为我们鼓舞助威，帮助我们快速成长。特别感谢那些从 beta 版本开始一路相随的用户，没有你们的信任，耐心和参与，就没有今天的 PingCAP。
开心的时刻总是特别想对很多帮助和支持我们的童鞋们说声谢谢，没有你们就没有 PingCAP，特别感谢每一位项目的贡献者。也许你已经知道了，我们专门为你们定制了一面荣誉墙，那里的色彩记录了你们的每一次贡献，如果你仍在埋头工作，来不及知道，我想请你过去逛逛，不负好时光。
这个世界还是有人相信未来是可以被创造的。感谢开源精神，让我们这样一个信仰创造未来的团队，可以站在未来的入口，因为相信和努力，获得源源不绝的正向的力量。面对未来，让我们可以摒弃对未知的恐惧和对不完美的妥协。
也感谢那些曾经的诋毁和吐槽，让我们不敢懈怠，砥砺前行。
然而 1.0 版本只是个开始，是新的起点，愿我们一路相扶，不负远途。</description>
    </item>
    
    <item>
      <title>谈谈开源(一)</title>
      <link>https://pingcap.com/blog-cn/talk-about-opensource/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-about-opensource/</guid>
      <description>源码面前，了无秘密 &amp;mdash;- 侯捷
 前言 很多人的『开源』是一个比较时髦且有情怀的词汇，不少公司也把开源当做 KPI 或者是技术宣传的手段。但是在我们看来，大多数人开源做的并不好，大多数开源项目也没有被很好的维护。比如前一段时间微博上流传关于 Tengine 的讨论，一个优秀的开源项目不止是公布源代码就 OK 了，还需要后续大量的精力去维护，包括制定 RoadMap、开发新功能、和社区交流、推动项目在社区中的使用、对使用者提供一定程度的支持，等等。
目前我们在国内没看到什么特别好的文章讲如何运营一个开源项目，或者是如何做一个顶级的开源项目。TiDB 这个项目从创建到现在已经有两年多，从开发之初我们就坚定地走开源路线，陆续开源了 TiDB、TiKV、PD 这三个核心组件，获得了广泛的关注，项目在 GitHub 的 Trending 上面也多次登上首页。在这两年中，我们在这方面积累了一些经验和教训，这里和大家交流一下我们做开源过程中的一些感受，以及参与开源项目（至少是指 TiDB 相关项目）的正确姿势。
什么是开源  Open-source software (OSS) is computer software with its source code made available with a license in which the copyright holder provides the rights to study, change, and distribute the software to anyone and for any purpose.
&amp;mdash;- From Wikipedia
 本文讨论的开源是指开源软件，简而言之，开源就是拥有源代码版权的人，允许其他人在一定许可证所述范围内，访问源代码，并用于一些自己的目的。 最基本的要求就是其他人可以访问源代码，另外获取代码后能做什么，就需要一个专门的许可证来规范（可以是自己写的，也可以用一个别人写好的）。里面一般会规定诸如对修改代码、新增代码、后续工作是否需要开源以及专利相关的事项。 OK，我们写一个 main.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Spark</title>
      <link>https://pingcap.com/blog-cn/tidb-meets-spark/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-meets-spark/</guid>
      <description>本文整理自 TiSpark 项目发起人马晓宇在 Strata Data Conference 上分享的《When TiDB Meets Spark》演讲实录。
 先介绍我自己，我是 PingCAP 的马晓宇，是 TiDB OLAP 方向的负责人，也是 TiSpark 项目的发起人，主要是做 OLAP 方面的 Feature 和 Product 相关的工作，之前是网易的 Big Data Infra Team Leader，先前的经验差不多都是在 SQL、Hadoop 和所谓大数据相关的一些东西。
今天主要会讲的议程大概这么几项。
首先稍微介绍一下 TiDB 和 TiKV，因为 TiSpark 这个项目是基于它们的，所以你需要知道一下 TiDB 和 TiKV 分别是什么，才能比较好理解我们做的是什么事情。
另外正题是 TiSpark 是什么，然后 TiSpark 的架构，除了 Raw Spark 之外，我们提供了一些什么样的不一样的东西，再然后是 Use Case，最后是项目现在的状态。
首先说什么是 TiDB。你可以认为 TiDB 是现在比较火的 Spanner 的一个开源实现。它具备在线水平扩展、分布式 ACID Transaction、HA、Auto failover 等特性，是一个 NewSQL 数据库。
然后什么是 TiKV，可能我们今天要说很多次了。TiKV 其实是 TiDB 这个产品底下的数据库存储引擎，更形象，更具体一点，这是一个架构图。</description>
    </item>
    
    <item>
      <title>Linearizability 一致性验证</title>
      <link>https://pingcap.com/blog-cn/linearizability/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/linearizability/</guid>
      <description>上篇文章介绍了 TiDB 如何使用 Jepsen 来进行一致性验证，并且介绍了具体的测试案例，但是并没有对 Jepsen 背后的一致性验证算法做过多介绍。这篇文章将会深入 Jepsen 的核心库 knossos，介绍 knossos 库所涉及的 Linearizability（线性化）一致性验证算法。
Linearizability 一致性模型 什么是一致性模型？ 一致性模型确定了编写系统的程序员与系统之间的某种协议，如果程序员遵守了这种协议，那么这个系统就能提供某种一致性。常见的一致性模型有：
 Strict Consistency Linearizability (Atomic Consistency) Sequential Consistency Casual Consistency Serializability ……  需要注意的是这里的系统指并发系统，分布式系统只是其中的一类。
什么是 Linearizability？ 首先我们需要引入*历史*（history）的概念，*历史*是并发系统中由 invocation 事件和 response 事件组成的有限序列。
  invocation: &amp;lt;x op(args*) A&amp;gt;，x 表示被执行对象的名称；op 表示操作名称，如读和写；args* 表示一系列参数值；A 表示进程的名称
 response：&amp;lt;x term(res*) A&amp;gt;，term 表示结束（termination）状态；res* 表示一系列结果值
 如果 invocation 和 response 的 x（对象）和 A（进程）相同，那么我们认为它们是对应操作，并且 complete（H）表示历史中的最多成对操作
   当我们的历史 H 满足以下条件时我们把它称为*顺序化*（sequential）历史：</description>
    </item>
    
    <item>
      <title>当 TiDB 遇上 Jepsen</title>
      <link>https://pingcap.com/blog-cn/tidb-jepsen/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-jepsen/</guid>
      <description>本篇文章主要介绍 TiDB 是如何使用分布式一致性验证框架 Jepsen 进行一致性验证的。
什么是 Jepsen Jepsen 是由 Kyle Kingsbury 采用函数式编程语言 Clojure 编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统（etcd, cockroachdb&amp;hellip;）进行了“攻击”（一致性验证），并且帮助其中的部分系统找到了 bug。这里一系列的博客展示了作者的验证过程以及对于一致性验证的许多思考。
Jepsen 如何工作 Jepsen 验证系统由 6 个节点组成，一个控制节点（control node），五个被控制节点（默认为 n1, n2, n3, n4, n5），控制节点将所有指令发送到某些或全部被控制节点，这些指令包括底层的 shell 命令到上层的 SQL 语句等等。Jepsen 提供了几个核心 API 用于验证分布式系统：
 DB
DB 封装了所验证的分布式系统下载、部署、启动和关闭命令，核心函数由 setup 和 teardown 组成，在 TiDB 的 Jepsen 测试中，setup 负责下载 TiDB 并且依次启动 Placement Driver、TiKV 和 TiDB；teardown 负责关闭整个 TiDB 系统并且删除日志。
 Client
Client 封装了每一个测试所需要提供的客户，每个 client 提供两个接口：setup 和 invoke，setup 负责对 TiDB 进行连接，而 invoke 则包含了测试中 client 对 TiDB 调用的 sql 语句，具体语句依测试而定。</description>
    </item>
    
    <item>
      <title>TiSpark (Beta) 用户指南</title>
      <link>https://pingcap.com/blog-cn/tispark/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tispark/</guid>
      <description>TiSpark 是 PingCAP 推出的为了解决用户复杂 OLAP 需求的产品。借助 Spark 平台本身的优势，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP （Hybrid Transactional/Analytical Processing）需求。 TiSpark 依赖 TiKV 集群和 PD 的存在。当然，TiSpark 也需要你搭建一个 Spark 集群。本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 相关信息。
一、概述 TiSpark 是将 Spark SQL 直接运行在 TiDB 存储引擎 TiKV 上的 OLAP 解决方案。TiSpark 架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查；
 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。
 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。</description>
    </item>
    
    <item>
      <title>PAX：一个 Cache 友好高效的行列混存方案</title>
      <link>https://pingcap.com/blog-cn/pax/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pax/</guid>
      <description>今年，Spanner 终于发了另一篇 Paper 「Spanner: Becoming a SQL System」，里面提到 Spanner 使用了一种新的存储格式 - Ressi，用来支持 OLTP 和 OLAP。在 Ressi 里面，使用了 PAX 来组织数据。因为 TiDB 定位就是一个 HTAP 系统，所以我也一直在思考在 TiKV 这层如何更好的存储数据，用来满足 HTAP 的需要，既然 Spanner 使用了 PAX，那么就有研究的必要了。
PAX 的论文可以看看 「Weaving Relations for Cache Performance」 或者 「Data Page Layouts for Relational Databases on Deep Memory Hierarchies」。
NSM and DSM 在谈 PAX 之前，NSM 和 DSM 还是绕不开的话题，NSM 就是通常说的行存，对于现阶段很多偏重 OLTP 的数据，譬如 MySQL 等，都采用的这种方式存储的数据。而 DSM，则是通常的说的列存，几乎所有的 OLAP 系统，都采用的这种方式来存储的底层数据。
NSM 会将 record 依次在磁盘 page 里面存放，每个 page 的末尾会存放 record 的 offset，便于快速的定位到实际的 record。如果我们每次需要得到一行 record，或者 scan 所有 records，这种格式非常的高效。但如果我们的查询，仅仅是要拿到 record 里面的一列数据，譬如 select name from R where age &amp;lt; 40，那么对于每次 age 的遍历，除了会将无用的其他数据一起读入，每次读取 record，都可能会引起 cache miss。</description>
    </item>
    
    <item>
      <title>gRPC-rs：从 C 到 Rust</title>
      <link>https://pingcap.com/blog-cn/grpc-rs/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc-rs/</guid>
      <description>介绍 在上篇文章中，我们讲到 TiKV 为了支持 gRPC，我们造了个轮子 gRPC-rs，这篇文章简要地介绍一下这个库。首先我们来聊聊什么是 gRPC。gRPC 是 Google 推出的基于 HTTP2 的开源 RPC 框架，希望通过它使得各种微服务之间拥有统一的 RPC 基础设施。它不仅支持常规的平台如 Linux，Windows，还支持移动设备和 IoT，现有十几种语言的实现，现在又多了一种语言 Rust。
gRPC 之所以有如此多的语言支持，是因为它有一个 C 写的核心库(gRPC core)，因此只要某个语言兼容 C ABI，那么就可以通过封装，写一个该语言的 gRPC 库。Rust 对 C 有良好的支持，gRPC-rs 就是对 gRPC core ABI 的 Rust 封装。
Core 能异步处理 RPC 请求，在考虑到 Rust 中已有较为成熟的异步框架 Futures，我们决定将 API 设计成 Future 模式。
gRPC-rs 架构图
我们将根据架构图从底向上地讲一下，在上一篇文章中已经讨论过传输层和协议，在这就不再赘述。
gRPC Core Core 中有几个比较重要的对象：
 Call 以及 4 种类型 RPC： Call 代表了一次 RPC，可以派生出四种类型 RPC，
 Unary： 这是最简单的一种 RPC 模式，即一问一答，客户端发送一个请求，服务端返回一个回复，该轮 RPC 结束。 Client streaming： 这类的 RPC 会创建一个客户端到服务端的流，客户端可以通过这个流，向服务端发送多个请求，而服务端只会返回一个回复。 Server streaming： 与上面的类似，不过它会创建一个服务端到客户端的流，服务端可以发送多个回复， Bidirectional streaming： 如果说上面两类是单工，那么这类就是双工了，客户端和服务端可以同时向对方发送消息。   值得一提的是由于 gRPC 基于 HTTP2，它利用了 HTTP2 多路复用特性，使得一个 TCP 连接上可以同时进行多个 RPC，一次 RPC 即为 HTTP2 中的一个 Stream。</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 重构内建函数进度报告</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</guid>
      <description>6 月 22 日，TiDB 发布了一篇如何十分钟成为 TiDB Contributor 系列的第二篇文章，向大家介绍如何为 TiDB 重构 built-in 函数。
截止到目前，得到了来自社区的积极支持与热情反馈，TiDB 参考社区 contributors 的建议，对计算框架进行了部分修改以降低社区同学参与的难度。
本文完成以下2 项工作，希望帮助社区更好的参与进 TiDB 的项目中来:
 对尚未重写的 built-in 函数进行陈列 对继上篇文章后，计算框架所进行的修改，进行详细介绍  一. 尚未重写的 built-in 函数陈列如下： 共计 165 个 在 expression 目录下运行 grep -rn &amp;quot;^\tbaseBuiltinFunc$&amp;quot; -B 1 * | grep &amp;quot;Sig struct {&amp;quot; | awk -F &amp;quot;Sig&amp;quot; &#39;{print $1}&#39; | awk -F &amp;quot;builtin&amp;quot; &#39;{print $3}&#39; &amp;gt; ~/Desktop/func.txt 命令可以获得所有未实现的 built-in 函数
   0 1 2 3 4     Coalesce Uncompress Log10 Default UnaryOp   Greatest UncompressedLength Rand InetAton IsNull   Least ValidatePasswordStrength Pow InetNtoa In   Interval Database Round Inet6Aton Row   CaseWhen FoundRows Conv Inet6Ntoa SetVar   If CurrentUser CRC32 IsFreeLock GetVar   IfNull User Sqrt IsIPv4 Values   NullIf ConnectionID Arithmetic IsIPv4Prefixed BitCount   AesDecrypt LastInsertID Acos IsIPv6 Reverse   AesEncrypt Version Asin IsUsedLock Convert   Compress Benchmark Atan MasterPosWait Substring   Decode Charset Cot NameConst SubstringIndex   DesDecrypt Coercibility Exp ReleaseAllLocks Locate   DesEncrypt Collation PI UUID Hex   Encode RowCount Radians UUIDShort UnHex   Encrypt Regexp Truncate AndAnd Trim   OldPassword Abs Sleep OrOr LTrim   RandomBytes Ceil Lock LogicXor RTrim   SHA1 Floor ReleaseLock BitOp Rpad   SHA2 Log AnyValue IsTrueOp BitLength   Char Format FromDays DayOfWeek Timestamp   CharLength FromBase64 Hour DayOfYear AddTime   FindInSet InsertFunc Minute Week ConvertTz   Field Instr Second WeekDay MakeTime   MakeSet LoadFile MicroSecond WeekOfYear PeriodAdd   Oct Lpad Month Year PeriodDiff   Quote Date MonthName YearWeek Quarter   Bin DateDiff Now FromUnixTime SecToTime   Elt TimeDiff DayName GetFormat SubTime   ExportSet DateFormat DayOfMonth StrToDate TimeFormat   UTCTim ToSeconds TimestampDiff DateArith Extract   UnixTimestamp UTCTimestamp UTCDate Time CurrentTime   ToDays TimestampAdd TimeToSec CurrentDate SysDate    二.</description>
    </item>
    
    <item>
      <title>TiDB Best Practice</title>
      <link>https://pingcap.com/blog-cn/tidb-best-practice/</link>
      <pubDate>Wed, 05 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-best-practice/</guid>
      <description>本文档用于总结在使用 TiDB 时候的一些最佳实践，主要涉及 SQL 使用、OLAP/OLTP 优化技巧，特别是一些 TiDB 专有的优化开关。 建议先阅读讲解 TiDB 原理的三篇文章(讲存储，说计算，谈调度)，再来看这篇文章。
前言 数据库是一个通用的基础组件，在开发过程中会考虑到多种目标场景，在具体的业务场景中，需要根据业务的实际情况对数据的参数或者使用方式进行调整。
TiDB 是一个兼容 MySQL 协议和语法的分布式数据库，但是由于其内部实现，特别是支持分布式存储以及分布式事务，使得一些使用方法和 MySQL 有所区别。
基本概念 TiDB 的最佳实践与其实现原理密切相关，建议读者先了解一些基本的实现机制，包括 Raft、分布式事务、数据分片、负载均衡、SQL 到 KV 的映射方案、二级索引的实现方法、分布式执行引擎。下面会做一点简单的介绍，更详细的信息可以参考 PingCAP 公众号以及知乎专栏的一些文章。
Raft Raft 是一种一致性协议，能提供强一致的数据复制保证，TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功，这样即使丢掉少数副本，也能保证系统中还有最新的数据。比如最大 3 副本的话，每次写入 2 副本才算成功，任何时候，只丢失一个副本的情况下，存活的两个副本中至少有一个具有最新的数据。
相比 Master-Slave 方式的同步，同样是保存三副本，Raft 的方式更为高效，写入的延迟取决于最快的两个副本，而不是最慢的那个副本。所以使用 Raft 同步的情况下，异地多活成为可能。在典型的两地三中心场景下，每次写入只需要本数据中心以及离得近的一个数据中心写入成功就能保证数据的一致性，而并不需要三个数据中心都写成功。但是这并不意味着在任何场景都能构建跨机房部署的业务，当写入量比较大时候，机房之间的带宽和延迟成为关键因素，如果写入速度超过机房之间的带宽，或者是机房之间延迟过大，整个 Raft 同步机制依然无法很好的运转。
分布式事务 TiDB 提供完整的分布式事务，事务模型是在 Google Percolator 的基础上做了一些优化。具体的实现大家可以参考这篇文章。这里只说两点：
 乐观锁
TiDB 的事务模型采用乐观锁，只有在真正提交的时候，才会做冲突检测，如果有冲突，则需要重试。这种模型在冲突严重的场景下，会比较低效，因为重试之前的操作都是无效的，需要重复做。举一个比较极端的例子，就是把数据库当做计数器用，如果访问的并发度比较高，那么一定会有严重的冲突，导致大量的重试甚至是超时。但是如果访问冲突并不十分严重，那么乐观锁模型具备较高的效率。所以在冲突严重的场景下，推荐在系统架构层面解决问题，比如将计数器放在 Redis 中。
 事务大小限制
由于分布式事务要做两阶段提交，并且底层还需要做 Raft 复制，如果一个事务非常大，会使得提交过程非常慢，并且会卡住下面的 Raft 复制流程。为了避免系统出现被卡住的情况，我们对事务的大小做了限制：
 单条 KV entry 不超过 6MB KV entry 的总条数不超过 30w KV entry 的总大小不超过 100MB  在 Google 的 Cloud Spanner 上面，也有类似的限制。</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（2）- 火焰图</title>
      <link>https://pingcap.com/blog-cn/flame-graph/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/flame-graph/</guid>
      <description>在前一篇文章，我们简单提到了 perf，实际 perf 能做的事情远远不止这么少，这里就要好好介绍一下，我们在 TiKV 性能调优上面用的最多的工具 - 火焰图。
火焰图，也就是 FlameGraph，是超级大牛 Brendan Gregg 捣鼓出来的东西，主要就是将 profile 工具生成的数据进行可视化处理，方便开发人员查看。我第一次知道火焰图，应该是来自 OpenResty 的章亦春介绍，大家可以详细去看看这篇文章动态追踪技术漫谈。
之前，我的所有工作在很长一段时间几乎都是基于 Go 的，而 Go 原生提供了很多相关的 profile 工具，以及可视化方法，所以我没怎么用过火焰图。但开始用 Rust 开发 TiKV 之后，我就立刻傻眼了，Rust 可没有官方的工具来做这些事情，怎么搞？自然，我们就开始使用火焰图了。
使用火焰图非常的简单，我们仅仅需要将代码 clone 下来就可以了，我通常喜欢将相关脚本扔到 /opt/FlameGraph 下面，后面也会用这个目录举例说明。
一个简单安装的例子：
wget https://github.com/brendangregg/FlameGraph/archive/master.zip unzip master.zip sudo mv FlameGraph-master/ /opt/FlameGraph CPU 对于 TiKV 来说，性能问题最开始关注的就是 CPU，毕竟这个是一个非常直观的东西。
当我们发现 TiKV CPU 压力很大的时候，通常会对 TiKV 进行 perf，如下：
perf record -F 99 -p tikv_pid -g -- sleep 60 perf script &amp;gt; out.perf 上面，我们对一个 TiKV 使用 99 HZ 的频繁采样 60 s，然后生成对应的采样文件。然后我们生成火焰图：</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 为 TiDB 重构 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function/</guid>
      <description>这是十分钟成为 TiDB Contributor 系列的第二篇文章，让大家可以无门槛参与大型开源项目，感谢社区为 TiDB 带来的贡献，也希望参与 TiDB Community 能为你的生活带来更多有意义的时刻。
为了加速表达式计算速度，最近我们对表达式的计算框架进行了重构，这篇教程为大家分享如何利用新的计算框架为 TiDB 重写或新增 built-in 函数。对于部分背景知识请参考这篇文章，本文将首先介绍利用新的表达式计算框架重构 built-in 函数实现的流程，然后以一个函数作为示例进行详细说明，最后介绍重构前后表达式计算框架的区别。
重构 built-in 函数整体流程  在 TiDB 源码 expression 目录下选择任一感兴趣的函数，假设函数名为 XX
 重写 XXFunctionClass.getFunction() 方法
 该方法参照 MySQL 规则，根据 built-in 函数的参数类型推导函数的返回值类型 根据参数的个数、类型、以及函数的返回值类型生成不同的函数签名，关于函数签名的详细介绍见文末附录  实现该 built-in 函数对应的所有函数签名的 evalYY() 方法，此处 YY 表示该函数签名的返回值类型
 添加测试：
 在 expression 目录下，完善已有的 TestXX() 方法中关于该函数实现的测试 在 executor 目录下，添加 SQL 层面的测试  运行 make dev，确保所有的 test cast 都能跑过
  示例 这里以重写 LENGTH() 函数的 PR 为例，进行详细说明</description>
    </item>
    
    <item>
      <title>深入了解 gRPC：协议</title>
      <link>https://pingcap.com/blog-cn/grpc/</link>
      <pubDate>Sun, 18 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc/</guid>
      <description>经过很长一段时间的开发，TiDB 终于发了 RC3。RC3 版本对于 TiKV 来说最重要的功能就是支持了 gRPC，也就意味着后面大家可以非常方便的使用自己喜欢的语言对接 TiKV 了。
gRPC 是基于 HTTP/2 协议的，要深刻理解 gRPC，理解下 HTTP/2 是必要的，这里先简单介绍一下 HTTP/2 相关的知识，然后在介绍下 gRPC 是如何基于 HTTP/2 构建的。
HTTP/1.x HTTP 协议可以算是现阶段 Web 上面最通用的协议了，在之前很长一段时间，很多应用都是基于 HTTP/1.x 协议，HTTP/1.x 协议是一个文本协议，可读性非常好，但其实并不高效，笔者主要碰到过几个问题：
Parser 如果要解析一个完整的 HTTP 请求，首先我们需要能正确的读出 HTTP header。HTTP header 各个 fields 使用 \r\n 分隔，然后跟 body 之间使用 \r\n\r\n 分隔。解析完 header 之后，我们才能从 header 里面的 content-length 拿到 body 的 size，从而读取 body。
这套流程其实并不高效，因为我们需要读取多次，才能将一个完整的 HTTP 请求给解析出来，虽然在代码实现上面，有很多优化方式，譬如：
 一次将一大块数据读取到 buffer 里面避免多次 IO read 读取的时候直接匹配 \r\n 的方式流式解析  但上面的方式对于高性能服务来说，终归还是会有开销。其实最主要的问题在于，HTTP/1.</description>
    </item>
    
    <item>
      <title>来自 PingCAP CEO 的信：说在 B 轮融资完成之际</title>
      <link>https://pingcap.com/blog-cn/series-B-funding/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/series-B-funding/</guid>
      <description>平时技术说得多，今天说点走心的。
从决定出来创业到现在，刚好两年多一点，如果把 PingCAP 比喻成一个孩子的话， 刚是过了蹒跚学步的时期，前方有更大更美好的世界等我们去探索。这两年时间，在一片质疑声之中 ，TiDB 还算顽强的从无到有成长了起来。其实这一切的初心也很简单，最开始只不过是几个不愿妥协的分布式系统工程师对心目中&amp;rsquo;完美&amp;rsquo;的数据库的探索。很欣喜的看到 TiDB 的日渐成熟，周边工具和社区渐渐壮大，我感到由衷的自豪，在这个过程中，也一次又一次的挑战着技术和各自能力的边界，很庆幸能和自己的产品一起成长。
坚持做正确的事，哪怕这看起来是一条更困难的路。TiDB 从诞生的第一天起便决定开源，虽然更多的是商业上的考量，不过里面也有一点点读书人兼济天下的情怀和对传统 Hacker 精神的贯彻。在我们之前，很多人认为分布式 OLTP 和 OLAP 融合几乎是不可能的事情，也有无数的人，其中不乏亲朋好友，劝我们说在国内做这个事情几乎难于登天，而且没有成功的先例。不过我们还是相信一个朴素道理，有价值的技术一定会有它的舞台，另外，任何事情如果没有尝试就打退堂鼓也不是我们的风格。如果没有成功的先例，那就一起来创造先例，做开创者是我们每个人的梦想。说实话，从技术上来说，这个领域是一个非常前沿的领域，大多数时候我们面前是无人区，也很幸运，目前看来技术上和预想的没有出现大的偏差，整个产品和团队也在稳步的前进。
整个团队也从一开始的 3 个人，到今天 63 个志同道合的伙伴结伴前行，又一次很幸运，能凑齐这么一个具有很强战斗力和国际视野的团队，挑战计算机领域最困难和最前沿的课题之一，前方还有无数个迷人的问题等待着被解决，有时候也只能摸索着前进，不过这正是这个事情有意思的地方。谢谢你们，和你们一同工作，是我的荣幸。
到今天，我们很自豪的宣布，已经有数十家客户将 TiDB 使用在各自的生产环境中解决问题，感谢我们早期的铁杆用户和可爱的社区开发者，是你们让 TiDB 一点点的变得更加稳定成熟，随着社区的不断变大，TiDB 正以惊人的速度正向迭代，这就是开源的力量。
最后，PingCAP 也刚顺利的完成了 1500 万美金的 B 轮融资，感谢这轮的领投方华创资本，以及跟投方经纬中国，云启资本，峰瑞资本，险峰华兴。我们的征途是星辰大海，感谢有你们的一路支持。
刘奇、黄东旭、崔秋
PingCAP
2017-6-13</description>
    </item>
    
    <item>
      <title>使用 Ansible 安装部署 TiDB</title>
      <link>https://pingcap.com/blog-cn/deployment-by-ansible/</link>
      <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/deployment-by-ansible/</guid>
      <description>背景知识 TiDB 作为一个分布式数据库，在多个节点分别配置安装服务会相当繁琐，为了简化操作以及方便管理，使用自动化工具来批量部署成为了一个很好的选择。
Ansible 是基于 Python 研发的自动化运维工具，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能，而且使用简单，仅需在管理工作站上安装 Ansible 程序配置被管控主机的 IP 信息，被管控的主机无客户端。基于以上原因，我们选用自动化工具 Ansible 来批量的安装配置以及部署 TiDB。
下面我们来介绍如何使用 Ansible 来部署 TiDB。
TiDB 安装环境配置如下 操作系统使用 CentOS7.2 或者更高版本，文件系统使用 EXT4。
 说明：低版本的操作系统(例如 CentOS6.6 )和 XFS 文件系统会有一些内核 Bug，会影响性能，我们不推荐使用。
    IP Services     192.168.1.101 PD Prometheus Grafana Pushgateway Node_exporter   192.168.1.102 PD TiDB Node_exporter   192.168.1.103 PD TiDB Node_exporter   192.168.1.104 TiKV Node_exporter   192.168.1.105 Tikv Node_exporter   192.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 谈调度</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-3/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-3/</guid>
      <description>为什么要进行调度 先回忆一下第一篇文章提到的一些信息，TiKV 集群是 TiDB 数据库的分布式 KV 存储引擎，数据以 Region 为单位进行复制和管理，每个 Region 会有多个 Replica（副本），这些 Replica 会分布在不同的 TiKV 节点上，其中 Leader 负责读/写，Follower 负责同步 Leader 发来的 raft log。了解了这些信息后，请思考下面这些问题：
 如何保证同一个 Region 的多个 Replica 分布在不同的节点上？更进一步，如果在一台机器上启动多个 TiKV 实例，会有什么问题？ TiKV 集群进行跨机房部署用于容灾的时候，如何保证一个机房掉线，不会丢失 Raft Group 的多个 Replica？ 添加一个节点进入 TiKV 集群之后，如何将集群中其他节点上的数据搬过来? 当一个节点掉线时，会出现什么问题？整个集群需要做什么事情？如果节点只是短暂掉线（重启服务），那么如何处理？如果节点是长时间掉线（磁盘故障，数据全部丢失），需要如何处理？ 假设集群需要每个 Raft Group 有 N 个副本，那么对于单个 Raft Group 来说，Replica 数量可能会不够多（例如节点掉线，失去副本），也可能会 过于多（例如掉线的节点又回复正常，自动加入集群）。那么如何调节 Replica 个数？ 读/写都是通过 Leader 进行，如果 Leader 只集中在少量节点上，会对集群有什么影响？ 并不是所有的 Region 都被频繁的访问，可能访问热点只在少数几个 Region，这个时候我们需要做什么？ 集群在做负载均衡的时候，往往需要搬迁数据，这种数据的迁移会不会占用大量的网络带宽、磁盘 IO 以及 CPU？进而影响在线服务？  这些问题单独拿出可能都能找到简单的解决方案，但是混杂在一起，就不太好解决。有的问题貌似只需要考虑单个 Raft Group 内部的情况，比如根据副本数量是否足够多来决定是否需要添加副本。但是实际上这个副本添加在哪里，是需要考虑全局的信息。整个系统也是在动态变化，Region 分裂、节点加入、节点失效、访问热点变化等情况会不断发生，整个调度系统也需要在动态中不断向最优状态前进，如果没有一个掌握全局信息，可以对全局进行调度，并且可以配置的组件，就很难满足这些需求。因此我们需要一个中心节点，来对系统的整体状况进行把控和调整，所以有了 PD 这个模块。</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（1）</title>
      <link>https://pingcap.com/blog-cn/iostat-perf-strace/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/iostat-perf-strace/</guid>
      <description>使用 iostat 定位磁盘问题 在一个性能测试集群，我们选择了 AWS c3.4xlarge 机型，主要是为了在一台机器的两块盘上面分别跑 TiKV。在测试一段时间之后，我们发现有一台 TiKV 响应很慢，但是 RocksDB 并没有相关的 Stall 日志，而且慢查询也没有。
于是我登上 AWS 机器，使用 iostat -d -x -m 5 命令查看，得到如下输出：
Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 xvdb 8.00 12898.00 543.00 579.00 31.66 70.15 185.84 51.93 54.39 7.03 98.79 0.60 66.80 xvdc 0.00 0.00 206.00 1190.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说计算</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-2/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-2/</guid>
      <description>关系模型到 Key-Value 模型的映射 在这我们将关系模型简单理解为 Table 和 SQL 语句，那么问题变为如何在 KV 结构上保存 Table 以及如何在 KV 结构上运行 SQL 语句。 假设我们有这样一个表的定义：
CREATE TABLE User { ID int, Name varchar(20), Role varchar(20), Age int, PRIMARY KEY (ID)， Key idxAge (age) }; SQL 和 KV 结构之间存在巨大的区别，那么如何能够方便高效地进行映射，就成为一个很重要的问题。一个好的映射方案必须有利于对数据操作的需求。那么我们先看一下对数据的操作有哪些需求，分别有哪些特点。
对于一个 Table 来说，需要存储的数据包括三部分：
 表的元信息 Table 中的 Row 索引数据  表的元信息我们暂时不讨论，会有专门的章节来介绍。 对于 Row，可以选择行存或者列存，这两种各有优缺点。TiDB 面向的首要目标是 OLTP 业务，这类业务需要支持快速地读取、保存、修改、删除一行数据，所以采用行存是比较合适的。
对于 Index，TiDB 不止需要支持 Primary Index，还需要支持 Secondary Index。Index 的作用的辅助查询，提升查询性能，以及保证某些 Constraint。查询的时候有两种模式，一种是点查，比如通过 Primary Key 或者 Unique Key 的等值条件进行查询，如 select name from user where id=1; ，这种需要通过索引快速定位到某一行数据；另一种是 Range 查询，如 select name from user where age &amp;gt; 30 and age &amp;lt; 35;，这个时候需要通过idxAge索引查询 age 在 20 和 30 之间的那些数据。Index 还分为 Unique Index 和 非 Unique Index，这两种都需要支持。</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说存储</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-1/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-1/</guid>
      <description>引言 数据库、操作系统和编译器并称为三大系统，可以说是整个计算机软件的基石。其中数据库更靠近应用层，是很多业务的支撑。这一领域经过了几十年的发展，不断的有新的进展。
很多人用过数据库，但是很少有人实现过一个数据库，特别是实现一个分布式数据库。了解数据库的实现原理和细节，一方面可以提高个人技术，对构建其他系统有帮助，另一方面也有利于用好数据库。
研究一门技术最好的方法是研究其中一个开源项目，数据库也不例外。单机数据库领域有很多很好的开源项目，其中 MySQL 和 PostgreSQL 是其中知名度最高的两个，不少同学都看过这两个项目的代码。但是分布式数据库方面，好的开源项目并不多。 TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于分布式数据库自身的复杂性，很多人并不能很好的理解整个项目，所以我希望能写一些文章，自顶向上，由浅入深，讲述 TiDB 的一些技术原理，包括用户可见的技术以及大量隐藏在 SQL 界面后用户不可见的技术点。
保存数据 数据库最根本的功能是能把数据存下来，所以我们从这里开始。
保存数据的方法很多，最简单的方法是直接在内存中建一个数据结构，保存用户发来的数据。比如用一个数组，每当收到一条数据就向数组中追加一条记录。这个方案十分简单，能满足最基本，并且性能肯定会很好，但是除此之外却是漏洞百出，其中最大的问题是数据完全在内存中，一旦停机或者是服务重启，数据就会永久丢失。
为了解决数据丢失问题，我们可以把数据放在非易失存储介质（比如硬盘）中。改进的方案是在磁盘上创建一个文件，收到一条数据，就在文件中 Append 一行。OK，我们现在有了一个能持久化存储数据的方案。但是还不够好，假设这块磁盘出现了坏道呢？我们可以做 RAID （Redundant Array of Independent Disks），提供单机冗余存储。如果整台机器都挂了呢？比如出现了火灾，RAID 也保不住这些数据。我们还可以将存储改用网络存储，或者是通过硬件或者软件进行存储复制。到这里似乎我们已经解决了数据安全问题，可以松一口气了。But，做复制过程中是否能保证副本之间的一致性？也就是在保证数据不丢的前提下，还要保证数据不错。保证数据不丢不错只是一项最基本的要求，还有更多令人头疼的问题等待解决：
 能否支持跨数据中心的容灾？ 写入速度是否够快？ 数据保存下来后，是否方便读取？ 保存的数据如何修改？如何支持并发的修改？ 如何原子地修改多条记录？  这些问题每一项都非常难，但是要做一个优秀的数据存储系统，必须要解决上述的每一个难题。 为了解决数据存储问题，我们开发了 TiKV 这个项目。接下来我向大家介绍一下 TiKV 的一些设计思想和基本概念。
Key-Value 作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。简单来讲，可以将 TiKV 看做一个巨大的 Map，其中 Key 和 Value 都是原始的 Byte 数组，在这个 Map 中，Key 按照 Byte 数组总的原始二进制比特位比较顺序排列。 大家这里需要对 TiKV 记住两点：
 这是一个巨大的 Map，也就是存储的是 Key-Value pair 这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是我们可以 Seek 到某一个 Key 的位置，然后不断的调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value  讲了这么多，有人可能会问了，这里讲的存储模型和 SQL 中表是什么关系？在这里有一件重要的事情要说四遍：</description>
    </item>
    
    <item>
      <title>基于 Tile 连接 Row-Store 和 Column-Store</title>
      <link>https://pingcap.com/blog-cn/tile-row-store/</link>
      <pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tile-row-store/</guid>
      <description>在之前的 Kudu 的文章里面，我已经提到过，行列混存是一个非常有意思的研究方向，因为不同的存储方式有不同的针对应用场景，但作为技术人员，折腾是天性，所以大家都在研究如何融合行存和列存，让一个服务能尽量满足大部分应用需求，而这也是 TiDB 在努力的方向。
在 Kudu Paper 里面说到，Kudu 首先在 mem 里面使用行存，但刷到硬盘之后，则使用的是列存，这当然是一个可以尝试的方式，但我觉得应该还有更多种的解决方式，于是找到了 CMU 的 Peloton 以及相关的 Paper，觉得有必要研究记录一下。
Storage Model 很多时候，我喜欢用行存和列存，但看 Paper 的时候，发现都喜欢使用 NSM 和 DSM 来说明，这里就简单说明一下。
NSM NSM 是 N-ary storage model 的简称，当然就是通常的行存了。NSM 主要针对 OLTP 场景，因为需要高性能的随机写入，NSM 的存储方式如下：
NSM 不适用需要读取大量数据，并分析特定 column 的场景，因为 NSM 需要把整个 record 给读出来，在拿到对应的 column 数据分析，数据数据量很大，整个开销会很大。
DSM DSM 是 decomposition storage model 的简称，也就是列存。DSM 主要针对 OLAP 场景，因为需要对一些特定的 column 进行快速扫描分析，DSM 的存储方式如下：
DSM 当然就不适用与需要频繁随机更新的情况，因为任何写入，DSM 需要将 record 分开写入到不同的地方，写开销会很大。
FSM 为了解决这个问题，就有了一个 FSM flexible storage model 来融合 NSM 和 DSM，在 Peloton 里面，它把这套系统叫做 HTAP (Hybrid Transactional/Analytical Processing)，</description>
    </item>
    
    <item>
      <title>Kudu - 一个融合低延迟写入和高性能分析的存储系统</title>
      <link>https://pingcap.com/blog-cn/kudu/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/kudu/</guid>
      <description>Kudu 是一个基于 Raft 的分布式存储系统，它致力于融合低延迟写入和高性能分析这两种场景，并且能很好的嵌入到 Hadoop 生态系统里面，跟其他系统譬如 Cloudera Impala，Apache Spark 等对接。
Kudu 很类似 TiDB。最开始，TiDB 是为了 OLTP 系统设计的，但后来发现我们 OLAP 的功能也越来越强大，所以就有了融合 OLTP 和 OLAP 的想法，当然这条路并不是那么容易，我们还有很多工作要做。因为 Kudu 的理念跟我们类似，所以我也很有兴趣去研究一下它，这里主要是依据 Kudu 在 2015 发布的 paper，因为 Kudu 是开源的，并且在不断的更新，所以现在代码里面一些实现可能还跟 paper 不一样了，但这里仅仅先说一下我对 paper 的理解，实际的代码我后续研究了在详细说明。
为什么需要 Kudu？ 结构化数据存储系统在 Hadoop 生态系统里面，通常分为两类：
 静态数据，数据通常都是使用二进制格式存放到 HDFS 上面，譬如 Apache Avro，Apache Parquet。但无论是 HDFS 还是相关的系统，都是为高吞吐连续访问数据这些场景设计的，都没有很好的支持单独 record 的更新，或者是提供好的随机访问的能力。
 动态数据，数据通常都是使用半结构化的方式存储，譬如 Apache HBase，Apache Cassandra。这些系统都能低延迟的读写单独的 record，但是对于一些像 SQL 分析这样需要连续大量读取数据的场景，显得有点捉紧见拙。
  上面的两种系统，各有自己的侧重点，一类是低延迟的随机访问特定数据，而另一类就是高吞吐的分析大量数据。之前，我们并没有这样的系统可以融合上面两种情况，所以通常的做法就是使用 pipeline，譬如我们非常熟悉的 Kafka，通常我们会将数据快速写到 HBase 等系统里面，然后通过 pipeline，在导出给其它分析系统。虽然我们在一定层面上面，我们其实通过 pipeline 来对整个系统进行了解耦，但总归要维护多套系统。而且数据更新之后，并不能直接实时的进行分析处理，有延迟的开销。所以在某些层面上面，并不是一个很好的解决方案。</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：Cloud-Native 的分布式数据库架构与实践</title>
      <link>https://pingcap.com/blog-cn/talk-cloud-native/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-cloud-native/</guid>
      <description>4 月 19 日，我司 CTO 黄东旭同学在全球云计算开源大会上，发表了《Cloud-Native 的分布式数据库架构与实践》主题演讲，以下为演讲实录。
实录 大家好，今天我的题目是 Cloud-Native 与分布式数据库的实践。先简单的介绍一下自己，我是 PingCAP 的联合创始人和 CTO，过去一直在做基础软件领域的工程师，基本上做的所有的东西都是开源。在分享之前我想说一下为什么现在各行各业或者整个技术软件社区一直在重复的再造数据库，现在数据库到底怎么了，为什么这么百花齐放？
 首先随着业务的多种多样，还有不管是传统行业还是互联网行业，业务的迭代速度越来越互联网化，使得整个数据量其实是一直在往上走的；
 第二就是随着 IOT 的设备还有包括像手机、移动互联网蓬勃的发展，终端其实也不再仅仅是传统的 PC 客户端的数据的接入；
 第三方面随着现在 AI 或者大数据分析一些模型或者理论上的突破，使得在大数据上进行计算的手段越来越多样，还有在物理上一些硬件的新的带有保护的内存，各种各样新的物理的设备，越来越多的硬件或者物理上的存储成本持续的降低，使得我们的数据库需要要面对更多的挑战。
  关联数据库理论是上世纪七十年代做出来的东西，现在四十年过去不管是物理的环境还是计算模型都是完全不一样的阶段，还抱着过去这种观念可能并不是一个面向未来的设计。而且今天我的题目是 Cloud-Native，有一个比较大胆的假设，大家在过去三十年的计算平台基本都是在一台 PC 或者一个服务器或者一个手机这样的独立的计算平台，但是未来我觉得一切的服务都应该是分布式的。因为我觉得摩尔定律已经失效了，所以未来的操作系统会是一个大规模分布式的操作系统，在上面跑的任何的进程，任何的服务都应该是分布式的，在这个假设下怎么去做设计，云其实是这个假设最好的载体。怎么在这个假设上去设计面向云的技术软件，其实是最近我一直在思考的一个问题。其实在这个时代包括面向云的软件，对业务开发来说尽量还是不要太多的改变过去的开发习惯。你看最近大数据的发展趋势，从最传统的关系数据库到过去十年相比，整个改变了用户的编程模型，但是改变到底是好的还是不好的，我个人觉得其实并不是太好。最近这两年大家会看到整个学术圈各种各样的论文都在回归，包括 DB 新时代的软件都会把扩展性和分布式放在第一个要素。
大家可能听到主题会有点蒙，叫 Cloud-Native，Cloud-Native 是什么？其实很早的过去也不是没有人做过这种分布式系统的尝试，最早是 IBM 提出面向服务的软件架构设计，最近热门的 SOA、Micro Service 把自己的服务拆分成小的服务，到现在谷歌一直对外输出一个观点就是 Cloud-Native，就是未来大家的业务看上去的分布式会变成一个更加透明的概念，就是你怎么让分布式的复杂性消失在云的基础设施后，这是 Cloud-Native 更加关心的事情。
这个图是 CNCF 的一个基金会，也是谷歌支持的基金会上扒过来的图。这里面有一个简单的定义，就是 SCALE 作为一等公民，面向 Cloud-Native 的业务必须是弹性伸缩的，不仅能伸也得能缩；第二就是在对于这种 Cloud-Native 业务来说是面向 Micro service 友好；第三就是部署更加的去人工化。
最近大家可能也看到很多各种各样容器化的方案，背后代表的意义是什么？就是整个运维和部署脱离人工，大家可以想象过去十几二十年来，一直以来运维的手段是什么样的。我找了一个运维，去买服务器，买服务器装系统，在上面部署业务。但是现在 Cloud-Native 出现变得非常的自动化，就相当于把人的功能变得更低，这是很有意义的，因为理想中的世界或者未来的世界应该怎么样，一个业务可能会有成百上千的物理节点，如果是人工的去做运维和部署是根本不可能做得到的，所以其实构建整个 Cloud-Native 的基础设施的两个条件：第一个就是存储本身的云化；第二就是运维要和部署的方式必须是云化的。
我就从这两个点说一下我们 TiDB 在上面的一些工作和一些我的思考。
存储本身的云化有几个基本条件，大家过去认为是高可用，主要停留在双活。其实仔细去思考的话，主备的方案是很难保证数据在完全不需要人工的介入情况下数据的一致性可用性的，所以大家会发现最近这几年出来的分布式存储系统的可用性的协议跟复制协议基本都会用类似 Raft/Paxos 基于选取的一致性算法，不会像过去做这种老的复制的方案。
第二就是整个分片的策略，作为分布式系统数据一定是会分片的，数据分片是来做分布式存储唯一的思路，自动分片一定会取代传统的人工分片来去支撑业务。比如传统分片，当你的数据量越来越大，你只能做分库分表或者用中间件，不管你分库分表还是中间件都必须制订自己人工的分辨规则，但是其实在一个真正面向 Cloud 的数据库设计里，任何一种人的介入的东西都是不对的。</description>
    </item>
    
    <item>
      <title>如何从零开始参与大型开源项目</title>
      <link>https://pingcap.com/blog-cn/how-to-contribute/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-contribute/</guid>
      <description>写在前面的话 上世纪 70 年代，IBM 发明了关系型数据库。但是随着现在移动互联网的发展，接入设备越来越多，数据量越来越大，业务越来越复杂，传统的数据库显然已经不能满足海量数据存储的需求。虽然目前市场上也不乏分布式数据库模型，但没有品位的文艺青年不是好工程师，我们觉得，不，这些方案都不是我们想要的，它们不够美，鲜少能够把分布式事务与弹性扩展做到完美。
受 Google Spanner/F1 的启发，一款从一开始就选择了开源道路的 TiDB 诞生了。 它是一款代表未来的新型分布式 NewSQL 数据库，它可以随着数据增长而无缝水平扩展，只需要通过增加更多的机器来满足业务增长需求，应用层可以不用关心存储的容量和吞吐，用东旭的话说就是「他自己会生长」。
在开源的世界里，TiDB 和 TiKV 吸引了更多的具有极客气质的开发者，目前已经拥有超过 9000 个 star 和 100 个 contributor，这已然是一个世界顶级开源项目的水准。而成就了这一切的，则是来自社区的力量。
最近我们收到了很多封这样的邮件和留言，大家说：
 谢谢你们，使得旁人也能接触大型开源项目。本身自己是DBA，对数据库方面较干兴趣，也希望自己能逐步深入数据库领域，深入TiDB，为 TiDB 社区贡献更多、更有价值的力量。
 我是一个在校学生，刚刚收到邮件说我成为了 TiDB 的 Contributor，这让我觉得当初没听父母的话坚持了自己喜欢的计算机技术，是个正确的选择，但我还需要更多的历练，直到能完整地展现、表达我的思维。
  这让我感触颇多，因为，应该是我们感谢你们才是啊，没有社区，一个开源项目就成不了一股清泉甚至一汪海洋。 公司的小姑娘说，她觉得还有很多的人想要参与进来的，可工程师团队欠缺平易近人的表达，这个得改。
于是便有了这篇文章以及未来的多篇文章和活动，我们欢迎所有的具有气质的开发者能和 TiDB 一起成长，一起见证数据库领域的革新，改变世界这事儿有时候也不那么难。
我要重点感谢今天这篇文章的作者，来自社区的朱武（GitHub ID:viile ）、小卢（GitHub ID:lwhhhh ）和杨文（GitHub ID: yangwenmai），当在 TiDB Contributor Club 里提到想要做这件事的时候，是他们踊跃地加入了 TiDB Tech Writer 的队伍，高效又专业地完成了下文的编辑，谢谢你们。
一个典型的开源项目是由什么组成的 The Community（社区）  一个项目经常会有一个围绕着它的社区，这个社区由各个承担不同角色的用户组成。
 项目的拥有者：在他们账号中创建项目并拥有它的用户或者组织。
 维护者和合作者：主要做项目相关的工作和推动项目发展，通常情况下拥有者和维护者是同一个人，他们拥有仓库的写入权限。
 贡献者：发起拉取请求 (pull request) 并且被合并到项目里面的人。</description>
    </item>
    
    <item>
      <title>十分钟成为 TiDB Contributor 系列 | 添加內建函数</title>
      <link>https://pingcap.com/blog-cn/add-a-built-in-function/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/add-a-built-in-function/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后首先会经过 parser，从文本 parse 成为 AST（抽象语法树），通过 Query Optimizer 生成执行计划，得到一个可以执行的 plan，通过执行这个 plan 即可得到结果，这期间会涉及到如何获取 table 中的数据，如何对数据进行过滤、计算、排序、聚合、滤重以及如何对表达式进行求值。 对于一个 builtin 函数，比较重要的是进行语法解析以及如何求值。其中语法解析部分需要了解如何写 yacc 以及如何修改 TiDB 的词法解析器，较为繁琐，我们已经将这部分工作提前做好，大多数 builtin 函数的语法解析工作已经做完。 对 builtin 函数的求值需要在 TiDB 的表达式求值框架下完成，每个 builtin 函数被认为是一个表达式，用一个 ScalarFunction 来表示，每个 builtin 函数通过其函数名以及参数，获取对应的函数类型以及函数签名，然后通过函数签名进行求值。 总体而言，上述流程对于不熟悉 TiDB 的朋友而言比较复杂，我们对这部分做了些工作，将一些流程性、较为繁琐的工作做了统一处理，目前已经将大多数未实现的 buitlin 函数的语法解析以及寻找函数签名的工作完成，但是函数实现部分留空。换句话说，只要找到留空的函数实现，将其补充完整，即可作为一个 PR。
添加 builtin 函数整体流程  找到未实现的函数
在 TiDB 源码中的 expression 目录下搜索 errFunctionNotExists，即可找到所有未实现的函数，从中选择一个感兴趣的函数，比如 SHA2 函数：
func (b *builtinSHA2Sig) eval(row []types.Datum) (d types.Datum, err error) { return d, errFunctionNotExists.GenByArgs(&amp;#34;SHA2&amp;#34;) } 实现函数签名</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Raft 的优化</title>
      <link>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 07 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</guid>
      <description>在分布式领域，为了保证数据的一致性，通常都会使用 Paxos 或者 Raft 来实现。但 Paxos 以其复杂难懂著称，相反 Raft 则是非常简单易懂，所以现在很多新兴的数据库都采用 Raft 作为其底层一致性算法，包括我们的 TiKV。
当然，Raft 虽然简单，但如果单纯的按照 Paper 的方式去实现，性能是不够的。所以还需要做很多的优化措施。本文假定用户已经熟悉并了解过 Raft 算法，所以对 Raft 不会做过多说明。
Simple Request Flow 这里首先介绍一下一次简单的 Raft 流程：
 Leader 收到 client 发送的 request。 Leader 将 request append 到自己的 log。 Leader 将对应的 log entry 发送给其他的 follower。 Leader 等待 follower 的结果，如果大多数节点提交了这个 log，则 apply。 Leader 将结果返回给 client。 Leader 继续处理下一次 request。  可以看到，上面的流程是一个典型的顺序操作，如果真的按照这样的方式来写，那性能是完全不行的。
Batch and Pipeline 首先可以做的就是 batch，大家知道，在很多情况下面，使用 batch 能明显提升性能，譬如对于 RocksDB 的写入来说，我们通常不会每次写入一个值，而是会用一个 WriteBatch 缓存一批修改，然后在整个写入。 对于 Raft 来说，Leader 可以一次收集多个 requests，然后一批发送给 Follower。当然，我们也需要有一个最大发送 size 来限制每次最多可以发送多少数据。</description>
    </item>
    
    <item>
      <title>TiDB 的正确使用姿势</title>
      <link>https://pingcap.com/blog-cn/how-to-use-tidb/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-use-tidb/</guid>
      <description>最近这几个月，特别是 TiDB RC1 发布后，越来越多的用户已经开始测试起来，也有很多朋友已经在生产环境中使用，我们这边也陆续的收到了很多用户的测试和使用反馈。非常感谢各位小伙伴和早期用户的厚爱，而且看了这么多场景后，也总结出了一些 TiDB 的使用实践 (其实 Spanner 的最佳实践大部分在 TiDB 中也是适用的，MySQL 最佳实践也是），也是借着 Google Cloud Spanner 发布的东风，看了一下 Spanner 官方的一些最佳实践文档，写篇文章讲讲 TiDB 以及分布式关系型数据库的一些正确的使用姿势，当然，时代也在一直发展，TiDB 也在不停的进化，这篇文章基本上只代表近期的一些观察。
 首先谈谈 Schema 设计的一些比较好的经验。由于 TiDB 是一个分布式的数据库，可能在表结构设计的时候需要考虑的事情和传统的单机数据库不太一样，需要开发者能够带着「这个表的数据会分散在不同的机器上」这个前提，才能做更好的设计。
和 Spanner 一样，TiDB 中的一张表的行（Rows）是按照主键的字节序排序的（整数类型的主键我们会使用特定的编码使其字节序和按大小排序一致），即使在 CREATE TABLE 语句中不显式的创建主键，TiDB 也会分配一个隐式的。 有四点需要记住： 1. 按照字节序的顺序扫描的效率是比较高的； 2. 连续的行大概率会存储在同一台机器的邻近位置，每次批量的读取和写入的效率会高； 3. 索引是有序的（主键也是一种索引），一行的每一列的索引都会占用一个 KV Pair，比如，某个表除了主键有 3 个索引，那么在这个表中插入一行，对应在底层存储就是 4 个 KV Pairs 的写入：数据行以及 3 个索引行。 4. 一行的数据都是存在一个 KV Pair 中，不会被切分，这点和类 BigTable 的列式存储很不一样。
表的数据在 TiDB 内部会被底层存储 TiKV 切分成很多 64M 的 Region（对应 Spanner 的 Splits 的概念），每个 Region 里面存储的都是连续的行，Region 是 TiDB 进行数据调度的单位，随着一个 Region 的数据量越来越大和时间的推移，Region 会分裂/合并，或者移动到集群中不同的物理机上，使得整个集群能够水平扩展。</description>
    </item>
    
    <item>
      <title>Spanner - CAP, TrueTime and Transaction</title>
      <link>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</guid>
      <description>最近非常关注的一件事情就是 Google Spanner Cloud 的发布，这应该算是 NewSQL 又一个里程碑的事件。NewSQL 的概念应该就是在 12 年 Google Spanner 以及 F1 的论文发表之后，才开始慢慢流行，然后就开始有企业尝试根据 paper 做自己的 NewSQL，譬如国外的 CockroachDB 以及国内我们 PingCAP。
Spanner 的论文在很早就发布了，国内也有很多中文翻译，这里笔者只是想聊聊自己对 Spanner 的理解，以及 Spanner 的一些关键技术的实现，以及跟我们自己的 TiDB 的相关对比。
CAP 在分布式领域，CAP 是一个完全绕不开的东西，大家应该早就非常熟悉，这里笔者只是简单的再次说明一下：
 C：一致性，也就是通常说的线性一致性，假设在 T 时刻写入了一个值，那么在 T 之后的读取一定要能读到这个最新的值。 A：完全 100% 的可用性，也就是无论系统发生任何故障，都仍然能对外提供服务。 P：网络分区容忍性。  在分布式环境下面，P 是铁定存在的，也就是只要我们有多台机器，那么网络隔离分区就一定不可避免，所以在设计系统的时候我们就要选择到底是设计的是 AP 系统还是 CP 系统，但实际上，我们只要深入理解下 CAP，就会发现其实有时候系统设计上面没必要这么纠结，主要表现在：
 网络分区出现的概率很低，所以我们没必要去刻意去忽略 C 或者 A。多数时候，应该是一个 CA 系统。 CAP 里面的 A 是 100% 的可用性，但实际上，我们只需要提供 high availability，也就是仅仅需要满足 99.99% 或者 99.999% 等几个 9 就可以了。  Spanner 是一个 CP + HA 系统，官方文档说的可用性是优于 5 个 9 ，稍微小于 6 个 9，也就是说，Spanner 在系统出现了大的故障的情况下面，大概 31s+ 的时间就能够恢复对外提供服务，这个时间是非常短暂的，远远比很多外部的系统更加稳定。然后鉴于 Google 强大的自建网络，P 很少发生，所以 Spanner 可以算是一个 CA 系统。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Lease Read</title>
      <link>https://pingcap.com/blog-cn/lease-read/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/lease-read/</guid>
      <description>Raft log read TiKV 是一个要保证线性一致性的分布式 KV 系统，所谓线性一致性，一个简单的例子就是在 t1 的时间我们写入了一个值，那么在 t1 之后，我们的读一定能读到这个值，不可能读到 t1 之前的值。
因为 Raft 本来就是一个为了实现分布式环境下面线性一致性的算法，所以我们可以通过 Raft 非常方便的实现线性 read，也就是将任何的读请求走一次 Raft log，等这个 log 提交之后，在 apply 的时候从状态机里面读取值，我们就一定能够保证这个读取到的值是满足线性要求的。
当然，大家知道，因为每次 read 都需要走 Raft 流程，所以性能是非常的低效的，所以大家通常都不会使用。
我们知道，在 Raft 里面，节点有三个状态，leader，candidate 和 follower，任何 Raft 的写入操作都必须经过 leader，只有 leader 将对应的 raft log 复制到 majority 的节点上面，我们才会认为这一次写入是成功的。所以我们可以认为，如果当前 leader 能确定一定是 leader，那么我们就可以直接在这个 leader 上面读取数据，因为对于 leader 来说，如果确认一个 log 已经提交到了大多数节点，在 t1 的时候 apply 写入到状态机，那么在 t1 之后后面的 read 就一定能读取到这个新写入的数据。
那么如何确认 leader 在处理这次 read 的时候一定是 leader 呢？在 Raft 论文里面，提到了两种方法。</description>
    </item>
    
    <item>
      <title>TiKV 源码浅析 - PD Scheduler</title>
      <link>https://pingcap.com/blog-cn/pd-scheduler/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pd-scheduler/</guid>
      <description>在前面的文章里面，我们介绍了 PD 一些常用功能，以及它是如何跟 TiKV 进行交互的，这里，我们重点来介绍一下 PD 是如何调度 TiKV 的。
介绍 假设我们只有一个 TiKV，那么根本就无需调度了，因为数据只可能在这一台机器上面，client 也只可能跟这一个 TiKV 进行交互。但我们知道，在分布式存储领域，这样的情况不可能一直持续，因为数据量的增量一定会超过当前机器的物理存储极限，必然我们需要将一部分数据迁移到其他机器上面去。
在之前的文章里面，我们介绍过，TiKV 是通过 range 的方式将数据进行切分的。我们使用 Region 来表示一个数据 range，每个 Region 有多个副本 peer，通常为了安全，我们会使用至少三个副本。
最开始系统初始化的时候，我们只有一个 region，当数据量持续增大，超过了 Region 设置的最大 size（64MB） 阈值的时候，region 就会分裂，生成两个新的 region。region 是 PD 调度 TiKV 的基本单位。当我们新增加一个 TiKV 的时候，PD 就会将原来TiKV 里面的一些 Region 调度到这个新增的 TiKV 上面，这样就能保证整个数据均衡的分布在多个 TiKV 上面。因为一个 Region 通常是 64MB，其实将一个 Region 从一个 TiKV 移动到另一个 TiKV，数据量的变更其实不大，所以我们可以直接使用 Region 的数量来大概的做数据的平衡。譬如，现在假设有六个 TiKV，我们有一百个 region，每个 Region 三个副本 peer，总共三百个 Region peer，我们只要保证每个 TiKV 有五十个左右的 Region peer，就大概知道数据是平衡了。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Placement Driver</title>
      <link>https://pingcap.com/blog-cn/placement-driver/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/placement-driver/</guid>
      <description>介绍 Placement Driver (后续以 PD 简称) 是 TiDB 里面全局中心总控节点，它负责整个集群的调度，负责全局 ID 的生成，以及全局时间戳 TSO 的生成等。PD 还保存着整个集群 TiKV 的元信息，负责给 client 提供路由功能。
作为中心总控节点，PD 通过集成 etcd ，自动的支持 auto failover，无需担心单点故障问题。同时，PD 也通过 etcd 的 raft，保证了数据的强一致性，不用担心数据丢失的问题。
在架构上面，PD 所有的数据都是通过 TiKV 主动上报获知的。同时，PD 对整个 TiKV 集群的调度等操作，也只会在 TiKV 发送 heartbeat 命令的结果里面返回相关的命令，让 TiKV 自行去处理，而不是主动去给 TiKV 发命令。这样设计上面就非常简单，我们完全可以认为 PD 是一个无状态的服务（当然，PD 仍然会将一些信息持久化到 etcd），所有的操作都是被动触发，即使 PD 挂掉，新选出的 PD leader 也能立刻对外服务，无需考虑任何之前的中间状态。
初始化 PD 集成了 etcd，所以通常，我们需要启动至少三个副本，才能保证数据的安全。现阶段 PD 有集群启动方式，initial-cluster 的静态方式以及 join 的动态方式。
在继续之前，我们需要了解下 etcd 的端口，在 etcd 里面，默认要监听 2379 和 2380 两个端口。2379 主要是 etcd 用来处理外部请求用的，而 2380 则是 etcd peer 之间相互通信用的。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - multi-raft 设计与实现</title>
      <link>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</guid>
      <description>概述 本文档主要面向 TiKV 社区开发者，主要介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读文档之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本文档并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。
Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。
Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。
Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region 会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - 如何使用 Raft</title>
      <link>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</guid>
      <description>本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本系列文章并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
 架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。 Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。 Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。 Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 信心的毁灭与重建</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-3/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-3/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为下篇。
 -接中篇- ScyllaDB 有一个开源的东西，是专门用来给文件系统做 Failure Injection 的, 名字叫做 CharybdeFS。如果你想测试你的系统，就是文件系统在哪不断出问题，比如说写磁盘失败了，驱动程序分配内存失败了，文件已经存在等等，它都可以测模拟出来。
CharybdeFS: A new fault-injecting file system for software testing
Simulate the following errors:
 disk IO error (EIO) driver out of memory error (ENOMEM) file already exists (EEXIST) disk quota exceeded (EDQUOT)  再来看看 Cloudera，下图是整个 Cloudera 的一个 Failure Injection 的结构。
一边是 Tools，一边是它的整个的 Level 划分。比如说整个 Cluster， Cluster 上面有很多 Host，Host 上面又跑了各种 Service，整个系统主要用于测试 HDFS， HDFS 也是很努力的在做有效的测试。然后每个机器上部署一个 AgenTEST，就用来注射那些可能出现的错误。</description>
    </item>
    
    <item>
      <title>Percolator 和 TiDB 事务算法</title>
      <link>https://pingcap.com/blog-cn/percolator-and-txn/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/percolator-and-txn/</guid>
      <description>本文先概括的讲一下 Google Percolator 的大致流程。Percolator 是 Google 的上一代分布式事务解决方案，构建在 BigTable 之上，在 Google 内部 用于网页索引更新的业务，原始的论文在此。原理比较简单，总体来说就是一个经过优化的二阶段提交的实现，进行了一个二级锁的优化。TiDB 的事务模型沿用了 Percolator 的事务模型。 总体的流程如下：
读写事务 1) 事务提交前，在客户端 buffer 所有的 update/delete 操作。 2) Prewrite 阶段:
首先在所有行的写操作中选出一个作为 primary，其他的为 secondaries。
PrewritePrimary: 对 primaryRow 写入 L 列(上锁)，L 列中记录本次事务的开始时间戳。写入 L 列前会检查:
 是否已经有别的客户端已经上锁 (Locking)。 是否在本次事务开始时间之后，检查 W 列，是否有更新 [startTs, +Inf) 的写操作已经提交 (Conflict)。  在这两种种情况下会返回事务冲突。否则，就成功上锁。将行的内容写入 row 中，时间戳设置为 startTs。
将 primaryRow 的锁上好了以后，进行 secondaries 的 prewrite 流程:
 类似 primaryRow 的上锁流程，只不过锁的内容为事务开始时间及 primaryRow 的 Lock 的信息。 检查的事项同 primaryRow 的一致。  当锁成功写入后，写入 row，时间戳设置为 startTs。</description>
    </item>
    
    <item>
      <title>TiKV 的 MVCC（Multi-Version Concurrency Control）机制</title>
      <link>https://pingcap.com/blog-cn/mvcc-in-tikv/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mvcc-in-tikv/</guid>
      <description>并发控制简介 事务隔离在数据库系统中有着非常重要的作用，因为对于用户来说数据库必须提供这样一个“假象”：当前只有这么一个用户连接到了数据库中，这样可以减轻应用层的开发难度。但是，对于数据库系统来说，因为同一时间可能会存在很多用户连接，那么许多并发问题，比如数据竞争（data race），就必须解决。在这样的背景下，数据库管理系统（简称 DBMS）就必须保证并发操作产生的结果是安全的，通过可串行化（serializability）来保证。
虽然 Serilizability 是一个非常棒的概念，但是很难能够有效的实现。一个经典的方法就是使用一种两段锁（2PL）。通过 2PL，DBMS 可以维护读写锁来保证可能产生冲突的事务按照一个良好的次序（well-defined) 执行，这样就可以保证 Serializability。但是，这种通过锁的方式也有一些缺点：
 读锁和写锁会相互阻滞（block）。 大部分事务都是只读（read-only）的，所以从事务序列（transaction-ordering）的角度来看是无害的。如果使用基于锁的隔离机制，而且如果有一段很长的读事务的话，在这段时间内这个对象就无法被改写，后面的事务就会被阻塞直到这个事务完成。这种机制对于并发性能来说影响很大。  多版本并发控制（Multi-Version Concurrency Control，以下简称 MVCC） 以一种优雅的方式来解决这个问题。在 MVCC 中，每当想要更改或者删除某个数据对象时，DBMS 不会在原地去删除或这修改这个已有的数据对象本身，而是创建一个该数据对象的新的版本，这样的话同时并发的读取操作仍旧可以读取老版本的数据，而写操作就可以同时进行。这个模式的好处在于，可以让读取操作不再阻塞，事实上根本就不需要锁。这是一种非常诱人的特型，以至于在很多主流的数据库中都采用了 MVCC 的实现，比如说 PostgreSQL，Oracle，Microsoft SQL Server 等。
TiKV 中的 MVCC 让我们深入到 TiKV 中的 MVCC，了解 MVCC 在 TiKV 中是如何 实现 的。
1. Timestamp Oracle(TSO) 因为TiKV 是一个分布式的储存系统，它需要一个全球性的授时服务，下文都称作 TSO（Timestamp Oracle），来分配一个单调递增的时间戳。 这样的功能在 TiKV 中是由 PD 提供的，在 Google 的 Spanner 中是由多个原子钟和 GPS 来提供的。
2. Storage 从源码结构上来看，想要深入理解 TiKV 中的 MVCC 部分，src/storage 是一个非常好的入手点。 Storage 是实际上接受外部命令的结构体。</description>
    </item>
    
    <item>
      <title>解析 TiDB 在线数据同步工具 Syncer</title>
      <link>https://pingcap.com/blog-cn/tidb-syncer/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-syncer/</guid>
      <description>TiDB 是一个完全分布式的关系型数据库，从诞生的第一天起，我们就想让它来兼容 MySQL 语法，希望让原有的 MySQL 用户 (不管是单机的 MySQL，还是多机的 MySQL Sharding) 都可以在基本不修改代码的情况下，除了可以保留原有的 SQL 和 ACID 事务之外，还可以享受到分布式带来的高并发，高吞吐和 MPP 的高性能。
对于用户来说，简单易用是他们试用的最基本要求，得益于社区和 PingCAP 小伙伴们的努力，我们提供基于 Binary 和 基于 Kubernetes 的两种不同的一键部署方案来让用户可以在几分钟就可以部署起来一个分布式的 TiDB 集群，从而快速地进行体验。 当然，对于用户来说，最好的体验方式就是从原有的 MySQL 数据库同步一份数据镜像到 TiDB 来进行对于对比测试，不仅简单直观，而且也足够有说服力。实际上，我们已经提供了一整套的工具来辅助用户在线做数据同步，具体的可以参考我们之前的一篇文章：TiDB 作为 MySQL Slave 实现实时数据同步, 这里就不再展开了。后来有很多社区的朋友特别想了解其中关键的 Syncer 组件的技术实现细节，于是就有了这篇文章。
首先我们看下 Syncer 的整体架构图, 对于 Syncer 的作用和定位有一个直观的印象。
从整体的架构可以看到，Syncer 主要是通过把自己注册为一个 MySQL Slave 的方式，和 MySQL Master 进行通信，然后不断读取 MySQL Binlog，进行 Binlog Event 解析，规则过滤和数据同步。从工程的复杂度上来看，相对来说还是非常简单的，相对麻烦的地方主要是 Binlog Event 解析和各种异常处理，也是容易掉坑的地方。
为了完整地解释 Syncer 的在线同步实现，我们需要有一些额外的内容需要了解。
###MySQL Replication 我们先看看 MySQL 原生的 Replication 复制方案，其实原理上也很简单：</description>
    </item>
    
    <item>
      <title>通过 raft 的 leader lease 来解决集群脑裂时的 stale read 问题</title>
      <link>https://pingcap.com/blog-cn/stale-read/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/stale-read/</guid>
      <description>问题： 当 raft group 发生脑裂的情况下，老的 raft leader 可能在一段时间内并不知道新的 leader 已经被选举出来，这时候客户端在老的 leader 上可能会读取出陈旧的数据（stale read）。 比如，我们假想一个拥有 5 个节点的 raft group:
其中 Node 5 是当前的 raft leader，当出现网络分区时，在 Node 5 的 raft lease 任期还没结束的一段时间内，Node 5 仍然认为自己是当前 term 的 leader，但是此时，另外一边分区已经在新的 term 中选出了新的 leader。
如果此时，客户端在新的 leader 上更新了某个值 x，此时是可以更新成功的（因为还是可以复制到多数派）。但是在分区的另一端，此时一个客户端去读取 x 的值，Node 5 还会返回老的值，这样就发生了 stale read。
解决方案
引入一个新的概念, region leader。region leader 是一个逻辑上的概念, 任意时刻对于某一个 region 来说, 一定只拥有一个 region leader, 每个 region leader 在任期之内尝试每隔 t 时间间隔, 在 raft group 内部更新一下 region leader 的 lease.</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/blog-cn/mpp-smp-tidb/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mpp-smp-tidb/</guid>
      <description>今天主要是想把我们 TiDB 做 SQL 性能优化的一些经验和一些思考，就此跟大家探讨一下。题目写的比较大，但是内容还是比较简单。我们做 TiDB 的 SQL 层时，一开始做的很简单，就是通过最简单的 KV 接口(Get/Set/Seek)去存数据、取数据，做一些非常直白、简单的计算。然而后来我们发现，这个方案在性能上不可接受，可能行不通，我们就重新思考了这个事情。
TiDB 的目标是做一个 NewSQL 的 database ，什么是 NewSQL？从 Wikipedia 上我们看到 NewSQL 的定义『NewSQL is a class of modern relational database management systems that seek to provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system.』。首先NewSQL Database 需要能存储海量数据，这点就像一些 NoSQL 数据库一样。然后，能够提供事务的功能。所以 NewSQL 中的计算，主要有两个特点。第一个，就是数据是海量的，这跟 MySQL 传统数据有可能不一样，他们当然可以通过一些 sharding 的方式来进行处理，但是 sharding 之后会损失，比如说你不能跨节点做 Join，没有跨节点事务等。二是，在海量数据情况下，我们还需要对数据进行随时的取用，因为数据存在那，你算不出来就是对用户没有价值、没有意义的，所以我们需要在海量数据的前提下，能够随时把它计算出来。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 错误注入</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-2/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为中篇。
 -接上篇- 当然测试可能会让你代码变得没有那么漂亮，举个例子：
这是知名的 Kubernetes 的代码，就是说它有一个 DaemonSetcontroller，这 controller 里面注入了三个测试点，比如这个地方注入了一个 handler ，你可以认为所有的注入都是 interface。比如说你写一个简单的 1+1=2 的程序，假设我们写一个计算器，这个计算器的功能就是求和，那这就很难注入错误。所以你必须要在你正确的代码里面去注入测试逻辑。再比如别人 call 你的这个 add 的 function，然后你是不是有一个 error？这个 error 的问题是它可能永远不会返回一个 error，所以你必须要人肉的注进去，然后看应用程序是不是正确的行为。说完了加法，再说我们做一个除法。除法大家知道可能有处理异常，那上面是不是能正常处理呢？上面没有，上面写着一个比如说 6 ÷ 3，然后写了一个 test，coverage 100%，但是一个除零异常，系统就崩掉了，所以这时候就需要去注入错误。大名鼎鼎的 Kubernetes 为了测试各种异常逻辑也采用类似的方式，这个结构体不算长，大概是十几个成员，然后里面就注入了三个点，可以在里面注入错误。
那么在设计 TiDB 的时候，我们当时是怎么考虑 test 这个事情的？首先一个百万级的 test 不可能由人肉来写，也就是说你如果重新定义一个自己的所谓的 SQL 语法，或者一个 query language，那这个时候你需要构建百万级的 test，即使全公司去写，写个两年都不够，所以这个事情显然是不靠谱的。但是除非说我的 query language 特别简单，比如像 MongoDB 早期的那种，那我一个“大于多少”的这种，或者 equal 这种条件查询特别简单的，那你确实是不需要构建这种百万级的 test。但是如果做一个 SQL 的 database 的话，那是需要构建这种非常非常复杂的 test 的。这时候这个 test 又不能全公司的人写个两年，对吧？所以有什么好办法呢？MySQL 兼容的各种系统都是可以用来 test 的，所以我们当时兼容 MySQL 协议，那意味着我们能够取得大量的 MySQL test。不知道有没有人统计过 MySQL 有多少个 test，产品级的 test 很吓人的，千万级。然后还有很多 ORM， 支持 MySQL 的各种应用都有自己的测试。大家知道，每个语言都会 build 自己的 ORM，然后甚至是一个语言的 ORM 都有好几个。比如说对于 MySQL 可能有排第一的、排第二的，那我们可以把这些全拿过来用来测试我们的系统。</description>
    </item>
    
    <item>
      <title>TiDB 作为 MySQL Slave 实现实时数据同步</title>
      <link>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</guid>
      <description>由于 TiDB 本身兼容绝大多数的 MySQL 语法，所以对于绝大多数业务来说，最安全的切换数据库方式就是将 TiDB 作为现有数据库的从库接在主 MySQL 库的后方，这样对业务方实现完全没有侵入性下使用 TiDB 对现有的业务进行备份，应对未来数据量或者并发量增长带来的单点故障风险，如需上线 TiDB，也只需要简单的将业务的主 MySQL 地址指向 TiDB 即可。
下面我们详细介绍了如何将 MySQL 的数据迁移到 TiDB，并将 TiDB 作为 MySQL 的 Slave 进行数据同步。
这里我们假定 MySQL 以及 TiDB 服务信息如下:
+------------------+-------------+----------------------------------------+ | Name | Address | Port | User | Password | +------------------+-------------+----------------------------------------+ | MySQL | 127.0.0.1 | 3306 | root | | | TiDB | 127.0.0.1 | 4000 | root | | +------------------+-------------+--------+-----------+-------------------+ 使用 checker 进行 Schema 检查 在迁移之前，我们可以使用 TiDB 的 checker 工具，checker 是我们开发的一个小工具，用于检测目标 MySQL 库中的表的表结构是否支持无缝的迁移到 TiDB，TiDB 支持绝大多数的 MySQL 常用的原生数据类型，所以大多数情况 checker 的返回应该是 ok。如果 check 某个 table schema 失败，表明 TiDB 当前并不支持，我们不能对该 table 里面的数据进行迁移。checker 包含在 TiDB 工具集里面，我们可以直接下载。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 理念</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-1/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-1/</guid>
      <description>本话题系列文章整理自 PingCAP NewSQL Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为上篇。
 今天主要是介绍分布式系统测试。对于 PingCAP 目前的现状来说，我们是觉得做好分布式系统测试比做一个分布式系统更难。就是你把它写出来不是最难的，把它测好才是最难的。大家肯定会觉得有这么夸张吗？那我们先从一个最简单的、每个人都会写的 Hello world 开始。
A simple “Hello world” is a miracle We should walk through all of the bugs in:
 Compiler Linker VM (maybe) OS  其实这个 Hello world 能够每次都正确运行已经是一个奇迹了，为什么呢？首先，编译器得没 bug，链接器得没 bug ；然后我们可能跑在 VM 上，那 VM 还得没 bug；并且 Hello world 那还有一个 syscall，那我们还得保证操作系统没有 bug；到这还不算吧，我们还得要硬件没有 bug。所以一个最简单程序它能正常运行起来，我们要穿越巨长的一条路径，然后这个路径里面所有的东西都不能出问题，我们才能看到一个最简单的 Hello world。
但是分布式系统里面呢，就更加复杂了。比如大家现在用的很典型的微服务。假设你提供了一个微服务，然后在微服务提供的功能就是输出一个 Hello world ，然后让别人来 Call。
A RPC “Hello world” is a miracle We should walk through all of the bugs in:</description>
    </item>
    
    <item>
      <title>Building a Reliable Large-Scale Distributed Database - Principles and Practice</title>
      <link>https://pingcap.com/blog-cn/talk-principles-practice/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-principles-practice/</guid>
      <description>大家好，我叫申砾，是 PingCAP Tech Leader，负责 TiDB 技术相关的工作。我曾就职网易有道、360 搜索，主要在做垂直搜索相关的事情，现在主要关注分布式计算/存储领域。过去的一年半时间我在 PingCAP 做分布式关系数据库 TiDB。目前我们的整个项目已经开源了大概一年时间，获得了不少关注。在 Github 上 Star 数量超过 5k，并且 Contributor 数量为 50+，拥有一个活跃的社区，在国内和国际上都有一定的知名度。 今天主要想和大家分享一下我们在做一款开源的分布式数据库产品过程中得到的一些经验和体会，包括技术上、产品上以及开源社区方面的内容，不会涉及太多技术上的细节。
数据库现状 近年来，随着移动互联网、物联网、人工智能等技术的兴起，我们已经进入了一个信息爆炸的大数据时代，需要处理和分析的数据越来越多，这些数据如何保存、如何应用是一个重要的问题。
传统的 SQL 数据库一般通过中间件、分库分表等方案获得 Scale 的能力。但是这些方案仍然很难做到对应用透明且保证数据均匀分布，同时也无法支持一致性的跨节点事务、JOIN 等操作。在进行扩容的时候往往需要人工介入，随着集群规模的增大，维护和扩展的复杂度呈指数级上升。
以 Google 的 BigTable 论文为开端，涌现出了一大批 NoSQL 方案。这些方案致力于解决扩展性，而牺牲一致性。如果采用 NoSQL 方案替换原有关系型数据库，往往要涉及大规模的业务重构，这相当于将数据库层的计算逻辑复杂度转嫁给业务层，同时还要损失掉事务等特性。
以上两种方案都没有完美地解决高可用的问题，跨机房多活、故障恢复、扩容经常都需要繁重的人工介入。
最近几年，人们希望有一种既有 SQL/NoSQL 的优点，又能避免他们的不足的新型数据库，于是提出了 NewSQL 的概念。Google 发布的 Spanner/F1，算是第一个真正在大规模业务上验证过的分布式数据库，向业界证明了 NewSQL 这条道路的正确性。TiDB 作为 Google Spanner/F1 的开源实现，正是业界盼望已久的 NewSQL 开源数据库。
什么是 NewSQL 并不是所有号称 NewSQL 的数据库都是 NewSQL。我们认为作为 NewSQL 数据库需要有下面几点特性：
首先是 Scale。这点上我想大家都深有体会，不管什么数据解决方案，最基本的要求就是能有足够的能力，保存用户所有的数据。
第二是事务。ACID Transaction，这个东西如果业务不需要，就感觉不到；一旦你的业务有这种需求，就能体会到它的重要性了。事实证明这个需求是广泛存在的，Google 的 BigTable 没有提供事务，结果内部很多业务都有需求，于是各个组造了一堆轮子，Jeff Dean 看不下去，出来说他最大的错误就是没有给 BigTable 提供事务。</description>
    </item>
    
    <item>
      <title>回到过去，找回遗失的珍宝 - TiDB 的历史读功能</title>
      <link>https://pingcap.com/blog-cn/time-travel/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/time-travel/</guid>
      <description>数据作为业务的核心，关系着整个业务的生死，所以对于数据库来说，数据的安全性是放在首位的，从宏观角度来看，安全性不仅仅在于的数据库本身足够稳定不会主动的丢失数据，有的时候更是对业务本身甚至人为失误造成损失是否有足够且便捷的应对方案，例如在游戏行业中经常遇到的反作弊(作弊玩家回档)问题，对于金融业务的审计需求等等，如果在数据库层面上提供相关机制，会让业务开发的工作量和复杂度减少很多。
传统的方案会定期备份数据，几天一次，甚至一天一次，把数据全量备份。当意外发生的时候，可以用来还原。但是用备份数据还原，代价还是非常大的，所有备份时间点后的数据都会丢失，你绝对不希望走到这一步。另外全量备份带来的存储和计算资源的额外开销，对于企业来说也是一笔不小的成本。
可是这种事情是无法完全避免的，我们所有的人都会犯错。对于一个快速迭代的业务，应用的代码不可能做到全面充分的测试，很可能因为应用逻辑的 Bug 导致数据写错，或者被恶意用户找到 bug，当你发现问题时，可以立即把应用回滚到旧版本，但是写错的数据却会一直留在数据库里。
出现这种问题的时候，你该怎么办？你只知道有些数据不对了，但是对的数据是什么，你不知道。如果能回到过去，找回之前的数据该多好。
TiDB 针对这样的需求和场景支持历史版本的读取，所以可以将错误的版本之前的数据取出来，将损失降到最低。
如何使用 TiDB 的历史读功能 使用这个功能非常简单，只需要执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;2016-10-10 09:30:11.123&amp;quot;
这个 session variable 的名字是 TiDB 里定义的 tidb_snapshot, 值是一个时间的字符串，精确到毫秒，执行了这个语句之后，之后这个客户端发出的所有读请求，读到的都是这个时间点看到的数据，这时是不能进行写操作的，因为历史是无法改变的。如果想退出历史读模式，读取最新数据，只需要再次执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;&amp;quot;
把 tidb_snapshot 设置成空字符串就可以了。
即使在那个历史时间点后，发生了 Schema 更改也没有关系，TiDB 会使用当时的 Schema 执行 SQL 请求。
TiDB 历史读功能和其他数据库的比较 这个功能 MySQL 并不支持，但是在其他的数据库里，比如 Oracle, PostgreSQL 里有类似的功能，叫做历史表(Temporial Table)，是一个SQL 标准。使用的方法是需要你用特殊的建表语法，额外创建一张历史表，历史表比原表多了两个系统定义的字段，代表有效时间，这多出的两个字段是系统维护的。当原表更新数据的时候，系统会把旧版本数据插入到历史表里，当你查询历史数据时，需要用一个特殊的语法指定历史时间，得到需要的结果。
TiDB 和其他数据库的历史表功能相比，主要有以下两个优势：
1，系统默认支持
如果不是默认的行为，我们通常不会特意去建一张历史表，到真正需要用到的时候，你会发现历史表没有创建。
2，使用方便
不需要额外建一张表，不需要用特殊的语法查询。
3，全局视角，而不是以表为单位
TiDB 即使执行了 Drop Table, Drop Database 这样的操作，也可以读到旧的数据。</description>
    </item>
    
    <item>
      <title>How do we build TiDB</title>
      <link>https://pingcap.com/blog-cn/how-do-we-build-tidb/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-do-we-build-tidb/</guid>
      <description>首先我们聊聊 Database 的历史，在已经有这么多种数据库的背景下我们为什么要创建另外一个数据库；以及说一下现在方案遇到的困境，说一下 Google Spanner 和 F1，TiKV 和 TiDB，说一下架构的事情，在这里我们会重点聊一下 TiKV。因为我们产品的很多特性是 TiKV 提供的，比如说跨数据中心的复制，Transaction，auto-scale。
再聊一下为什么 TiKV 用 Raft 能实现所有这些重要的特性，以及 scale，MVCC 和事务模型。东西非常多，我今天不太可能把里面的技术细节都描述得特别细，因为几乎每一个话题都可以找到一篇或者是多篇论文。但讲完之后我还在这边，所以详细的技术问题大家可以单独来找我聊。
后面再说一下我们现在遇到的窘境，就是大家常规遇到的分布式方案有哪些问题，比如 MySQL Sharding。我们创建了无数 MySQL Proxy，比如官方的 MySQL proxy，Youtube 的 Vitess，淘宝的 Cobar、TDDL,以及基于 Cobar 的 MyCAT，金山的 Kingshard，360 的 Atlas，京东的 JProxy，我在豌豆荚也写了一个。可以说，随便一个大公司都会造一个MySQL Sharding的方案。
为什么我们要创建另外一个数据库？ 昨天晚上我还跟一个同学聊到，基于 MySQL 的方案它的天花板在哪里，它的天花板特别明显。有一个思路是能不能通过 MySQL 的 server 把 InnoDB 变成一个分布式数据库，听起来这个方案很完美，但是很快就会遇到天花板。因为 MySQL 生成的执行计划是个单机的，它认为整个计划的 cost 也是单机的，我读取一行和读取下一行之间的开销是很小的，比如迭代 next row 可以立刻拿到下一行。实际上在一个分布式系统里面，这是不一定的。
另外，你把数据都拿回来计算这个太慢了，很多时候我们需要把我们的 expression 或者计算过程等等运算推下去，向上返回一个最终的计算结果，这个一定要用分布式的 plan，前面控制执行计划的节点，它必须要理解下面是分布式的东西，才能生成最好的 plan，这样才能实现最高的执行效率。
比如说你做一个 sum，你是一条条拿回来加，还是让一堆机器一起算，最后给我一个结果。 例如我有 100 亿条数据分布在 10 台机器上，并行在这 10 台 机器我可能只拿到 10 个结果，如果把所有的数据每一条都拿回来，这就太慢了，完全丧失了分布式的价值。聊到 MySQL 想实现分布式，另外一个实现分布式的方案是什么，就是 Proxy。但是 Proxy 本身的天花板在那里，就是它不支持分布式的 transaction，它不支持跨节点的 join，它无法理解复杂的 plan，一个复杂的 plan 打到 Proxy 上面，Proxy 就傻了，我到底应该往哪一个节点上转发呢，如果我涉及到 subquery sql 怎么办？所以这个天花板是瞬间会到，在传统模型下面的修改，很快会达不到我们的要求。</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：分布式数据库模式与反模式</title>
      <link>https://pingcap.com/blog-cn/talk-tidb-pattern/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-tidb-pattern/</guid>
      <description>我叫黄东旭，是 PingCAP 的联合创始人兼 CTO，也是本场论坛的主持人。我原来在 MSRA，后来到了网易、豌豆荚。跟在座的大部分数据分析师不太一样的是，我是一个数据库开发，虽然是 CTO，但是还在写代码。
同时，我也是一些用的比较广泛的分布式的开源软件的作者。比如说我们做的 TiDB、TiKV 这些大型的分布式关系型数据库的项目。
我们现在正在做一个 OLTP 的数据库，主要 focus 在大数据的关系型数据库的存储和可扩展性，还有关系的模型，以及在线交易型数据库上的应用。
所以，今天整个数据库的模式和反模式，我都会围绕着如何在一个海量的并发，海量的数据存储的容量上，去做在线实时的数据库业务的一些模式来讲。并从数据库的开发者角度，来为大家分享怎样写出更加适合数据库的一些程序。
基础软件的发展趋势 一开始我先简单介绍一下，现在我认为的一些基础软件上的发展趋势。
开源 第一点，开源是一个非常大的趋势。大家可以看到一些比较著名的基础软件，基本都是开源的，比如 Docker，比如 k8s。甚至在互联网公司里面用的非常多的软件，像 MySQL、Hadoop 等这种新一代的大数据处理的数据库等基础软件，也大多是开源的。其实这背后的逻辑非常简单：在未来其实你很难去将你所有的技术软件都用闭源, 因为开源会慢慢组成一个生态，而并不是被某一个公司绑定住。比如国家经常说去 IOE，为什么？很大的原因就是基本上你的业务是被基础软件绑死的，这个其实是不太好的一个事情。而且现在跟过去二十年前不一样，无论是开源软件的质量，还是社区的迭代速度，都已经是今非昔比，所以基本上开源再也不是低质低量的代名词，在互联网公司已经被验证很多次了。
分布式 第二，分布式会渐渐成为主流的趋势。这是为什么？这个其实也很好理解，因为随着数据量越来越大，大家可以看到，随着现在的硬件发展，我感觉摩尔定律有渐渐失效的趋势。所以单个节点的计算资源或者计算能力，它的增长速度是远比数据的增长速度要慢的。在这种情况下，你要完成业务，存储数据，要应对这么大的并发，只有一种办法就是横向的扩展。横向的扩展，分布式基本是唯一的出路。scale-up 和 scale-out 这两个选择其实我是坚定的站在 scale-out 这边。当然传统的关系数据库都会说我现在用的 Oracle，IBM DB2，他们现在还是在走 scale-up 的路线，但是未来我觉得 scale-out 的方向会渐渐成为主流。 碎片化
碎片化 第三，就是整个基础软件碎片化。现在看上去会越来越严重。但是回想在十年前、二十年前，大家在写程序的时候，我上面一层业务，下面一层数据库。但是现在你会发现，随着可以给你选择的东西越来越多，可以给你在开源社区里面能用到的组件越来越多，业务越来越复杂，你会发现，像缓存有一个单独的软件，比如 redis，队列又有很多可以选择的，比如说 zeromq, rabbitmq, celery 各种各样的队列；数据库有 NoSQL、HBase，关系型数据库有 MySQL 、PG 等各种各样的基础软件都可以选。但是就没有一个非常好东西能够完全解决自己的问题。所以这是一个碎片化的现状。
微服务 第四，是微服务的模式兴起。其实这个也是最近两年在软件架构领域非常火的一个概念。这个概念的背后思想，其实也是跟当年的 SOA 是一脉相承的。就是说一个大的软件项目，其实是非常难去 handle 复杂度的，当你业务变得越来越大以后，维护成本和开发成本会随着项目的代码量呈指数级别上升的。所以现在比较流行的就是，把各个业务之间拆的非常细，然后互相之间尽量做到无状态，整个系统的复杂度可以控制，是由很多比较简单的小的组件组合在一起，来对外提供服务的。
这个服务看上去非常美妙，一会儿会说有什么问题。最典型的问题就是，当你的上层业务都拆成无状态的小服务以后，你会发现原有的逻辑需要有状态的存储服务的时候你是没法拆的。我所有的业务都分成一小块，每一小块都是自己的数据库或者数据存储。比如说一个简单的 case，我每一个小部分都需要依赖同一个用户信息服务，这个信息服务会变成整个系统的一个状态集中的点，如果这个点没有办法做弹性扩展或者容量扩展的话，就会变成整个系统很致命的单点。
所以现在整个基础软件的现状，特别在互联网行业是非常典型的几个大的趋势。我觉得大概传统行业跟互联网行业整合，应该在三到五年，这么一个时间。所以互联网行业遇到的今天，可能就是传统行业，或者其他的行业会遇到的明天。所以，通过现在整个互联网里面，在数据存储、数据架构方面的一些比较新的思想，我们就能知道如何去做这个程序的设计，应对明天数据的量级。
现有存储系统的痛点 其实今天主要的内容是讲存储系统，存储系统现在有哪些痛点？其实我觉得在座的各位应该也都能切身的体会到。
弹性扩展 首先，大数据量级下你如何实现弹性扩展？因为我们今天主要讨论的是 OLTP ，是在线的存储服务，并不是离线分析的服务。所以在线的存储服务，它其实要做到的可用性、一致性，是要比离线的分析业务强得多的。但是在这种情况下，你们怎样做到业务无感知的弹性扩展，你的数据怎么很好的满足现有的高并发、大吞吐，还有数据容量的方案。
可用性 第二，在分布式的存储系统下，你的应用的可用性到底是如何去定义，如何去保证？其实这个也很好理解，因为在大规模的分布式系统里面，任何一个节点，任何一个数据中心或者支架都有可能出现硬件的故障，软件的故障，各种各样的故障，但这个时候你很多业务是并没有办法停止，或者并没有办法去容忍 Down time 的。所以在一个新的环境之下，你如何对你系统的可用性做定义和保证，这是一个新的课题。一会儿我会讲到最新的研究方向和成果。</description>
    </item>
    
    <item>
      <title>TiKV 事务模型概览，Google Spanner 开源实现</title>
      <link>https://pingcap.com/blog-cn/tidb-transaction-model/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-transaction-model/</guid>
      <description>随着时代的发展，应用和数据的规模越来越大。然而在这个一切都可以水平扩展的时代，你会发现，大多数应用的最下层的关系型数据库，竟然难以找到一个优雅易用的水平扩展解决方案，一直以来不得不依赖静态 Sharding ，牺牲掉事务，然后在业务层各种 Workarounds。作为后端开发者应该深有体会。
层出不穷的 NoSQL 看似解决了数据水平扩展的问题，但是由于跨行事务的缺失和接口的局限，在很多业务中落地还是需要付出很多代价的。最近 Google 基础设施的神人 Jeff Dean 在一次采访中回顾自己作为工程师最大的后悔是什么的问题时提到，他最后悔的事情是没有在 BigTable 中加入跨行事务模型，以至于后来各种各样的团队尝试在 BigTable 上不停的造事务的轮子，但其实这个特性应该是由 BigTable 提供。同样的观点也在他后来的论文中反复提到过。
Google 2012 年在 OSDI 上发表了 Spanner，作为 BigTable 的下一代产品，最主要的特性就是支持跨行事务和在分布式场景上实现 Serializable 的事务隔离级别。我们在2015年底从零开始按照论文做 Spanner 的开源实现 TiKV，于近期开源，和 Spanner 一样，也是一个支持分布式事务和水平扩展的 KV 数据库。一个分布式数据库涉及的技术面非常广泛，今天我们主要探讨的是 TiKV 的 MVCC（多版本并发控制） 和 Transaction 实现。
MVCC 其实并不是一个老的概念了，在传统的单机关系型数据库使用 MVCC 技术来规避大量的悲观锁的使用，提高并发事务的读写性能。值得注意的是 MVCC 只是一个思想，并不是某个特定的实现，它表示每条记录都有多个版本的，互相不影响，以一个 kv 数据库为例从逻辑上的一行的表示就并不是
Record := {key, value} 而是
Record := {key, value, version} 支持分布式 MVCC 在 KV 系统中比较著名的应该是在 BigTable。在 TiKV 中我们的整个事务模型是构建在一个分布式 MVCC 的基础之上：
可以看到，整个 TiKV 的底层本地存储是依赖了 RocksDB，RocksDB 是一个单机的嵌入式 KV 数据库，是一个 LSM Tree的实现，是 Facebook 基于 LevelDB 的修改版本，其特点是写入性能特别好，数据存储是有序的 KV Pairs，对于有序 key 的迭代的场景访问效率较高。</description>
    </item>
    
    <item>
      <title>基于 Raft 构建弹性伸缩的存储系统的一些实践</title>
      <link>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</guid>
      <description>最近几年来，越来越多的文章介绍了 Raft 或者 Paxos 这样的分布式一致性算法，且主要集中在算法细节和日志同步方面的应用。但是呢，这些算法的潜力并不仅限于此，基于这样的分布式一致性算法构建一个完整的可弹性伸缩的高可用的大规模存储系统，是一个很新的课题，我结合我们这一年多以来在 TiKV 这样一个大规模分布式数据库上的实践，谈谈其中的一些设计和挑战。
本次分享的主要内容是如何使用 Raft 来构建一个可以「弹性伸缩」存储。其实最近这两年也有很多的文章开始关注类似 Paxos 或者 Raft 这类的分布式一致性算法，但是主要内容还是在介绍算法本身和日志复制，但是对于如何基于这样的分布式一致性算法构建一个大规模的存储系统介绍得并不多，我们目前在以 Raft 为基础去构建一个大规模的分布式数据库 TiKV ，在这方面积累了一些第一手的经验，今天和大家聊聊类似系统的设计，本次分享的内容不会涉及很多 Raft 算法的细节，大家有个 Paxos 或者 Raft 的概念，知道它们是干什么的就好。
##先聊聊 Scale 其实一个分布式存储的核心无非两点，一个是 Sharding 策略，一个是元信息存储，如何在 Sharding 的过程中保持业务的透明及一致性是一个拥有「弹性伸缩」能力的存储系统的关键。如果一个存储系统，只有静态的数据 Sharding 策略是很难进行业务透明的弹性扩展的，比如各种 MySQL 的静态路由中间件（如 Cobar）或者 Twemproxy 这样的 Redis 中间件等，这些系统都很难无缝地进行 Scale。 ##Sharding 的几种策略 在集群中的每一个物理节点都存储若干个 Sharding 单元，数据移动和均衡的单位都是 Sharding 单元。策略主要分两种，一种是 Range 另外一种是 Hash。针对不同类型的系统可以选择不同的策略，比如 HDFS 的Datanode 的数据分布就是一个很典型的例子：
###首先是 Range Range 的想法比较简单粗暴，首先假设整个数据库系统的 key 都是可排序的，这点其实还是蛮普遍的，比如 HBase 中 key 是按照字节序排序，MySQL 可以按照自增 ID 排序，其实对于一些存储引擎来说，排序其实是天然的，比如 LSM-Tree 或者 BTree 都是天然有序的。Range 的策略就是一段连续的 key 作为一个 Sharding 单元：</description>
    </item>
    
    <item>
      <title>云时代数据库的核心特点</title>
      <link>https://pingcap.com/blog-cn/cloud-native-db/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cloud-native-db/</guid>
      <description>引言 最近几年，随着云计算相关技术的发展，各种不同类型的云层出不穷，服务越来越多不同类型的企业业务，传统企业也渐渐开始探索上云的道路。在云上，作为业务最核心的数据库，相比之前的传统方案会有哪些变化呢？在正式聊云时代的数据库特点之前，我们需要了解一下目前云时代架构发生的变化。
畅想一下，未来的服务都跑在云端，任何的服务资源都可以像水电煤一样按需选购。从 IaaS 层的容器/虚拟机，到 PaaS 层的数据库，缓存和计算单元，再到 SaaS 层的不同类型的应用，我们只需要根据自身业务特点进行资源选配，再也不用担心应用服务支撑不住高速的业务增长，因为在云上一切都是弹性伸缩的。有了可靠的基础软件架构，我们就可以把更多精力放到新业务的探索，新模式的创新，就有可能产生更多不一样的新场景，从而催生更强大能力的云端服务，这是一件多么 cool 的事情。
当然，理想要一步一步实现，未来的基础软件栈到底会怎样呢？社区在这方面正在进行积极地探索，其中最有代表性的就是基于容器（以 Docker 为代表）的虚拟化技术和微服务（Microservice）。
在云时代，一切都应该是可伸缩的，使用 k8s（Kubernetes）在保证资源平衡的前提下，通过 Docker 部署我们依托于容器的微服务模块，我们不用关心服务到底跑在哪里，只需要关心我们需要多少服务资源。Docker 提供了极大的便利性，一次构建，到处运行，我们可以很好地解决开发、测试和上线的环境一致性问题。（如果不能很好地保证测试和实际上线环境的一致性，则很有可能需要花费远超过开发的时间去发现和修复问题。）k8s 更是在 Docker 构建的基础上增加了更多的云特性，包括 Docker 的升级，高可用和弹性伸缩等等。 关于 Docker/k8s 相关的讨论已经很多了，因为时间关系，关于具体的细节就不再展开。我们只需要了解，有了它，可以很轻松地解决服务的安装和部署。
下面再聊聊微服务，微服务将一个服务拆分成相对独立的更小的子服务单元，不同的子服务单元之间通过统一的接口（HTTP/RPC 等）进行数据交互。
相比于传统的解决方案，这种架构有很多的优点。
 更好的开发效率和可维护性。微服务将一个单独的服务进行更细力度的拆分，每一个子服务单元专注于更小的功能模块，可以更好地根据业务建立对应的数据模型，降低复杂度，使得开发变得更轻松，维护和部署变得更加友好. 更好的可扩展性。每个不同的子服务单元相互独立，彼此之间没有任何依赖，所以可以根据业务的具体需要，灵活地部署多个子服务单元进行水平扩展。 更强的容错性。当其中一个子服务出现故障的时候，可以通过辅助的负载均衡工具，自动路由到其他的子服务，不会影响整体服务的可用性.  当然，微服务也不是一个银弹，相对来说，这种方案会使整体系统的设计更加复杂，同时也加大了网络的延迟，对整个系统测试的复杂度也会更高。
Docker 提供的隔离型和可移植性，与微服务是一种天然的契合，微服务将整个软件进行拆分和解耦，而通过 Docker/k8s 可以很自然地做到独立的部署，高可用和容错性，似乎一切都可以完美地运转起来。但是真的是这样么？我们是不是忽略了什么？
是的，我们在讨论前面的问题的时候忽略了一个很重要的东西：状态。
从整个技术发展的角度来看，微服务是一个非常有意义的探索。每个人都期望着每个微服务的子服务都是无状态的，这样我可以自由地启停和伸缩，没有任何的心智负担，但是现实的业务情况是什么样的呢？比如一个电商网站，用户正在下单购买一件商品，此时平台是通过订单子服务的 A 应用来提供服务的，突然，因为机器故障，订单子服务的 A 应用不可用了，改由订单子服务的 B 应用提供服务，那么它是必须要知道刚才用户的订单信息的，否则正在访问自己订单页面的用户会发现自己的订单信息突然不见了。虽然我们尽量想把子服务设计成无状态的，但是很多时候状态都是不可避免的，我们不得不通过存储层保存状态，业界最主要的还是各种数据库，包括 RDBMS 和 NoSQL，比如使用 MySQL、MongoDB、HBase、Cassandra 等，特别是有些场景还要考虑数据一致性问题的时候，更加重了对存储层的依赖。
由此可见，云计算时代系统的架构发生了巨大的变化，这一方面为用户提供了更优秀的特性，另一方面也对云计算的组件提出了更高的要求。数据库作为云计算最基础的组件之一，也需要适应这种架构的变化。（这里我们主要关注 SQL 数据库，云时代的数据库以下简称云数据库。）
那么云数据库主要有一些什么样的特点呢？我认为主要有以下几点。 弹性伸缩 传统的数据库方案，常见的会选用 Oracle，MySQL，PostgreSQL。在云时代，数据量的规模有爆发性的增长，传统的数据库很容易遇到单机的存储瓶颈，不得不选用一些集群方案，常见的比如 Oracle RAC、 MySQL Sharding 等，而这些集群方案或多或少都有一些不令人满意的地方。
比如说，Oracle RAC 通过共享存储的硬件方案解决集群问题，这种方式基本上只能通过停机换用更大的共享内存硬件来解决扩容问题，RAC 节点过多会带来更多的并发问题，同样也会带来更高的成本。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</guid>
      <description>子查询简介 子查询是嵌套在另一个查询中的 SQL 表达式，比较常见的是嵌套在 FROM 子句中，如 SELECT ID FROM (SELECT * FROM SRC) AS T。对于出现在 FROM 中的子表达式，一般的 SQL 优化器都会处理的很好。但是当子查询出现在 WHERE 子句或 SELECT 列表中时，优化的难度就会大大增加，因为这时子查询可以出现在表达式中的任何位置，如 CASE...WHEN... 子句等。
对于不在 FROM 子句出现的子查询，分为“关联子查询”(Correlated Subquery) 和“非关联子查询”。关联子查询是指子查询中存在外部引用的列，例如：
SELECT * FROM SRC WHERE EXISTS(SELECT * FROM TMP WHERE TMP.id = SRC.id) 对于非关联子查询，我们可以在 plan 阶段进行预处理，将其改写成一个常量。因此，本文只考虑关联子查询的优化。
一般来说，子查询语句分为三种：
 标量子查询（Scalar Subquery），如(SELECT&amp;hellip;) + (SELECT&amp;hellip;)
 集合比较（Quantified Comparision），如T.a = ANY(SELECT&amp;hellip;)
 存在性测试（Existential Test），如NOT EXISTS(SELECT&amp;hellip;)，T.a IN (SELECT&amp;hellip;)
  对于简单的存在性测试类的子查询，一般的做法是将其改写成 SEMI-JOIN。但是很少有文献给出通用性的算法，指出什么样的查询可以“去关联化”。对于不能去关联化的子查询，数据库的做法通常是使用类似 Nested Loop 的方式去执行，称为 correlated execution。</description>
    </item>
    
    <item>
      <title>TiDB 下推 API 实现细节 - Union Scan</title>
      <link>https://pingcap.com/blog-cn/tidb-api-union-scan/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-api-union-scan/</guid>
      <description>TiDB 集群的架构分为上层的 SQL 层和底层的 KV 层，SQL 层通过调用 KV 层的 API 读写数据，由于 SQL 层的节点和 KV 层节点通常不在一台机器上，所以，每次调用 KV 的 API 都是一次 RPC, 而往往一个普通的 Select 语句的执行，需要调用几十到几十万次 KV 的接口，这样的结果就是性能非常差，绝大部分时间都消耗在 RPC 上。
为了解决这个问题，TiDB 实现了下推 API，把一部分简单的 SQL 层的执行逻辑下推到 KV 层执行，让 KV 层可以理解 Table 和 Column，可以批量读取多行结果，可以用 Where 里的 Expression 对结果进行过滤, 可以计算聚合函数，大幅减少了 RPC 次数和数据的传输量。
TiDB 的下推 API 通过把 SQL 层的计算下推到 KV 层，大幅减少 RPC 次数和数据传输量，使性能得到数量级的提升。但是当我们一开始启用下推 API 的时候，发现了一个问题，就是当事务写入了数据，但是还未提交的时候，又执行了 Select 操作。
这个时候，刚刚写入的未提交的脏数据读不到，得到的结果是错误的，比如我们在一个空表 t 执行：
begin; insert t values (1); select * from t; 这时我们期待的结果是一条记录 “1”，但是启用下推 API 后得到的结果是空。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/blog-cn/cases/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cases/TOC/</guid>
      <description> 用户案例 目录  互联网  转转 摩拜单车 易果集团 特来电 同程旅游 去哪儿网 饿了么（一） 饿了么（二） 今日头条 G7 二维火 客如云 凤凰网 零氪科技 一面数据 Mobikok 猿辅导  游戏  西山居 游族网络 盖娅互娱 株式会社 FUNYOURS JAPAN  金融  北京银行 Ping++ 360 金融  大型企业  海航易建 威锐达测控 万达网络科技集团   </description>
    </item>
    
  </channel>
</rss>