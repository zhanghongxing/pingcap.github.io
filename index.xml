<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PingCAP Site</title>
    <link>https://pingcap.com/</link>
    <description>Recent content on PingCAP Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 09 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://pingcap.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TiDB 在西山居实时舆情监控系统中的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-xishanju/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-xishanju/</guid>
      <description>公司简介 西山居创建 1995 年初夏，在美丽的海滨小城珠海，西山居工作室孕育而生，一群西山居居士们十年如一日尅勊业业的奋斗。&amp;rdquo;创造快乐，传递快乐！&amp;rdquo; 一直是西山居居士们的创作宗旨。西山居以领先的技术作为坚实的基础以独特的本土化产品为玩家提供时尚化服务。在未来，西山居仍以娱乐软件为主导产品，不断进行研发和市场活动，逐步发展成为国内最优秀的集制作、发行于一体的数字化互动娱乐公司。
业务背景 由于公司产品的社交属性都非常强，对相关舆情进行分析与了解就显得很有必要，在此背景下，舆情监控系统应运而生。该系统利用算法组提供的分词算法，对文本进行解析与分类，打上各类标记后再通过计算产生中间结果。舆情系统直接查询这些中间结果，产生各类报表与趋势图，为及时掌握各类舆情趋势提供便利。用户可以自由组合舆情关注点，从而对平台有很严格的实时交互性查询要求，是典型的实时 HTAP 类业务。
存储技术选型 舆情系统之前我们曾经实现过一个客服系统，这个系统要求能实时查询，但面对是海量的玩家行为记录。在当时情况下（2016 年），可以选择的对象只有 MyCAT 这类数据库中间件，通过综合压力测试后，我们选定了 KingShard 这一款由公司前同事开发的中间件，KingShard 虽然没有 MyCAT 丰富的周边功能，但它在满足我们业务需求的核心功能上有更快的表现。但正因为有了这一次中间件的使用，我们对中间件有了比较全面的了解，它们在查询优化上有着天生的弱点，无法满足更复杂的查询或者表现极不友好，为此我们还不得不砍掉了客服系统的部分业务功能，所以在那时我已开始寻找更优的技术方案，其中分布式数据库是我们考察的重点方向。
BigTable、GFS、MapReduce 是谷歌在分布式存储与查询领域的探索成果，他们没有公开具体实现代码，但却发布了相应论文，对分布式文件系统、大数据挖掘和 NoSQL 发展起了重大促进作用。开源界根据这一成果开发出对应产品是 HBase、HDFS、Hadoop，这三个产品红极一时，相关周边产品更是百花齐放，很多细分领域都同时出现了多个产品竞争，让整个生态非常繁荣但也变得复杂，提高了我们的学习与使用成本。那么，在一些领域中有没有更加简单、直接、具有较强融合能力的解决方案呢？此时距谷歌这三篇论文发表已近 10 年，谷歌内部早已在尝试融合 NoSQL 和 SQL，并对它们进行了多次更新换代，Spanner、F1 两篇论文便是谷歌在这一方向的探索成果。开源分布式数据库 TiDB 便是受论文启发而设计的 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL，具有支持分布式事务、无限的水平扩展、数据强一致性保证等核心 NewSQL 特性。
当时，舆情系统接入的第一个游戏平均每天入库数据量就已达到 8500 万条，并且还需要支持各种实时交互性查询，显然中间件已不能满足要求，传统的关系型数据库则更加不可能了。考虑到以后还会有其它游戏接入，我们果断选择了分布式数据库。 随着互联网经济的发展，数据量跟并发数也在飞速增长，单机数据库已越来越不能满足要求了，为此谷歌、阿里等大厂都有了自研的分布式数据库，但都没有开源，而 MySQL 的 MGR 及相关功能进展的步子太小，TiDB 的出现很好的弥补了市场空白，成为我们的唯一选择。
服务器配置 舆情系统是内部孵化项目，服务器具体如下：
新购物理机器 6 台：
旧物理机 4 台：
我们将对资源使用相对较小的 PD、监控服务分别放在旧物理机上，TiDB、TiKV 和 TiSpark 则分配在新机器上，详细如下：
其中每个 TiKV 分配 CPU 10C / 内存 64G / 硬盘 2T，每个 TiSpark 分配 CPU 20C / 内存 64G。在资源有限情况下，结合数据量及舆情系统的 AP 业务属性，我们设计了这样相对复杂的架构，目的是为了充分利用好服务器资源，让它们能承担更极限的压力，事后有多次历史数据的导入也证明了我们这样设计的必要性，多谢 TiDB 的兄弟全程耐心指导及帮助。</description>
    </item>
    
    <item>
      <title>TiDB 分布式数据库在转转公司的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</guid>
      <description>公司及业务架构介绍 转转二手交易网 —— 把家里不用的东西卖了变成钱，一个帮你赚钱的网站。由腾讯与 58 集团共同投资。为海量用户提供一个有担保、便捷的二手交易平台。转转是 2015 年 11 月 12 日正式推出的 APP，遵循“用户第一”的核心价值观，以“让资源重新配置，让人与人更信任”为企业愿景，提倡真实个人交易。
转转二手交易涵盖手机、3C 数码、母婴用品等三十余个品类。在系统设计上，转转整体架构采用微服务架构，首先按照业务领域模型垂直拆分成用户、商品、交易、搜索、推荐微服务。对每一个功能单元（商品等），继续进行水平拆分，分为商品网关层、商品业务逻辑层、商品数据访问层、商品 DB / Cache，如下图所示： 项目背景 1. 面临的问题 转转后端业务现阶段主要使用 MySQL 数据库存储数据，还有少部分业务使用 MongoDB。虽然目前情况下使用这两种存储基本可以满足我们的需求，但随着业务的增长，公司的数据规模逐渐变大，为了应对大数据量下业务服务访问的性能问题，MySQL 数据库常用的分库、分表方案会随着 MySQL Sharding（分片）的增多，业务访问数据库逻辑会越来越复杂。而且对于某些有多维度查询需求的表，我们总需要引入额外的存储或牺牲性能来满足我们的查询需求，这样会使业务逻辑越来越重，不利于产品的快速迭代。
从数据库运维角度讲，大数据量的情况下，MySQL 数据库在每次 DDL 都会对运维人员造成很大的工作量，当节点故障后，由于数据量较大，恢复时间较长。但这种 M - S 架构只能通过主从切换并且需要额外的高可用组件来保障高可用，同时在切换过程由于需要确定主库状态、新主库选举、新路由下发等原因，还是会存在短暂的业务访问中断的情况。 综上所述，我们面临的主要问题可归纳为：
 数据量大，如何快速水平扩展存储；
 大数据量下，如何快速 DDL；
 分库分表造成业务逻辑非常复杂；
 常规 MySQL 主从故障转移会导致业务访问短暂不可用。
  2. 为什么选择 TiDB 针对上章提到的问题，转转基础架构部和 DBA 团队考虑转转业务数据增速，定位简化业务团队数据库使用方案，更好的助力业务发展，决定启动新型存储服务（NewSQL）的选型调研工作。 TiDB 数据库，结合了关系库与 KV 存储的优点，对于使用方，完全可以当做 MySQL 来用，而且不用考虑数据量大了后的分库分表以及为了支持分库分表后的多维度查询而建立的 Mapping 表，可以把精力全部放在业务需求上。所以我们把 TiDB 作为选型的首选对象展开了测试和试用。
TiDB 测试 1. 功能测试 TiDB 支持绝大多数 MySQL 语法，业务可以将基于 MySQL 的开发，无缝迁移至 TiDB。不过目前 TiDB 不支持部分 MySQL 特性，如：存储过程、自定义函数、触发器等。</description>
    </item>
    
    <item>
      <title>北京银行企业级 NewSQL 数据库赋能金融科技建设</title>
      <link>https://pingcap.com/cases-cn/user-case-beijing-bank/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-beijing-bank/</guid>
      <description> 近年来，国家不断提高对信息技术安全可控的战略要求，银行业希望在快速发展业务的同时不断降低经营成本。这不仅促使商业银行积极提升自主掌控能力，也促使商业银行对基础软件的服务能力、软硬件升级成本控制提出新的要求。与此同时，面对互联网金融带来的交易复杂度及交易频次的大幅提升，商业银行信息系统采用的传统数据库一体化解决方案，在应对此类场景时遇到了明显的性能瓶颈，而提升系统性能只靠替换式的硬件升级，成本昂贵。在这种背景下，引入一种高性能、可弹性扩展、能够支持OLTP场景的数据库成为我行系统建设的优先选择方案。
一、 分布式数据库的价值与应用场景 分布式事务数据库采用多种模式实现数据的分散存储，将数据库压力分散到不同服务器上。与集中式数据库相比，分布式数据库可以均衡交易负载，并采用高并发的架构提升系统的交易处理能力，而其统一的资源管理机制也使得数据库的性能扩展不再是设备的替换式升级，而是通过增加存储或计算节点来实现弹性升级，极大地节约了升级成本。
虽然分布式事务数据库在互联网应用场景下的探索取得了良好的成效和大量的实战经验，积累了很多成熟的技术，但相比互联网企业，金融行业对风险控制的要求更高，所以在面对高复杂度交易场景、业务实时一致性等方面的需求时，需要更为完善的技术方案支持。目前绝大部分分布式数据库解决方案都是基于 MySQL 主从复制结合分库分表中间件方式进行改造和集成，无法提供商业银行交易场景中的强一致性和完整的分布式事务要求，对业务和应用有侵入性，需要做一定的技术调整和事务妥协，并且此类架构离银行业务场景中的高可用和多中心容灾及多活的高级别安全要求也有一定距离。
所以，我行在选型前先确定了六个需要特别关注的特性：ACID 特性、横向扩展能力、可用性、可维护性、透明性、兼容性。需要特别说明的是透明性和兼容性，区域银行等体量的金融机构相比互联网企业来说科技资源有限，所以希望新的分布式数据库对架构、开发、运维的影响能够降到最低，同时能够支持传统系统的迁移。
新一代分布式 NewSQL 数据库对应用透明，像一个单机数据库一样使用，支持水平扩展的同时保证分布式事务和数据的强一致性，从而避免传统分库分表、事务补偿等方案对上层应用及业务流程的影响，另一方面如果能兼容传统单机数据库，传统应用平移时不需要人工改写代码，就能极大减少迁移成本。
二、具有北京银行特色的选型方案 由于金融行业对风险控制的严格要求，以及在交易复杂度、业务实时一致性等方面诉求不同于互联网企业。所以，我行对于分布式数据库的选择也比较谨慎,利用两轮专项POC评测来探索分布式数据库的适用场景及性能指标，稳步推进由传统数据库向分布式数据库的迁移。
在第一轮 POC 测试中，主要进行了多场景的性能测试。由于 Sysbench 等开源测试工具对 OLTP 的性能测试存在较大的局限性，于是我行提出了“标准化交易组”的概念，用银行真实交易逻辑，模拟多表跨节点事务，最大程度的还原银行实际应用场景，检验数据库产品的实际交易性能。
第二轮 POC 测试关注更为全面的数据库产品特性。在当前数据库主流评测指标的基础上，结合银行的关注要点，我行自主提出了一套“分布式事务数据库评测指标”（见图），将分布式事务数据库能力进行了分解，形成具体的指标项，使得评测标准更加标准化，评测结果更加客观。
图1：分布式事务数据库评测指标
选型过程中，从多维度考察了多家厂商的产品，包括 TPS、QPS 等性能指标，和算法性能、可靠性、安全备份、数据库兼容性、产品化程度等功能指标。同时，我行也得到了 Intel 实验室的大力支持，提供最新架构的计算和存储设备进行对比测试。
结合两轮 POC 结果，TiDB 分布式数据库产品表现出了架构的先进性和高效的性能，水平扩展能力、交易处理能力和功能指标均符合我行对分布式数据库产品的要求。其采用的 Raft 算法保证了数据的强一致性，同时可以实现两地三中心多活的部署方式，以上特性在应用中具备较大优势。除了优秀的开源社区环境，其背后的团队在开发支持、技术培训、运维服务、成本控制等方面也表现出了优秀的素质。
三、NewSQL 数据库平台的建设进展 我行在进行分布式事务数据库选型之初，就将目标定为可以承载银行核心系统与核心业务，所以选型过程和应用迁移都是基于这一目标，在数据库投产后将首先应用于互联网支付业务，之后迁移部分核心系统功能模块，并进一步扩展到其他场景的使用。其他感兴趣的用户也可以从非核心业务用起，或先作为备份数据系统。
为了更好满足应用端的需求以及业务的扩展，对业务的交易量和数据量进行了预估。结合预估结果以及行内系统建设要求，北京银行率先采用了两地三中心五副本的高可用部署架构方案，支持同城两中心多活，并具备服务器级、机柜级、数据中心级容灾能力。
随着业务不断发展，客户数量、账户数量、业务交易量都会上升，这对我行信息系统的数据存储能力、运算能力等方面提出了更高的要求。我行也对系统架构进行了长远规划，利用分布式 NewSQL 数据库集群的横向水平扩展能力，通过增加存储或计算节点来实现弹性升级，节约成本与实施难度。
2018 年 3 月 22 日，北京银行分布式 NewSQL 数据库集群正式投产，成为国内首家采用同类方案应用于核心交易场景的银行。在数据库投产后，将进行生产环境多活和灾备的验证，并开始应用切换。
四、对开源软件的一些理解 银行在开展技术能力转型建设的过程中，必然会应用越来越多的开源技术。开源软件是当前软件发展的趋势，互联网企业的大规模应用和快速迭代使开源软件成为先进技术事实上的代表。传统银行业使用开源软件的初衷是希望快速获得互联网企业同样的能力，但是否存在困难与阻碍呢？
第一、大部分银行的科技资源状况使之不具备源代码级的掌控能力和基于开源组件的架构设计能力。大多选择采用由国外社区控制的软件或是直接购买国内互联网公司封装好的全家桶解决方案，很难做到真正意义的自主、安全、可控。
第二、开源软件变化快、分支多、依赖“试错”的创新，跟银行追求稳健、长期的内部机制存在差异甚至冲突，反映在选型、测试、变更、运维等各个环节。
第三、开源软件的极客思维更多面向开发者，而非使用者，灾备、监控、审计等企业级功能经常落后于核心功能，在培训、ISV 持、维保服务上跟传统企业的需求还有差距。
所以银行业采用开源软件并取得成功的成本可能会比原有模式更高。值得欣慰的是，随着多年的技术积累，国内越来越多的类似 PingCAP 这样专注于底层核心基础软件研发的团队开始崭露头角，通过全球开源协作的方式极大的提升软件的迭代速度和成熟度，且愿意倾听传统行业的客户需求，有一颗做好产品与服务的诚心。不同于部分银行在新兴业务上采用互联网公司提供的整体外包解决方案，北京银行寻求自主可控能力，主动在模式和管理上创新，与互联网思维和技术不断切磋、碰撞、融合。通过研究、评测、应用、部署等工作，在实践中做到了自主掌控。双方在合作中互惠互利，利用双方优势，实现了信息系统服务能力的快速提升，打造出具有北京银行特色的创新驱动力。
五、结语 今后我行会尝试将更多高频高并发、对可扩展性和可用性有较高要求的业务场景迁移到分布式系统上。充分发挥分布式数据库的优势，探索和开辟创新发展的新路径。同时也希望我行在分布式数据库建设过程中的经验可以分享给更多的金融机构。借此北京银行愿与各同业机构和互联网企业携手并进，为推动银行数据库应用升级贡献自己的一份力量！
 作者简介
于振华，北京银行软件开发部，核心系统架构管理，长期从事银行核心系统研发、规划，当前主要研发方向集中在构建先进、高效、面向OLTP的银行交易系统，提升银行信息系统服务能力。
张小龙，北京银行软件开发部，核心系统架构设计，长期从事银行核心系统对公业务、中间业务模型研发、规划，软件项目管理。参与构建新型面向OLTP的银行交易系统架构设计。
 </description>
    </item>
    
    <item>
      <title>TiDB 在海航易建科技与香港航空研发收益支持系统过程中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ekingtech/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ekingtech/</guid>
      <description>背景介绍 收益支持系统（Revenue Support System，简称 RSS）是海航易建科技与香港航空共同研发的基于大数据实时分析处理的航空业务支持和决策系统。RSS 的目标在于根据顾客需求进行市场细分和定价，在科学分析的基础上通过价格和座位库存控制手段平衡需求和供给的关系，将产品销售给合适的旅客，其核心价值在于支撑和帮助航空公司业务人员和决策者进行业务管理和科学决策。 RSS 在航空公司角色和定位，决定了该系统对 OLAP 和 OLTP 的操作在准确性和实时性方面具有很高的要求，并且由于航空公司每天产生海量的订票、值机、离港和财务数据，使得要求系统在数据存储方面要有很好的水平扩展能力。
前期方案 前期我们主要使用 MySQL 数据库,但是单表记录大于 2000 万行时，现有的业务报表查询和导出操作明显变慢，通过各种 sql 调优和代码优化手段，也无法继续满足服务等级协议，只能通过分库分表来解决，但是这会增加的后续业务逻辑开发复杂度与数据库运维困难。后来，随着业务的深入和数据的积累，代理人在全球各个全球分销系统（Global Distribution System，GDS）中的订座数据数据（Marketing Information Data Tapes，MIDT）就近2年的数据就超过 3.8 亿行，后续会同步近 10 年的数据，初步预估单表数据量将突破10亿条数据，并且后续每年的正常量可能会突破 2 亿条，如果继续使用 MySQL，必然面临着更细粒度分库、分表的难题，而且当前业界很多分表分库的中间件对 OLAP 支持的并不完美,而且很难满足复杂的 OLAP 需求，并且需要进行分表策略的额外配置。这样必然加大了开发和运维的难度和降低了开发的灵活性。
在这个过程中，我们曾经使用 HDFS + Hive + Spark + Kylin 作为大数据解决方案，但是这个方案对于实时的OLTP却满足不了。
为了满足两者的需求，我们需要把一份大数据存储两份，MySQL + 分表中间件做 OLTP 操作，HDFS + Hive + Spark + Kylin 做 OLAP 分析。
茅塞顿开 在业务遇到不可妥协的技术瓶颈后，我们重新评估业务模型，发现对于数据库的选型必须满足：
 支持业务弹性的水平扩容与缩容；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL 和复杂的查询，尽量少的改动代码；</description>
    </item>
    
    <item>
      <title>TiDB 在威锐达 WindRDS 远程诊断及运维中心的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-weiruida/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-weiruida/</guid>
      <description>公司简介 西安锐益达风电技术有限公司成立于 2012 年 1 月 4 日，是一家专业化的工业测量仪器系统、机电产品和计算机软件研发、设计和制造公司，是北京威锐达测控系统有限公司在西安成立的全资子公司。依托大学的科研实力，矢志不渝地从事仪器仪表及测量系统的研究和应用开发，积累了丰富的专业知识和实践经验，具备自主开发高端仪器系统和工程实施的完整技术能力。
为了适应我国大型风电运营商设备维护管理的需求，破解风电监测技术难题，经过多年艰苦研发，研制了一种具有完全自主知识产权的网络化、模块化、集成化的风电机组状态监测与故障诊断系统，为风电机组全生命周期的运行维护管理提供一套完整的解决方案。
业务描述 威锐达 WindRDS 远程诊断与运维中心，是以设备健康监测为核心，实现企业设备全生命周期的健康监测和基于状态的预知性设备运营维护的管理平台。
本平台以多维、丰富的数据为基础，结合传统的诊断分析方法，并充分发挥利用大数据智能化的技术手段，快速及时的发现、分析定位设备运转及企业运维过程中的问题，并以流程化、自动化的软件系统辅助用户高效的跟踪、处理问题，目标提升企业设备运维管理的能力，节约运维成本，为企业创造价值。
图 1：WindRDS 系统交互图
痛点、选型指标 痛点  WindRDS 的数据平台，对于数据的存储当前选用流行的 MySQL 数据库，面对每年 T 级的数据增长量，以及随着数据量的快速增长导致访问性能的急剧下降，目前也只是通过传统的分表、分库等解决方案进行优化，但性能提升未达到预期，且后续维护升级复杂麻烦，不能很好的满足存储和性能弹性水平扩展的需求。
 本项目同时具有 OLTP 和 OLAP 应用需求，也曾设计构建混合型的数据存储方案（MySQL+ HDFS + Hive + Kylin + HBase + Spark），功能上可同时满足 OLTP 和 OLAP 应用需求，但问题也很明显，如：
 要满足一定程度的实时在线分析，还需要做一些数据迁移同步工作，需要开发实时同步 ETL 中间件，实时从存储事务数据的关系数据库向存储面向分析的 Hive、HBase 数据库同步数据，实时性及可靠性不能保证；
 对于基于 SQL 数据访问的应用程序的切换到该数据平台构成很大挑战，应用程序的数据访问层都需要进行修改适配，工作量大，切换成本高；
 对于面向大数据的的分布式数据库产品（Hive、HBase 等）投入成本高且维护复杂，容易出错，可维护性差。
   选型指标  支持容量及性能的水平弹性扩缩；
 支持对使用 MySQL 协议的应用程序的便捷稳定的迁移，无需修改程序；
 满足业务故障自恢复的高可用，且易维护；</description>
    </item>
    
    <item>
      <title>TiDB 在 Ping&#43;&#43; 金融聚合支付业务中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</guid>
      <description>Ping++ 介绍 Ping++ 是国内领先的支付解决方案 SaaS 服务商。自 2014 年正式推出聚合支付产品，Ping++ 便凭借“7 行代码接入支付”的极致产品体验获得了广大企业客户的认可。
如今，Ping++ 在持续拓展泛支付领域的服务范围，旗下拥有聚合支付、账户系统、商户系统三大核心产品，已累计为近 25000 家企业客户解决支付难题，遍布零售、电商、企业服务、O2O、游戏、直播、教育、旅游、交通、金融、房产等等 70 多个细分领域。
Ping++ 连续两年入选毕马威中国领先金融科技 50 强，并于 2017 成功上榜 CB Insights 全球 Fintech 250 强。从支付接入、交易处理、业务分析到业务运营，Ping++ 以定制化全流程的解决方案来帮助企业应对在商业变现环节可能面临的诸多问题。
TiDB 在 Ping++ 的应用场景 - 数据仓库整合优化 Ping++ 数据支撑系统主要由流计算类、报表统计类、日志类、数据挖掘类组成。其中报表统计类对应的数据仓库系统，承载着数亿交易数据的实时汇总、分析统计、流水下载等重要业务:
随着业务和需求的扩展，数仓系统历经了多次发展迭代过程：
 由于业务需求中关联维度大部分是灵活多变的，所以起初直接沿用了关系型数据库 RDS 作为数据支撑，数据由自研的数据订阅平台从 OLTP 系统订阅而来。
 随着业务扩大，过大的单表已不足以支撑复杂的查询场景，因此引入了两个方案同时提供数据服务：ADS，阿里云的 OLAP 解决方案，用来解决复杂关系型多维分析场景。ES，用分布式解决海量数据的搜索场景。
 以上两个方案基本满足业务需求，但是都仍存在一些问题：
 ADS：一是数据服务稳定性，阿里云官方会不定期进行版本升级，升级过程会导致数据数小时滞后，实时业务根本无法保证。二是扩容成本，ADS 为按计算核数付费，如果扩容就必须购买对应的核数，成本不是那么灵活可控。
 ES：单业务搜索能力较强，但是不适合对复杂多变的场景查询。且研发运维代价相对较高，没有关系型数据库兼容各类新业务的优势。
   所以需要做出进一步的迭代整合，我们属于金融数据类业务，重要性安全性不能忽视、性能也得要有保障，经过我们漫长的调研过程，最终，由 PingCAP 研发的 TiDB 数据库成为我们的目标选型。
TiDB 具备的以下核心特征是我们选择其作为实时数仓的主要原因：
 高度兼容 MySQL 语法；</description>
    </item>
    
    <item>
      <title>TiDB 在游族网络平台部的深度应用</title>
      <link>https://pingcap.com/cases-cn/user-case-youzu/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-youzu/</guid>
      <description>公司介绍 游族网络股份有限公司（SZ.002174）成立于 2009 年，是全球领先的互动娱乐供应商。公司以“大数据”、“全球化”、“精品化”为战略方向，立足全球化游戏研发与发行，知名 IP 管理，大数据与智能化，泛娱乐产业投资四大业务板块全面发展。
背景 2017 年初的时候，游族的用户中心体系面临迭代和重构，当时数据库有数亿多的核心数据，通过 hash key 分为了 1024 张表在 64 个数据库中来存储，使用自研的代码框架来进行对应 hash key 的 seek 操作。这时，非 hash key 的查询、DDL 变更等业务需求，分表分库逻辑代码框架的局限，让研发和运维都面临较高的数据库使用成本，数据库不能灵活高效的支撑业务需求。
图 1：分库分表方案架构图
为了解决上述问题，游族的技术团队急需一套同时满足如下的条件的数据库分布式集群：
 能够提供实时的 OLTP 的一致性数据存储服务；
 弹性的分布式架构；
 配套的监控备份方案；
 稳定的高可用性；
 较低的迁移重构成本。
  前期选择 最开始先考察了几个方案，但都有相对来说的不足：
 方案一，将整个分表分库逻辑剥离到开源分表分库中间件上：
 基于 2PC 的 XA 弱事务的一致性保证不尽如人意；
 高可用架构更加复杂，单分片的局部不可用会对全局产生影响；
 备份恢复的复杂度高；
 这些方案引入了新的 sharding key 和 join key 的设计问题，整体的迁移难度不降反升。
  方案二，官方的 MySQL cluster 集群：</description>
    </item>
    
    <item>
      <title>TiDB 在摩拜单车在线数据业务的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobike/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobike/</guid>
      <description>背景 摩拜单车于 2015 年 1 月成立，2016 年 4 月 22 日地球日当天正式推出智能共享单车服务，截至 2017 年 11 月中旬，已先后进入国内外超过 180 个城市，运营着超过 700 万辆摩拜单车，为全球超过 2 亿用户提供着智能出行服务，日订单量超过 3000 万，成为全球最大的智能共享单车运营平台和移动物联网平台。摩拜每天产生的骑行数据超过 30TB，在全球拥有最为全面的骑行大数据，飞速增长的业务使摩拜面临数据库扩展与运维的巨大挑战。
面对飞速增长的并发数与数据量，单机数据库终将因无法支撑业务压力而罢工。在摩拜正式上线以来，我们就在不断思考数据库扩展和运维的未来，近年来业内对数据库进行扩展的常见的方案是通过中间件把数据库表进行水平拆分，将表内数据按照规则拆分到多个物理数据库中。使用这样的中间件方案，在数据库扩容时需要先停下业务，再重构代码，之后进行数据迁移，对于摩拜这样与时间赛跑的创业公司来讲代价巨大，中间件方案对业务过强的侵入性，不支持跨分片的分布式事务，无法保证强一致性事务的特性都使我们望而却步。
摩拜单车于 2017 年初开始使用 TiDB，从最早的 RC3、RC4、PreGA、到现在的 1.0 正式版，一步步见证了 TiDB 的成熟和稳定。目前支撑着摩拜内部的实时分析和部分线上业务，同时正在规划迁移更多的线上业务至 TiDB。
目前，TiDB 在摩拜部署了数套集群，近百个节点，承载着数十 TB 的各类数据。
TiDB 在摩拜的角色和主要应用场景 在摩拜，TiDB 是一个核心的数据交易与存储支撑平台，引入它的主要目的是用来解决海量数据的在线存储、大规模实时数据分析和处理。
在我们看来，TiDB 的好处主要有：
 弹性扩容。具有 NoSQL 类似的扩容能力，在数据量和访问流量持续增长的情况下能够通过水平扩容提高系统的业务支撑能力，并且响应延迟稳定； 简单易用。兼容 MySQL 协议，基本上开箱即用，完全不用担心传统分库分表方案带来的心智负担和复杂的维护成本，而且用户界面友好，常规的技术技术人员都可以很高地进行维护和管理； 响应及时。因为和 PingCAP 团队有非常深入的合作关系，所以有任何问题都可以第一时间和 PingCAP 团队直接沟通交流，遇到问题都能很快的处理和解决。  下面介绍 TiDB 的应用场景：
场景一：开关锁日志成功率统计 开关锁成功率是摩拜业务监控的重点指标之一。
在每次开、关锁过程中，用户和锁信息会在关键业务节点产生海量日志，通过对线上日志的汇总分析，我们把用户的行为规整为人和车两个维度，通过分布式、持久化消息队列，导入并存放到 TiDB 里。在此过程中，通过对不同的实体添加不同的标签，我们就能方便地按照地域、应用版本、终端类型、用户、自行车等不同的维度，分别统计各个类别的开锁成功率。
按照我们的估计，这个业务一年的量在数百亿，所以使用单机的 MySQL 库需要频繁的进行归档，特别是遇到单机数据库瓶颈的情况下，扩容更是带来了非常大的挑战，这在我们有限的人力情况下，完全是个灾难。所以要支撑整个 Mobike 的后端数据库，我们必须要寻找简单易用的方案，极大地减少在单个业务上的人力成本开销。其次，根据我们之前使用分库分表的经验，对于这类需要频繁更新表结构进行 DDL 操作的业务，一旦数据量过大，很很容易出现数据库假死的情况，不仅影响服务的可用性，更严重的是很可能导致数据不一致的情况出现。最后，我们希望不管今后的业务量如何激增，业务需求如何变化，都可以保持业务逻辑可以很方便地升级支持。</description>
    </item>
    
    <item>
      <title>TiDB / TiSpark 在易果集团实时数仓中的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yiguo/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yiguo/</guid>
      <description>项目背景 目前企业大多数的数据分析场景的解决方案底层都是围绕 Hadoop 大数据生态展开的，常见的如 HDFS + Hive + Spark + Presto + Kylin，在易果集团，我们初期也是采取这种思路，但是随着业务规模的快速增长和需求的不断变化，一些实时或者准实时的需求变得越来越多，这类业务除了有实时的 OLTP 需求，还伴随着一些有一定复杂度的 OLAP 的需求，单纯地使用 Hadoop 已经无法满足需求。
现有的准实时系统运行在 SQL Server 之上，通过开发人员编写和维护相应的存储过程来实现。由于数据量不大，SQL Server 能够满足需求，但是随着业务的发展，数据量随之增长，SQL Server 越来越不能满足需求，当数据量到达一定的阶段，性能便会出现拐点。这个时候，这套方案已完全无法支撑业务，不得不重新设计新的方案。
选型评估 在评估初期，Greenplum、Kudu、TiDB 都进入了我们的视野，对于新的实时系统，我们有主要考虑点：
 首先，系统既要满足 OLAP 还要满足 OLTP 的基本需求；
 其次，新系统要尽量降低业务的使用要求；
 最后，新系统最好能够与现有的 Hadoop 体系相结合。
  Greenplum 是一套基于 PostgreSQL 分析为主的 MPP 引擎，大多用在并发度不高的离线分析场景，但在 OLTP 方面，我们的初步测试发现其对比 TiDB 的性能差很多。
再说说 Kudu。Kudu 是 CDH 2015年发布的一套介于 Hbase 和 HDFS 中间的一套存储系统，目前在国内主要是小米公司应用的较多，在测试中，我们发现其在 OLTP 表现大致与 TiDB 相当，但是一些中等数据量下，其分析性能相比 TiDB 有一定差距。另外我们的查询目前主要以 Presto 为主，Presto 对接 Kudu 和 PostgreSQL 都是需要考虑兼容性的问题，而 TiDB 兼容 MySQL 协议，在应用初期可以直接使用 Presto-MySQL 进行统一查询，下一步再考虑专门开发 Presto-TiDB。</description>
    </item>
    
    <item>
      <title>TiDB 帮助万达网络科技集团实现高性能高质量的实时风控平台</title>
      <link>https://pingcap.com/cases-cn/user-case-wanda/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-wanda/</guid>
      <description>万达网络科技集团 是中国唯一的实业+互联网大型开放型平台公司，拥有飞凡信息、快钱支付、征信、网络信贷、大数据等公司，运用大数据、云计算、人工智能、场景应用等技术为实体产业实现数字化升级，为消费者提供生活圈的全新消费服务。
万达网络科技集团的技术团队，建设和维护着一套实时风控平台。这套实时风控平台，承担着各种关键交易的在线风控数据的写入和查询服务。实时风控平台后端的数据库系统在高性能，可靠性，可扩展性上有很高的要求，并且需要满足如下核心功能和业务要求：
 风控相关业务数据实时入库
 实时风控规则计算
 通过 BI 工具分析风控历史数据
 ETL 入库到 Hadoop 数据仓库
 应用开发侧需要兼容 MySQL，降低应用改造门槛
  为实现上述业务目标，万达网络科技集团的技术团队在实时风控数据库选型的早期阶段，首先选择了 MySQL Galera Cluster 作为数据库集群的技术架构。这套 MySQL 数据库架构通过不同于 MySQL 主流复制技术的复制机制，实现在多个 MySQL 节点间建立强同步关系，实现数据的副本和高可用。但经过业务实践，发现这套方案有诸多问题，其中比较突出的有以下几点：
 MySQL Galera Cluster 自身的强同步机制以大幅度降低集群整体性能为代价，集群整体性能比单节点 MySQL 还差。所以不能很好的满足“风控相关业务数据实时入库”的业务需求。
 同时，MySQL Galera Cluster 的 JOIN 支持非常弱，不足以支持 BI 相关的复杂分析。
 集群整体性能的短板加上对 JOIN 支持的薄弱，使得要在业务上实现大并发高性能的风控规则计算变的很困难。
  万达的技术团队还考察了市场上用的比较多的 MySQL 主从复制以及通过 MySQL Proxy 中间件实现分库分表的方案。但这些方案，无论是高可用安全性，强一致性，还是对业务应用所需要的复杂事务／JOIN 操作以及横向扩展能力上，都无法满足实时风控平台的业务要求。这些问题集中反映在以下几个方面：
 基于 MySQL 主从复制方式的高可用方案，容易出现诸如接入层脑裂和数据不一致的风险。
 基于 MySQL Proxy 中间件的方案，缺少对分库分表后的跨库跨表的分布式事务支持以及对复杂 JOIN 的良好支持，因此也无法满足业务上风控规则实时计算和复杂查询的需求以及对业务团队的 BI 需求的支持。</description>
    </item>
    
    <item>
      <title>盖娅互娱 | 日均数据量千万级，MySQL、TiDB 两种存储方案的落地对比</title>
      <link>https://pingcap.com/cases-cn/user-case-gaea-ad/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-gaea-ad/</guid>
      <description>背景介绍 盖娅广告匹配系统（GaeaAD）用于支撑盖娅互娱全平台实时广告投放系统，需要将广告数据和游戏 SDK 上报的信息进行近实时匹配，本质上来说需要实时的根据各个渠道的广告投放与相应渠道带来的游戏玩家数据进行计算，实现广告转化效果分钟级别的展现及优化。
初期的 MySQL 存储方案 在系统设计之初，基于对数据量的预估以及简化实现方案考虑，我们选用了高可用的 MySQL RDS 存储方案，当时的匹配逻辑主要通过 SQL 语句来实现，包含了很多联表查询和聚合操作。当数据量在千万级别左右，系统运行良好，基本响应还在一分钟内。
图 1 MySQL RDS 存储方案架构图
遭遇瓶颈，寻找解决方案 然而随着业务的发展，越来越多游戏的接入，盖娅广告系统系统接收数据很快突破千万/日，高峰期每次参与匹配的数据量更是需要翻几个番，数据库成为了业务的瓶颈。由于此时，整个技术架构出现了一些问题：
1. 单次匹配耗时已从原本的 10 秒左右增加到 2 分钟以上，最慢的聚合查询甚至达到 20 分钟，时效性受到严重挑战。而且 MySQL 的问题是查询的时间随着数据量的增长而增长，以至于数据量越大的情况下查询越慢。
2. 随着历史数据的积累，单表数据很快达到亿级别，此时单表的读写压力已经接近极限。
3. 由于第一点提到的查询性能问题以及单机的容量限制，需要定时删除数据，对于一些时间跨度较长的业务查询需求没法满足。
根据数据量的增长情况来看，分布式数据库会是很好的解决方案。首先考虑的是业务的垂直及水平拆分或者基于 MySQL 的数据库中间件方案和一些主流的 NoSQL 方案。
但是仔细评估后，最先排除掉的是业务水平拆分的方案，因为业务逻辑中包含大量的关联查询和子查询，如果拆表后这些查询逻辑就没有办法透明的兼容，而且是比较核心的业务系统，时间精力的关系也不允许整体做大的重构。中间件的问题和分库分表的问题类似，虽然解决了大容量存储和实时写入的问题，但是查询的灵活度受限，而且多个 MySQL 实例的维护成本也需要考虑。
第二个方案就是采用 NoSQL，因为此系统需要接收业务端并发的实时写入和实时查询，所以使用类似 Greenplum，Hive 或者 SparkSQL 这样的系统不太合适，因为这几个系统并不是针对实时写入设计的， MongoDB 的问题是文档型的查询访问接口对业务的修改太大，而且 MongoDB 是否能满足在这么大数据量下高效的聚合分析可能是一个问题。
所以很明显，我们当时的诉求就是能有一款数据库既能像 MySQL 一样便于使用，最好能让业务几乎不用做任何修改，又能满足分布式的存储需求，还要保证很高的复杂查询性能。
当时调研了一下社区的分布式数据库解决方案，找到了 TiDB 这个项目，因为协议层兼容 MySQL，而且对于复杂查询的支持不错，业务代码完全不用修改直接就能使用，使迁移使用成本降到极低。
技术转身，使用 TiDB 在部署测试的过程中，我们使用 TiDB 提供的 Syncer 工具将 TiDB 作为 MySQL Slave 接在原业务的 MySQL 主库后边观察，确保读写的兼容性以及稳定性，经过一段时间观察后，确认读写没有任何问题，业务层的读请求切换至 TiDB，随后把写的流量也切换至 TiDB 集群，完成平滑的上线。</description>
    </item>
    
    <item>
      <title>TiDB 在特来电的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-telaidian/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-telaidian/</guid>
      <description>背景介绍 特来电新能源有限公司是创业板第一股特锐德（300001）的全资子公司，主要从事新能源汽车充电网的建设、运营及互联网的增值服务。特来电颠覆了传统充电桩的模式，世界首创了电动汽车群智能充电系统，获得 336 项技术专利，以“无桩充电、无电插头、群管群控、模块结构、主动防护、柔性充电”的特点引领世界新能源汽车充电的发展，系统的鉴定结论为：“产品世界首创、技术水平国际领先。主动柔性充电对电池寿命可以延长 30% 左右，电池充电的安全性可以提升 100 倍以上。”
特来电采用互联网思维，依靠国际领先的汽车群智能充电技术和系统，创新电动汽车充电商业模式，建设全国最大的汽车充电网，通过大系统卖电、大平台卖车、大共享租车、大数据修车、大支付金融、大客户电商，打造让客户满意、政府放心的中国最大汽车充电网生态公司，引领充电网、车联网、互联网“三网融合”的新能源互联网。
为什么研究 TiDB 特来电大数据平台通过开源与自研相结合的方式，目前已经上线多套集群满足不同的业务需求。目前在大数据存储和计算方面主要使用了 HBase、Elasticsearch、Druid、Spark、Flink。大数据技术可谓是百花齐放、百家争鸣，不同的技术都有针对性的场景。结合实际情况，选择合适的技术不是一件容易的事情。
随着接入大数据平台的核心业务的增加，我们在 OLAP 上主要遇到以下痛点问题：
 随着基于大数据分析计算的深入应用，使用 SQL 进行分析的需求越来越旺盛，但目前已经上线的大数据集群（HBase、Elasticsearch、Druid、Spark、Flink）对 SQL 的支持度都比较弱。
 目前进入大数据集群的数据主要以宽表方式进行，导致在数据归集和后期基础数据放生变化时应用成本较高。
 数据仓库业务有些还是基于复杂的 T+1 模式的 ETL 过程，延时较高，不能实时的反映业务变化。
 由于每个大数据集群主要针对特定的场景，数据重复存储的情况较多，这就造成了存储成本的增加，同时也会导致数据的不一致性。
 目前进入 HDFS / Druid / ES 的数据，在历史数据更新时，成本较高，灵活性降低。
  大数据技术发展迅速，我们也一直希望采用新的技术可以解决我们以上问题，我们关注到目前 NewSQL 技术已经有落地产品，并且不少企业在使用，所以决定在我们平台内尝试引入 NewSQL 技术解决我们的痛点问题。
我们先了解一下 NewSQL。
图 1 数据库发展史
如图 1 所示，数据库的发展经历了 RDBMS、NoSQL 以及现在的 NewSQL，每种不同的技术都有对应的产品，每种数据库的技术背后，都有典型的理论支撑。2003 年 Google GFS 开创了分布式文件系统、2006 年的 BigTable 论文催生了 Hadoop 生态，在 2012 年的 Spanner 和 2013 年的 F1 论文发表后，被业界认为指明了未来关系型数据库的发展。</description>
    </item>
    
    <item>
      <title>支撑百亿级应用的 NewSQL——TiDB 在同程旅游的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-tongcheng/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-tongcheng/</guid>
      <description>项目背景 初次接触 TiDB，是通过同程网首席架构师王晓波先生的分享，当时同程网正在使开发和数据库全面往开源方向转型，由于业务需要，很多在线业务数据量和访问量都非常的大，而 MySQL 无法满足大数据量下的复杂查询需求，为了使数据库分片对开发透明，同程自研了 DBrouter。但分片后的合并、实时汇总统计及全量数据的监控仍然是困扰我们的一个难点。一直没有特别好的办法解决。
急速增长的业务 2016 年国庆前，同程的票务项目（微信九宫格中的火车票、机票等票务业务背后是同程在提供）由于流量激增，订单库压力越来越大，同时相关业务需求也在增加，开发不断的在订单库上新增各种查询，例如为了及时定位异常而增加的限定各类条件的分钟级订单量监控（每分钟执行根据不同的条件进行汇总的订单量）。这样的功能越来越多，同时订单库总大小数 T 左右。对此，公司内部决定将票务订单库进行分片来降低单库压力，应对即将到来的国庆高峰订单爆发。
引入 TiDB 经过评估，发现公司自研的分片可以满足绝大多数的查询需求，但是部分复杂条件的查询将会影响整个分片集群的性能，少量的全片扫描 SQL 经常会占用 80% 以上的 IO 资源，导致其他的查询性能下降。这时，刚好我们的首席架构师提议，使用 TiDB 试试，经过中间件组和 DBA 组的配合测试，我们尝试将 TiDB 作为所有数据的集合库提供复杂查询，分片集群则提供简单查询，同时由于 TiDB 高度兼容 MySQL 的连接协议，我们基于 PingCAP 提供的数据同步工具 Syncer 进行了二次开发，可以自定义库名和表名（后来同 TiDB 工程师交流，他们最新的 Wormhole &amp;amp; Syncer 也都已经支持了自定义选项），同时新增了同步状态监控，如 TPS、延迟等，如果出现异常，会通过微信告警。从 MySQL 将数据实时同步到 TiDB 来确保数据的一致。
确定方案后，我们连夜安排压测同事和开发同事协作，紧急测试，发现这套分片集群 + TiDB 的方案能够满足我们的功能和性能方面的需求，于是迅速调整了该项目的架构，我们将数千个 MySQL 分片汇总到一个 TiDB 集群，保障了 2016 年国庆的高峰平稳渡过。当时的流量达到了我们平时流量的 2 倍，然而并没有出现异常。
该实时同步查询系统架构如下所示： 在该项目实施成功后，我们加深了对于 TiDB 的使用。并根据 PingCAP 的建议和协助部署了各类监控。
同时，为了更好的关注数据库的情况，第一时间发现异常，我们将 TiDB 的异常报警接入了公司的监控系统和自愈系统。当发生异常的时候，监控系统会第一时间发现，然后自愈系统会依据提前制定的愈合逻辑处理对应异常，在第一时间恢复应用的可用。
更大规模的使用 业务上线以后，我们很快又迁移了机票业务实时同步业务到 TiDB。至本文截稿时，在同程内部，目前共有数套 TiDB 集群，部署服务器数量近百台，总数据量数十 TB。其中最大的一个集群 10 多个数据节点，近十 TB 数据，数据量过百亿，支撑了每天过亿的访问，并提供千万级别的数据监控服务，平均 QPS 在 5000，高峰 QPS 过万。</description>
    </item>
    
    <item>
      <title>TiDB 在株式会社 FUNYOURS JAPAN 的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-funyours-japan/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-funyours-japan/</guid>
      <description>背景 株式会社 FUNYOURS JAPAN 自 2014 在日本成立以来，营运多款颇受好评的页游跟手游，如：剣戟のソティラス、九十九姬 等，对于营运游戏来说，能够了解游戏中的玩家在做什么，喜欢的偏好是什么，关卡的设计是否平衡，都是相当重要的，所以随着营运时间的增长，资料库数据在亿笔以上也是寻常的。
所以我们的技术单位也一直不断在评估市面上的各种资料库以及如何改进目前现有系统与架构，近年来最热门的资料库系统可以说是 NoSQL 了，不论 MongoDB，Cassandra，Redis，HBase 等等都占有一片天，具有读写快速，容易扩展等特性。经过初步了解后，采用 NoSQL 方式，需要对于目前的资料储存架构整个重新设计，并且需要配合采用的该套 NoSQL 资料库进行业务改造设计，那么该采用哪一套 NoSQL 资料库又是一个需要慎重考虑的课题。先回过头来看当前最需要处理改进的项目：
1. 储存空间扩展不易
2. 单台资料库效能有限
初期方案 在处理储存空间不足的部分，一开始我们先采用了 MySQL innoDB 提供的压缩表格格式，对于需要时常读写更新的部分使用了 8K page size，过往的日志部分采用 4K page size，效果非常令人满意，释放了大量的储存空间，并且对于效能来说没有造成可察觉的影响。这部分网路上的测试比较多，就不在此多做说明。但是很快的压缩表格节省的空间毕竟是有限的，接下来只能增加 volume 容量以及将没有需要更新的过往日志移动到其他资料库上，虽然造成维护工作跟时间的繁复与负担，但是问题解决了。
基于 MySQL 资料库架构单台的性能限制上，我们采用了多组的资料库伺服器，来满足所需的效能。当然不同组之间资料是不共通的，也就是无法直接使用 SQL 来做跨组间的操作，需要额外的程式来作业。而当然为了大量的资料存取上的效能，分表分库对表格进行 partition 这些作业都少不了。
初识 TiDB 使用 NoSQL 式资料库看似可以完美的提供出一个解法，但需要付出的成本也是高昂的。于是我们把眼光落到了 MySQL Cluster 上，这时看到了 Google 发布 Cloud Spanner beta 的新闻，NewSQL？这是什么? 很快的引起了我们浓厚的兴趣，然后经过多方调研，我们发现了 TiDB：一个开源在 GitHub 上的 NewSQL 资料库。官方也持续不断发布了很多相关的文章，随着对 TiDB 的认识，认为对于目前现况是很合适的最佳化方案，相容于 MySQL，高可用性，容易水平扩展。
在可行性评估与测试的时候，一开始采用了 TiKV 3 台搭配 PD 3 台，TiDB 2 台混搭 PD 的架构，使用了文件建议的 ansible 安装，这时遇到两个困难，第一个是在 ansible 检查机器效能的时候会因为硬碟读写效能而无法安装。由于是使用云端机器，所以对硬体方面没有太大的弹性，只好自己手动去修改脚本才能顺利安装。第二个也是在 ansible 里面会检查 ntp 同步服务是否启动，但是 centos7 预设的时间同步服务是 chrony，所以也是修改了脚本（后来的版本有提供 flag 能切换，也有自动安装 ntp 的选项），总之是顺利安装了。这时因为 PingCAP 才刚发布了 ansible 安装的方式，所以文件对于水平扩展部分，如新增 TiKV、 PD 、TiDB 机器，或者移除机器，官方 doc 没有详细说明，于是就写了封 mail 联系 PingCAP，发完信出去吃午餐回来，官方已经回复并且邀请加入 wechat，提供更即时的沟通跟支援，实在是很令人惊艳。</description>
    </item>
    
    <item>
      <title>TiDB 在 360 金融贷款实时风控场景应用</title>
      <link>https://pingcap.com/cases-cn/user-case-360/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-360/</guid>
      <description>背景 近几年来基于互联网渠道的现金贷业务发展十分迅猛，无论是新兴的互联网企业还是传统的金融机构，都想在这个领域快速占领市场，攫取客户。然而在线贷款业务与其他互联网业务有着明显的不同，源自金融的基因决定了重视风险的必要性，这不仅关系到产品的收益，也直接影响了产品是否可以成功。
将业务推到线上意味着无法准确的获取客户信息，只能通过有限的渠道验证客户的真实性和偿还能力，极大的增加了风险成本。如果申请步骤过于繁琐则降低了用户体验，不利于产品的推广和客户的使用。因此对于互联网贷款风控的一项挑战就是能够在尽可能短的时间内，有限数据的情况下，给出明确的风险判断。
应用 建立风险策略的过程中，使用各种风险变量以及相关的衍生变量，通过专家模型进行评分，是一种较为典型的方法。实际应用中，我们发现除了已经被广泛使用的消费行为数据，基本收入数据等，基于特定维度的用户间社交关系也是比较有效的模型变量。
在使用这些变量的过程中，我们面临最直接的问题是数据量。如果考虑将用户手机通讯录中出现的电话号码作为一项关系关联的形式，假设每位用户通讯录中联系人的个数平均为 100 个，那 100 万个注册用户就有对应大约 1 亿个联系人。事实上，在系统上线大约 1 年不到的时间内，我们几张存储社交关系的表已经达到了大约 50 亿左右的规模。
相对于数据存储，变量的衍生加工和查询匹配是个更加有挑战性的工作。一个人的社交关系是个很典型的「图」数据结构。而很多专家模型中的规则是需要匹配某个用户 3 层以上关系的，最简单的就是匹配用户通过联系人关系，跃进 3 层后，命中系统黑名单的人数。我们还是按照平均 100 个联系人来估算，跃进 3 层后，需要匹配的关联人数为 100 * 100 * 100，即 100 万。而类似计算量的规则不在少数，需要调用这些计算规则的业务场景也较为频繁，同时对响应时间的要求也高。
V1.0 版本的解决方案 在评估阶段，我们考虑了几种方案，各有利弊。首先被淘汰的是使用 MySQL 的解决方案。使用关系型数据库的优势是在查询方面的便捷性。在开发效率上，SQL 是开发人员和数据分析人员的必备技能，能够较快的在功能上实现需求。但是在数据存储和计算层面，MySQL 的表现则差强人意。在面对大数据量时，MySQL 能采取的水平扩展策略无非是分库分表，这样的后果就是查询逻辑变的非常复杂，不易维护，且性能下降的较为严重。
另一个方案是把 HBase 作为数据存储的解决方案。它的优点很明显，可以水平扩展，数据量不再是瓶颈。但是它的缺点也同样明显，即对开发人员不友好，查询的 API 功能性较差，只能通过 key 来获取单条数据，或是通过 scan API 来批量读取。更关键的是 HBase 对图这样的数据结构支持的不好，只能通过使用 tall table 和存储冗余数据的形式来模拟。
第三个方案是使用纯粹的图数据库。首先我们考察了开源的 Titan，发现这个项目已经废弃了，主力团队貌似研发了一个新的商业图数据库，并成立了公司。而且 Titan 的存储引擎也是使用了 HBase 和 Cassandra(根据需求两者选一)，性能并不能满足我们的要求。接着我们考察了两款开源的商业产品 Neo4j 和 OrientDB。他们两者都提供了免费的社区版本，当然在功能上比商业版少了些。其中 Neo4j 的社区版不支持 HA，只能在单机上运行。而 OrientDB 的数据版支持 HA 和 Sharding。在编程接口上两者都支持各种主流的编程语言。Neo4j 提供了自家独创的，基于模式匹配的查询语言 cypher。OrientDB 则提供了类 SQL 的语法 API，可谓各有所长。</description>
    </item>
    
    <item>
      <title>TiDB 在爱奇艺的应用及实践</title>
      <link>https://pingcap.com/cases-cn/user-case-iqiyi/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-iqiyi/</guid>
      <description>背景介绍 爱奇艺，中国高品质视频娱乐服务提供者，2010 年 4 月 22 日正式上线，推崇品质、青春、时尚的品牌内涵如今已深入人心，网罗了全球广大的年轻用户群体，积极推动产品、技术、内容、营销等全方位创新。企业愿景为做一家以科技创新为驱动的伟大娱乐公司。我们在前沿技术领域也保持一定的关注度。
随着公司业务的快速发展，原来普遍使用的 MySQL 集群遇到了很多瓶颈，比如单机 MySQL 实例支撑的数据量有限，只能通过不停删除较旧的数据来维持数据库的运转。同时单表的数据行数不断增大导致查询速度变慢。急需一种可扩展、高可用同时又兼容 MySQL 访问方式的数据库来支撑业务的高速发展。
我司从 2017 年年中开始调研 TiDB，并且在数据库云部门内部系统中使用了 TiDB 集群。从今年 TiDB 推出 2.0 之后，TiDB 愈发成熟，稳定性与查询效率都有很大提升。今年陆续接入了边控中心、视频转码、用户登录信息等几个业务，这几个业务背景和接入方式如下详述。
项目介绍 1. 边控中心 边控中心存储的是机器的安全统计信息，包括根据 DC、IP、PORT 等不同维度统计的流量信息。上层业务会不定期做统计查询，其业务页面如下：
图 1 边控中心上层业务页面（一）
图 2 边控中心上层业务页面（二）
在选型过程中，也考虑过时序型数据库 Apache Druid（http://druid.io），但是 Druid 聚合查询不够灵活，最终放弃 Druid 选择了 TiDB 数据库。TiDB 几乎完全兼容 MySQL 的访问协议，可以使用现有的 MySQL 连接池组件访问 TiDB，业务迁移成本低，开发效率高。
边控中心是爱奇艺第一个在线业务使用 TiDB 的项目，所以我们制定了详细的上线计划。
 第一，部署单独的 TiDB 集群。然后，为了数据安全，部署了 TokuDB 集群，用作 TiDB 集群的备份数据库。
 第二，我们通过 TiDB-Binlog 将 TiDB 集群的数据变更实时同步到 TokuDB 集群中，作为 TiDB 的灾备方案。</description>
    </item>
    
    <item>
      <title>Qunar 高速发展下数据库的创新与发展 - TiDB 篇</title>
      <link>https://pingcap.com/cases-cn/user-case-qunar/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-qunar/</guid>
      <description>目前互联网公司数据存储主要依赖于 MySQL 为代表的关系型数据库，但是随着业务量的增长，使用场景更加多样，传统的关系型数据库不能很好的满足业务需求，主要是在两个维度：一是随着数据量爆炸式增长，性能急剧下降，而且很难在单机内存储；二是一些场景下业务对响应速度要求较高，数据库无法及时返回结果，而传统的 memcached 缓存又存在无法持久化数据，存储容量受限于内存等问题。针对这两个问题，去哪儿的 DBA 团队分别调研了 TiDB 和 InnoDB memcached 以满足业务需求，为用户提供更多的选择方案。
接下来的文章系列，我们将陆续为大家带来 TiDB 和 InnoDB memcached 在去哪儿的调研和实践，本篇文章先介绍 TiDB。
分布式数据库诞生背景 随着互联网的飞速发展，业务量可能在短短的时间内爆发式地增长，对应的数据量可能快速地从几百 GB 涨到几百个 TB，传统的单机数据库提供的服务，在系统的可扩展性、性价比方面已经不再适用。随着业界相关分布式数据库论文的发布，分布式数据库应运而生，可以预见分布式数据库必将成为海量数据处理技术发展的又一个核心。
目前业界最流行的分布式数据库有两类，一个是以 Google Spanner 为代表，一个是以 AWS Auraro 为代表。 Spanner 是 shared nothing 的架构，内部维护了自动分片、分布式事务、弹性扩展能力，数据存储还是需要 sharding，plan 计算也需要涉及多台机器，也就涉及了分布式计算和分布式事务。主要产品代表为 TiDB、CockroachDB、OceanBase 等。 Auraro 主要思想是计算和存储分离架构，使用共享存储技术，这样就提高了容灾和总容量的扩展。但是在协议层，只要是不涉及到存储的部分，本质还是单机实例的 MySQL，不涉及分布式存储和分布式计算，这样就和 MySQL 兼容性非常高。主要产品代表为 PolarDB。
去哪儿数据存储方案现状 在去哪儿的 DBA 团队，主要有三种数据存储方案，分别是 MySQL、Redis 和 HBase。
MySQL 是去哪儿的最主要的数据存储方案，绝大部分核心的数据都存储在 MySQL 中。MySQL 的优点不用多说，缺点是没法做到水平扩展。MySQL 要想能做到水平扩展，唯一的方法就业务层的分库分表或者使用中间件等方案。因此几年前就出现了各大公司重复造轮子，不断涌现出中间层分库分表解决方案，比如百度的 DDBS，淘宝的 TDDL，360 的 Atlas 等。但是，这些中间层方案也有很大局限性，执行计划不是最优，分布式事务，跨节点 join，扩容复杂（这个心酸 DBA 应该相当清楚）等。Redis 主要作为缓存使用，针对读访问延时要求高的业务，使用场景有限。 HBase 因其分布式的特点，可以通过 RS 的增加线性提升系统的吞吐，HDFS 具有水平扩展容量的能力，主要用来进行大数据量的存储，如日志、历史数据、订单快照等。HBase 底层存储是 LSM-Tree 的数据结构，与 B+ Tree 比，LSM-Tree 牺牲了部分读性能，用来大幅提升写性能。 但在实际运维的过程中，HBase 也暴露了一些缺点： 1.</description>
    </item>
    
    <item>
      <title>TiKV 在饿了么的大规模应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-eleme-1/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-eleme-1/</guid>
      <description>背景介绍 饿了么从 2008 年创建以来，一直都是飞速的发展。目前，饿了么已覆盖了 2000 多个城市，拥有 2.6 亿的用户，130 万的商户，300万的骑手。饿了么在配送时间上追求卓越，目前饿了么的准时达订单平均配送时长已达到 28 分钟以内。从 2015 年开始，饿了么形成了 2 大业务，在线交易平台业务和即时配送平台业务。饿了么的用户量和订单量的快速增长，带来了数据量的快速增长，从而产生对大数据量存储的强烈需求，并且很多数据都是 KeyValue 格式的数据。之前饿了么没有统一的 Key-Value 存储系统，这部分数据被存储在 MySQL、Redis、Mongo、Cassandra 等不同的系统中，将数据存储在这些系统中，带来一些问题，比如数据扩容不方便、内存不可靠、性能不达标、运维不方便等。
我们希望用一套统一的 Key-Value 存储系统来存储这些 Key-Value 形式的数据，并且满足以下所有的技术要求：
 大数据量，可以存储至少数十 TB 级别的数据。
 高性能，在满足高 QPS 的同时，保证比较低的延时。
 高可靠，数据被可靠的持久化存储，少量机器的损坏不会导致数据的丢失。
 高可用，作为在线服务的底层依赖存储，要有非常完善的高可用性能力，外卖服务不同于电子商务，对实时性要求非常高，对系统的可用性的要求则是更高的。
 易运维，可以在不停服的基础上进行数据迁移，和集群扩容。
  从 2017 年下半年开始，饿了么开始基于 TiKV 构建饿了么的 Key-Value 存储系统，并且取得了很好的应用效果。饿了么对 Key-Value 系统的使用是在线系统，由离线计算集群生成数据，在线服务消费这些数据。这些在线服务覆盖了饿了么在线交易和即时配送 2 大平台，在线交易平台中的首页搜索、商品品类、商品排序、天降红包等等，即时配送平台中的物流旗手智能调度等，各种在线服务都在使用我们的 Key-Value 系统。 目前，TiKV 的应用会影响饿了么全平台 80% 的流量，包括从用户选餐下单到订单配送整个饿了么流程。
TiKV集群上线情况  目前已在饿了么部署了十几套 TiKV 集群，分别位于北京、上海、广州的四个机房，共计 100+ 机器节点，承载了数十 TB 的数据。
 配置了完备的监控告警系统，所有集群都已接入，可以在集群出现问题时及时发送告警信息，为集群的正常运行提供了保障。</description>
    </item>
    
    <item>
      <title>TiDB 在今日头条的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-toutiao/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-toutiao/</guid>
      <description>本文整理自今日头条数据库中间件/分布式数据库负责人吴镝（知乎 ID：吴镝）在 TiDB DevCon2018 上的分享内容。
 TiDB 主要应用在今日头条核心 OLTP 系统 - 对象存储系统中，存储其中一部分元数据，支持头条图片和视频相关业务，比如抖音等。
如今（数据截至发文），TiDB 支撑着今日头条 OLTP 系统里 QPS 比较高的场景：集群容量约几十 T，日常 QPS 峰值会达到几十万。
为什么我们需要用 TiDB 今日头条内部有一些业务数据量非常大，之前用的 MySQL 的单机盘是大概 2.8T 的 SSD 盘。我们做对象存储。因为头条不但做视频，还做图片，这些视频和图片当中基本上都是用我们自研的 S3 存储系统，这种存储系统需要一个元数据，比如一个图片存下来，它存在 S3 系统的哪个机器、哪个文件、哪个偏移里面的数据，还有比如一个大的视频，S3 会把它切成很多小的视频片段，每一个分片的位置，都会存在元数据里面。
用 TiDB 之前，元数据是存在 MySQL 里的一个 2.8TB 的盘，因为增长的特别快，所以导致磁盘不够用，只能用分库分表的方案。我们以前用的的分库分表方案是 MyCAT。但用这个方案的过程中我们有遇到了一些问题，比如丢数据。某一个数据我 commit 了之后，最后发现这个数据丢了。
再就是连接的问题，目前头条做分片是大概固定分 100 个片。如果你的业务是需要分库分表，那你这边搞 101 个分片，这样有些业务，他用了一个分片键，用分片键来做查询，那可能中间件只用一个连接就可以找到相关数据。但有些业务，确实有不带分片键的请求。会导致 select 语句过来的时候，下面会建 101 个对后端的连接，也就是说，因为有连接的限制，有一个没有带分片键的这种请求过来之后， MyCAT 可以启 101 个连接到后面的每一个 MySQL 库。那这样的话，有时候我给它 5 万个连接，他一下子就把一百万用掉了。这样会导致它在非分片键的 select 请求，它连接速度消耗非常快，经常在业务这边会抛出说，连接数不够。
头条的数据库主要用的是 MySQL 和 MongoDB，相对比较单一，所我们也想多尝试一些其他的数据库。</description>
    </item>
    
    <item>
      <title>TiDB 在 G7 的实践和未来</title>
      <link>https://pingcap.com/cases-cn/user-case-g7/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-g7/</guid>
      <description>背景 2010 年，G7 正式为物流运输行业提供面向车队管理的 SaaS 服务，经过持续创新，通过软硬一体化的产品技术能力，致力于数字化每一辆货车，以实时感知技术创造智慧物流新生态。G7 为客户提供全方位的数据服务、智能的安全和运营管理、手机管车、数字运力、以及 ETC、油和金融等增值服务。
目前，G7 连接了 600,000 辆货车，每天行驶 6500 万公里（可绕地球赤道 1625 圈），13.5 亿个轨迹点和 2,200 万次车辆事件触发，并且以直线速度飞速增长。G7 每天产生的车辆行驶、状态、消费等数据超过 2T，飞速增加的车辆、数据类型和复杂的金融业务，使得数据库的事务、分析、扩展和可用性面临巨大的挑战。
在大量的车辆信息和轨迹相关数据业务中，当前我们通过 Spark、Hive 等对大量原始数据进行分析后，存入阿里云 DRDS，对外提供基础数据接口服务。由于清洗后的数据量依然很大，使用 DRDS 的存储成本非常高，且面对很多 OLAP 的查询时，效率不如人意。
而在金融和支付这种复杂业务场景中，面临 CAP 中 C 和 P 的挑战。在以往的工作中，支付系统由于面临强一致性事务的高峰值写入问题，采用了 2PC+MySQLXA（单个 MySQL 作为参与者，上层增加 Proxy 作为协调者）完成了分布式事务数据库的方案。但是这种方案在 Partition 中，极为麻烦。同时，运营和风控系统经常需要做相对复杂的查询，要么通过 MySQL+ETL+OLAP 数据库（成本高），要么容忍查询的效率问题。
探索 G7 的技术团队一直在寻找一种能解决上述问题的数据库。要找到这样一种数据库，除了需要满足上述需求以外，还需要满足另一个需求：可维护性和易迁移性。这要求该数据库具体需要满足如下几个要求：
 兼容 MySQL 协议，使得数据库的变更对上层业务透明，这个有多重要，做过基础架构升级落地的同学应该深有感触。
 支持 MySQL 的主从同步机制，使得数据库的变更可以平滑逐步升级，降低变更风险。
 必须是开源的。数据库的稳定需要付出很大的精力和时间，在这个过程中，或多或少都出现问题。出现问题不可怕，可怕的是无法定位和解决问题，只能依赖“他人”。数据库的一个 BUG 对“他人”来说，可能是一个小问题，对 G7 业务而言，可能是一个巨大的灾难。当“屁股”不在同一个板凳上时，我们需要对数据库有很强的掌控力。
 开源的同时，背后一定需要有一个有实力的技术团队或商业公司的全力投入。在见识了不少“烂尾”和“政绩”的开源项目后，只有一个稳定全职投入的技术团队或商业公司，才能最终让这个数据库越来越好。
  在这么多限制和需求的情况下，TiDB+TiSpark 很快进入我们的视线，并且开始调研。通过和 TiDB 技术人员的交流，除了满足上述的需求外，如下技术细节使我们一致认为可以选择这样的方案：</description>
    </item>
    
    <item>
      <title>TiDB 在二维火餐饮管理实时报表中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-erweihuo/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-erweihuo/</guid>
      <description>二维火 SaaS 平台介绍 二维火作为餐饮商家管理标准化服务提供商，帮助商家节省经营成本、提升服务效果是我们的使命。在商家日常生产中，上游系统产生了很多数据，包括供应链采购系统（Support），门店收银系统（POS），食客排队系统（Queueing），智能厨房显示系统（KDS），电子菜谱系统等（E-Menu）， 一个实时、精准、可多维度分析的报表系统能充分利用这些数据，支持商家对经营决策进行优化，极大提升商家工作效率。主要服务于以下场景：
 收银员交接班需要通过收银软件、财务报表进行多维度对账，来保障收银员一天的辛苦劳动。
 商家运营人员需要时段性监控每个门店的经营状况，并通过监控数据实时调整运营策略。
 中小型店老板解放自我，不再需要时时刻刻呆在门店里，也能从原料变化到收入波动进行实时把控。
 大型门店连锁更有专门的指挥中心，实时了解每个门店的经营状况，实现一体化管理。
  二维火各类报表界面：
二维火实时报表的业务约束  要求实时或者准实时，数据延迟不超过 3 秒。
 数据量大、数据增速快，报表结果查询需要在 500 ms 之内返回结果。
 查询维度多，查询条件复杂，涉及十几个业务表，上百个维度汇总查询。
  随着业务范围扩大以及功能扩展，实时报表业务不光承担了报表业务，业务方同时希望这是一个数据实时、可多维度查询分析的数据平台工具，为业务进行各种数据支持。
二维火数据的特殊场景  商家门店连锁关系不是固定的，A 门店数据今天属于 AA 连锁，明天可能会变成 BB 连锁。
 数据展现多人多面，权限不同展现结果不同。
 数据变更非常频繁，一条数据最少也会经过五六次变更操作。
 实时报表展现的不仅是当天数据，涉及到挂帐、垮天营业、不结账等复杂状况，生产数据的生命周期往往会超过一个月以上。
  如果用 MySQL 作为报表存储引擎的话，一个门店所属连锁总部变更，相当于分库的路由值产生了变化，意味着需要对这家店的数据进行全量迁移，这是个灾难性的事情，我们希望连锁只是个属性，而不用受到 Sharding Key 的制约导致的一地鸡毛。
开始的解决方案 我们的业务数据是构建在 MySQL 之上，按照业务和商家维度进行分库。利用 Otter 订阅业务数据，进行数据整理归并到 Apache Solr[1] 中，输出分析、统计报表所需要的数据。然而随着业务的快速发展以及客户定制化需求不断增加，Solr 的瓶颈从一张白纸慢慢地被填充。
 不断的添加检索维度，需要不停的对索引进行 Full Build，Solr 的 Full Build 成本慢慢地高成了一座大山。</description>
    </item>
    
    <item>
      <title>TiDB 在饿了么归档环境的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-eleme-2/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-eleme-2/</guid>
      <description>背景 随着业务增长，公司数据规模不断膨胀，表变多、变大。一方面占用的磁盘、CPU 等物理资源疾速上涨，另一方面大表性能下降且变更困难。实际上，很多大表的数据无需保留很久，比如某些业务可能只需近 3 周或近 3 个月的数据。对此类表，可依据业务要求，在线上环境只保留指定天数的数据，其余超出时间范围的过期数据可予以删除。出于某些原因，比如对账，线上业务查冷数据等，从生产环境删除的数据不能直接丢弃，需要存档以备不时之需，所谓归档。
方案 目前我们公司主要使用的是 MySQL 数据库服务，那么我们使用大磁盘容量的机器搭建几套主从结构的 MySQL 集群，配上高可用机制，将生产环境指定库表、指定时间范围之外且满足其他指定条件的数据按照一定的顺序定期分批导入到这些目标集群，并在每批确认导入成功后对源生产环境的数据予以删除，下批再从上次结束的位点开始导入、删除，如此循环重复，使生产环境表的数据始终维持在指定的时间范围。至于归档目标环境的数据则可以根据公司的要求统一保留指定的时间，比如 1 年。对于归档目标环境过期的数据可以进行直接删除处理。
问题 上述是一个典型的归档系统需要完成的基本功能和基本的处理流程，如果数据规模不是很大且增幅稳定而且表结构固定，那么上述流程可以很好的运行的。但现实的情况是公司数据规模庞大、数据增长迅速，而且由于业务发生变化等原因，后端的表结构可能需要跟着变化。而且，还需要考虑归档对生产集群正常业务的影响、对主从延迟的影响和 DDL 的影响等（这部分内容不在本文讨论范围）。
对于表结构变更有两种处理方式，
 “温和型”：在发现源端表结构发生变更后，相应的在目标端的表上执行同样的变更，以确保两端表结构一致数据可以正常写入；
 “粗暴型”：一旦发现源端表结构发生了变更，则在目标端轮转一个新表（旧表重命名，然后按源表新的表结构在目标端重建表）以确保源和目标表结构统一。
  “粗暴型”的解决方式可以很好的处理结构不一致问题，但如前边所述，一些线上的业务可能需要查询归档环境的冷数据，比如，用户想要查询半年前的订单数据，对于这类表简单粗暴的将其重命名会对业务查询归档数据造成困难；“温和型”的解决方式不仅可以处理表结构不一致的问题，而且也可以避免轮转表导致的数据查询问题，但是，对于 MySQL 来说，当归档表变得很大的时候，DDL 通常会非常耗时。
对于数据规模大、数据增长快这一情况，尽管选用了大磁盘容量的机型来存储归档数据，但因表多且数据量大往往在运行几个月后磁盘空间即被写满。这部分数据因为还没超出指定的有效期，所以还不能从归档目标环境直接清理，而 MySQL 又不能方便的进行容量扩展，所以只能考虑将现有的归档作业迁移至新的归档目标集群进行归档，而这一迁移也会对需要访问归档环境数据的应用造成影响。
另外，尽管启用了高可用机制，因为归档环境数据量大，一旦归档目标集群发生了 Master 节点切换，要想重新同步一份数据搭建一个 Slave 节点会非常耗时。
上述问题可简要概括为三个主要痛点：
 快速 Online DDL；
 水平扩展存储容量；
 故障恢复后的数据自动同步。
  探索 弹性伸缩和快速 Online DDL 不是我们在归档环境遇到的个案问题，其实也是数据库业界普遍会遇到的两个问题，尤其是现如今各类海量数据的大背景下，也因此出现过诸多解决方案。比如，TokuDB 存储引擎就可以快速安全的处理 DDL，而且是作为 MySQL 插件的方式提供的，所以对于基于 MySQL 的应用几乎可以不用进行任何改造就可以在 TokuDB 引擎上运行。而且 TokuDB 引擎有很高的压缩比，这一点对很多资源敏感型的用户也很具吸引力。
美中不足的是，TokuDB 只是插件式的存储引擎，并不能解决弹性扩容问题。 MySQL Cluster、PXC 等具备弹性扩容能力，但它们只是扩展了计算能力，并不能扩展存储能力，且大表的 DDL 依然是个问题。Cassandra，Vertica 这类分布式列式存储可以对计算和存储方便的进行弹性伸缩，DDL 也可以快速安全的进行，但这类数据库是非关系型的，不支持分布式事务（对于归档应用不是什么问题），且对于基于 MySQL 的应用需要进行大量兼容性的改造才可能迁移至这些存储（对于 MySQL 的归档意味着我们要进行额外的大量的改造工作）。</description>
    </item>
    
    <item>
      <title>TiDB 助力客如云餐饮 SaaS 服务</title>
      <link>https://pingcap.com/cases-cn/user-case-keruyun/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-keruyun/</guid>
      <description>公司介绍 客如云成立于 2012 年，是全球领先、 国内最大的 SaaS 系统公司。 目前面向餐饮、 零售等服务业商家， 提供软硬一体的新一代智能化前台、收银等 SaaS 云服务，包括预订、排队、外卖、点餐、收银、会员管理、进销存等系统服务，并将数据实时传达云端。我们是客如云的大数据基础架构组，负责公司的大数据架构和建设工作，为公司提供大数据基础数据服务。
业务发展遇到的痛点 1. 随着公司业务架构越来越复杂，技术架构组需要在服务器端与应用端尽可能的通过微服务化实现业务解耦，同时需要第三方熔断服务机制来保证核心业务正常运行。数据库层面，为了保证高并发的实时写入、实时查询、实时统计分析，我们针对地做了很多工作，比如对实时要求较高的服务走缓存、对大表进行分库分表操作、对有冷热属性的大表进行归档、库分离，虽然用大量人力资源解决了部分问题，但是同时也带来了历史数据访问、跨库分表操作、多维度查询等问题。
2. 大数据量下，MySQL 稍微复杂的查询都会很慢，线上业务也存在单一复杂接口包含执行几十次 SQL 的情况，部分核心交易大库急需解决访问性能。
3. 餐饮行业有明显的业务访问高峰时间，高峰期期间数据库会出现高并发访问，而有些业务，比如收银，在高峰期出现任何 RDS 抖动都会严重影响业务和用户体验。
4. 传统的数仓业务往往有复杂的 T+1 的 ETL 过程，无法实时的对业务变化进行动态分析和及时决策。
业务描述 大数据的 ODS（Operational Data Store）以前选型的是 MongoDB，ODS 与支持 SaaS 服务的 RDS 进行数据同步。初期的设想是线上的复杂 SQL、分析 SQL，非核心业务 SQL 迁移到大数据的 ODS 层。同时 ODS 也作为大数据的数据源，可以进行增量和全量的数据处理需求。但是由于使用的 MongoDB，对业务有一定侵入，需要业务线修改相应查询语句，而这点基本上遭到业务线的同学不同程度的抵制。同时目前大数据使用的是 Hadoop + Hive 存储和访问方案，业务线需要把历史明细查询迁移到 Hadoop ，然后通过 Impala、Spark SQL、Hive SQL 进行查询，而这三个产品在并发度稍微高的情况下，响应时间都会很慢，所以大数据组在提供明细查询上就比较麻烦。 同时更为棘手的是，面对客户查询服务（历史细则、报表等），这类查询的并发会更高，而且客户对响应时间也更为敏感，我们首先将处理后的数据（历史细则等）放在了 MongoDB 上（当时 TiDB 1.0 还没有 GA，不然就使用 TiDB 了），然后针对 OLAP 查询使用了 Kylin ，先解决了明细查询的问题。 但是由于业务很复杂, 数据变更非常频繁，一条数据最少也会经过五六次变更操作。报表展现的不仅是当天数据，涉及到挂账、跨天营业、不结账、预定等复杂状况，生产数据的生命周期往往会超过一个月以上。所以当前的 OLAP 解决方案还有痛点，所以后续我们要把 OLAP 查询移植一部分到 TiDB 上面去，来减轻 Kylin 的压力并且支持更加灵活的查询需求，这个目前还在论证当中。 同时，我们发现 TiDB 有一个子项目 TiSpark， TiSpark 是建立在 Spark 引擎之上，Spark 在机器学习领域里有诸如 MLlib 等诸多成熟的项目，算法工程师们使用 TiSpark 去操作 TiDB 的门槛非常低，同时也会大大提升算法工程师们的效率。我们可以使用 TiSpark 做 ETL，这样我们就能做到批处理和实时数仓，再结合 CarbonData 可以做到非常灵活的业务分析和数据支持，后期根据情况来决定是否可以把一部分 Hive 的数据放在 TiDB 上。</description>
    </item>
    
    <item>
      <title>TiDB 在凤凰网新闻内容业务的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ifeng/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ifeng/</guid>
      <description>背景 凤凰网（纽交所上市公司，代码：FENG）是全球领先的跨平台网络新媒体公司，整合旗下综合门户凤凰网、手机凤凰网和凤凰视频三大平台，秉承&amp;rdquo;中华情怀，全球视野，兼容开放，进步力量&amp;rdquo;的媒体理念，为主流华人提供互联网、无线通信、电视网的三网融合无缝衔接的新媒体优质内容与服务。
在媒体行业，新闻内容就是核心的业务数据，我们需要一个稳定的、具有高可用的、易水平扩展的数据存储系统，来存放公司核心数据，在最早，我们采用比较流行的 MySQL 来存储各个业务模块的内容，通过主从切换的方式进行高可用，但随着数据量的增加，MySQL 单机容量成为了瓶颈，传统的基于 MySQL 分片方案在实现及运维都需要比较昂贵的成本，同时 MySQL 主流主从切换方案由于机制问题，在判断“主库真死”，“新主库选举”及“新路由信息广播”上都存在一些不足，整体时间消耗比较大，并不能达到公司核心业务的高可用要求。于是，我们不得不寻找新的解决方案。
选择 TiDB 前期方案选择
在选择评估初期，我们主要有以下几个考虑点：
 支持业务弹性的水平扩容与缩容；
 满足业务故障自恢复的高可用；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL，尽量少的改动代码；
 使用上、运维上要足够优化，最好支持在线 DDL。
  在寻找的道路中，我们惊喜的发现了 TiDB — 中国人研发主导的开源分布式数据库。
数据库容量及扩展
记得有这样一句话：“单机 MySQL 能解决的问题，不要使用 TiDB！”，我们原有的数据存储存放于多个 MySQL 数据库中。诚然，对于数据量小的库来说，一些常见的点查、范围查 MySQL 的性能要比 TiDB 的性能好，如果不考虑扩张的问题，短期内使用主从 MySQL 比使用 TiDB 更满足我们的线上需求，但是，即使如此，我们也不得不考虑成本问题。将多套线上的主从 MySQL 迁移到 TiDB，更能充分利用服务器资源，减少资源的浪费。而对于很多业务来说，扩张问题是不可能回避的，对数据日益增长的数据库来说，单表响应时间会越来越长，而分库分表的成本过高，代码需要改动和测试，即使业务上能接受这一次的操作，那下次扩容呢？TiDB 通过底层自动进行分片帮我们解决了这个问题，同时业务量的增加或减少可以通过添加减少节点来处理，代码上基本无改动，这也是我们所期望的。
高可用
对于原有的主从 MySQL，并没有配置高可用，我们也对 MHA 等第三方工具做过调研，在发生主从切换后，在新路由信息分发这块也依赖修改网络配置或者数据库中间件（DBproxy），有一定的时间成本，虽然业界有很多中间件方案，但也很多问题和技术成本，所以这个方向并不是我们首选，之前的方式是一旦 MySQL 主数据库宕机，我们通过内部的监控系统获知，再进行更改 Keepalived + HAproxy 配置，即使人为响应非常及时，其影响的时间也早已超过业务的容忍。而选择天然的多节点 TiDB 自然就避免了这一点，配合网络 HAproxy 完全实现了 DB 层面的高可用。前一段时间，我们内部监控系统升级，其中一台机器没有对 TiKV 添加监控，而该 TiKV 节点由于硬件原因服务宕了几天，我们业务上也未感知，当然这是我们的失误，但是也侧面反应了 TiDB 自身的高可用机制。</description>
    </item>
    
    <item>
      <title>TiDB 在零氪科技（LinkDoc）大数据医疗系统的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-linkdoc/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-linkdoc/</guid>
      <description>公司介绍 零氪科技作为全球领先的人工智能与医疗大数据平台，拥有国内最大规模、体量的医疗大数据资源库和最具优势的技术支撑服务体系。多年来，零氪科技凭借在医疗大数据整合、处理和分析上的核心技术优势，依托先进的人工智能技术，致力于为社会及行业、政府部门、各级医疗机构、国内外医疗器械厂商、药企等提供高质量医疗大数据整体解决方案，以及人工智能辅助决策系统（辅助管理决策、助力临床科研、AI 智能诊疗）、患者全流程管理、医院舆情监控及品牌建设、药械研发、保险控费等一体化服务。
LinkDoc 的主要应用场景 LinkDoc 通过将患者真实的病例数据和算法模型应用于肿瘤治疗，构建精准的诊疗模型并提供数据支持，从而辅助医院管理决策、辅助科研、辅助临床诊疗。目前 Hubble 系统“肺癌淋巴结跳跃转移风险预测”模块可避免肺癌病人由于误判而导致提前 8-10 个月的复发，每年能让近两万病人的生命再延长 8-10 个月。Hubble 系统“AI - 肺结节智能诊断”模块全自动地识别 CT 影像中所有的结节，识别率达 91.5%。LinkDoc 希望凭借医疗大数据整合、处理和分析上的核心技术优势，以互联网人工智能上的创新研发，提升中国医师的全球医学水准，并通过支持药物研发与医疗保险行业的发展，让每一位患者享有普惠、精准的医疗服务。
支撑 LinkDoc 业务的底层数据库平台也面临着医疗行业新领域的技术 &amp;amp; 业务挑战，如数据量的快速增长（亿级别）、大数据量下的清洗逻辑的数据擦写、分析型事物对数据库的读压力都要求我们在数据库平台进行重新探索，选择一款适合医疗大数据业务的数据库解决方案。
选择 TiDB 业务痛点  数据量大，单实例 MySQL 扩容操作复杂；
 写入量大，主从延时高，由于业务对数据有低延时的要求，所以传统的 MySQL 主从架构在该项目下不能满足需求，大量数据写入下主库成为性能瓶颈；
 随着数据量越来越大，部分统计查询速度慢；
 分库分表业务开发和维护成本高。
  业务需求  高可靠性 &amp;amp; 稳定性；
 可扩展性，可随数据量 &amp;amp; 请求量增长快速提升存储 &amp;amp; 请求处理能力；
 更低的延时。
  方案调研 未选择 TiDB 之前我们调研了 MyCAT、Cobar、Atlas 等中间件解决方案，这些中间件整体来说就是让使用者觉得很“拧巴”，从社区支持、MySQL 功能兼容、系统稳定性上都不尽人意，需要业务做大量改造，对于快速发展的公司来说切换成本太高。
在 LinkDoc 首席架构师王晓哲的推荐下我们调研了 TiDB, TiDB 的如下特性让我们眼前一亮：</description>
    </item>
    
    <item>
      <title>TiDB 助力一面数据实现消费领域的决策分析平台</title>
      <link>https://pingcap.com/cases-cn/user-case-yimian/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yimian/</guid>
      <description>公司介绍 深圳市一面网络技术有限公司（下称：一面数据）是一家为消费领域的领导企业提供实时、精准、全面的数据洞察和决策指导的创新型企业，利用人工智能和算法，进行自然语言处理，语义情感分析，回归预测模型等，帮助客户实现精准产品运营和预测市场变化。一面数据服务于国内外一流企业，包括世界最大的对冲基金、国际一线汽车品牌、快消品龙头厂商，以及时尚鞋服大牌等。
改造前系统架构 一面数据的核心 IT 系统覆盖了从数据获取、数据清洗处理、数据建模到数据可视化的全套数据分析流程。核心系统每天有海量从互联网采集的公开数据和来自企业内部的数据，对数据存储的容量、扩展性和可用性都有很高的要求。
起初，一面数据的核心系统采用的是多个 MySQL 实例和一个 Cassandra 集群。MySQL 多实例集群主要存储指定特征的爬虫数据，Cassandra 主要存储数据量大、不适合存储 MySQL 的全页面缓存的数据。在数据量/请求量小的时候系统运行正常。下图为一面数据改造前系统构架图：
随着数据量的增长，逐渐暴露出很多问题：
 MySQL：随着数据增长，存储容量接近单机的磁盘极限，单机的磁盘 IO 繁忙且易阻塞，查询性能难以满足业务增长的需求。数据量大了以后，传统的 MySQL 水平扩展能力弱，性能和稳定性容易产生问题，在数据量和访问量增长到一定阶段将无法满足常见的 OLAP 场景分析需求。技术团队通过诊断系统性能问题，认识到现有数据库已经成为瓶颈。
 Cassandra：Cassandra 对磁盘 IO 和内存要求高，添加一个实例，需要从其他实例迁数据，对网络带宽、 磁盘要求特别高。另外 CQL 支持的特性太少，业务开发麻烦，例如不能联表，不支持主键之外的索引，对主键以外的查询比较困难，虽然有 Secondary Index，但是使用限制大。生态圈不完善，例如很难找到好用的监控。
  改造后的系统架构 引入 TiDB 替换 MySQL 和 Cassandra 为从根本上解决以上问题，一面数据的技术团队决定通过增加部署一套高性能的数据库系统，以解决当前业务的痛点。 在评估和验证了 MySQL Sharding 和 MongoDB 等传统技术手段之后，团队认识到：基于 MySQL Sharding (即利用 MySQL 中间件分库分表) 架构在高可用安全能力，业务和查询的灵活支持以及运维管理难度和成本上都不尽如人意，有着诸多架构上和技术上的缺陷；而 MongoDB 比较适合存储爬虫数据，但迁移成本高，不管是数据还是应用程序都需要做侵入性修改和调整，难度和开发成本骤升。另外，作为 NoSQL 数据库，MongoDB 不支持 SQL 和 JOIN ，对 BI 工具的支持也不完善，数据分析师们无法直接使用。 最终从满足业务需求、降低切换成本和减少运维成本等角度考虑，一面数据选择了分布式关系型数据库－TiDB 作为业务的首选事务型数据库。</description>
    </item>
    
    <item>
      <title>TiDB 在 Mobikok 广告系统中的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobikok/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobikok/</guid>
      <description>公司介绍 Mobikok（可可网络）成立于 2013 年，是一家快速成长的移动互联网营销公司，专注于移动 eCPM 营销。总部在中国深圳，聚焦于订阅 offer 的海外流量变现业务。Mobikok 提供的接口方式支持各类手机端流量（API、SDK、Smartlink），RTB（实时竞价系统）对接海外的 DSP（Demand-Side Platform，需求方平台）高效优化客户的广告效果。截止目前，系统已对 2 亿用户进行广告优化，已接入上百家广告主以及上百家渠道，Mobikok 致力于高效，便捷，专业的帮助广告主以及渠道互惠共赢。
场景介绍：SSP 系统 订阅 SSP（Sell-Side-Platform）平台当前业务主要分为：SDK、Smartlink、Online API 以及 Offline API；在当前 SSP SDK 业务系统当中，累计用户已达到 2 亿，最初使用的是 MySQL 主从分表的方式存储用户数据，随着数据量的增加，MySQL 单机容量以及大数据量查询成为了瓶颈；当单表数据达到 2 千万以上时，单机 MySQL 的查询以及插入已经不能满足业务的需求，当访问量到一定阶段后，系统响应能力在数据库这一块是一个瓶颈。
一次很偶然的机会在 GitHub 上面了解到 TiDB，并且因为现在业务系统当中使用的 Redis 集群是 Codis，已在线上稳定使用两年，听闻 TiDB 创始团队就是之前 Codis 的作者，所以对 TiDB 有了极大的兴趣并且进行测试。通过测试单机 MySQL 和 TiDB 集群，当数据量达到数千万级别的时候发现 TiDB 效率明显高于 MySQL。所以就决定进行 MySQL 到 TiDB 迁移。
迁移后整体架构图：
引入 TiDB 在选择使用替换 MySQL 方案当中。我们主要考虑几点：
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 高度兼容 MySQL，少改动代码；</description>
    </item>
    
    <item>
      <title>TiDB 在猿辅导数据快速增长及复杂查询场景下的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yuanfudao/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yuanfudao/</guid>
      <description>猿辅导是国内拥有最多中小学生用户的在线教育机构，旗下有猿题库、小猿搜题、猿辅导三款在线教育 APP，为用户提供在线题库、拍照搜题、名师在线辅导相关的服务。其中，猿辅导 APP 已经有超过 116 万付费用户，提供小学英语、奥数，和初中高中全学科的直播辅导课程，全国任何地区的中小学生，都可以享受在家上北京名师辅导课的服务。
海量的题库、音视频答题资料、用户数据以及日志，对猿辅导后台数据存储和处理能力都提出了严峻的要求。
猿辅导的业务决定了其后台系统具有以下特点：
 数据体量大，增速快，存储系统需要能够灵活的水平扩展；
 有复杂查询，BI 方面的需求，可以根据索引，例如城市、渠道等，进行实时统计；
 数据存储要具备高可用、高可运维性，实现自动故障转移。
  在最初方案选型时，猿辅导初期考虑用单机 MySQL。但根据业务发展速度预估，数据存储容量和并发压力很快就会达到单机数据库的处理瓶颈。如果在 MySQL 上加入分库中间件方案，则一定要指定 sharding key，这样是无法支持跨 shard 的分布式事务。同时 proxy 的方案对业务层的侵入性较强，开发人员必须了解数据库的分区规则，无法做到透明。
除此之外，分库分表很难实现跨 shard 的聚合查询，例如全表的关联查询、子查询、分组聚合等业务场景，查询的复杂度需要转嫁给开发者。即使某些中间件能实现简单的 join 支持，但是仍然没有办法保证查询的正确性。另外广播是一个没有办法 Scale 的方案，当集群规模变大，广播的性能开销是很大的。同时，传统 RDBMS 上 DDL 锁表的问题，对于数据量较大的业务来说，锁定的时间会很长，如果使用 gh-ost 这样第三方工具来实现非阻塞 DDL，额外的空间开销会比较大，而且仍然需要人工的介入确保数据的一致性，最后切换的过程系统可能会有抖动。可以说，运维的复杂性是随着机器数量指数级增长，而扩容复杂度则是直接转嫁给了 DBA。
最终，猿辅导的后台开发同学决定寻求一个彻底的分布式存储解决方案。通过对社区方案的调研，猿辅导发现分布式关系型数据库 TiDB 项目。
TiDB 是一款定位于在线事务处理/在线分析处理（HTAP）的融合型数据库产品，具备在线弹性水平扩展、分布式强一致性事务、故障自恢复的高可用、跨数据中心多活等核心特性；对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案，并在此过程中保证了事务的 ACID 特性。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。用户可以把 TiDB 当作一个容量无限扩展的单机数据库，复杂的分布式事务和数据复制由底层存储引擎来支持，开发者只需要集中精力在业务逻辑的开发上面。
图为 TiDB 与传统的 MySQL 中间件方案的一些对比
TiDB 集群主要分为三个组件：TiDB Server、TiKV Server、PD Server。
TiDB 整体架构图
TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以企业在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。</description>
    </item>
    
    <item>
      <title>TiKV 是如何存取数据的</title>
      <link>https://pingcap.com/blog-cn/how-tikv-store-get-data/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-tikv-store-get-data/</guid>
      <description>本文会详细的介绍 TiKV 是如何处理读写请求的，通过该文档，同学们会知道 TiKV 是如何将一个写请求包含的数据更改存储到系统，并且能读出对应的数据的。
基础知识 在开始之前，我们需要介绍一些基础知识，便于大家去理解后面的流程。
Raft TiKV 使用 Raft 一致性算法来保证数据的安全，默认提供的是三个副本支持，这三个副本形成了一个 Raft Group。
当 Client 需要写入某个数据的时候，Client 会将操作发送给 Raft Leader，这个在 TiKV 里面我们叫做 Propose，Leader 会将操作编码成一个 entry，写入到自己的 Raft Log 里面，这个我们叫做 Append。
Leader 也会通过 Raft 算法将 entry 复制到其他的 Follower 上面，这个我们叫做 Replicate。Follower 收到这个 entry 之后也会同样进行 Append 操作，顺带告诉 Leader Append 成功。
当 Leader 发现这个 entry 已经被大多数节点 Append，就认为这个 entry 已经是 Committed 的了，然后就可以将 entry 里面的操作解码出来，执行并且应用到状态机里面，这个我们叫做 Apply。
在 TiKV 里面，我们提供了 Lease Read，对于 Read 请求，会直接发给 Leader，如果 Leader 确定自己的 lease 没有过期，那么就会直接提供 Read 服务，这样就不用走一次 Raft 了。如果 Leader 发现 lease 过期了，就会强制走一次 Raft 进行续租，然后在提供 Read 服务。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十九）tikv-client（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</guid>
      <description>上篇文章 中，我们介绍了数据读写过程中 tikv-client 需要解决的几个具体问题，本文将继续介绍 tikv-client 里的两个主要的模块——负责处理分布式计算的 copIterator 和执行二阶段提交的 twoPhaseCommitter。
copIterator copIterator 是什么 在介绍 copIterator 的概念之前，我们需要简单回顾一下前面 TiDB 源码阅读系列文章（六）中讲过的 distsql 和 coprocessor 的概念以及它们和 SQL 语句的关系。
tikv-server 通过 coprocessor 接口，支持部分 SQL 层的计算能力，大部分只涉及单表数据的常用的算子都可以下推到 tikv-server 上计算，计算下推以后，从存储引擎读取的数据虽然是一样的多，但是通过网络返回的数据会少很多，可以大幅节省序列化和网络传输的开销。
distsql 是位于 SQL 层和 coprocessor 之间的一层抽象，它把下层的 coprocessor 请求封装起来对上层提供一个简单的 Select 方法。执行一个单表的计算任务。最上层的 SQL 语句可能会包含 JOIN，SUBQUERY 等复杂算子，涉及很多的表，而 distsql 只涉及到单个表的数据。一个 distsql 请求会涉及到多个 region，我们要对涉及到的每一个 region 执行一次 coprocessor 请求。
所以它们的关系是这样的，一个 SQL 语句包含多个 distsql 请求，一个 distsql 请求包含多个 coprocessor 请求。
copIterator 的任务就是实现 distsql 请求，执行所有涉及到的 coprocessor 请求，并依次返回结果。</description>
    </item>
    
    <item>
      <title>Weekly update (September 17 ~ September 23, 2018)</title>
      <link>https://pingcap.com/weekly/2018-09-25-tidb-weekly/</link>
      <pubDate>Tue, 25 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-09-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 29 PRs in the TiDB repository.
Added  Support dumping statistics for partitioned tables Add a variable to control the statement priority of a TiDB server Add a WithRecovery() function in the util package  Improved  Remove the DDL version in metrics Set TiDBMemQuotaQuery to the value in the configuration file Prune columns for LogicalTableDual Optimize the IsPoint() function for performance Support limit/group-by/order-by clauses in Point_Get Reuse chunks to reduce memory usage in UnionScan Add correctness check for some system variables Optimize constant fold for null parameter expressions to simplify the outer join Enhance predicate pushdown over join Support the init_vector argument for the built-in function AES_ENCRYPT/AES_DECRYPT  Fixed  Fix a bug in the Format() function for some expressions Fix the session time in show processlist Fix INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>TiKV 集群版本的安全迁移</title>
      <link>https://pingcap.com/blog-cn/tikv-cluster-migration/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-cluster-migration/</guid>
      <description>问题描述 在 TiDB 的产品迭代中，不免会碰到一些兼容性问题出现。通常协议上的兼容性 protobuf 已经能帮我们处理的很好，在进行功能开发，性能优化时，通常会保证版本是向后兼容的，但并不保证向前兼容性，因此，当集群中同时有新旧版本节点存在时，旧版本不能兼容新版本的特性，就有可能造成该节点崩溃，影响集群可用性，甚至丢失数据。目前在有不兼容的版本升级时，会要求进行离线升级，但这会影响到服务，我们需要一个适合的机制来进行不停服务的升级。因此我们需要在进行滚动升级时，让这些不能保证整个集群的向后兼容性的功能不被启用。只有在保证集群中所有节点都已经升级完成后，我们才安全的启用这些功能。
常见的当我们对引入新的 RaftCommand 的时候，旧版本的 TiKV 并不能识别新的添加的 RaftCommand，对于不能认知的 RaftCommand TiKV 有不同的处理，可能会报错退出或忽略。比如为了支持 Raft Learner, 在 raftpb 里对添加新的 ConfChange 类型。 当 PD 在进行 Region 调度时，会先发送 AddLearner 到 TiKV 上，接受到这个命令的肯定是这个 Region 的 Leader，在进行一系列检查后，会将该命令 Proposal, 而 Follwer 如果是旧版本的话，在 Apply 这条 Command 就会出错。而在滚动升级时，很有可能存在 Leader 是新版本，Follwer 是老版本的情况。
引入版本检查机制 TiDB 的版本定义是遵循 Semver 的版本规则的。版本格式一般由主版本号（Major），次版本号（Minor），修订号（Patch），版本号递增规则如下：
 主版本号：当进行了不兼容的 API 修改。 次版本号：当做了向下兼容的功能性新增。 修订号：当做了向下兼容的问题修正。  先行版本号（PreRelase）及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。比如 TiDB 目前的版本是 2.1.0-beta，先行版号为 beta 版。
在此之前，集群并没有版本的概念，虽然每个组件都有各自的版本信息，但各个节点的各自组件的版本都可以任意的。没有一个管理机制可以管理或查看所有组件的版本信息。为了解决滚动升级过程中存在多个版本的兼容性问题，这里引入集群版本的概念，并由 TiDB 集群的中心节点 PD 来进行管理和检查。
具体实现 1.</description>
    </item>
    
    <item>
      <title>Weekly update (September 10 ~ September 16, 2018)</title>
      <link>https://pingcap.com/weekly/2018-09-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-09-17-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repository.
Added  Add a design document for TiDB cluster&amp;rsquo;s system timezone Support resigning the DDL owner and use the ddl/owner/resign HTTP method Write system timezone into the MYSQL.TIDB table in the bootstrap stage Add two built-in functions decode and encode Add a proposal document for a Volcano/Cascades model based SQL planner  Improved  Make the decimal default precision visible in SHOW CREATE TABLE Use the pumps client to write binlog files Improve the error message of GC life time Fill the data length fields for INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>PingCAP Raises $50 Million in Series C Round, Sets Eyes on Global Expansion, Cross-Cloud Offering, and More Core Technology Investment</title>
      <link>https://pingcap.com/blog/series-c-announcement/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/series-c-announcement/</guid>
      <description>Read the coverage on TechCrunch, Business Insider, SiliconANGLE
PingCAP Raises $50 Million in Series C Round
SAN MATEO, CA., September 11, 2018 &amp;ndash; PingCAP, a leading distributed database company that created the popular cloud-native NewSQL database TiDB, announces a $50 million Series C funding round led by FOSUN and Morningside Venture Capital. All previous investors—China Growth Capital, Yunqi Partners, Matrix Partners China, and others—have also participated in this round. PingCAP plans to use this new capital to expand the TiDB ecosystem globally, build cross-cloud product offering, and invest in innovation of its core technology.</description>
    </item>
    
    <item>
      <title>Weekly update (September 03 ~ September 09, 2018)</title>
      <link>https://pingcap.com/weekly/2018-09-10-tidb-weekly/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-09-10-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 39 PRs in the TiDB repository.
Added  Add different labels for restricted SQL and general SQL metrics Add the USR1 signal handler to dump goroutine Use the point get plan for the UPDATE statement Support load data with IgnoreLines Support the json_contains builtin function  Improved  Make Analyze Buckets number configurable Set HIGH_PRIORITY for the bootstrap SQL statements Only check the range typed partition when creating a partitioned table Make a tiny refactor in the reorganization stage of adding indices Relax the tso backoff limit Reduce chunk&amp;rsquo;s iterator function call Improve compatibility for the MariaDB client Do AutoAnalyze on a certain period of a day Change the logic of converting the logical join to the index join Read the inner table and build hash table parallel in hash join Add batch copy to the inner join and the left and right outer join Add a ctxPool field to the worker struct to make executing the SQL statement in the DDL package possible  Fixed  Fix some datetime related cases which are inconsistent with MySQL Fix a compatibility problem of analyzing period variables Fix an error in the parser when parsing a single line comment ended with a newline character Fix an issue that the gc_delete_range table is queried with a wrong form of timestamp Fix an issue that the bit type can use null as its default value Return the correct column name and column label name Fix a panic when logging detailed statistics Fix a wrong count output of explain for the TableScan plan Fix the update join result when the join table order is changed Fix the issue that creating a partitioned table with bigint columns fails  Weekly update in TiSpark Last week, we released a new version 1.</description>
    </item>
    
    <item>
      <title>使用 TiKV 构建分布式类 Redis 服务</title>
      <link>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</guid>
      <description>什么是 Redis Redis 是一个开源的，高性能的，支持多种数据结构的内存数据库，已经被广泛用于数据库，缓存，消息队列等领域。它有着丰富的数据结构支持，譬如 String，Hash，Set 和 Sorted Set，用户通过它们能构建自己的高性能应用。
Redis 非常快，没准是世界上最快的数据库了，它虽然使用内存，但也提供了一些持久化机制以及异步复制机制来保证数据的安全。
Redis 的不足 Redis 非常酷，但它也有一些问题：
 内存很贵，而且并不是无限容量的，所以我们不可能将大量的数据存放到一台机器。 异步复制并不能保证 Redis 的数据安全。 Redis 提供了 transaction mode，但其实并不满足 ACID 特性。 Redis 提供了集群支持，但也不能支持跨多个节点的分布式事务。  所以有时候，我们需要一个更强大的数据库，虽然在延迟上面可能赶不上 Redis，但也有足够多的特性，譬如：
 丰富的数据结构 高吞吐，能接受的延迟 强数据一致 水平扩展 分布式事务  为什么选择 TiKV 大约 4 年前，我开始解决上面提到的 Redis 遇到的一些问题。为了让数据持久化，最直观的做法就是将数据保存到硬盘上面，而不是在内存里面。所以我开发了 LedisDB，一个使用 Redis 协议，提供丰富数据结构，但将数据放在 RocksDB 的数据库。LedisDB 并不是完全兼容 Redis，所以后来，我和其他同事继续创建了 RebornDB，一个完全兼容 Redis 的数据库。 无论是 LedisDB 还是 RebornDB，因为他们都是将数据放在硬盘，所以能存储更大量的数据。但它们仍然不能提供 ACID 的支持，另外，虽然我们可以通过 codis 去提供集群的支持，我们也不能很好的支持全局的分布式事务。
所以我们需要另一种方式，幸运的是，我们有 TiKV。
TiKV 是一个高性能，支持分布式事务的 key-value 数据库。虽然它仅仅提供了简单的 key-value API，但基于 key-value，我们可以构造自己的逻辑去创建更强大的应用。譬如，我们就构建了 TiDB ，一个基于 TiKV 的，兼容 MySQL 的分布式关系型数据库。TiDB 通过将 database 的 schema 映射到 key-value 来支持了相关 SQL 特性。所以对于 Redis，我们也可以采用同样的办法 - 构建一个支持 Redis 协议的服务，将 Redis 的数据结构映射到 key-value 上面。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十八）tikv-client（上）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</guid>
      <description>在整个 SQL 执行过程中，需要经过 Parser，Optimizer，Executor，DistSQL 这几个主要的步骤，最终数据的读写是通过 tikv-client 与 TiKV 集群通讯来完成的。
为了完成数据读写的任务，tikv-client 需要解决以下几个具体问题：
 如何定位到某一个 key 或 key range 所在的 TiKV 地址？
 如何建立和维护和 tikv-server 之间的连接？
 如何发送 RPC 请求？
 如何处理各种错误？
 如何实现分布式读取多个 TiKV 节点的数据？
 如何实现 2PC 事务？
  我们接下来就对以上几个问题逐一解答，其中 5、6 会在下篇中介绍。
如何定位 key 所在的 tikv-server 我们需要回顾一下之前 《三篇文章了解 TiDB 技术内幕——说存储》 这篇文章中介绍过的一个重要的概念：Region。
TiDB 的数据分布是以 Region 为单位的，一个 Region 包含了一个范围内的数据，通常是 96MB 的大小，Region 的 meta 信息包含了 StartKey 和 EndKey 这两个属性。当某个 key &amp;gt;= StartKey &amp;amp;&amp;amp; key &amp;lt; EndKey 的时候，我们就知道了这个 key 所在的 Region，然后我们就可以通过查找该 Region 所在的 TiKV 地址，去这个地址读取这个 key 的数据。</description>
    </item>
    
    <item>
      <title>Weekly update (August 27 ~ September 02, 2018)</title>
      <link>https://pingcap.com/weekly/2018-09-03-tidb-weekly/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-09-03-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 45 PRs in the TiDB repository.
Added  Enable the Mutex profiling in the TiDB server Let Analyze use the RC level and the low priority Support Grow of the chunk capacity Add job action and schema version information to metrics Forbid users to drop an important system table Support rollback when adding an index in a partitioned table Add a KeyOnly option for the Seek operation Maintain HistColl in StatsInfo of DataSource Add a TiDB tracing prototype  Improved  Remove goroutine_pool Remove the test coverage task from travis Rebase the auto increment ID when needed Fix the lint tool Make the duplicate error output in the Update statement more clearly Bump Go version to 1.</description>
    </item>
    
    <item>
      <title>TiDB Reaches the 200 Contributors Milestone</title>
      <link>https://pingcap.com/blog/tidb-community-200-contributors/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/tidb-community-200-contributors/</guid>
      <description>Dear TiDB Contributors:
As you might’ve noticed, TiDB recently added its 200th contributor. As CEO and co-founder of PingCAP who began building TiDB three years ago, I would like to thank the entire TiDB community for helping us reach this important milestone!
TiDB development started in 2015. In August 2018, we welcomed our 200th contributor!
Here are a few of my favorite contributions to highlight:
 @dbjoa (from Samsung Electronics) contributed plan cache for prepared statements, resulting in a performance gain of 27%!</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十七）DDL 源码解析</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</guid>
      <description>DDL 是数据库非常核心的组件，其正确性和稳定性是整个 SQL 引擎的基石，在分布式数据库中，如何在保证数据一致性的前提下实现无锁的 DDL 操作是一件有挑战的事情。本文首先会介绍 TiDB DDL 组件的总体设计，介绍如何在分布式场景下支持无锁 shema 变更，描述这套算法的大致流程，然后详细介绍一些常见的 DDL 语句的源码实现，包括 create table、add index、drop column、drop table 这四种。
DDL in TiDB TiDB 的 DDL 通过实现 Google F1 的在线异步 schema 变更算法，来完成在分布式场景下的无锁，在线 schema 变更。为了简化设计，TiDB 在同一时刻，只允许一个节点执行 DDL 操作。用户可以把多个 DDL 请求发给任何 TiDB 节点，但是所有的 DDL 请求在 TiDB 内部是由 owner 节点的 worker 串行执行的。
 worker：每个节点都有一个 worker 用来处理 DDL 操作。 owner：整个集群中只有一个节点能当选 owner，每个节点都可能当选这个角色。当选 owner 后的节点 worker 才有处理 DDL 操作的权利。owner 节点的产生是用 Etcd 的选举功能从多个 TiDB 节点选举出 owner 节点。owner 是有任期的，owner 会主动维护自己的任期，即续约。当 owner 节点宕机后，其他节点可以通过 Etcd 感知到并且选举出新的 owner。  这里只是简单概述了 TiDB 的 DDL 设计，下两篇文章详细介绍了 TiDB DDL 的设计实现以及优化，推荐阅读：</description>
    </item>
    
    <item>
      <title>Weekly update (August 20 ~ August 26, 2018)</title>
      <link>https://pingcap.com/weekly/2018-08-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-08-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 34 PRs in the TiDB repository.
Added  Make the query feedback work for the partitioned table Support a new aggregate framework for HashAggExec  Fixed  Fix a bug when using a correlated column as the index Fix the prepare result for zero timestamp/time/datetime Fix the Enum type flag bug Make partition by range value accept the constant expression Fix concat in the GROUP statement Fix selecting null value for table partition Use the unified infoschema in select .</description>
    </item>
    
    <item>
      <title>TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库</title>
      <link>https://pingcap.com/blog-cn/tidb-operator-introduction/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-operator-introduction/</guid>
      <description>TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（pingcap/tidb-operator）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。
要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。
TiDB 和 Kubernetes 简介 TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。  TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。
 TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。
 PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。
  上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.72】TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库</title>
      <link>https://pingcap.com/meetup/meetup-2018-08-20/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-08-20/</guid>
      <description>TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具，目前已经开源。在上周六举办的 Infra Meetup 第 72 期上，我司邓栓老师为大家分享了 TiDB Operator 开源的细节，并演示了单机快速体验 TiDB Operator 的操作。 以下是邓栓老师撰写的技术详解文章和 Meetup 现场视频。希望大家通过文字和视频深入了解 TiDB Operator 之后，可以速来贡献代码、成为 Contributor ！( ´▽｀)  TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（pingcap/tidb-operator）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。
要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。</description>
    </item>
    
    <item>
      <title>Weekly update (August 13 ~ August 19, 2018)</title>
      <link>https://pingcap.com/weekly/2018-08-20-tidb-weekly/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-08-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repository.
Added  Store the TiDB server information to PD and add the HTTP API handle Support dropping the index for the partitioned table Support the Replace operation for table partition Add BatchPut and BatchDelete for the Raw client Support CharsetOpt to load the data statement in Parser  Fixed  Fix group_concat when the chunk size is set to 1 Fix the admin check index panic when the index contains the pkIsHandle column Fix the fraction part handle of current_timestamp Fix the panic in checkRangePartitioningKeysConstraints when creating table partitions by range columns Set the proper customized timezone Set the types of index columns in CheckIndexRangeExec Fix the missing microsecond for the timestamp Fix duplicate row check when the chunk size is small Fix the return value of resultType/flag in the enum/set column information  Improved  Log detailed statistics for the query feedback Collect execution details and output them in the slow query log Notify the statistics worker when truncating tables Add a new interface MergePartialResult for the new aggregation framework  Weekly update in TiSpark Last week, we landed 2 PRs in the TiSpark repository.</description>
    </item>
    
    <item>
      <title>9 Why&#39;s to Ask When Evaluating a Distributed Database</title>
      <link>https://pingcap.com/blog/9-whys-to-ask-when-evaluating-a-distributed-database/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/9-whys-to-ask-when-evaluating-a-distributed-database/</guid>
      <description>When I first started building TiDB with my co-founders, we encountered countless challenges, pitfalls, and critical design choices that could have made or broken the project. To build an enterprise-grade distributed database like TiDB from scratch, we have to constantly make difficult decisions that balance the speed of development with long-term considerations for our customers and our team.
Three years and two big releases later, TiDB 2.0 is now deployed in-production in more than 200 companies.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</guid>
      <description>在之前的一篇文章 《TiDB 源码阅读系列文章（四）INSERT 语句概览》 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。
本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。
INSERT 语句的种类 从广义上讲，TiDB 有以下六种 INSERT 语句：
 Basic INSERT
 INSERT IGNORE
 INSERT ON DUPLICATE KEY UPDATE
 INSERT IGNORE ON DUPLICATE KEY UPDATE
 REPLACE
 LOAD DATA
  这六种语句理论上都属于 INSERT 语句。
第一种，Basic INSERT，即是最普通的 INSERT 语句，语法 INSERT INTO VALUES ()，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。
第二种，语法 INSERT IGNORE INTO VALUES ()，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 SHOW WARNINGS 看到哪些行没有被插入。</description>
    </item>
    
    <item>
      <title>Weekly update (August 06 ~ August 12, 2018)</title>
      <link>https://pingcap.com/weekly/2018-08-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-08-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repositories.
Added  Support the Update operation for table partition Support the prefix index in admin check table  Fixed  Fix behaviors of builtin LTrim, RTrim and Trim Fix group_concat(a) when a is null Make USE INDEX(PRIMARY) work on the integer primary key Fix admin check table false alarm when the index contains the pkIsHandle column Fix inconsistent row count estimation Fix a bug when applying the RenameTable diff  Improved  Perform the batch check for the constrains when adding a unique index Remove Exists in plan and executor Disable the Read Committed isolation level Refactor joinResultGenerator to handle the unmatched outer records Adjust the way of checking all the schema versions Update the import path from coreos/gofail to etcd-io/gofail to fix CI  Weekly update in TiKV and PD Last week, we landed 27 PRs in the TiKV and PD repositories.</description>
    </item>
    
    <item>
      <title>Managing the Surging Data Volume of a Fast-Growing Marketplace with TiDB</title>
      <link>https://pingcap.com/success-stories/tidb-in-zhuanzhuan/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/success-stories/tidb-in-zhuanzhuan/</guid>
      <description>Industry: E-commerce
Authors: Xuan Sun (Chief Architect at Zhuan Zhuan), Dong Chen (Senior Engineer at Zhuan Zhuan) and Haodong Ji (Senior Database Administrator at Zhuan Zhuan)
The Letgo of China, Zhuan Zhuan is a mobile app that enables our 100 million users to engage in “recommerce,” the e-commerce of buying and selling of second-hand goods ranging from smartphones and clothes to furniture and baby gear. Co-invested by 58.com Inc., the leading online classifieds and listings website in China, and the internet services giant Tencent, our platform has experienced tremendous growth since its launch in 2015.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十五）Sort Merge Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</guid>
      <description>什么是 Sort Merge Join 在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 wikipedia。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。
TiDB Sort Merge Join 实现 执行过程 TiDB 的实现代码在 tidb/executor/merge_join.go 中 MergeJoinExec.NextChunk 是这个算子的入口。下面以 SELECT * FROM A JOIN B ON A.a = B.a 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：
 顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。
 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。</description>
    </item>
    
    <item>
      <title>Weekly update (July 30 ~ August 05, 2018)</title>
      <link>https://pingcap.com/weekly/2018-08-06-tidb-weekly/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-08-06-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 68 PRs in the TiDB repositories.
Added  Support the Delete operation for table partition Support analyzing the partition table  Fixed  Fix the union result when mixing signed and unsigned columns Add BatchPut for RawKV Fix a bug about wrong copying in index join Fix a panic caused by the local feedback Fix a bug in decimal multiplication Sort user records in the privilege cache Fix TruncateTo Fix a bug of update with an outer join Fix admin cleanup index for non-unique handles in a unique index Fix a bug when eliminating a projection Skip inner rows when the join keys contain NULL  Improved  Support fast path point select Always choose the smaller child as the outer table for IndexJoin Remove FromID from expression.</description>
    </item>
    
    <item>
      <title>Landing Your First Rust Pull Request in TiKV</title>
      <link>https://pingcap.com/blog/adding-built-in-functions-to-tikv/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/adding-built-in-functions-to-tikv/</guid>
      <description>This guide is intended to show how you can land your first Pull Request (PR) in Rust to contribute to TiKV in less than 30 minutes. But before we do that, here’s some helpful background.
TiDB (&amp;ldquo;Ti&amp;rdquo; = Titanium) is an open-source distributed scalable Hybrid Transactional and Analytical Processing (HTAP) database, built by the company PingCAP (that’s us!) and its active open-source community (that’s you!). It’s designed to provide infinite horizontal scalability, strong consistency, and high availability with MySQL compatibility.</description>
    </item>
    
    <item>
      <title>三十分钟成为 Contributor | 为 TiKV 添加 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。
图 1
如图 1，当 TiDB 收到来自客户端的查询请求
select count(*) from t where a + b &amp;gt; 5
时，执行顺序如下：
 TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV
 TiKV 收到请求后，循环以下过程
 获取下一行完整数据，并按列解析
 使用参数中的 where 表达式对数据进行过滤
 若上一条件符合，进行聚合计算
  TiKV 向 TiDB 返回聚合计算结果
 TiDB 对所有涉及的结果进行二次聚合，返回给客户端
  这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。</description>
    </item>
    
    <item>
      <title>Weekly update (July 23 ~ July 29, 2018)</title>
      <link>https://pingcap.com/weekly/2018-07-30-tidb-weekly/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-07-30-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Add the sum_decimal method for AggFunc Support truncating and dropping partitioned tables Implement the reorganization of table partition when adding the index  Fixed  Fix a bug that the bit and year column types are not supported when a partition table is created Fix a bug in the decimal modulo operation Refactor the code of building Insert Fix a panic caused by the outdated feedback Fix a panic that is upgraded from the old version TiDB Fix a bug that null values cannot be found using the unique index  Improved  Add the partition function check when creating a partition table Provide preliminary support for the parallel DDL operation Use feedback timely Optimize DecodeRowKey Remove the types.</description>
    </item>
    
    <item>
      <title>Weekly update (July 16 ~ July 22, 2018)</title>
      <link>https://pingcap.com/weekly/2018-07-23-tidb-weekly/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-07-23-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 41 PRs in the TiDB repositories.
Added  Support group_concat in the new aggregation evaluation framework Support the remained types (String/Time/Duration/JSON) for Max/Min Support FIRST_ROW in the new aggregation evaluation framework Support the admin check table statement for table partition Add the proposal template Add the new storage row format proposal Add the design document about the new aggregate framework Set the PB field type and the ExtraHandle column type  Fixed  Fix the daylight saving time issue Fix the panic of creating partition tables Fix the bug in loading data Fix the OOM issue in the batch operations Add keepalive Truncate the prefix index from runes when the charset is UTF-8 Check b.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</guid>
      <description>在 统计信息（上） 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。
文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。
数据结构定义 直方图的定义可以在 histograms.go 中找到，值得注意的是，对于桶的上下界，我们使用了在 《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。
CM Sketch 的定义可以在 cmsketch.go 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 table，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 table 中得到。
除此之外，对列和索引的统计信息，分别使用了 Column 和 Index 来记录，主要包含了直方图，CM Sketch 等。 统计信息创建 在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 builder.go 中切分成不同的任务，然后在 analyze.go 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。
列直方图的创建 在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。
在 collect 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。</description>
    </item>
    
    <item>
      <title>Weekly update (July 09 ~ July 15, 2018)</title>
      <link>https://pingcap.com/weekly/2018-07-16-tidb-weekly/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-07-16-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories.
Added  Support BIT_AND/BIT_XOR in the new aggregation framework Support COUNT in the new aggregation framework Support AVG(DISTINCT) in the new aggregation framework Add the GENERATION_EXPRESSION column in information_schema.columns Support more syntactic rules regarding the SET syntax Support ADMIN SHOW DDL JOBS &amp;lt;NUMBER&amp;gt; to specify the lines of the results Support showing AUTO_INCREMENT in information_schema.tables  Fixed  Fix a bug in INSERT SELECT FROM ON DUPLICATE KEY UPDATE Fix the numeric type overflow in the binary protocol Fix the results of decimal Minus/Round/Mul  Improved  Check the schema when the DDL fails Refine the explain result format Speed up autoAnalyze when data is unchanged  Weekly update in TiKV and PD Last week, we landed 19 PRs in the TiKV and PD repositories.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</guid>
      <description>简述 在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 a = 1 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 a = 1 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。
索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。
关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：三篇文章了解 TiDB 技术内幕 - 说计算 ）。
这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：
CREATE TABLE t (a int primary key, b int, c int); select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5; 计算索引逻辑区间范围的流程如下：</description>
    </item>
    
    <item>
      <title>TiSpark: More Data Insights, Less ETL</title>
      <link>https://pingcap.com/blog/tispark-more-data-insights-no-more-etl/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/tispark-more-data-insights-no-more-etl/</guid>
      <description>Author: Shawn Ma is a Tech Lead at PingCAP in the OLAP team. Previously, he was Tech Lead at Netease and Quantcast. He received his Masters in Computer Science from University of California&amp;ndash;Irvine.
When we released TiDB 2.0 in April, part of that announcement also included the release of TiSpark 1.0&amp;ndash;an integral part of the TiDB platform that makes complex analytics on &amp;ldquo;fresh&amp;rdquo; transactional data possible. Since then, many people in the TiDB community have been asking for more information about TiSpark.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.72】TiDB 2.1 新特性与未来规划</title>
      <link>https://pingcap.com/meetup/meetup-2018-07-10/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-07-10/</guid>
      <description>在上周六举办的 Infra Meetup No.71 上，我司申砾老师重点介绍了 TiDB 2.1 Beta 版本在 Raft / PD / SQL 执行引擎等方面的新特性以及未来的规划（中间穿插着我司 CTO 的各种「插播新闻」😂）。当天虽然下着小雨，但丝毫没有影响大家的热情，活动结束后还有不少童鞋留下来讨论哦～以下是现场视频&amp;amp;文字回顾，enjoy ！
视频回顾 视频 | Infra Meetup No.72：TiDB 2.1 新特性与未来规划
可下载 完整 PPT 配合观看
干货节选 TiDB 2.0 版本于今年 4 月底发布，经过两个月的开发，2.1-Beta 版本于 6 月底发布。这个版本在 2.0 的基础之上做了不少改进。
在 Raft 方面，2.1 最大的变化是引入了 Learner 和 PreVote 两个特性。其中 Learner 可以加强调度过程中的数据安全性，并且为将来 OLAP 请求读 Learner 副本打下基础；PreVote 可以增强系统的稳定性，降低诸如网络隔离后节点重新加入造成的系统抖动。
在 PD 方面，2.1 优化了热点调度功能，收集更详细更准确的集群负载信息，并做更合理的调度在 SQL 优化器方面对 CBO 框架做了进一步改进，提升代价估算准确度。
在 SQL 执行引擎方面，将 Hash 聚合算子以及 Projection 算子做了并行化，提升大数据量下查询的性能。同时我们也在探索 OLTP 场景下的性能提升方案，预计到 2.</description>
    </item>
    
    <item>
      <title>Weekly update (July 02 ~ July 08, 2018)</title>
      <link>https://pingcap.com/weekly/2018-07-09-tidb-weekly/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-07-09-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 34 PRs in the TiDB repositories.
Added  Support session variables warning_count and error_count Support BIT_OR in the new aggregation function framework  Fixed  Fix the privilege bug when reusing chunks Fix the issue that the Hash Aggregate operator cannot exit Fix a panic on Stream Aggregate Fix the results of SHOW CREATE TABLE when adding indices Fix the results of non-integer inputs for bit related aggregate functions  Improved  Use feedback to refine updating statistics information Refactor statistics updating mechanism to speed up analyzing tables Allow the user to kill his own connections without the SUPER privilege  Weekly update in TiSpark Last week, we landed 5 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十二）统计信息(上)</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</guid>
      <description>在 TiDB 里，SQL 优化的过程可以分为逻辑优化和物理优化两个部分，在物理优化阶段需要为逻辑查询计划中的算子估算运行代价，并选择其中代价最低的一条查询路径作为最终的查询计划。这里非常关键的一点是如何估算查询代价，本文所介绍的统计信息是这个估算过程的核心模块。
这部分内容非常复杂，所以会分成两篇文章来介绍。本篇文章介绍统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价。上篇侧重于介绍原理，下篇会结合原理介绍 TiDB 的源码实现。
统计信息是什么 为了得到查询路径的执行代价，最简单的办法就是实际执行这个查询计划，不过这样子做就失去了优化器的意义。不过，优化器并不需要知道准确的代价，只需要一个估算值，以便能够区分开代价差别较大的执行计划。因此，数据库常常会维护一些实际数据的概括信息，用以快速的估计代价，这便是统计信息。
在 TiDB 中，我们维护的统计信息包括表的总行数，列的等深直方图，Count-Min Sketch，Null 值的个数，平均长度，不同值的数目等等。下面会简单介绍一下直方图和 Count-Min Sketch。
直方图简介 直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。根据分桶策略的不同，常见的直方图可以分为等深直方图和等宽直方图。
在 TiDB 中，我们选择了等深直方图，于 1984 年在 Accurate estimation of the number of tuples satisfying a condition 文献中提出。相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差。所谓的等深直方图，就是落入每个桶里的值数量尽量相等。举个例子，比方说对于给定的集合 {1.6, 1.9, 1.9, 2.0, 2.4, 2.6, 2.7, 2.7, 2.8, 2.9, 3.4, 3.5}，并且生成 4 个桶，那么最终的等深直方图就会如下图所示，包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3。
Count-Min Sketch 简介 Count-Min Sketch 是一种可以处理等值查询，Join 大小估计等的数据结构，并且可以提供很强的准确性保证。自 2003 年在文献 An improved data stream summary: The count-min sketch and its applications 中提出以来，由于其创建和使用的简单性获得了广泛的使用。</description>
    </item>
    
    <item>
      <title>Weekly update (June 25 ~ July 01, 2018)</title>
      <link>https://pingcap.com/weekly/2018-07-02-tidb-weekly/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-07-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 39 PRs in the TiDB repositories.
Added  Add a session variable tidb_ddl_reorg_worker_cnt to control the number of the DDL organization workers Support parallel HASH aggregation and greatly improve the performance of the aggregation function Print explain results in a tree style Support the SHOW ERRORS statement and improve the SHOW WARNINGS statement  Fixed  Make the INSERT IGNORE statement ignore BadNullError Fix a bug when only_full_group_by is set in SQL_MODE Fix the wrong results of avg(double) Make the CREATE TABLE IF NOT EXISTS LIKE statement work again Set the correct startHandle when some errors occur in adding indexes Fix a bug in pushing down TopN Fix the response result bug of COM_FIELD_LIST Fix a bug of the str_to_date() function Fix a bug of the INSERT statement when the field type is unsigned float/double  Improved  Use the average error of the row count which is estimated by statistics to determine the pseudo column Use CorrelatedColumn to calculate range Make the frequency of updating the statistic metadata depend on the table size Refactor the execution framework of the aggregate functions Speed up the CreateTable operation Stop calling expression.</description>
    </item>
    
    <item>
      <title>Ele.me? TiDB At Your Service</title>
      <link>https://pingcap.com/success-stories/tidb-in-eleme/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/success-stories/tidb-in-eleme/</guid>
      <description>Industry: Food Delivery
Authors: Yanzhao Zhang (Senior Database Engineer at Ele.me) and Dongming Chen (Senior Infrastructure Engineer at Ele.me)
Ele.me, which means &amp;ldquo;Are you hungry?&amp;rdquo; in Chinese, is the largest online food delivery platform in China. Our platform allows users to order all kinds of food and beverages and get their takeout delivered within 30 minutes. Currently, with 3 million scooter-riding delivery staff, Ele.me is serving 260 million customers and 1.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十一）Index Lookup Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</guid>
      <description>什么是 Index Lookup Join Nested Loop Join 在介绍 Index Lookup Join 之前，我们首先看一下什么是 Nested Loop Join（NLJ）。 NLJ 的具体定义可以参考 Wikipedia。NLJ 是最为简单暴力的 Join 算法，其执行过程简述如下：
 遍历 Outer 表，取一条数据 r；
 遍历 Inner 表，对于 Inner 表中的每条数据，与 r 进行 join 操作并输出 join 结果；
 重复步骤 1，2 直至遍历完 Outer 表中的所有数据。
  NLJ 算法实现非常简单并且 join 结果的顺序与 Outer 表的数据顺序一致。
但是存在性能上的问题：执行过程中，对于每一条 OuterRow，我们都需要对 Inner 表进行一次全表扫操作，这将消耗大量时间。
为了减少对于 Inner 表的全表扫次数，我们可以将上述步骤 1 优化为每次从 Outer 表中读取一个 batch 的数据，优化后的算法即 Block Nested-Loop Join（BNJ），BNJ 的具体定义可以参考 Wikipedia。</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.70】Paper Party：CEO 解读 TiDB 下一代存储引擎</title>
      <link>https://pingcap.com/meetup/meetup-2018-06-26/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-06-26/</guid>
      <description>上周六举办的 Infra Meetup No.70，我们换了一个开阔些的场地——嗯，没看错，是我司的一间办公室，然而掏空了房间里的椅子沙发，还是不够坐。
爆满的原因当然是我司 CEO 刘奇的「重磅分享」：刘奇分享了受威斯康辛的论文启发的 TiDB 下一代存储引擎的设计考量及实践，以及「关门福利」——非常强悍的测试结果，以下是现场视频 &amp;amp; 文字回顾，enjoy！
视频回顾 视频 | Infra Meetup No.70：CEO 解读 TiDB 下一代存储引擎
论文 slides 链接
我司 CEO 刘奇首先为大家介绍了新的磁盘进化发展趋势，如何做软硬件协同设计，以及硬件的发展对数据库系统架构的影响。
干货节选 存储引擎是数据库的核心组件之一，目前 TiDB 使用 LSM-Tree 作为底层的存储引擎，其良好的顺序写入特性得到了很大的发挥。然而 LSM-Tree 模型本身也不是尽善尽美，其中较为突出的缺点是写放大比较严重。该问题也吸引了不少学者的研究，也有不少改进论文出现。来自威斯康辛的论文 WiscKey: Separating Keys from Values in SSD-conscious Storage 是其中的典型代表。
刘奇接着介绍了新一代存储引擎利用新的硬件特性的方式（比如充分发挥 SSD/NVMe/Optane 的多通道写入对存储引擎的提升），并解读了威斯康辛的论文在这方面的实践——利用多通道的并行能力来弥补 Key-Value 分离带来的开销。这个方法实现简单，效果极佳。TiDB 的新一代存储模型也受到这篇论文的启发。
最后，刘奇分享了 PingCAP 在这方面的思考与实践，以及对下一代存储引擎设计的具体考量，并展示了正在研发的 TiDB 下一代存储引擎的强悍实测性能。测试结果显示，相比当前的版本，系统整体性能提升了 2-10 倍。
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。</description>
    </item>
    
    <item>
      <title>Weekly update (June 18 ~ June 24, 2018)</title>
      <link>https://pingcap.com/weekly/2018-06-25-tidb-weekly/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-06-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 18 PRs in the TiDB repositories.
Added  Support the binary fetch command Add a variable to disable auto-retry of the transaction block  Fixed  Allow comments to end up with multiple asterisks as MySQL does  Improved  Allow using IndexJoin in more scenarios Improve the performance of the insert ignore on duplicate key update statement Optimize the accuracy of index row count estimation  Weekly update in TiSpark Last week, we landed 5 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Weekly update (June 11 ~ June 17, 2018)</title>
      <link>https://pingcap.com/weekly/2018-06-19-tidb-weekly/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-06-19-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 26 PRs in the TiDB repositories.
Added  Support the MySQL syntax show privileges Add the limit for the number of columns when adding columns Add the sanity check of the precision and the scale for numeric types  Fixed  Fix the wrong results of the CONCAT_WS built-in function Fix a bug in right join when some predicates are pushed to the right table Fix the missing start timestamp for TableDual in a transaction  Improved  Refactor the structure of the DDL package Remove new lines and add the user information in the query log Make the limitation of query memory usage configurable Change the factor of the descending scan according to the improvement of descending scan performance in TiKV  Weekly update in TiKV and PD Last week, we landed 28 PRs in the TiKV and PD repositories.</description>
    </item>
    
    <item>
      <title>十问 TiDB ：关于架构设计的一些思考</title>
      <link>https://pingcap.com/blog-cn/10-questions-tidb-structure/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/10-questions-tidb-structure/</guid>
      <description>“我希望能够把 TiDB 的设计的一些理念能够更好的传达给大家，相信大家理解了背后原因后，就能够把 TiDB 用的更好。”
 做 TiDB 的缘起是从思考一个问题开始的：为什么在数据库领域有这么多永远也躲不开的坑？从 2015 年我们写下第一行代码，3 年以来我们迎面遇到无数个问题，一边思考一边做，尽量用最小的代价来快速奔跑。
作为一个开源项目，TiDB 是我们基础架构工程师和社区一起努力的结果，TiDB 已经发版到 2.0，有了一个比较稳定的形态，大量在生产环境使用的伙伴们。可以负责任的说，我们做的任何决定都经过了非常慎重的思考和实践，是经过内部和社区一起论证产生的结果。它未必是最好的，但是在这个阶段应该是最适合我们的，而且大家也可以看到 TiDB 在快速迭代进化。
这篇文章是关于 TiDB 代表性“为什么”的 TOP 10，希望大家在了解了我们这些背后的选择之后，能更加纯熟的使用 TiDB，让它在适合的环境里更好的发挥价值。
这个世界有很多人，感觉大于思想，疑问多于答案。感恩大家保持疑问，我们承诺回馈我们的思考过程，毕竟有时候很多思考也很有意思。
一、为什么分布式系统并不是银弹 其实并没有什么技术是完美和包治百病的，在存储领域更是如此，如果你的数据能够在一个 MySQL 装下并且服务器的压力不大，或者对复杂查询性能要求不高，其实分布式数据库并不是一个特别好的选择。 选用分布式的架构就意味着引入额外的维护成本，而且这个成本对于特别小的业务来说是不太划算的，即使你说需要高可用的能力，那 MySQL 的主从复制 + GTID 的方案可能也基本够用，这不够的话，还有最近引入的 Group Replication。而且 MySQL 的社区足够庞大，你能 Google 找到几乎一切常见问题的答案。
我们做 TiDB 的初衷并不是想要在小数据量下取代 MySQL，而是尝试去解决基于单机数据库解决不了的一些本质的问题。
有很多朋友问我选择分布式数据库的一个比较合适的时机是什么？我觉得对于每个公司或者每个业务都不太一样，我并不希望一刀切的给个普适的标准（也可能这个标准并不存在），但是有一些事件开始出现的时候：比如是当你发现你的数据库已经到了你每天开始绞尽脑汁思考数据备份迁移扩容，开始隔三差五的想着优化存储空间和复杂的慢查询，或者你开始不自觉的调研数据库中间件方案时，或者人肉在代码里面做 sharding 的时候，这时给自己提个醒，看看 TiDB 是否能够帮助你，我相信大多数时候应该是可以的。
而且另一方面，选择 TiDB 和选择 MySQL 并不是一刀切的有你没他的过程，我们为了能让 MySQL 的用户尽可能减小迁移和改造成本，做了大量的工具能让整个数据迁移和灰度上线变得平滑，甚至从 TiDB 无缝的迁移回来，而且有些小数据量的业务你仍然可以继续使用 MySQL。所以一开始如果你的业务和数据量还小，大胆放心的用 MySQL 吧，MySQL still rocks，TiDB 在未来等你。
二、为什么是 MySQL 和上面提到的一样，并不是 MySQL 不好我们要取代他，而是选择兼容 MySQL 的生态对我们来说是最贴近用户实际场景的选择：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十）Chunk 和执行框架简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</guid>
      <description>什么是 Chunk TiDB 2.0 中，我们引入了一个叫 Chunk 的数据结构用来在内存中存储内部数据，用于减小内存分配开销、降低内存占用以及实现内存使用量统计/控制，其特点如下：
 只读
 不支持随机写
 只支持追加写
 列存，同一列的数据连续的在内存中存放
  Chunk 本质上是 Column 的集合，它负责连续的在内存中存储同一列的数据，接下来我们看看 Column 的实现。
1. Column Column 的实现参考了 Apache Arrow，Column 的代码在 这里。根据所存储的数据类型，我们有两种 Column：
 定长 Column：存储定长类型的数据，比如 Double、Bigint、Decimal 等
 变长 Column：存储变长类型的数据，比如 Char、Varchar 等
  哪些数据类型用定长 Column，哪些数据类型用变长 Column 可以看函数 addColumnByFieldType 。
Column 里面的字段非常多，这里先简单介绍一下：
 length   用来表示这个 Column 有多少行数据。
 nullCount  用来表示这个 Column 中有多少 NULL 数据。
 nullBitmap  用来存储这个 Column 中每个元素是否是 NULL，需要特殊注意的是我们使用 0 表示 NULL，1 表示非 NULL，和 Apache Arrow 一样。</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.69】CASPaxos，一个有趣的 RSM 算法</title>
      <link>https://pingcap.com/meetup/meetup-2018-06-12/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-06-12/</guid>
      <description>上周六，Infra Meetup 时隔一个月终于回归北京大本营，北京的朋友们格外热情，会议室最后都挤不下啦 ～现场有几位朋友拿着提前打印的论文认真地记笔记，分享结束后大家还围绕 CASPaxos 讨论了很久，瞬间有种“Paper Party”的感觉——看来 Infra Meetup 不定期的论文分享大大激发了社区小伙伴的“学术”之心啊！（不过，全场最大的亮点还是我司 CTO 的“魔性”PPT……）
视频回顾 视频 | Infra Meetup No.69：CASPaxos，一个有趣的 RSM 算法
配合 PPT 观看更佳～
干货节选 本期 Meetup 我司 CTO 黄东旭分享了一篇有趣的论文——CASPaxos: Replicated State Machines without logs。他首先通过一个简单的例子通俗易懂地介绍了经典 Paxos 的算法。随后引入了 RSM（日志复制状态机）的概念 ， 并指出 CASPaxos 其实是在经典 Paxos 的基础上进行了拓展，变成了没有日志的 RSM 。接着，他介绍了 CASPaxos 的主体算法，包括 membership change 算法以及用 CASPaxos 实现一个通用数据库时需要考虑的问题。
来自大神的“魔性” PPT
东旭接着对比了目前常用的 RSM 算法 ，比如 TiDB 中用到的 Raft 算法与 CASPaxos 的区别。相较而言，CASPaxos 目前是一个偏学术性的理论，在工业上应用的完整度和相关优化算法还不够。CASPaxos 的优点在于出现异常时的不可用时间非常短，并且没有额外的日志开销，缺陷是做数据丢失的故障恢复代价比较高，而且读依然是多数派读，对业务上的灵活性会有一些影响。
P.S. 东旭还和现场的朋友们一起针对 CASPaxos 的缺点，大开脑洞，畅聊了一些可能的优化方法 。现场越聊越嗨，不得不说大家想法都很“清奇”啊 ( ´▽｀) 。</description>
    </item>
    
    <item>
      <title>Weekly update (June 04 ~ June 10, 2018)</title>
      <link>https://pingcap.com/weekly/2018-06-11-tidb-weekly/</link>
      <pubDate>Mon, 11 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-06-11-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 50 PRs in the TiDB repositories.
Added  Support ALTER TABLE RENAME KEY Support SHOW MASTER STATUS Support setting TSO into the tidb_snapshot session variable Support the ALTER TABLE DROP COLUMN CASCADE syntax  Fixed  Make TIDB_SMJ take effect when no index can be used Fix the SelectLock option for the UNION statement Fix a bug of the DROP USER statement Fix a bug of WrapWithCastAsJSON Detect the duplication of table alias for the JOIN statement Fix some bugs of the DECIMAL values Do not allow the YEAR type to have the UNSIGNED flag Refine row count estimation Fix a bug of failing to fetch the profile by pprof Fix the wrong result of the UNION statement Fix the wrong result of Merge Join Handle NULL datum when converting it to a string in statistics Fix the issue of checking LIMIT and ORDER BY in the UNION statement  Improved  Add max backoff settings for tikv-client Support parallel projection Make the error message of ADMIN CHECK TABLE more readable Improve the constant folding for the IF and IFNULL built-in functions Push the FLOOR built-in function to TiKV Push the built-in functions IS TRUE/IS FALSE to TiKV Append the current time into the error message when backoff occurs Refine the result of the EXPLAIN statement  Weekly update in TiSpark Last week, we landed 2 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>How To Spin Up an HTAP Database in 5 Minutes with TiDB &#43; TiSpark</title>
      <link>https://pingcap.com/blog/how_to_spin_up_an_htap_database_in_5_minutes_with_tidb_tispark/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/how_to_spin_up_an_htap_database_in_5_minutes_with_tidb_tispark/</guid>
      <description>TiDB is an open-source distributed Hybrid Transactional and Analytical Processing (HTAP) database built by PingCAP, powering companies to do real-time data analytics on live transactional data in the same data warehouse &amp;ndash; no more ETL, no more T+1, no more delays. More than 200 companies are now using TiDB in production. Its 2.0 version was launched in late April 2018 (read about it in this blog post).
In this 5-minute tutorial, we will show you how to spin up a standard TiDB cluster using Docker Compose on your local computer, so you can get a taste of its hybrid power, before using it for work or your own project in production.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（九）Hash Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</guid>
      <description>什么是 Hash Join Hash Join 的基本定义可以参考维基百科：Hash join。简单来说，A 表和 B 表的 Hash Join 需要我们选择一个 Inner 表来构造哈希表，然后对 Outer 表的每一行数据都去这个哈希表中查找是否有匹配的数据。
我们不用 “小表” 和 “大表” 这两个术语是因为：对于类似 Left Outer Join 这种 Outer Join 来说，如果我们使用 Hash Join，不管 Left 表相对于 Right 表而言是大表还是小表，我们都只能使用 Right 表充当 Inner 表并在之上建哈希表，使用 Left 表来当 Outer 表，也就是我们的驱动表。使用 Inner 和 Outer 更准确，没有迷惑性。在 Build 阶段，对 Inner 表建哈希表，在 Probe 阶段，对由 Outer 表驱动执行 Join 过程。
TiDB Hash Join 实现 TiDB 的 Hash Join 是一个多线程版本的实现，主要任务有：
 Main Thread，一个，执行下列任务：</description>
    </item>
    
    <item>
      <title>Weekly update (May 28 ~ June 03, 2018)</title>
      <link>https://pingcap.com/weekly/2018-06-04-tidb-weekly/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-06-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 50 PRs in the TiDB repositories.
Added  Support the Trace syntax Support the TIDB_IS_DDL_OWNER builtin function  Support ALL for builtin aggregate function BIT_AND/BIT_OR/BIT_XOR  Fixed  Check the correctness of decimal&amp;rsquo;s exponent part Fix the affected row count for the UPDATE statement Fix the range construction for the IN builtin function Fix the empty result of the JOIN statement Fix row count estimation for the LIMIT operator Fix the error message of the DIV builtin function Check the schema name of the column for the CREATE TABLE statement Fix the side effect of casting one decimal to another decimal  Improved  Push ABS to TiKV Wait for a while when some errors occurred to avoid retrying the DDL job too many times Unify the log format of the connection ID Ignore foreign keys in the SHOW CREATE TABLE statement Change statistics delta update duration to 1 minute Check invalid tasks after physical optimization Unify the DDL logs  Weekly update in TiSpark Last week, we landed 2 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.68】虚怀迎远客 魔都 Talk 「长」</title>
      <link>https://pingcap.com/meetup/meetup-2018-05-26/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-05-26/</guid>
      <description>距离去年在上海举办的 TechDay 已经过去了近一年，上海社区小伙伴们积攒已久的热情终于在上周六的 Infra Meetup 现场释放了出来~ 现场爆满不说，Q&amp;amp;A 环节大家都抢着与讲师互动，结束后还有小伙伴意犹未尽，强烈要求多在上海举办这样的技术交流趴（我们会努力的，嗯💪）。以下是现场视频&amp;amp;文字回顾，enjoy！
 现场同学坐定之后，我司 CTO 黄东旭简短开场，欢迎 Percona CEO Peter Zaitsev 做客 Infra Meetup No.68 上海站～随后 Peter 带来了 Using MySQL for Distributed Database Architectures 的主题演讲。
Using MySQL for Distributed Database Architectures Percona CEO Peter Zaitsev
视频链接：1st Talk by Peter Zaitsev
Peter 首先介绍了 MySQL 最近几个版本迭代的性能升级数据。他认为 MySQL 单机性能提升很大，但是与分布式数据库在应用场景上仍有较大的区别，很多问题是单机解决不了的。从而引出了基于 MySQL 做分布式尝试的方法论，并从高可用、扩展性、数据分布策略几个方面进行了详细解读。随后分享了在 MySQL 上实现分布式计算和分布式系统的方法。
Peter 提到不同业务对数据库的需求不一样，对隔离级别和一致性的要求也不一样, 需要仔细思考相关配置。他重点介绍了 Percona 数据库管理工具和集群方案，同时分享了对市面上常见的基于 MySQL 分片的中间件的看法，以及对 TiDB 等 NewSQL 未来发展的期待。
How to build a Self-Driving database PingCAP CTO 黄东旭</description>
    </item>
    
    <item>
      <title>Weekly update (May 21 ~ May 27, 2018)</title>
      <link>https://pingcap.com/weekly/2018-05-28-tidb-weekly/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-05-28-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 44 PRs in the TiDB repositories.
Added  Make tidb_max_chunk_size a global variable Add a timeout for writing binlogs Support high_priority for DELETE/UPDATE/REPLACE INTO statements Support changing the log level online Support ComChangeUser Support JOIN hint for UPDATE/DELETE statements  Fixed  Fix the compatibility problem of ON UPDATE CURRENT_TIMESTAMP Fix a bug of ON DUPLICATE KEY UPDATE Fix the decimal fraction of DIV Fix count estimation of betweenRowCount Fix the wrong result of CEIL(DECIMAL) Fix the wrong result of CEIL(INT) integer Fix the cost estimation of Index Scan and Table Scan Fix a bug of deleting an index in YEAR type Fix the wrong result of FLOOR Fix the false alarm of ADMIN CHECK TABLE Fix a panic of MAX/MIN Fix a bug in rebuildRange when the plan cache for the PREPARE statement is enabled  Improved  Create a new backoff for each Region Do not log the Write error during handshake Refine the log level of stats Set the rollback log to the debug level Refine the comparison between the timestamp column and the string constant Push CEIL down to TiKV  Weekly update in TiSpark Last week, we landed 2 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Implement Raft in Rust</title>
      <link>https://pingcap.com/blog/implement-raft-in-rust/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/implement-raft-in-rust/</guid>
      <description>Consensus is one of the most important challenges in designing and building distributed systems&amp;ndash;how to make sure multiple nodes (or agents, processes, threads, tasks, participants, etc.) in a group agree on a specific value proposed by at least one of the nodes. As an open-source distributed scalable HTAP database, TiDB uses the Raft Consensus Algorithm in its distributed transactional key-value storage engine, TiKV, to ensure data consistency, auto-failover, and fault tolerance.</description>
    </item>
    
    <item>
      <title>Weekly update (May 14 ~ May 20, 2018)</title>
      <link>https://pingcap.com/weekly/2018-05-21-tidb-weekly/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-05-21-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 40 PRs in the TiDB repositories.
Added  Support TIME and TIMESTAMP binary types for the PREPARE/EXECUTE statements Make tidb_build_stats_concurrency a global variable Support USE INDEX in the DELETE FROM statement  Fixed  Fix the compatibility problem of the UNION statement Fix range calculation of Index Scan when Prepared Plan Cache is enabled Check the AUTO_INCREMENT column for the SHARD_ROW_ID_BITS statement Set PB code for builtinArithmeticDivideDecimalSig  Improved  Refine the error message about Invalid default value Make the error log for WriteConflict more friendly  Add the schema version to the log Support warnings when using Coprocessor streaming Add the DDL Callback log Do not log handshake error Log slow processing and waiting Coprocessor tasks separately with different labels Do not bind graceful shutdown to SIGTERM  Weekly update in TiSpark Last week, we landed 4 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Weekly update (May 07 ~ May 13, 2018)</title>
      <link>https://pingcap.com/weekly/2018-05-14-tidb-weekly/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-05-14-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 55 PRs in the TiDB repositories.
Added  Support renaming a table as its original name Allow correlated columns to be pushed down to TiKV Support local latches for the transactions in TiDB Add an option to stop writing Binlog when TiDB meets some Binlog errors Add an HTTP API to enable or disable the general log of TiDB Update the logrus package to a new version  Fixed  Set lastInsertID in the duplicated update statement Fix several bugs of statistics feedback Fix a bug occurred when values are inserted into a time column Fix a bug when creating a table and renaming a table run concurrently Rollback all keys when Prewrite fails Fix a bug when adding index meets handle = MaxInt64 Fix a bug when the limit offset is a multiple of MaxChunkSize Fix a bug when a complex subquery exists in the Update statement  Improved  Refine the error message about Out of range value for column Set gc_worker and loadDeleteRangeSQL to a much higher priority Make tidb_opt_insubquery_unfold a global variable Uniform the calculation method of pseudo statistics Improve the CPU usage when opentracing is not enabled  Weekly update in TiKV and PD Last week, we landed 24 PRs in the TiKV and PD repositories.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.67】杭州站</title>
      <link>https://pingcap.com/meetup/meetup-2018-05-09/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-05-09/</guid>
      <description>上周日 Infra Meetup 首次走进杭州，感谢热情的杭州社区小伙伴们冒雨参加活动～这次活动由我司数据库专家马晓宇老师和资深数据库架构师房晓乐老师为大家带来精彩的分享，还有来自二维火、挖财、蘑菇街的社区小伙伴带来了三个闪电 Talk，分享了他们的 TiDB 实践经验。
马晓宇：TiDB 架构及 2.0 详解 首先，我司数据库专家马晓宇老师带来《TiDB 架构及 2.0 详解》精彩分享，介绍了 TiDB 的方方面面，包括存储模块 TiKV，调度模块 PD，计算模块 TiDB， OLAP 组件 TiSpark，数据流转 Syncer 和 Binlog 以及 Cloud 集成等等众多组件和独立产品。
马晓宇老师更与现场的同学深入探讨了 TiDB 背后的技术细节以及一些重大选择的原因。
例如，从单体 KV 演进到分布式，就不得不思考如何多副本容错，且还需要在多个副本之间达到一致性，这是选择 Raft 协议的根本动机。然而，仅仅是 Raft 并不能满足扩展性的需求，因此又引入了 Raft Group / Region 的分片机制，再加上 PD 模块的调度，让数据和负载均衡得以实现。
在 TiDB 部分，马晓宇老师重点介绍了数据库计算引擎的详细架构，包含模块及其不同作用，详细讲解了用户的 SQL 输入如何被分解分析之后产生执行计划并执行，以及数据在 TiDB 中如何将行数据以及索引编码成 TiKV 所需的键值对等等。
另外，4 月底 TiDB 2.0 GA 和 TiSpark 1.0 正式发布，马晓宇老师在分享中也提到了 TiDB 和 TiSpark 版本的重大提升：相对 1.0 版本，TiDB 加强了稳定性和性能，针对 TPC-H 等分析型场景，TiDB 有了本质的飞跃。而 TiSpark 1.</description>
    </item>
    
    <item>
      <title>Weekly update (April 30 ~ May 06, 2018)</title>
      <link>https://pingcap.com/weekly/2018-05-07-tidb-weekly/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-05-07-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 24 PRs in the TiDB repositories.
Added  Add DB_NAME and TABLE_NAME in the result of ADMIN SHOW DDL JOBS Add an HTTP API to scatter Regions of a table Add the tidb_retry_limit session variable to control the transaction retry limit Add the auto_analyze_ratio session variable to control the automatic analysis ratio Support the ALTER TABLE FORCE syntax  Fixed  Restrict the column type in range partition Check the privilege for SHOW CREATE TABLE and information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（八）基于代价的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</guid>
      <description>概述 本文是 TiDB 源码阅读系列文章的第八篇。内文会先简单介绍制定查询计划以及优化的过程，然后用较大篇幅详述在得到逻辑计划后，如何基于统计信息和不同的属性选择等生成各种不同代价的物理计划，通过比较物理计划的代价，最后选择一个代价最小的物理计划，即 Cost-Based Optimization（CBO）的过程。
优化器框架 一般优化器分两个阶段进行优化，即基于规则的优化（Rule-Based-Optimization，简称 RBO）和基于代价的优化（CBO）。
TiDB 主要分为两个模块对计划进行优化：
 逻辑优化，主要依据关系代数的等价交换规则做一些逻辑变换。
 物理优化，主要通过对查询的数据读取、表连接方式、表连接顺序、排序等技术进行优化。
  相比 RBO，CBO 依赖于统计信息的准确性与及时性，执行计划会及时的根据数据变换做对应的调整。
优化器流程 TiDB 一个查询语句的简单流程：一个语句经过 parser 后会得到一个抽象语法树（AST），首先用经过合法性检查后的 AST 生成一个逻辑计划，接着会进行去关联化、谓词下推、聚合下推等规则化优化，然后通过统计数据计算代价选择最优的物理计划，最后执行。流程如下图 1。
 图 1 
物理算子简介 通过之前介绍物理层优化的方式，我们可以知道同一个逻辑算子可能因为它的数据读取、计算方式等不同会生成多个不同的物理算子，例如逻辑上的 Join 算子转换成物理算子可以选择 HashJoin、SortMergeJoin、IndexLookupJoin。
这里会简单介绍一些逻辑算子可选择的物理算子。例如语句：select sum(*) from t join s on t.c = s.c group by a。此语句中逻辑算子有 DataSource、Aggregation、Join 和 Projection，接下来会对其中几个典型的逻辑算子对应的物理算子进行一个简单介绍，如下表：
CBO 流程 基于代价优化的的主要思路是计算所有可能的执行计划的代价，并挑选代价最小的执行计划的路径。那么可以倒推出，首先得到需要采集对应表的统计信息，那么就可以用来计算出每个算子的执行代价，最后将得到每条路径上算子的代价按路径各自累加获取代价最小的路径。具体的代码实现在 plan/optimizer.go 中 dagPhysicalOptimize 函数，本文介绍的流程基本上也都由此函数完成，代码如下： func dagPhysicalOptimize(logic LogicalPlan) (PhysicalPlan, error) { logic.preparePossibleProperties() logic.deriveStats() t, err := logic.</description>
    </item>
    
    <item>
      <title>Weekly update (April 23 ~ April 29, 2018)</title>
      <link>https://pingcap.com/weekly/2018-05-02-tidb-weekly/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-05-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Add the CHANGELOG.md file to the TiDB repository Support more ODBC syntaxes Support PARTITION BY RANGE COLUMNS in SHOW CREATE TABLE Support the ALTER CONVERT TO syntax Support the ALTER TABLE AUTO_INCREMENT syntax Support the SET NAMES COLLATE DEFAULT syntax  Fixed  Fix Dump/Load statistics information Fix data race on the LockKeys() function Fix range calculating in the TableHandlesToKVRanges() function Fix the compatibility problem of the UNION statement Fix the wrong behavior of the tryToGetMemTask() function Refine the optimization rule of &amp;ldquo;TopN Push Down&amp;rdquo;  Improved  Add more log information about slow queries Log the slow Coprocessor task in detail Enhance the validation of column names when creating a table  Weekly update in TiSpark Last week, we released TiSpark 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 is Ready - Faster, Smarter, and Battle-Tested</title>
      <link>https://pingcap.com/blog/tidb-2-0-announcement/</link>
      <pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/tidb-2-0-announcement/</guid>
      <description>TiDB 2.0 is Ready! TiDB is an open-source distributed scalable Hybrid Transactional and Analytical Processing (HTAP) database. It is designed to provide infinite horizontal scalability, strong consistency, and high availability. TiDB is MySQL compatible and serves as a one-stop data warehouse for both OLTP (Online Transactional Processing) and OLAP (Online Analytical Processing) workload.
When we launched TiDB 1.0 last October, we were excited but also a bit nervous. After working on TiDB heads-down, non-stop for more than two years, even with the support of a large (and growing) open-source community, we weren’t sure how the world would receive what we’ve built.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 GA Release</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</guid>
      <description>2018 年 4 月 27 日，TiDB 发布 2.0 GA 版。相比 1.0 版本，对 MySQL 兼容性、系统稳定性、优化器和执行器做了很多改进。
TiDB  SQL 优化器
 精简统计信息数据结构，减小内存占用
 加快进程启动时加载统计信息速度
 支持统计信息动态更新 [experimental]
 优化代价模型，对代价估算更精准
 使用 Count-Min Sketch 更精确地估算点查的代价
 支持分析更复杂的条件，尽可能充分的使用索引
 支持通过 STRAIGHT_JOIN 语法手动指定 Join 顺序
 GROUP BY子句为空时使用 Stream Aggregation 算子，提升性能
 支持使用索引计算 Max/Min 函数
 优化关联子查询处理算法，支持将更多类型的关联子查询解关联并转化成 Left Outer Join
 扩大 IndexLookupJoin 的使用范围，索引前缀匹配的场景也可以使用该算法
  SQL 执行引擎
 使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用，显著提升 TPC-H 结果</description>
    </item>
    
    <item>
      <title>详解 | TiDB 2.0 GA is here!</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</guid>
      <description>去年十月份的时候，我们发布了 TiDB 1.0 版本，为此我们日夜兼程奋斗了两年半时间，我们认为 1.0 版本达到了可在生产环境中使用的程度。在接下来的六个月中，我们一方面维护 1.0 版本的稳定性并且增加必要的新特性，另一方面马不停蹄的开发 2.0 版本。经过半年时间，6 个 RC 版本，今天 TiDB 2.0 GA 版本正式发布。
2.0 版本规划 在 2.0 版本的规划阶段，我们对“这个版本需要做什么”进行了深入思考，我们根据现有用户的情况、技术发展趋势以及社区的声音，认为 2.0 版本需要聚焦在以下几点：
 保证 TiDB 的稳定性以及正确性。这两点是一个数据库软件的基础功能，作为业务的基石，任何一点抖动或者错误都可能对业务造成巨大的影响。目前已经有大量的用户在线上使用 TiDB，这些用户的数据量在不断增加、业务也在不断演进。我们非常关注 TiDB 集群如何保持长期稳定运行、如何减小系统的抖动、如何进行智能的调度，为此做了大量的调研和分析。
 提升 TiDB 在大数据量下的查询性能。从我们接触下来的用户来看，很多客户都有少则上百 GB，多则上百 TB 的数据，一方面数据会持续增加，另一方面也希望能对这些数据做实时的查询。所以如果能提升大数据量下的查询性能，对用户会很有帮助。
 优化 TiDB 的易用性和可维护性。TiDB 整套系统的复杂性比较高，运维及使用的难度要大于单机数据库，所以我们希望能提供尽可能方便的方案帮助用户使用 TiDB。比如尽可能简化部署、升级、扩容方式，尽可能容易的定位系统中出现的异常状态。
  围绕上面三点原则，我们做了大量的改进，一些是对外可见（如 OLAP 性能的显著提升、监控项的大量增加以及运维工具的各项优化），还有更多的改进是隐藏在数据库背后，默默的提升整个数据库的稳定性以及正确性。
正确性和稳定性 在 1.0 版本发布之后，我们开始构建和完善自动化测试平台 Schrodinger，彻底告别了之前靠手工部署集群测试的方式。同时我们也新增了非常多的测试用例，做到测试从最底层 RocksDB，到 Raft，再到 Transaction，然后是 SQL 都能覆盖。
在 Chaos 测试上面，我们引入了更多的错误注入工具，例如使用 systemtap 对 I/O 进行 delay 等，也在代码特定的业务的逻辑进行错误注入测试，充分保证 TiDB 在异常条件下面也能稳定运行。</description>
    </item>
    
    <item>
      <title>Weekly update (April 16 ~ April 22, 2018)</title>
      <link>https://pingcap.com/weekly/2018-04-23-tidb-weekly/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-04-23-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 36 PRs in the TiDB repositories.
Added  Add TiDB HTTP API to query the DDL history information Add the session variable tidb_optimizer_selectivity_level to control the selectivity estimation level Add table partition information in SHOW CREATE TABLE Analyze the table automatically when the modified row count of a table is too large  Fixed  Check if the column name already exists before renaming a column Fix a problem when parallel executing CREATE TABLE IF NOT EXISTS Fix pseudo selectivity estimation for the primary key Eliminate Projection when the schema length is 0 Set the hash join concurrency in NewSessionVars  Improved  Refactor scalarFuncToPBExpr Improve the cost estimation for physical aggregate operators Improve the execution performance of the UnionScanExec operator Cache global variables  Weekly update in TiSpark Last week, we landed 8 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.66】Application of TLA&#43; at PingCAP</title>
      <link>https://pingcap.com/meetup/meetup-2018-04-17/</link>
      <pubDate>Tue, 17 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-04-17/</guid>
      <description>上周六的 Meetup 上，我司董麒麟同学为大家讲解了 TLA+ 在 TiDB 中的应用。现奉上现场视频 &amp;amp; 干货节选，Enjoy～
 视频回顾 视频 | Infra Meetup No.66：Application of TLA+ at PingCAP
可下载 完整 PPT 配合观看
干货节选 TLA+ 是一个用来设计、描述和验证并发系统的一套形式化语言，易学易用。在 TiDB 中，我们非常关心一些关键系统的设计正确性，所以使用 TLA+ 来保证这一点。PingCAP 在 2017 年底开始尝试使用 TLA+，到目前为止，已经用 TLA+ 验证了我们优化过的 Percolator 协议以及 Multi-raft region merge 的正确性。这些代码可以在 pingcap/tla-plus 上找到。
TLA+ 可以在一个比代码更高的层面上描述系统。在编写代码之前，将系统完整地表述一遍是很重要的。这能强迫我们去思考这个系统的细节，避免早期设计时出现失误并保证正确性。TLA+ 的基本原理是将系统描述成为一个状态机。系统可以用 TLA+ 来抽象出若干变量表达它的当前状态，并用形式化的语言去描述这个状态机的初始结束状态与状态转移。我们对这个系统的一些 Safety 性质比较感兴趣，这些 Safety 的性质也可以在 TLA+ 中用谓词来刻画。另外一个工具 TLC 可以用来验证被 TLA+ 抽象出来的系统模型。TLC 的原理是枚举状态机的所有可以遍历到的状态集。验证系统的正确性就是确保所有状态都满足对应的谓词。
TLA+ 在 TiDB 的第一个应用是 Percolator 事务协议。这个协议是一个二阶段提交算法，用来在只支持单行事物的存储上实现多行事务。这个协议的具体介绍可以在 这里 找到。和原始协议的不同，TiDB 做了一个很重要的优化，在 prewrite 阶段，我们并不是采取了先 prewrite 主锁，再并发副锁的策略，而是主锁和副锁一起并发。但是如果直接这样设计是存在问题的。在视频中可以看到我们是如何用 TLA+ 定位这个问题，然后提出了一个解决方案来克服这个问题。我们用 TLA+ 验证了优化的正确性。</description>
    </item>
    
    <item>
      <title>Weekly update (April 09 ~ April 15, 2018)</title>
      <link>https://pingcap.com/weekly/2018-04-16-tidb-weekly/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-04-16-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 32 PRs in the TiDB repositories.
Added  Update the average column size dynamically Update statistics using query feedback Use tidb_index_lookup_join_currency to control the number of IndexLookupJoin inner workers Add a TiDB system variable tidb_hash_join_concurrency Make pseudo estimate ratio configurable Show memory usage in show processlist  Fixed  Make inferring of decimal for unix_timestamp more consistent with MySQL Fix the bug of writing null value into not null column in write-only state Fix the IndexLookUpJoin hang problem Update the column&amp;rsquo;s offset when modifying the column Support insert ignore on duplicate update  Improved  Set explicit_defaults_for_timestamp = on for compatibility with MySQL Increase the default lease Improve the performance of Clone Use a cloned Expression when setting it to plan  Weekly update in TiSpark Last week, we landed 3 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>From Chaos to Order -- Tools and Techniques for Testing TiDB, A Distributed NewSQL Database</title>
      <link>https://pingcap.com/blog/chaos-practice-in-tidb/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/chaos-practice-in-tidb/</guid>
      <description>What is Chaos? In the world of distributed computing, you can never predict what will happen to your cluster. Anything is possible. A butterfly fluttering in Rio de Janeiro could change the weather in Chicago, or destroy an entire data center in Cairo. Network Time Protocol (NTP) might be out of sync, CPUs might mysteriously max out, or worse yet, your diligent DBA might accidentally remove data in the middle of the night.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（七）基于规则的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</guid>
      <description>在 TiDB 里面，SQL 优化的过程可以分为逻辑优化和物理优化两个部分。逻辑优化主要是基于规则的优化，简称 RBO（rule based optimization）。物理优化会为逻辑查询计划中的算子选择某个具体的实现，需要用到一些统计信息，决定哪一种方式代价最低，所以是基于代价的优化 CBO（cost based optimization）。
本篇将主要关注逻辑优化。先介绍 TiDB 中的逻辑算子，然后介绍 TiDB 的逻辑优化规则，包括列裁剪、最大最小消除、投影消除、谓词下推等等。
逻辑算子介绍 在写具体的优化规则之前，先简单介绍查询计划里面的一些逻辑算子。
 DataSource 这个就是数据源，也就是表，select * from t 里面的 t
 Selection 选择，例如 select xxx from t where xx = 5 里面的 where 过滤条件
 Projection 投影， select c from t 里面的取 c 列是投影操作
 Join 连接， select xx from t1, t2 where t1.c = t2.c 就是把 t1 t2 两个表做 Join
  选择，投影，连接（简称 SPJ） 是最基本的算子。其中 Join 有内连接，左外右外连接等多种连接方式。</description>
    </item>
    
    <item>
      <title>Weekly update (April 02 ~ April 08, 2018)</title>
      <link>https://pingcap.com/weekly/2018-04-09-tidb-weekly/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-04-09-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Support AdminCleanupIndex to clean up the dangling index Support AlterTableComment Add RawDeleteRange API Make session transaction isolation level take effect only once  Fixed  Fix row estimation for the pseudo unique key Fix row count estimation for the column with null values Fix the result of cast (0x10 as binary(2)) Fix zero value issue for binary type Merge BatchGet results to fix InsertIgnore in a transaction block  Improved  Track memory usage for NestedLoopApply Delete ranges when rolling back add index Optimize the insert executor on duplicate key update Upgrade mysql.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.65】「四美具，二难并」之成都行</title>
      <link>https://pingcap.com/meetup/meetup-2018-04-04/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2018-04-04/</guid>
      <description>上周 Infra Meetup 走进了成都，来自 G7 汇通天下的廖强老师和来自 PingCAP 的申砾、孙浩老师，为大家带来了三个干货满满的 Talk 。 这是第二场走出帝都的 Meetup，场面依然火爆～「四美具，二难并」 成都，唯有美食与同道者不可辜负！
 下午两点大家陆续进场，不得不说成都的同学们太热情了，场地差点坐不下，各式各样的椅子都被搬来了～等同学们坐定之后，PingCAP Engineering VP 申砾老师首先上台，深入讲解了 TiDB 的各项核心性能，让同学们对 TiDB 的架构和性能有了充分的认知。
申砾：《Deep Dive into TiDB》 视频回顾 | Infra Meetup No.65 成都站：Deep Dive into TiDB（申砾）
 PingCAP Engineering VP 申砾
 申砾老师从系统整体到技术细节，从核心项目到周边工具，介绍了 TiDB 的方方面面。
 TiDB 的设计目标、核心特性以及整体架构。
 系统分层介绍，包括分布式 Key-Value 存储引擎 TiKV 的核心技术及实现细节，分布式 SQL 引擎的设计思路以及优化器、执行引擎等核心组件的介绍。
 Cloud TiDB、TiSpark 等核心项目以及 TiDB 集群的周边工具。
 Q&amp;amp;A 环节：TiDB 在实践中的使用经验，TiDB 2.0 版本的最新进展以及如何实现性能上的巨大提升。
  短暂休息之后，G7 汇通天下技术合伙人廖强老师讲述了他为什么选择了 TiDB ，以及 G7 的实践方案。</description>
    </item>
    
    <item>
      <title>Blitzscaling the Largest Dockless Bikesharing Platform with TiDB’s Help</title>
      <link>https://pingcap.com/success-stories/tidb-in-mobike/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/success-stories/tidb-in-mobike/</guid>
      <description>Industry: Ridesharing
Data Growth Rate: ~30TB per day
Author: Chengjie Ding and Ming Hu (Infrastructure Platform Engineers at Mobike)
Mobike is the world’s first and largest dockless bike-sharing provider, serving over 200 million users in 200 cities across the world, operating over 9 million smart bikes. It’s an affordable and convenient way of transportation for short urban trips, with a patented bike design with a smart lock system and a mobile app.</description>
    </item>
    
    <item>
      <title>Weekly update (March 26 ~ April 01, 2018)</title>
      <link>https://pingcap.com/weekly/2018-04-02-tidb-weekly/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-04-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Support show grants for current_user(); Add manual GC back for some KV API users Support using decimal in INTERNAL  Fixed  Fix an unsigned decimal Fix a potential goroutine leak problem in copIterator Fix the AdminCheckTable bug when the column is nil and has a default value Fix type infer for the binary literal Fix a bug that lexer.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（六）Select 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</guid>
      <description>在先前的 TiDB 源码阅读系列文章（四） 中，我们介绍了 Insert 语句，想必大家已经了解了 TiDB 是如何写入数据，本篇文章介绍一下 Select 语句是如何执行。相比 Insert，Select 语句的执行流程会更复杂，本篇文章会第一次进入优化器、Coprocessor 模块进行介绍。
表结构和语句 表结构沿用上篇文章的：
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Select 语句只会讲解最简单的情况：全表扫描+过滤，暂时不考虑索引等复杂情况，更复杂的情况会在后续章节中介绍。语句为：
SELECT name FROM t WHERE age &amp;gt; 10; 语句处理流程 相比 Insert 的处理流程，Select 的处理流程中有 3 个明显的不同：
 需要经过 Optimize
Insert 是比较简单语句，在查询计划这块并不能做什么事情（对于 Insert into Select 语句这种，实际上只对 Select 进行优化），而 Select 语句可能会无比复杂，不同的查询计划之间性能天差地别，需要非常仔细的进行优化。
 需要和存储引擎中的计算模块交互
Insert 语句只涉及对 Key-Value 的 Set 操作，Select 语句可能要查询大量的数据，如果通过 KV 接口操作存储引擎，会过于低效，必须要通过计算下推的方式，将计算逻辑发送到存储节点，就近进行处理。</description>
    </item>
    
    <item>
      <title>刘寅：TiDB 工具链和生态</title>
      <link>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</guid>
      <description>本文为今年年初 PingCAP 商业产品团队负责人刘寅在 TiDB DevCon2018 上分享的 《 TiDB 工具链和生态》实录内容，文内详细介绍了 TiDB 的周边工具以及生态系统。enjoy~
 大家下午好，我叫刘寅。在 PingCAP 主要负责 TiDB 商业工具产品开发，也在做公司 SRE 方面的事情。今天下午我分享的主题是介绍下 TiDB 的周边工具以及生态系统。
今天要讲的内容主要包含这几方面，首先是关于 TiDB 的部署，这是很多使用 TiDB 的用户首先关心的事情。接下来会介绍 TiDB 的数据导入工具和数据迁移同步工具，以及管理配置，数据可视化相关的工具。
TiDB 的架构可能大家都比较清楚了。TiDB 是一个由若干模块组成的分布式系统。这些模块相互依赖协调工作组成一个集群，整体构成了 TiDB 数据库。这样一个架构，对于用户进行部署和运维，其复杂程度相对单机数据库比如 MySQL 来说不那么容易的事情。那让我们来看看如何快速部署一套 TiDB 集群实例。最近我们公开了一个项目 pingcap/tidb-docker-compose，这令我们在一个本地的开发和测试环境上跑一套 TiDB 变得非常简单。只需要用一个命令 docker-compose up 就能快速启动起来。docker-compose 是 Docker 生态中的一个非常便利的工具，它可以在本机方便的把 TiDB 的各个组件，包括它的监控，可视化工具，全部整合在一个 yaml 文件来描述，非常的方便。不仅可以通过我们官方 docker image 镜像启动，也可以支持从本地的 binary 启动。比如当我本机编译了一个特殊版本的 binary，我就可以直接构建本地镜像来启动，甚至还可以支持现场编译源码来启动。所以这对于我们自己开发和测试也是非常方便的。另外我们也做了一个很简化的配置文件，比如我不希望默认跑 3 个 TiKV，我想启 5 个或者更多，简单的改下配置就可以搞定。
对于生产环境的部署和运维，往往面对的是一个成规模的集群，docker-compose 的部署方式就不够了。我们建议采用提供的 Ansible 部署方式。用户首先在一个 Inventory 文件中描述和编排所需的 TiDB 集群拓扑，然后执行我们提供的 ansible-playbook 脚本，就可以快速部署和运维一个生产环境下的 TiDB 集群。我们现在很多的线上用户，也是用了这样的部署方式。</description>
    </item>
    
    <item>
      <title>Weekly update (March 19 ~ March 25, 2018)</title>
      <link>https://pingcap.com/weekly/2018-03-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-03-26-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repositories.
Added  Add the average column size for histogram Support STRAIGHT_JOIN to disable join reordering Add the AdminChecksumTable command Show Region key&amp;rsquo;s record ID or index values  Fixed  Support converting json to float64 Fix incompatible behavior when modifying value from Navicat GUI Fix panic by cloning the predicates of UnionScan Fix the syntax error on set transaction isolation level serializable Fix a data race on the concurrent access of Tracker.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第五篇，主要对 SQL Parser 功能的实现进行了讲解，内容来自社区小伙伴——马震（GitHub ID：mz1999 ）的投稿。
TiDB 源码阅读系列文章的撰写初衷，就是希望能与数据库研究者、爱好者进行深入交流，我们欣喜于如此短的时间内就收到了来自社区的反馈。后续，也希望有更多小伙伴加入到与 TiDB 『坦诚相见』的阵列中来。
 PingCAP 发布了 TiDB 的源码阅读系列文章，让我们可以比较系统的去学习了解TiDB的内部实现。最近的一篇《SQL 的一生》，从整体上讲解了一条 SQL 语句的处理流程，从网络上接收数据，MySQL 协议解析和转换，SQL 语法解析，查询计划的制定和优化，查询计划执行，到最后返回结果。
其中，SQL Parser 的功能是把 SQL 语句按照 SQL 语法规则进行解析，将文本转换成抽象语法树（AST），这部分功能需要些背景知识才能比较容易理解，我尝试做下相关知识的介绍，希望能对读懂这部分代码有点帮助。
TiDB 是使用 goyacc 根据预定义的 SQL 语法规则文件 parser.y 生成 SQL 语法解析器。我们可以在 TiDB 的 Makefile 文件中看到这个过程，先 build goyacc 工具，然后使用 goyacc 根据 parser.y 生成解析器 parser.go：
goyacc: $(GOBUILD) -o bin/goyacc parser/goyacc/main.go parser: goyacc bin/goyacc -o /dev/null parser/parser.y bin/goyacc -o parser/parser.go parser/parser.y 2&amp;gt;&amp;amp;1 ... goyacc 是 yacc 的 Golang 版，所以要想看懂语法规则定义文件 parser.</description>
    </item>
    
    <item>
      <title>Weekly update (March 12 ~ March 18, 2018)</title>
      <link>https://pingcap.com/weekly/2018-03-19-tidb-weekly/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-03-19-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 60 PRs in the TiDB repositories.
Added  Collect query feedbacks Support admin recover index Support retry and timeout for Coprocessor streaming API Export implicit rowid and use it in CRUD  Fixed  Fix the column length when converting the column information for tinyint Add the deprecation warning for builtin function PASSWORD Add missing columns in collations_information_applicability Fix the comparison between uint and int Fix the index iterator for unique index with a null value Fix insert into t1 (select * from t) Fix a bug when performing column substitution for join Change makeJoinRowToChunk to account for virtual rows Rollback the transaction when Compile returns error  Improved  Add a unit test for distsql.</description>
    </item>
    
    <item>
      <title>How to do Performance Tuning on TiDB, A Distributed NewSQL Database</title>
      <link>https://pingcap.com/blog/performance_tuning_on_a_distributed_newsql_database/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/performance_tuning_on_a_distributed_newsql_database/</guid>
      <description>Author: Jinpeng Zhang, Database Engineer, Storage Team at PingCAP
Doing performance tuning on distributed systems is no joking matter. It’s much more complicated than on a single node server, and bottlenecks can pop up anywhere, from system resources in a single node or subcomponent, to cooperation between nodes, to even network bandwidth. Performance tuning is a practice that aims to find these bottlenecks and address them, in order to reveal more bottlenecks and address them as well, until the system reaches an optimal performance level.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（四）Insert 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第四篇。上一篇文章简单介绍了整体流程，无论什么语句，大体上是在这个框架下运行，DDL 语句也不例外。
本篇文章会以 Insert 语句为例进行讲解，帮助读者理解前一篇文章，下一篇文章会介绍 Select 语句的执行流程。这两条是最常用的读、写语句，其他的语句相信读者能触类旁通，可以自行研究或者是等待后续的文章。对于这两类语句，目前也只会针对核心流程进行说明，更复杂的 Join、Insert-Into-OnDuplicate-Update 等会等到后面的文章进行讲解。另外本文会重点介绍每个语句在执行框架下面的具体执行逻辑，请读者阅读前先了解 Insert 语句的行为。
表结构 这里先给一个表结构，下面介绍的 SQL 语句都是在这个表上的操作。
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Insert 语句 INSERT INTO t VALUES (&amp;quot;pingcap001&amp;quot;, &amp;quot;pingcap&amp;quot;, 3); 以这条语句为例，解释 Insert 是如何运行的。
语句处理流程 首先大家回忆一下上一篇文章介绍的框架，一条 SQL 语句经过协议层、Parser、Plan、Executor 这样几个模块处理后，变成可执行的结构，再通过 Next() 来驱动语句的真正执行。对于框架，每类语句都差不多；对于每个核心步骤，每个语句会有自己的处理逻辑。
语法解析 先看 Parser，对于 Insert 语句的解析逻辑在这里，可以看到这条语句会被解析成下面这个结构：
// InsertStmt is a statement to insert new rows into an existing table. // See https://dev.</description>
    </item>
    
    <item>
      <title>Weekly update (March 05 ~ March 11, 2018)</title>
      <link>https://pingcap.com/weekly/2018-03-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-03-12-tidb-weekly/</guid>
      <description>TiDB 2.0 RC1 release TiDB 2.0 RC1 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
Weekly update in TiDB Last week, we landed 38 PRs in the TiDB repositories.
Added  Support checking the consistency of an index Support decoding a column value by HTTP API Add validation for configuration Add HTTP API for settings Employ memory Tracker to track memory usage during query execution  Fixed  Fix inconsistent behavior for insert Correct the behavior of the bit aggregate function Fix a bug that index is not used in a special case Fix the field length of Boolean type Handle warnings returned from tikv/mocktikv  Improved  Set low priority for adding an index Support pseudo profiling table for compatibility Enhance decorrelation Check the password format for create user identified by password XXX Avoid the random error during Leader checking in GC Make CommitMaxBackoff configurable  Weekly update in TiSpark Last week, we landed 8 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（三）SQL 的一生</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</guid>
      <description>概述 上一篇文章讲解了 TiDB 项目的结构以及三个核心部分，本篇文章从 SQL 处理流程出发，介绍哪里是入口，对 SQL 需要做哪些操作，知道一个 SQL 是从哪里进来的，在哪里处理，并从哪里返回。
SQL 有很多种，比如读、写、修改、删除以及管理类的 SQL，每种 SQL 有自己的执行逻辑，不过大体上的流程是类似的，都在一个统一的框架下运转。
框架 我们先从整体上看一下，一条语句需要经过哪些方面的工作。如果大家还记得上一篇文章所说的三个核心部分，可以想到首先要经过协议解析和转换，拿到语句内容，然后经过 SQL 核心层逻辑处理，生成查询计划，最后去存储引擎中获取数据，进行计算，返回结果。这个就是一个粗略的处理框架，本篇文章会把这个框架不断细化。
对于第一部分，协议解析和转换，所有的逻辑都在 server 这个包中，主要逻辑分为两块：一是连接的建立和管理，每个连接对应于一个 Session；二是在单个连接上的处理逻辑。第一点本文暂时不涉及，感兴趣的同学可以翻翻代码，看看连接如何建立、如何握手、如何销毁，后面也会有专门的文章讲解。对于 SQL 的执行过程，更重要的是第二点，也就是已经建立了连接，在这个连接上的操作，本文会详细讲解这一点。
对于第二部分，SQL 层的处理是整个 TiDB 最复杂的部分。这部分为什么复杂？原因有三点：
 SQL 语言本身是一门复杂的语言，语句的种类多、数据类型多、操作符多、语法组合多，这些『多』经过排列组合会变成『很多』『非常多』，所以需要写大量的代码来处理。
 SQL 是一门表意的语言，只是说『要什么数据』，而不说『如何拿数据』，所以需要一些复杂的逻辑选择『如何拿数据』，也就是选择一个好的查询计划。
 底层是一个分布式存储引擎，会面临很多单机存储引擎不会遇到的问题，比如做查询计划的时候要考虑到下层的数据是分片的、网络不通了如何处理等情况，所以需要一些复杂的逻辑处理这些情况，并且需要一个很好的机制将这些处理逻辑封装起来。这些复杂性是看懂源码比较大的障碍，所以本篇文章会尽量排除这些干扰，给大家讲解核心的逻辑是什么。
  这一层有几个核心概念，掌握了这几个也就掌握了这一层的框架，请大家关注下面这几个接口：
 Session
 RecordSet
 Plan
 LogicalPlan
 PhysicalPlan
 Executor
  下面的详细内容中，会讲解这些接口，用这些接口理清楚整个逻辑。
对于第三部分可以认为两块，第一块是 KV 接口层，主要作用是将请求路由到正确的的 KV Server，接收返回消息传给 SQL 层，并在此过程中处理各种异常逻辑；第二块是 KV Server 的具体实现，由于 TiKV 比较复杂，我们可以先看 Mock-TiKV 的实现，这里有所有的 SQL 分布式计算相关的逻辑。 接下来的几节，会对上面的三块详细展开描述。</description>
    </item>
    
    <item>
      <title>Weekly update (February 26 ~ March 04, 2018)</title>
      <link>https://pingcap.com/weekly/2018-03-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-03-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 27 PRs in the TiDB repositories.
Added  Support stream aggregation on TiKV Support long VARCHAR Set Range and OutputCounts in Coprocessor Response for streaming API Support COMMENT = string in partition definition Add restrict and cascade in DropTable  Fixed  Set have_profiling to NO  Improved  Remove invalid intervals in building Range Resolve locks in a batch Extract the same part from DNF&amp;rsquo;s leaves Simplify the logic of HashCode Improve the performance of decoding decimal Test coverage:  Improve the test coverage in the executor package Improve the test coverage in the plan package Improve the test coverage in the distsql package  Panic recover:  Add the recover mechanism for index lookup reader workers Add the recover mechanism for union workers Add the recover panic in owner.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二）初识 TiDB 源码</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第二篇，第一篇文章介绍了 TiDB 整体的架构，知道 TiDB 有哪些模块，分别是做什么的，从哪里入手比较好，哪些可以忽略，哪些需要仔细阅读。
这篇文章是一篇入门文档，难度系数比较低，其中部分内容可能大家在其他渠道已经看过，不过为了内容完整性，我们还是会放在这里。
TiDB 架构 本次 TiDB 源码之旅从这幅简单的架构图开始，这幅图很多人都看过，我们可以用一句话来描述这个图：『TiDB 是一个支持 MySQL 协议，以某种支持事务的分布式 KV 存储引擎为底层存储的 SQL 引擎』。从这句话可以看出有三个重要的事情，第一是如何支持 MySQL 协议，与 Client 交互，第二是如何与底层的存储引擎打交道，存取数据，第三是如何实现 SQL 的功能。本篇文章会先介绍一些 TiDB 有哪些模块及其功能简要介绍，然后以这三点为线索，将这些模块串联起来。
代码简介 TiDB 源码完全托管在 Github 上，从项目主页可以看到所有信息。整个项目使用 Go 语言开发，按照功能模块分了很多 Package，通过一些依赖分析工具，可以看到项目内部包之间的依赖关系。
大部分包都以接口的形式对外提供服务，大部分功能也都集中在某个包中，不过有一些包提供了非常基础的功能，会被很多包依赖，这些包需要特别注意。
项目的 main 文件在 tidb-server/main.go，这里面定义了服务如何启动。整个项目的 Build 方法可以在 Makefile 中找到。
除了代码之外，还有很多测试用例，可以在 xx_test.go 中找到。另外 cmd 目录下面还有几个工具包，用来做性能测试或者是构造测试数据。
模块介绍 TiDB 的模块非常多，这里做一个整体介绍，大家可以看到每个模块大致是做什么用的，想看相关功能的代码是，可以直接找到对应的模块。
   Package Introduction     ast 抽象语法树的数据结构定义，例如 SelectStmt 定义了一条 Select 语句被解析成什么样的数据结构   cmd/benchdb 简单的 benchmark 工具，用于性能优化   cmd/benchfilesort 简单的 benchmark 工具，用于性能优化   cmd/benchkv Transactional KV API benchmark 工具，也可以看做 KV 接口的使用样例   cmd/benchraw Raw KV API benchmark 工具，也可以看做不带事务的 KV 接口的使用样例   cmd/importer 根据表结构以及统计信息伪造数据的工具，用于构造测试数据   config 配置文件相关逻辑   context 主要包括 Context 接口，提供一些基本的功能抽象，很多包以及函数都会依赖于这个接口，把这些功能抽象为接口是为了解决包之间的依赖关系   ddl DDL 的执行逻辑   distsql 对分布式计算接口的抽象，通过这个包把 Executor 和 TiKV Client 之间的逻辑做隔离   domain domain 可以认为是一个存储空间的抽象，可以在其中创建数据库、创建表，不同的 domain 之间，可以存在相同名称的数据库，有点像 Name Space。一般来说单个 TiDB 实例只会创建一个 Domain 实例，其中会持有 information schema 信息、统计信息等。   executor 执行器相关逻辑，可以认为大部分语句的执行逻辑都在这里，比较杂，后面会专门介绍   expression 表达式相关逻辑，包括各种运算符、内建函数   expression/aggregation 聚合表达式相关的逻辑，比如 Sum、Count 等函数   infoschema SQL 元信息管理模块，另外对于 Information Schema 的操作，都会访问这里   kv KV 引擎接口以及一些公用方法，底层的存储引擎需要实现这个包中定义的接口   meta 利用 structure 包提供的功能，管理存储引擎中存储的 SQL 元信息，infoschema/DDL 利用这个模块访问或者修改 SQL 元信息   meta/autoid 用于生成全局唯一自增 ID 的模块，除了用于给每个表的自增 ID 之外，还用于生成全局唯一的 Database ID 和 Table ID   metrics Metrics 相关信息，所有的模块的 Metrics 信息都在这里   model SQL 元信息数据结构，包括 DBInfo / TableInfo / ColumnInfo / IndexInfo 等   mysql MySQL 相关的常量定义   owner TiDB 集群中的一些任务只能由一个实例执行，比如异步 Schema 变更，这个模块用于多个 tidb-server 之间协调产生一个任务执行者。每种任务都会产生自己的执行者。   parser 语法解析模块，主要包括词法解析 (lexer.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（一）序</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</guid>
      <description>在 TiDB DevCon2018 上，我们对外宣布了 TiDB 源码阅读分享活动，承诺对外发布一系列文章以及视频帮助大家理解 TiDB 源码。大家一直很关心这项活动的时间，而我们忙于新版本的开发，一直不得闲。在春节放假期间，终于有时间开始动手写这个系列。
为什么我们要做这件事情？
事情的起因是随着 TiDB 项目逐渐发展，代码日渐复杂，我们发现新入职的同学越来越难上手修改代码。我们萌生了做内部培训的想法，通过录制视频、写教程的方式，加快新同事融入的速度，做了几次之后，我们发现效果不错，除了新同学有不少收获之外，老同志们也了解了之前自己并不熟悉的模块，大家都有收获。我们想到开源社区面临同样的问题，也可以通过这项工作收益，所以萌生了把这个活动做细做大的想法，于是有了这项活动。
TiDB 作为一个开源项目，在开发过程中得到了社区的广泛关注，很多人在试用或者已经在线用 TiDB，并给出了很多很好的建议或者是问题反馈，帮助我们把项目做的更好。对于项目开发是这样，那么对于数据库技术的研究，也是这样。我们非常希望能和对数据库研究者、爱好者交流，我们在过去的两年中组织过近百场技术 Meetup 或者 Talk，在和大家的交流过程中，我们发现国内的数据库技术水平非常好，在交流过程中总能碰撞出火花。通过这项活动，我们希望能和大家做更深入的交流，通过源码阅读，让 TiDB 与大家 『坦诚相见』。
前言 学习一种系统最好的方法是阅读一些经典著作并研究一个开源项目，数据库也不例外。单机数据库领域有很多好的开源项目，MySQL、PostgreSQL 是其中知名度最高的两个，不少人看过这两个项目的代码。我们在刚做数据库的时候也看过不少 MySQL、PG 的代码，从中受益良多。但是分布式数据库方面，好的开源项目并不多，有一些知名的系统并不开源，比如 F1/Spanner，还有一些系统疏于维护或者是从开源变成闭源，比如被 Apple 收购后闭源的 FoundationDB（还好当初 clone 了一份代码 :)，参见 这里，我们在内部或者外部也组织过一些开源系统代码阅读的 Talk，不过并不系统。
TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于整个系统的复杂性，很多人并不能很好的理解整个项目。我们希望通过这一系列文章自顶向下，由浅入深，讲述 TiDB 的技术原理以及实现细节，帮助大家掌握这个项目。
背景知识 本系列文章会聚焦在 TiDB 自身，读者需要有一些基本的知识，包括但不限于：
 Go 语言，不需要精通，但是至少要能读懂代码，知道 Goroutine、Channel、Sync 等组件的使用
 数据库基础知识，了解一个单机数据库由哪些功能、哪些组件
 SQL 基础知识，知道基本的 DDL、DML 语句，事务的基本常识
 基本的后端服务知识，比如如何启动一个后台进程、RPC 是如何工作的 一些网络、操作系统的常识
 总体而言，读者需要了解基本的数据库知识以及能看懂 Go 语言程序，我相信这一点对于大多数同学来说，并不是问题。
  除了上述比较通用的知识之外，还希望读者能够看一下我之前写过的三篇文章（说存储，讲计算，论调度），了解一些 TiDB 的基本原理。
读者可以有哪些收获 通过这一系列文章可以获得什么？首先是通过了解 TiDB 的基本原理，明白一个关系型数据库的基本原理；其次通过阅读 TiDB 的代码，知道一个数据库是如何实现的，将教科书中看到的数据库原理落地。第三，了解一个数据库的实现对其行为的影响，可以更好的理解数据库为什么是这样的，并推广到其他的数据库，相信对读者用好其他数据库也有帮助。第四，可以看到一个大型的分布式系统是如何设计、构建以及优化的。最后，大家理解了 TiDB 的代码后，如果后续工作中有需求，可以引用 TiDB 的代码，目前一些公司已经在自己的产品中用到了 TiDB 的部分模块，例如 Parser。</description>
    </item>
    
    <item>
      <title>Weekly update (February 12 ~ February 25, 2018)</title>
      <link>https://pingcap.com/weekly/2018-02-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-02-26-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 27 PRs in the TiDB repositories.
Added  Support the select 1 order by 1 syntax  Fixed  Fix the bug in insert statements when dropping columns Fix the bug when updating the stats table  Improved  Allow golint to check context.Context in make check Do not import golang.org/x/net/context as goctx alias Move the package context to sessionctx Add the recover mechanism for join workers Add StatementsPerTransaction and TransactionDuration metrics Add keep alive metrics to figure out whether TiDB instance is down  Weekly update in TiKV and PD Last two weeks, we landed 13 PRs in the TiKV and PD repositories.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</guid>
      <description>2018 年 2 月 24 日，TiDB 发布 1.1 Beta 版。该版本在 1.1 Alpha 版的基础上，对 MySQL 兼容性、系统稳定性做了很多改进。
TiDB  添加更多监控项, 优化日志
 兼容更多 MySQL 语法。
 在 information_schema 中支持显示建表时间
 提速包含 MaxOneRow 算子的查询
 控制 Join 产生的中间结果集大小，进一步减少 Join 的内存使用
 增加 tidb_config session 变量，输出当前 TiDB 配置
 修复 Union 和 Index Join 算子中遇到的 panic 问题
 修复 Sort Merge Join 算子在部分场景下结果错误的问题
 修复 Show Index 语句显示正在添加过程中的索引的问题
 修复 Drop Stats 语句失败的问题</description>
    </item>
    
    <item>
      <title>Bringing TiKV to Rust Devroom at FOSDEM 2018</title>
      <link>https://pingcap.com/blog/FOSDEM-2018-Rust-Devroom-reflection/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/FOSDEM-2018-Rust-Devroom-reflection/</guid>
      <description>At the crack of dawn on February 1, I landed in Brussels, Belgium, for the first time in my life. The goal of my trip wasn’t to taste the local cuisine, tour world-famous museums, or grab a pint of the local brew (though I ended up doing all those things anyway). It was to deliver a talk three days later at &amp;ldquo;FOSDEM 2018 Rust Devroom&amp;rdquo; about our experience at PingCAP using Rust to build TiKV, a distributed transactional Key-Value storage engine.</description>
    </item>
    
    <item>
      <title>Weekly update (February 05 ~ February 11, 2018)</title>
      <link>https://pingcap.com/weekly/2018-02-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-02-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 67 PRs in the TiDB repositories.
Added  CreateIndex supports the LOCK option. Add GoVersion info for tidb_version Add a session variable to show the configuration Support show stats_healthy to check if a table needs to be analyzed  Removed  Remove the useless field in jsonColumn Clean up the abandoned storage engine
  Fixed  Check the CreateTable statement charset option Fix the bug of show index printing non-public index when add index operation is not finished Treat a decimal truncate as a warning in update  Improved  Run GC workers parallelly Pass the operator label from Plan to Executor Prepare the candidate index to improve performance Use pseudo estimation when the stats of some table is outdated Ignore the error and keep GC always working Set a min count for AutoAnalyze to avoid the auto analysis of small tables Improve importer tools:  Support randDate by statistics Support generating other types of columns randomly by statistics Generate a string by statistics Support VARCHAR in set Generate the integer data by Histogram  Refine metrics in TiDB:  Rename _count to _num Unify metrics naming Add a metric for pseudo estimation Make metrics content clearer and compacter Move domain metrics and add the privilege load counter Add metrics for DDL and the server Add metrics for the DDL worker Add metrics for expensive executors and statement nodes Add metrics for stats Fix inconsistent labels for the panic counter Move DDL metrics from the ddl package to the metrics package Refine TiKV client metrics Add metrics for the DDL owner Add metrics and logs for ticlient   Weekly update in TiSpark Last week, we landed 6 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Weekly update (January 29 ~ February 04, 2018)</title>
      <link>https://pingcap.com/weekly/2018-02-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-02-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repositories.
Added  Support the load stats command  Removed  Remove iota in DDL package to make the constant clearer  Fixed  limit and offset can be parameter markers in the prepared statement IndexOption can be a list in creating a table Fix the bug of some field length missing in creating a table Fix the bug of parsing Datetime overflow Trim leading zeros before parsing integer literal Fix the float truncate bug  Improved  Importer tools support loadStats by path Support mock table info for importer tools Let DO statement be a read only statement Improve an error handling in ddl Reduce memory allocation in buildDataSource Make Explain clearer Add the metrics package and recover Panic of Worker Refine the joinResult generator to return maxChunkSize chunk Limit lock count for ScanLock request Enhance the IndexRange calculation Refine metrics in TiDB:  Refine DistSQL metrics Add metrics for the meta package Move and refine the server metrics Add metrics for DDL syncer Update metrics for session   Weekly update in TiSpark Last week, we landed 6 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Weekly update (January 22 ~ January 28, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-29-tidb-weekly/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-29-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Add the importer tool Add metrics for GC failure count Add metrics for TiDB-server panic Add metrics for async secondary lock cleanup Support create time in information_schema  Removed  Remove GetSessionVars() in expression evaluation Remove varsutil package, and make Systems a private member of SessionVars  Fixed  Avoid the generation of mysql.</description>
    </item>
    
    <item>
      <title>TiDB DevCon 2018 Recap - News, Latest Development, and Roadmap</title>
      <link>https://pingcap.com/blog/tidb-devcon-2018-recap/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/tidb-devcon-2018-recap/</guid>
      <description>On January 20th, 2018, a chilly Saturday in the middle of the winter, more than 200 coders, hackers, and techies streamed into Garage Café, a chic coffee shop in the heart of Beijing’s techhub, Zhongguancun. They weren’t there to get coffee. They weren’t there to stay warm. They were there to be part of TiDB DevCon 2018, a technology party for the developers, by the developers.
TiDB DevCon 2018 attendees signing-in on the event banner</description>
    </item>
    
    <item>
      <title>Weekly update (January 15 ~ January 21, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-22-tidb-weekly/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-22-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Add an interface for Chunk to count the memory usage Add a session variable to log the query string  Removed  Remove the old, never used IndexLookUpJoin  Fixed  group_concat should not modify the argument during execution Correct the unsigned pk&amp;rsquo;s behavior  Improved  Optimize the com_field_list command and make Use Database faster Improve the sort efficiency on lookupTableTask.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</guid>
      <description>2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确的估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT INGORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 region size Fix 了一些调度的 bug  TiKV  支持 Raft learner 优化 Raft Snapshot，减少 IO 开销 支持 TLS 优化 RocksDB 配置，提升性能 Coprocessor 支持更多下推操作 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 TiKV-CTL 的功能 region 支持按 table 进行分裂 支持 delete range 功能 支持设置 snapshot 导致的 IO 上限 完善流控机制  源码地址：https://github.</description>
    </item>
    
    <item>
      <title>Weekly update (January 08 ~ January 14, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-15-tidb-weekly/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-15-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Support the ODBC syntax of time/date/timestamp literal Add MaxProcs and make the runtime.GOMAXPROCS parameter configurable  Fixed  Fix a bug about index join Close HashJoin goroutines as soon as possible to avoid unexpected errors fetchShowTableStatus should append an integer to the third column instead of a string Correct the behavior when RunWorker is false Refine the typeInfer of group_concat  Improved  Avoid the Children type assertion Merge IntColumnRange with NewRange Upgrade the username length limit to 32 to be compatible with MySQL 5.</description>
    </item>
    
    <item>
      <title>Weekly update (January 01 ~ January 07, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-08-tidb-weekly/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 37 PRs in the TiDB repositories.
Added  Support the PACK_KEYS option in the CreateTable statement. Show job&amp;rsquo;s start time in the result of admin show ddl ....  Fixed  Fix a bug when initializing HTTP stats handler. Fix a bug when estimating row count for outdated histograms. Consider time zone for builtin functions curtime/sysdate/curdate.  Improved  Refactor Chunk.AppendRow to handle virtual.</description>
    </item>
    
    <item>
      <title>Weekly update (December 25 ~ December 31, 2017)</title>
      <link>https://pingcap.com/weekly/2018-01-02-tidb-weekly/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 36 PRs in the TiDB repositories.
Added  Add the Iterator interface in Chunk.  Removed  Remove the useless aggregation function during buildQuantifierPlan.  Fixed  Flen and Decimal of TypeNewDecimal should not be -1. To pass sysbench Prepare tests, set Fields for SelectStmt in PrepareExec. Fix the case that fails to split a table. Correct the type inference of the sum and avg functions.</description>
    </item>
    
    <item>
      <title>2017 Reflection and Gratitude</title>
      <link>https://pingcap.com/blog/pingcap-reflection-and-gratitude/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/pingcap-reflection-and-gratitude/</guid>
      <description>In open source, we trust!
2017 has witnessed the growth of PingCAP, from Beijing to Silicon Valley, and the evolution of TiDB, from RC1 to the 1.0 release, and then to the 1.0.5 release. As our CEO Max said in the TiDB 1.0 announcement, &amp;ldquo;because of the hard work and dedication of not just every member of our team, but also every contributor, user, and partner in our open source community.</description>
    </item>
    
    <item>
      <title>Weekly update (December 18 ~ December 24, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-25-tidb-weekly/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories.
Added  Support the builtin aggregation function bit_or.  Removed  Remove the old JSON type. Remove the HashSemiJoin plan and executor.  Fixed  Support showing the current auto_increment id in the result of show create table. Fix a bug of NewIndexLookUpJoin&#39;s Next(). Fix the trigger condition for AutoAnalyze. Only rebuild the range when using prepared cache.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.60】初探 Orca 查询优化器</title>
      <link>https://pingcap.com/meetup/meetup-2017-12-23/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-12-23/</guid>
      <description> 上周六，PingCAP Infra Meetup 迎来了第 60 期 👏 由我司 “SQL 小王子”韩飞同学出台，为大家带来了《初探 Orca 查询优化器》主题分享~
视频回顾 视频 | Infra Meetup No.60：初探 Orca 查询优化器
可下载 完整 PPT 配合观看
干货节选 Orca 优化器是基于代价面向 MPP 执行引擎的优化器，使用了先进 Cascades 模型，将优化分为 Exploration，Stats Derivation，Implemetation 等阶段。Orca 优化器可以将优化任务分解，利用多核 CPU 并行执行，以加快优化速度。
知乎上有个热门问题：在做一个数据库的过程中，最难的是哪个部分？
很多人都认为查询优化器可能是数据库中一个最难的部分。也有人会有疑问：一个 SQL 生成一个执行计划可能是一个很确定的事情，为什么会是最难的？
对此，韩飞同学表示，难点主要集中在基于代价的物理计划生成。
在本次分享中，韩飞同学从逻辑计划的优化及物理计划的优化讲起，重点介绍了 Orca 优化器的架构，算法实现，优化效果以及测试保证等问题。
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Tick or Tock? Keeping Time and Order in Distributed Databases</title>
      <link>https://pingcap.com/blog/Time-in-Distributed-Systems/</link>
      <pubDate>Fri, 22 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/Time-in-Distributed-Systems/</guid>
      <description>Preface At re:Invent 2017, Amazon Web Services (AWS) announced Amazon Time Sync Service, a highly accurate and reliable time reference that is natively accessible from Amazon EC2 instances. It is much like the Google TrueTime published in 2012. Why do Google and AWS both want to make efforts to provide global time service? Is there any inspiration for building distributed database? This topic is important to think about.
Time synchronization remains a hard nut to crack in distributed systems, especially for distributed databases such as TiDB where time is used to confirm the order of the transaction to guarantee the ACID compliance.</description>
    </item>
    
    <item>
      <title>Weekly update (December 11 ~ December 17, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-18-tidb-weekly/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-18-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repositories.
Added  Support SEPARATOR in the group_concat aggregate function. Support the BinaryJSON type. Add a config for the SQL parser to enable parsing syntax for window function. Support the http index MVCC interface.  Fixed  Show the index column length if necessary in show create table statement. Clear the delta info when rolling back a transaction.</description>
    </item>
    
    <item>
      <title>Weekly update (December 04 ~ December 10, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-11-tidb-weekly/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-11-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 45 PRs in the TiDB repositories.
Added  Add hints to force to choose HashJoin. Provide the HTTP API of table disk usage for tidb-ctl.  Fixed  Fix a bug when updating the JSON field. Delete the auto ID key when renaming the table. Fix a bug in JoinResultGenerator. Fix a bug when backfilling the index with nil. The value of a session variable should not be modified when getting a global variable.</description>
    </item>
    
    <item>
      <title>PingCAP Plants its Seed in Silicon Valley</title>
      <link>https://pingcap.com/blog/Silicon-Valley-Office-Announcement/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/Silicon-Valley-Office-Announcement/</guid>
      <description>PingCAP Plants its Seed in Silicon Valley PingCAP, a cutting-edge distributed Hybrid Transactional/Analytical Processing (HTAP) database company, is excited to announce the opening of its Silicon Valley office, located at the GSV Labs in Redwood City, California. GSV (Global Silicon Valley) Labs is a global innovation platform that houses more than 170 startups, investors, and partners in its 60,000 square foot space in the heart of Silicon Valley. Its member startups work in a wide range of technologies and industries, from Big Data and healthcare, to VR and education.</description>
    </item>
    
    <item>
      <title>Weekly update (November 27 ~ December 03, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-04-tidb-weekly/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Add an option to disable Chunk. Add the schema info API of the http status server.  Removed  Remove the Align method of IndexRange.  Fixed  Set the priority for IndexLookupExecutor when reading the table. Fix the length metadata of the decimal column returned to the client. Fix the bug about auto-increment key after renaming a table from the old DB to another DB.</description>
    </item>
    
    <item>
      <title>A TiKV Source Code Walkthrough – Raft Optimization</title>
      <link>https://pingcap.com/blog/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/optimizing-raft-in-tikv/</guid>
      <description>Paxos or Raft is frequently used to ensure data consistency in the distributed databases. But Paxos is known for its complexity and is rather difficult to understand while Raft is very simple. Therefore, a lot of emerging databases tend to use Raft as the consensus algorithm at its bottom layer. TiKV is no exception.
Simple as Raft is, its performance is not ideal if we follow exactly the way introduced in the Paper.</description>
    </item>
    
    <item>
      <title>Weekly update (November 20 ~ November 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 60 PRs in the TiDB repositories.
Added  Support the Create View syntax. Support the PAD_CHAR_TO_FULL_LENGTH sql_mode. Support the PROXY protocol.  Fixed  Fix a bug in retry(). Fix a bug about parse duration when the fsp round overflows 60 seconds. Fix the missing index update about automatic updating for TIMESTAMP. Fix a bug when val &amp;gt; MaxInt32 in the from_unixtime argument.</description>
    </item>
    
    <item>
      <title>Weekly update (November 13 ~ November 19, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-20-tidb-weekly/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories.
Removed  Remove redundant ResolveIndices. Remove useless error return.  Fixed  Fix the index recognized as prefix index when the column length is enlarged. Check the MaxInt64 and MinInt64 to avoid range error. Fix the estimation in betweenRowCount. Refine sql_mode no_backslash_escapes. Add deep copies for the update operation. Refine projection elimination when projection is the inner child of an outer join.</description>
    </item>
    
    <item>
      <title>使用 Rust 构建分布式 Key-Value Store</title>
      <link>https://pingcap.com/blog-cn/rust-key-value-store/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/rust-key-value-store/</guid>
      <description>引子 构建一个分布式 Key-Value Store 并不是一件容易的事情，我们需要考虑很多的问题，首先就是我们的系统到底需要提供什么样的功能，譬如：
 一致性：我们是否需要保证整个系统的线性一致性，还是能容忍短时间的数据不一致，只支持最终一致性。
 稳定性：我们能否保证系统 7 x 24 小时稳定运行。系统的可用性是 4 个 9，还有 5 个 9？如果出现了机器损坏等灾难情况，系统能否做的自动恢复。
 扩展性：当数据持续增多，能否通过添加机器就自动做到数据再次平衡，并且不影响外部服务。
 分布式事务：是否需要提供分布式事务支持，事务隔离等级需要支持到什么程度。
  上面的问题在系统设计之初，就需要考虑好，作为整个系统的设计目标。为了实现这些特性，我们就需要考虑到底采用哪一种实现方案，取舍各个方面的利弊等。
后面，我将以我们开发的分布式 Key-Value TiKV 作为实际例子，来说明下我们是如何取舍并实现的。
TiKV TiKV 是一个分布式 Key-Value store，它使用 Rust 开发，采用 Raft 一致性协议保证数据的强一致性，以及稳定性，同时通过 Raft 的 Configuration Change 机制实现了系统的可扩展性。
TiKV 提供了基本的 KV API 支持，也就是通常的 Get，Set，Delete，Scan 这样的 API。TiKV 也提供了支持 ACID 事务的 Transaction API，我们可以使用 Begin 开启一个事务，在事务里面对 Key 进行操作，最后再用 Commit 提交一个事务，TiKV 支持 SI 以及 SSI 事务隔离级别，用来满足用户的不同业务场景。
Rust 在规划好 TiKV 的特性之后，我们就要开始进行 TiKV 的开发。这时候，我们面临的第一个问题就是采用什么样的语言进行开发。当时，摆在我们眼前的有几个选择：</description>
    </item>
    
    <item>
      <title>Weekly update (November 06 ~ November 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB 2017-11-13
Last week, we landed 45 PRs in the TiDB repositories.
Added  Support more SQL modes in TiDB:  the NO_UNSIGNED_SUB sql_mode the REAL_AS_FLOAT sql_mode the PIPES_AS_CONCAT sql_mode the high_not_precedence sql_mode the ONLY_FULL_GROUP_BY sql_mode  Parse more privilege types like RELOAD, EVENT and so on. Support part of window function AST.  Removed  Remove joinBuilder. Remove resolver.go.  Fixed  Return error instead of panic if a subquery in JOIN ON condition.</description>
    </item>
    
    <item>
      <title>Weekly update (October 30 ~ November 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-06-tidb-weekly/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-06-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 51 PRs in the TiDB repositories.
Added  Provide the command option and log the success/fail information for slow-query.  Removed  Remove the old planner. Remove xeval. Remove the localstore storage engine.  Fixed  Change the selection plan to dual plan directly if the condition is always false. Insert column char(4) with latin1 charset by incorrect padding. Remove the check of initialized auto ID.</description>
    </item>
    
    <item>
      <title>Weekly update (October 23 ~ October 29, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-30-tidb-weekly/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-30-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 52 PRs in the TiDB repositories.
Added  Support the window function syntax.  Fixed  Fix an issue when the values builtin function meets the null value. Support the signed field option for the numeric type. Fix an issue of index reader. Fix an issue that the binlog client is not initialized correctly. Correct the schema type of ShowStmt. The default value length for Join should be changed for column pruning.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.55 Rust 专场】《Rocket Web 框架解析》</title>
      <link>https://pingcap.com/meetup/meetup-2017-10-25/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-10-25/</guid>
      <description>Rust 专场 2.0 Rust 作为系统级编程语言，同样可以非常方便的开发上层 Web 应用。借助目前 Rust 社区最火的 web 框架 Rocket，可以像动态语言一样方便地创建高性能的 Web 应用，同时可以拥有 Rust 强大的类型安全保障。
在上周六，我们邀请了 Rocket 的作者 Sergio Benitez，与大家面对面分享了《Rocket Web 框架解析》。
据 Sergio 现场表示，这是他首次来中国，以往虽然也有在公开场合解读过 Rocket Web 框架，但本次，有些新鲜内容可是第一时间共享给 Rust 中国社区的小伙伴哦~
这一次，让我们跳过现场内容解读环节，直接为大家奉上新鲜出炉的干货视频，enjoy~~
视频 | Infra Meetup No.55：Rocket Web 框架解析
讲师介绍： Sergio Benitez，斯坦福大学博士四年级的学生，主要研究如何将编程语言理论与操作系统和安全性融合在一起。目前在做项目包括对 Rust 的类型系统 “Rusty Types” 的规范化，以及 Rust 的 Rocket Web Framework。在斯坦福大学之前，Sergio 曾在 Google、Apple 和 SpaceX 实习，参与的项目包括设计异常检测算法，火箭及其它航天器的操作系统的性能调优。
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。</description>
    </item>
    
    <item>
      <title>Weekly update (October 9 ~ October 22, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-23-tidb-weekly/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-23-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 83 PRs in the TiDB repositories.
Added  Support writing slow query log into separate files. Dummy implementation for the SHOW PROFILES statement. Add metrics for automatic analyzing. Support the operation of cancel DDL jobs. Add a new http status API to get meta regions.  Removed  Remove the self field in baseBuiltinFunc completely. Remove foldable from baseBuiltinFunc.  Fixed  Fix a bug occurred in select sum(float col)*0.</description>
    </item>
    
    <item>
      <title>PingCAP Launches TiDB 1.0</title>
      <link>https://pingcap.com/blog/2017-10-17-announcement/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-10-17-announcement/</guid>
      <description>PingCAP Launches TiDB 1.0, A Scalable Hybrid Database Solution October 16, 2017 - PingCAP Inc., a cutting-edge distributed database technology company, officially announces the release of TiDB 1.0. TiDB is an open source distributed Hybrid Transactional/Analytical Processing (HTAP) database that empowers businesses to meet both workloads with a single database.
In the current database landscape, infrastructure engineers often have to use one database for online transactional processing (OLTP) and another for online analytical processing (OLAP).</description>
    </item>
    
    <item>
      <title>写在 TiDB 1.0 发布之际 | 预测未来最好的方式就是创造未来</title>
      <link>https://pingcap.com/blog-cn/ga-1.0/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/ga-1.0/</guid>
      <description>如果只能用一个词来描述此刻的心情，我想说恍如隔世，这样说多少显得有几分矫情，或许内心还是想在能矫情的时候再矫情一次，毕竟当初做这一切的起因是为了梦想。还记得有人说预测未来最好的方式就是创造未来，以前看到这句话总觉得是废话，如今看到这一切在自己身上变成现实的一刻，感受是如此的真切，敲击键盘的手居然有点颤抖，是的，预测未来最好的方式就是创造未来。
还记得刚开始做的时候，只有很少的几个人相信这个事情可以做，毕竟难度比较高，就像有些户外旅行，只有方向，没有路。从零开始到发布 1.0 版本，历时 2 年 6 个月，终于还是做出来了。这是开源精神的胜利，是真正属于工程师们的荣耀。这个过程我们一直和用户保持沟通和密切协作，从最早纯粹的为 OLTP 场景的设计，到后来迭代为 HTAP 的设计，一共经历了 7 次重构，许多看得见的汗水，看不见的心跳，也许这就是相信相信的力量，总有那么一群人顶着世俗的压力，用自己的信念和力量在改变世界。在这个过程中，质疑的声音变少了，越来越多的人从观望，到为我们鼓舞助威，帮助我们快速成长。特别感谢那些从 beta 版本开始一路相随的用户，没有你们的信任，耐心和参与，就没有今天的 PingCAP。
开心的时刻总是特别想对很多帮助和支持我们的童鞋们说声谢谢，没有你们就没有 PingCAP，特别感谢每一位项目的贡献者。也许你已经知道了，我们专门为你们定制了一面荣誉墙，那里的色彩记录了你们的每一次贡献，如果你仍在埋头工作，来不及知道，我想请你过去逛逛，不负好时光。
这个世界还是有人相信未来是可以被创造的。感谢开源精神，让我们这样一个信仰创造未来的团队，可以站在未来的入口，因为相信和努力，获得源源不绝的正向的力量。面对未来，让我们可以摒弃对未知的恐惧和对不完美的妥协。
也感谢那些曾经的诋毁和吐槽，让我们不敢懈怠，砥砺前行。
然而 1.0 版本只是个开始，是新的起点，愿我们一路相扶，不负远途。</description>
    </item>
    
    <item>
      <title>Scale the Relational Database with NewSQL</title>
      <link>https://pingcap.com/blog/2017-10-10-nextcon/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-10-10-nextcon/</guid>
      <description>This is the speech Li SHEN gave at the 3rd NEXTCON: Cloud+Data NEXT Conference Seattle on September 16th, 2017.
 Speaker introduction Why we build a new relational database TiDB Project - Goal Architecture The core components of TiDB  The Storage stack Dynamic Multi-Raft Safe Split ACID Transaction Something we haven&amp;rsquo;t mentioned Placement Driver The SQL Layer What Happens behind a query SQL Layer Overview Cost-Based Optimizer  Tools matter Spark on TiKV Future plans  Speaker introduction Hello everyone, I am glad to be here in this beautiful city and share this talk with you.</description>
    </item>
    
    <item>
      <title>Weekly update (September 25 ~ October 08, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-09-tidb-weekly/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-09-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 62 PRs in the TiDB repositories.
Added  Support the SyncLog Key-Value request option. Support the NotFillCache Key-Value request option. Support the combination SQL modes.  Removed  Close the aggregation pushdown by default and remove the CBO switch. Remove some useless code. Remove the usage of TypeClass completely.  Fixed  Change the like function to be case sensitive. Prepare to enforce errcheck, step 1.</description>
    </item>
    
    <item>
      <title>Why did we choose Rust over Golang or C/C&#43;&#43; to develop TiKV?</title>
      <link>https://pingcap.com/blog/2017-09-26-whyrust/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-26-whyrust/</guid>
      <description>What is Rust Rust is a systems programming language sponsored by Mozilla Research. It moves fast and steady with a 6-week release cycle ever since its 1.0 version in May 2015.
See the following list for some of the features that most attract us:
 The design principles of Rust resemble with C++ in Abstraction without overhead and RAII (Resource acquisition is initialization).
 The minimum runtime and efficient C bindings empower Rust to be as efficient as C and C++, thus making it very suitable for the systems programming field where high performance matters the most.</description>
    </item>
    
    <item>
      <title>Weekly update (September 18 ~ September 24, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-25-tidb-weekly/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB 2017-09-25
Last week, we landed 63 PRs in the TiDB repositories.
Added  Use new expression framework by default. Support the DOT explain format. Support the syntax for EXPLAIN FORMAT = stringlit Support the TIME/TIMESTAMP literal  Removed  Remove expression/typeinfer.go entirely. Abandon the selection controller.  Fixed  Roll back the ID allocator when a transaction fails to commit. Fix the returned column length of all the SHOW statements.</description>
    </item>
    
    <item>
      <title>谈谈开源(一)</title>
      <link>https://pingcap.com/blog-cn/talk-about-opensource/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-about-opensource/</guid>
      <description>源码面前，了无秘密 &amp;mdash;- 侯捷
 前言 很多人的『开源』是一个比较时髦且有情怀的词汇，不少公司也把开源当做 KPI 或者是技术宣传的手段。但是在我们看来，大多数人开源做的并不好，大多数开源项目也没有被很好的维护。比如前一段时间微博上流传关于 Tengine 的讨论，一个优秀的开源项目不止是公布源代码就 OK 了，还需要后续大量的精力去维护，包括制定 RoadMap、开发新功能、和社区交流、推动项目在社区中的使用、对使用者提供一定程度的支持，等等。
目前我们在国内没看到什么特别好的文章讲如何运营一个开源项目，或者是如何做一个顶级的开源项目。TiDB 这个项目从创建到现在已经有两年多，从开发之初我们就坚定地走开源路线，陆续开源了 TiDB、TiKV、PD 这三个核心组件，获得了广泛的关注，项目在 GitHub 的 Trending 上面也多次登上首页。在这两年中，我们在这方面积累了一些经验和教训，这里和大家交流一下我们做开源过程中的一些感受，以及参与开源项目（至少是指 TiDB 相关项目）的正确姿势。
什么是开源  Open-source software (OSS) is computer software with its source code made available with a license in which the copyright holder provides the rights to study, change, and distribute the software to anyone and for any purpose.
&amp;mdash;- From Wikipedia
 本文讨论的开源是指开源软件，简而言之，开源就是拥有源代码版权的人，允许其他人在一定许可证所述范围内，访问源代码，并用于一些自己的目的。 最基本的要求就是其他人可以访问源代码，另外获取代码后能做什么，就需要一个专门的许可证来规范（可以是自己写的，也可以用一个别人写好的）。里面一般会规定诸如对修改代码、新增代码、后续工作是否需要开源以及专利相关的事项。 OK，我们写一个 main.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.56】MonetDB/X100 Paper 解读</title>
      <link>https://pingcap.com/meetup/meetup-2017-09-20/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-09-20/</guid>
      <description>上周六，PingCAP Infra Meetup 第 56 期特设论文专场，我司核心工程师张建与大家一起分享并解读了“MonetDB/X100: Hyper-Pipelining Query Execution” 论文。此篇论文作为分析型数据库领域内引用次数最多的论文之一，它为何如此火爆？在今天的文章里你应该可以找到答案。
 精彩视频 视频 | Infra Meetup No.56: MonetDB/X100 Paper 解读
精彩现场 在 PingCAP Infra Meetup 第 56 期论文专场，来了很多对 MonetDB/X100 论文感兴趣的小伙伴们。分享一开始，我司联合创始人兼 CEO 刘奇就为何选择 MonetDB/X100 这篇论文分享了自己看法。
刘奇提到:&amp;ldquo;如果大家有阅读近两年新出的一些 Paper，会发现里面引用率最高的一篇文章就是 MonetDB/X100。MonetDB/X100 发表于 2005 年，其实不算新。但读过该论文的人会发现目前主流的 OLAP 系统相关的技术，基本上都能在这篇论文中找到影子，如文中提到了列存、Pipeline，甚至是 JIT。他做 JIT 的思路不一样，都是比较早就有的，所以这是一篇很不错的论文。现在也可以看到很多性能比较的时候，大家新做了一个系统，说我的性能非常好，会拿出来 benchmark 说你看我打败了 MonetDB。
另外还有一些比较创新的项目，多是基于 MonetDB 改造的。一个就是英特尔最近出的一篇论文，他把 MonetDB 改造一下，把正则表达式的搜索，放到 FPGA 里面去。英特尔最近出了一款服务器，这个服务器的 CPU 和 FPGA 是放在一起的，他们得到 Performance 最小提倡是 2.3 倍以上，大概意思上就是说，MonetDB 在这上面做一个简单的改造，就可以适应到更新的硬件。
在 2012年的时候，第一个提供论文、代码的基于 MonetDB 的 GPU 的 Database 也出来了。当时是在 TPCH 的 query 里面，有一些复杂的 query，提升是非常的明显。所以大家可以看到，基于 MonetDB 改造的，在 FPGA 或者 GPU上运行的系统都有，实际上这是一个非常优秀的学术的原形，今年得了十年最佳论文奖。&amp;rdquo;</description>
    </item>
    
    <item>
      <title>Weekly update (September 11 ~ September 17, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-18-tidb-weekly/</link>
      <pubDate>Mon, 18 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-18-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repositories.
Added  Add required tables of MySQLX . Add TOML configuration file support.  Removed  Remove the performance schema instrumentation.  Fixed  Fix show create table with foreign key. Cast values only for modified columns in the update statement to avoid unnecessary check. Fix an OOM issue when analyzing table. Fix a cast (date as datetime) error.</description>
    </item>
    
    <item>
      <title>RocksDB in TiKV</title>
      <link>https://pingcap.com/blog/2017-09-15-rocksdbintikv/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-15-rocksdbintikv/</guid>
      <description>This is the speech Siddon Tang gave at the RocksDB meetup on August 28, 2017.
 Speaker Introduction Agenda Why did we choose RocksDB? How are we using RocksDB?  TiKV Architecture Region Raft InsertWithHint Prefix Iterator Table Property for Region Split Check Table Property for GC Check Ingest the SST File Others  How are we contributing? Future Plans  Speaker Introduction Hi every one, thanks for having me here, the RocksDB team.</description>
    </item>
    
    <item>
      <title>Futures and gRPC in Rust</title>
      <link>https://pingcap.com/blog/2017-09-12-futuresandgrpc/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-12-futuresandgrpc/</guid>
      <description>This is the speech Tang Liu (tl@pingcap.com) gave at the Bay Area Rust Meetup August 2017. See the video.
 Speaker Introduction Async Programming  Why not Sync? Why Async?  Callback Hell Coroutine Makes it Easy Future, Another Way   Futures in Rust  Futures Combinator Synchronization Stream Sink Task  gRPC  Why gRPC? HTTP/2 gRPC based on HTTP/2  Combine Futures and gRPC  C gRPC Keywords Pseudo Flow Unary Client Streaming Server Streaming Duplex Streaming  Unary Future Implementation  Client Unary Unary Future Resolve Future  Benchmark Misc  Speaker Introduction Hi everyone!</description>
    </item>
    
    <item>
      <title>Weekly update (September 04 ~ September 10, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-11-tidb-weekly/</link>
      <pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-11-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Add the column size limit when creating table. Add the syntax for admin show ddl jobs. SSL/TLS support.  Fixed  Fix an ORDER BY bug. Add entry limit for transactions when doing DDL job. Fix a bug during the limit operator pushdown. Check the default value of the column option in the CREATE TABLE statement.</description>
    </item>
    
    <item>
      <title>How we Hunted a Data Corruption bug in RocksDB</title>
      <link>https://pingcap.com/blog/2017-09-08-rocksdbbug/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-08-rocksdbbug/</guid>
      <description>Data was corrupted. A cluster panicked. The crime scene was compromised. What happened? Detective Huang (huachao@pingcap.com) went all lengths to locate the criminal and solved it once and for all.
Background As a distributed open source HTAP database, TiDB uses TiKV as its storage engine. Inside TiKV, we use RocksDB as the local storage. RocksDB is a great project. It&amp;rsquo;s mature, fast, tunable, and widely used in very large scale production environments.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.55】TiDB Pre-GA 版本新特性介绍以及后续功能展望</title>
      <link>https://pingcap.com/meetup/meetup-2017-09-06/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-09-06/</guid>
      <description>上周六，PingCAP Infra Meetup 第 55 期，由我司 Engineering VP 申砾为大家分享《TiDB Pre-GA 版本新特性介绍以及后续功能展望》。在活动现场，小伙伴们就 TiDB 新特性提出了很多问题，申砾在现场与大家有一番深度的交流与讨论。精彩现场小编立马为你呈现。
 精彩视频 视频 | Infra Meetup No.55：TiDB Pre-GA 版本新特性介绍以及后续功能展望
精彩现场 上周，TiDB 正式发布了 Pre-GA 版本。针对 Pre-GA 版本的新特性，PingCAP Infra Meetup 第 55 期特设定 Pre-GA 详解专场。活动当天，现场来了很多关注 TiDB 的粉丝们。
简单开场后，我司 Engineering VP 申砾同学介绍到本期内容主要围绕新版本带来的变化和内部实现细节，以及这种新型的 HTAP 数据库解决的实际问题和典型应用场景等做深度解析。
技术干货节选 TiDB Pre-GA 版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能方面做了大量优化工作。本次分享中，申砾就各个组件的优化做了详解：
TiDB 在优化器方面
 RC4 已经从一个假的基于代价产品模型，切换成一个真的基于代价产品模型，也真的是用统计信息去算。在 RC3 版本中，一些代价实际上是有规则算法的，比如说，A 等于 10 设置一个过滤比例，A 大于 10 又算另外一个过滤比例，这都是一些规则，RC4 是基于代价的一个传统模型。 Pre-GA 新特性也主要对代价模型做了一些调整。
 其次，在索引选择上做了优化，可以支持不同类型字段比较的索引选择，这一优化用户反馈查询速度明显变快。</description>
    </item>
    
    <item>
      <title>Weekly update (August 28 ~ September 03, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-04-tidb-weekly/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 42 PRs in the TiDB repositories.
Added  Add JSON into builtin if function.  Fixed  Fix bugs when doing natural JOIN or JOIN with using clause. Check whether date is zero and returns error when casting int as the time type. Support date time format when parse duration. Fix the issue that SHOW CREATE TABLE COMMENT is not escaped and the issue that FieldType.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Jepsen</title>
      <link>https://pingcap.com/blog/2017-09-01-tidbmeetsjepsen/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-01-tidbmeetsjepsen/</guid>
      <description>What is Jepsen? How does Jepsen work?  DB Client Checker Nemesis Generator  Jepsen tests that TiDB goes through  The Bank Test The Set Test The Register Test  Miscellaneous  What is Jepsen? Written by Kyle Kingsbury in Clojure. Jepsen is a test framework for distributed systems verification. Kingsbury has used it to verify the consistency of many famous distributed systems (etcd, ZooKeeper, CockroachDB, etc.) and found multiple bugs in some of these systems.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Spark</title>
      <link>https://pingcap.com/blog-cn/tidb-meets-spark/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-meets-spark/</guid>
      <description>本文整理自 TiSpark 项目发起人马晓宇在 Strata Data Conference 上分享的《When TiDB Meets Spark》演讲实录。
 先介绍我自己，我是 PingCAP 的马晓宇，是 TiDB OLAP 方向的负责人，也是 TiSpark 项目的发起人，主要是做 OLAP 方面的 Feature 和 Product 相关的工作，之前是网易的 Big Data Infra Team Leader，先前的经验差不多都是在 SQL、Hadoop 和所谓大数据相关的一些东西。
今天主要会讲的议程大概这么几项。
首先稍微介绍一下 TiDB 和 TiKV，因为 TiSpark 这个项目是基于它们的，所以你需要知道一下 TiDB 和 TiKV 分别是什么，才能比较好理解我们做的是什么事情。
另外正题是 TiSpark 是什么，然后 TiSpark 的架构，除了 Raw Spark 之外，我们提供了一些什么样的不一样的东西，再然后是 Use Case，最后是项目现在的状态。
首先说什么是 TiDB。你可以认为 TiDB 是现在比较火的 Spanner 的一个开源实现。它具备在线水平扩展、分布式 ACID Transaction、HA、Auto failover 等特性，是一个 NewSQL 数据库。
然后什么是 TiKV，可能我们今天要说很多次了。TiKV 其实是 TiDB 这个产品底下的数据库存储引擎，更形象，更具体一点，这是一个架构图。</description>
    </item>
    
    <item>
      <title>Weekly update (August 21 ~ August 27, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-28-tidb-weekly/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-28-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 55 PRs in the TiDB repositories.
Added  Support the &amp;lsquo;SHOW PLUGINS&amp;rsquo; syntax with dummy implementation. Add a system variable to split to-be-deleted data into batches autmatically. Add the date literal. Add the framework of the X protocol, and commond line arguments.  Fixed  Fix a panic when the set statement meets a subquery. Set charset and collation for the union&amp;rsquo;s result.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.54】数据库计算存储分离架构分析</title>
      <link>https://pingcap.com/meetup/meetup-2017-08-25/</link>
      <pubDate>Fri, 25 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-08-25/</guid>
      <description>上周六，PingCAP Infra Meetup 第 54 期，我们邀请到了知乎大 V 李凯（知乎 ID：郁白）为大家分享了《数据库计算存储分离架构分析》。在活动现场，郁白老师跟小伙伴们有一番深度的交流与思想碰撞。长话短说，小编带你一起回顾精彩现场。
 精彩视频 视频 | Infra Meetup No.54：数据库计算存储分离架构分析
精彩现场 PingCAP Infra Meetup 第 54 期的活动现场十分火爆，活动签到时间未开始，小伙伴们就早早来到现场占位置，我想说早来的小伙伴们还是很明智的。因为&amp;hellip;&amp;hellip;
后续到场的小伙伴只能酱婶儿滴扎堆在门口竖起耳朵听了，这场活动简直是一场郁白大神与粉丝的见面会。
说了这么多，先上一张郁白老师的图吧~ 🙂
技术干货节选 大数据下公有云面临的 5 个挑战 谈到存储架构分离，为什么现在会有 Aurora 架构？包括前一阵阿里的 PolarDB 推出来以后，他们也在分析为什么要做这个东西。
郁白老师认为单就公有云来说，现在云数据面临的挑战有以下 5 个：
 跨 AZ 的可用性与数据安全性。 现在都提多 AZ 部署，亚马逊在全球有 40 多个 AZ， 16 个 Region，基本上每一个 Region 之内的那些关键服务都是跨 3 个 AZ。你要考虑整个 AZ 意外宕机或者计划内维护要怎么处理，数据迁移恢复速度怎么样。以传统的 MySQL 为例，比如说一个机器坏了，可能这个机器上存了几十 T、上百 T 的数据，那么即使在万兆网卡的情况下，也要拷个几分钟或者几十分钟都有可能。那么有没有可能加快这个速度。 还有一个就是服务恢复的速度。可能大家广为诟病就是基于 MySQL Binlog 复制。在主机压力非常大的情况下，是有可能在切换到备机以后，这个备机恢复可能需要几分钟甚至几十分钟。关键因素是回放 Binlog 的效率，MySQL 即使最新版本也只能做到 Group Commit 内的并发回放。这是数据库 RTO 指标，能不能在秒级、分钟级把这个服务恢复起来，这是一个在设计系统的时候要考虑的关键问题。</description>
    </item>
    
    <item>
      <title>Linearizability 一致性验证</title>
      <link>https://pingcap.com/blog-cn/linearizability/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/linearizability/</guid>
      <description>上篇文章介绍了 TiDB 如何使用 Jepsen 来进行一致性验证，并且介绍了具体的测试案例，但是并没有对 Jepsen 背后的一致性验证算法做过多介绍。这篇文章将会深入 Jepsen 的核心库 knossos，介绍 knossos 库所涉及的 Linearizability（线性化）一致性验证算法。
Linearizability 一致性模型 什么是一致性模型？ 一致性模型确定了编写系统的程序员与系统之间的某种协议，如果程序员遵守了这种协议，那么这个系统就能提供某种一致性。常见的一致性模型有：
 Strict Consistency Linearizability (Atomic Consistency) Sequential Consistency Casual Consistency Serializability ……  需要注意的是这里的系统指并发系统，分布式系统只是其中的一类。
什么是 Linearizability？ 首先我们需要引入*历史*（history）的概念，*历史*是并发系统中由 invocation 事件和 response 事件组成的有限序列。
  invocation: &amp;lt;x op(args*) A&amp;gt;，x 表示被执行对象的名称；op 表示操作名称，如读和写；args* 表示一系列参数值；A 表示进程的名称
 response：&amp;lt;x term(res*) A&amp;gt;，term 表示结束（termination）状态；res* 表示一系列结果值
 如果 invocation 和 response 的 x（对象）和 A（进程）相同，那么我们认为它们是对应操作，并且 complete（H）表示历史中的最多成对操作
   当我们的历史 H 满足以下条件时我们把它称为*顺序化*（sequential）历史：</description>
    </item>
    
    <item>
      <title>Weekly update (August 14 ~ August 20, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-21-tidb-weekly/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-21-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 57 PRs in the TiDB repositories.
Added  Add the version information in diagnostic messages. Add the Close() method to RawKVClient. Add JSON in fieldTypeMergeRules. Add support to MySQL connector 6.06. Add Git branch name in tidb_version() and the starting log. Add the auto analyze feature for tables.  Fixed  DDL uses the correct method to check whether the context is done.</description>
    </item>
    
    <item>
      <title>The Design and Implementation of Multi-raft</title>
      <link>https://pingcap.com/blog/2017-08-15-multi-raft/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-08-15-multi-raft/</guid>
      <description>(Email: tl@pingcap.com)

 Placement Driver Raftstore  Region RocksDB / Keys Prefix Peer Storage Peer Multi-raft  Summary  Placement Driver Placement Driver (PD), the global central controller of TiKV, stores the metadata information of the entire TiKV cluster, generates Global IDs, and is responsible for the scheduling of TiKV and the global TSO time service.
PD is a critical central node. With the integration of etcd, it automatically supports the distributed scaling and failover as well as solves the problem of single point of failure.</description>
    </item>
    
    <item>
      <title>当 TiDB 遇上 Jepsen</title>
      <link>https://pingcap.com/blog-cn/tidb-jepsen/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-jepsen/</guid>
      <description>本篇文章主要介绍 TiDB 是如何使用分布式一致性验证框架 Jepsen 进行一致性验证的。
什么是 Jepsen Jepsen 是由 Kyle Kingsbury 采用函数式编程语言 Clojure 编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统（etcd, cockroachdb&amp;hellip;）进行了“攻击”（一致性验证），并且帮助其中的部分系统找到了 bug。这里一系列的博客展示了作者的验证过程以及对于一致性验证的许多思考。
Jepsen 如何工作 Jepsen 验证系统由 6 个节点组成，一个控制节点（control node），五个被控制节点（默认为 n1, n2, n3, n4, n5），控制节点将所有指令发送到某些或全部被控制节点，这些指令包括底层的 shell 命令到上层的 SQL 语句等等。Jepsen 提供了几个核心 API 用于验证分布式系统：
 DB
DB 封装了所验证的分布式系统下载、部署、启动和关闭命令，核心函数由 setup 和 teardown 组成，在 TiDB 的 Jepsen 测试中，setup 负责下载 TiDB 并且依次启动 Placement Driver、TiKV 和 TiDB；teardown 负责关闭整个 TiDB 系统并且删除日志。
 Client
Client 封装了每一个测试所需要提供的客户，每个 client 提供两个接口：setup 和 invoke，setup 负责对 TiDB 进行连接，而 invoke 则包含了测试中 client 对 TiDB 调用的 sql 语句，具体语句依测试而定。</description>
    </item>
    
    <item>
      <title>Weekly update (August 07 ~ August 13, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-14-tidb-weekly/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-14-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 78 PRs in the TiDB repositories.
Added  Enable pushing down the following operations to TiKV.  the JSON function ifnull minus and multiply  Use the Delete-in-Range feature to speed up the Drop Database/Table/Index operations. Support prioritizing statements.  Fixed  Fix the TimeDiff compatibility issue. Consider charset in Right/Left/Substr. Do not record metrics when running intenal SQL. Fix potential issue of schema validation check.</description>
    </item>
    
    <item>
      <title>How TiDB tackles fast data growth and complex queries for yuanfudao.com</title>
      <link>https://pingcap.com/success-stories/tidb-in-yuanfudao/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/success-stories/tidb-in-yuanfudao/</guid>
      <description>Yuanfudao.com is an online tutoring service targeting the K-12 educational segment in China with the largest number of elementary and secondary school student users. It owns three applications, Yuantiku (猿题库), the online question bank, Xiaoyuansouti (小猿搜题), the application for question search by taking pictures, and yuanfudao.com, an online tutoring service.
So far, the Yuanfudao APPs have more than 1.16 million paying users and provide live tutoring courses of English and Math Olympiad to the elementary users, as well as all the subjects for secondary school students.</description>
    </item>
    
    <item>
      <title>Weekly update (July 31 ~ August 06, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-07-tidb-weekly/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-07-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 54 PRs in the TiDB repositories.
Added  Support natural join. Add a switch for enabling cost-based optimizor. Assign low priority for SQL with full table scan and high priority for SQL with point get. Support \N which is the shotcut of null. Support TIMESTAMP in the get_format function. Add a flag to enable TCP keep-alive. Support DISTINCTROW.  Fixed  Truncate the trailing spaces for &amp;ldquo;CHAR[(M)]&amp;rdquo; types Fix float point parsing with leading dot.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.53】知乎数据平台实践</title>
      <link>https://pingcap.com/meetup/meetup-2017-08-05/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-08-05/</guid>
      <description> 今天的 Meetup，我们邀请到了知乎数据平台负责人王雨舟为大家做《知乎数据平台实践》的技术分享。
 又是一个美好的周末，勤劳的小蜜蜂们早早出来参加活动了~🙂 今天的活动现场又是爆满~ 感觉要换地儿的节奏啊~
今天 Meetup 的开场，我司联合创始人兼 CTO 黄东旭同学首先为大家分享了 TiDB 项目的最新进展。黄东旭同学好开心的样子，因为就在昨天，TiDB 正式发布 RC4 版 。
开场过后，接下来由知乎数据平台负责人王雨舟（江湖人称宇宙哥）开始为大家做技术分享。
宇宙哥真是 PingCAP 的真爱粉儿~ 穿着我司的文化衫亮相活动现场，超级有气场~
以下是部分技术干货分享，Enjoy~
宇宙哥在演讲开始先介绍了知乎大数据平台的整体架构情况
并讲解了埋点流程及使用 Protobuf 做埋点标准化规范
除此之外，宇宙哥还从以下几点来分析介绍 Druid
在知乎的实践：
 自定义多维分析功能和留存分析功能；
 如何做到实时数据分析；
 自定义指标、维度、报表、文件夹、Dashboard。
  这张 PPT 中有眼熟的部分哦😏宇宙哥用“丝般顺滑”总结了自己现在使用 TiDB 的感受，并表达了对 TiSpark 的期待✌️分享结束后，显然大家都还没有尽兴，接下来是一段时长堪比分享环节的 QA。激烈的讨论后现场小伙伴跟宇宙哥都嗨了，还没有嗨够的小伙伴我们下次见~
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Weekly update (July 24 ~ July 30, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-31-tidb-weekly/</link>
      <pubDate>Mon, 31 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-31-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 50 PRs in the TiDB repositories.
Added  Add a debugging tool for transaction inspection. Support two JSON syntactic sugars. Support renaming multiple tables in a single statement.  Fixed  Fix a bug in the update statement when doing the alter table after statement. Fix signed integer overflow in the minus unary scalar function. Fix the content in the information_schema for unsigned columns.</description>
    </item>
    
    <item>
      <title>A TiKV Source Code Walkthrough - Raft in TiKV</title>
      <link>https://pingcap.com/blog/2017-07-28-raftintikv/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-28-raftintikv/</guid>
      <description>(Email: tl@pingcap.com)

Table of content  Architecture Raft  Storage Config RawNode   Architecture Below is TiKV’s overall architecture:
Placement Driver: Placement Driver (PD) is responsible for the management scheduling of the whole cluster.
Node: Node can be regarded as an actual physical machine and each Node is responsible for one or more Store.
Store: Store uses RocksDB to implement actual data storage and usually one Store corresponds to one disk.</description>
    </item>
    
    <item>
      <title>TiSpark (Beta) 用户指南</title>
      <link>https://pingcap.com/blog-cn/tispark/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tispark/</guid>
      <description>TiSpark 是 PingCAP 推出的为了解决用户复杂 OLAP 需求的产品。借助 Spark 平台本身的优势，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP （Hybrid Transactional/Analytical Processing）需求。 TiSpark 依赖 TiKV 集群和 PD 的存在。当然，TiSpark 也需要你搭建一个 Spark 集群。本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 相关信息。
一、概述 TiSpark 是将 Spark SQL 直接运行在 TiDB 存储引擎 TiKV 上的 OLAP 解决方案。TiSpark 架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查；
 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。
 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。</description>
    </item>
    
    <item>
      <title>TiDB Best Practices</title>
      <link>https://pingcap.com/blog/2017-07-24-tidbbestpractice/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-24-tidbbestpractice/</guid>
      <description>From Li SHEN: shenli@pingcap.com
See the following blogs (Data Storage, Computing, Scheduling) for TiDB&amp;rsquo;s principles.
Table of Content  Preface Basic Concepts  Raft Distributed Transactions Data Sharding Load Balancing SQL on KV Secondary Indexes  Scenarios and Practices  Deployment Importing Data Write Query Monitoring and Log Documentation Best Scenarios for TiDB   Preface Database is a generic infrastructure system. It is important to, for one thing, consider various user scenarios during the development process, and for the other, modify the data parameters or the way to use according to actual situations in specific business scenarios.</description>
    </item>
    
    <item>
      <title>Weekly update (July 17 ~ July 23, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-24-tidb-weekly/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-24-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 60 PRs in the TiDB repositories.
Added  Add a tidb_version function to get the tidb-server version information. Support the READ COMMITTED isolation level. Support the ENCLOSED BY clause in the Load Data statement. Support creating index using type and comment.  Fixed  Fix a bug when in json_unquote. Fix field name with comment. Fix the wrong offset when using the Primary Key column as the handle.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.52】TiDB 自动化运维管理 —— TiDB-Operator》</title>
      <link>https://pingcap.com/meetup/meetup-2017-07-22/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-07-22/</guid>
      <description> 今天的 Meetup，由我司技术大拿邓栓同学为大家分享《TiDB 自动化运维管理 —— TiDB-Operator》。
 今日的帝都带着一丝凉爽，如此好天气怎能辜负。小伙伴们一清早就来到互动现场，一起来吃“营养早午餐”。
我司技术大拿邓栓同学激情满满的开始为大家做主题分享，主要从 TiDB-Operator 的功能介绍、整体架构、实现细节这几个纬度切入。
邓栓同学开场介绍到：分布式系统由于自身的复杂性，其管理和运维通常是非常困难的事情，借助 TiDB-Operator 我们能够轻松地将 TiDB 集群部署到 Kubernetes 集群之上，并做到自动化运维管理，极大地降低了人力运维成本，现场小伙伴们听呆了～
咦？what&amp;rsquo;wrong ? 黑灯瞎火嘛呢？
其实是小伙伴们在一起很专注的看 demo 演示~
活动最后，邓栓同学通过 demo 演示了 TiDB-operator bootstrap 一套完整的 TiDB 集群，然后在集群上面执行一个简单的操作就可以轻松实现扩容缩容，并且模拟物理节点挂掉时 TiDB-operator 对集群做自动恢复等各种自动化运维操作流程。
以上为最新前方报道～ enjoy 😁
讲师介绍：邓栓，PingCAP SRE 工程师，Kubernetes 爱好者，目前主要负责 TiDB 与各种云平台整合。Rust 中国社区联合创始人。
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>TiDB Internal (III) - Scheduling</title>
      <link>https://pingcap.com/blog/2017-07-20-tidbinternal3/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-20-tidbinternal3/</guid>
      <description>From Li SHEN: shenli@pingcap.com
Table of Content  Why scheduling The Requirements of Scheduling The Basic Operations of Scheduling Information Collecting The Policy of Scheduling The implementation of Scheduling Summary  Why scheduling? From the first blog of TiDB internal, we know that TiKV cluster is the distributed KV storage engine of TiDB database. Data is replicated and managed in Regions and each Region has multiple Replicas distributed on different TiKV nodes.</description>
    </item>
    
    <item>
      <title>PAX：一个 Cache 友好高效的行列混存方案</title>
      <link>https://pingcap.com/blog-cn/pax/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pax/</guid>
      <description>今年，Spanner 终于发了另一篇 Paper 「Spanner: Becoming a SQL System」，里面提到 Spanner 使用了一种新的存储格式 - Ressi，用来支持 OLTP 和 OLAP。在 Ressi 里面，使用了 PAX 来组织数据。因为 TiDB 定位就是一个 HTAP 系统，所以我也一直在思考在 TiKV 这层如何更好的存储数据，用来满足 HTAP 的需要，既然 Spanner 使用了 PAX，那么就有研究的必要了。
PAX 的论文可以看看 「Weaving Relations for Cache Performance」 或者 「Data Page Layouts for Relational Databases on Deep Memory Hierarchies」。
NSM and DSM 在谈 PAX 之前，NSM 和 DSM 还是绕不开的话题，NSM 就是通常说的行存，对于现阶段很多偏重 OLTP 的数据，譬如 MySQL 等，都采用的这种方式存储的数据。而 DSM，则是通常的说的列存，几乎所有的 OLAP 系统，都采用的这种方式来存储的底层数据。
NSM 会将 record 依次在磁盘 page 里面存放，每个 page 的末尾会存放 record 的 offset，便于快速的定位到实际的 record。如果我们每次需要得到一行 record，或者 scan 所有 records，这种格式非常的高效。但如果我们的查询，仅仅是要拿到 record 里面的一列数据，譬如 select name from R where age &amp;lt; 40，那么对于每次 age 的遍历，除了会将无用的其他数据一起读入，每次读取 record，都可能会引起 cache miss。</description>
    </item>
    
    <item>
      <title>gRPC-rs：从 C 到 Rust</title>
      <link>https://pingcap.com/blog-cn/grpc-rs/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc-rs/</guid>
      <description>介绍 在上篇文章中，我们讲到 TiKV 为了支持 gRPC，我们造了个轮子 gRPC-rs，这篇文章简要地介绍一下这个库。首先我们来聊聊什么是 gRPC。gRPC 是 Google 推出的基于 HTTP2 的开源 RPC 框架，希望通过它使得各种微服务之间拥有统一的 RPC 基础设施。它不仅支持常规的平台如 Linux，Windows，还支持移动设备和 IoT，现有十几种语言的实现，现在又多了一种语言 Rust。
gRPC 之所以有如此多的语言支持，是因为它有一个 C 写的核心库(gRPC core)，因此只要某个语言兼容 C ABI，那么就可以通过封装，写一个该语言的 gRPC 库。Rust 对 C 有良好的支持，gRPC-rs 就是对 gRPC core ABI 的 Rust 封装。
Core 能异步处理 RPC 请求，在考虑到 Rust 中已有较为成熟的异步框架 Futures，我们决定将 API 设计成 Future 模式。
gRPC-rs 架构图
我们将根据架构图从底向上地讲一下，在上一篇文章中已经讨论过传输层和协议，在这就不再赘述。
gRPC Core Core 中有几个比较重要的对象：
 Call 以及 4 种类型 RPC： Call 代表了一次 RPC，可以派生出四种类型 RPC，
 Unary： 这是最简单的一种 RPC 模式，即一问一答，客户端发送一个请求，服务端返回一个回复，该轮 RPC 结束。 Client streaming： 这类的 RPC 会创建一个客户端到服务端的流，客户端可以通过这个流，向服务端发送多个请求，而服务端只会返回一个回复。 Server streaming： 与上面的类似，不过它会创建一个服务端到客户端的流，服务端可以发送多个回复， Bidirectional streaming： 如果说上面两类是单工，那么这类就是双工了，客户端和服务端可以同时向对方发送消息。   值得一提的是由于 gRPC 基于 HTTP2，它利用了 HTTP2 多路复用特性，使得一个 TCP 连接上可以同时进行多个 RPC，一次 RPC 即为 HTTP2 中的一个 Stream。</description>
    </item>
    
    <item>
      <title>Weekly update (July 10 ~ July 16, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-17-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 51 PRs in the TiDB repositories.
Added  Support setting variables with ON and OFF. Support show stats_histgrams and show stats_buckets for debugging. Support the Scan API for the raw KV interface. Support the Show Charset statement. Support user name without quotes such as root@127.0.0.1.  Fixed  Fix a bug when explicitly inserting the null value into columns with the timestamp type.</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 重构内建函数进度报告</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</guid>
      <description>6 月 22 日，TiDB 发布了一篇如何十分钟成为 TiDB Contributor 系列的第二篇文章，向大家介绍如何为 TiDB 重构 built-in 函数。
截止到目前，得到了来自社区的积极支持与热情反馈，TiDB 参考社区 contributors 的建议，对计算框架进行了部分修改以降低社区同学参与的难度。
本文完成以下2 项工作，希望帮助社区更好的参与进 TiDB 的项目中来:
 对尚未重写的 built-in 函数进行陈列 对继上篇文章后，计算框架所进行的修改，进行详细介绍  一. 尚未重写的 built-in 函数陈列如下： 共计 165 个 在 expression 目录下运行 grep -rn &amp;quot;^\tbaseBuiltinFunc$&amp;quot; -B 1 * | grep &amp;quot;Sig struct {&amp;quot; | awk -F &amp;quot;Sig&amp;quot; &#39;{print $1}&#39; | awk -F &amp;quot;builtin&amp;quot; &#39;{print $3}&#39; &amp;gt; ~/Desktop/func.txt 命令可以获得所有未实现的 built-in 函数
   0 1 2 3 4     Coalesce Uncompress Log10 Default UnaryOp   Greatest UncompressedLength Rand InetAton IsNull   Least ValidatePasswordStrength Pow InetNtoa In   Interval Database Round Inet6Aton Row   CaseWhen FoundRows Conv Inet6Ntoa SetVar   If CurrentUser CRC32 IsFreeLock GetVar   IfNull User Sqrt IsIPv4 Values   NullIf ConnectionID Arithmetic IsIPv4Prefixed BitCount   AesDecrypt LastInsertID Acos IsIPv6 Reverse   AesEncrypt Version Asin IsUsedLock Convert   Compress Benchmark Atan MasterPosWait Substring   Decode Charset Cot NameConst SubstringIndex   DesDecrypt Coercibility Exp ReleaseAllLocks Locate   DesEncrypt Collation PI UUID Hex   Encode RowCount Radians UUIDShort UnHex   Encrypt Regexp Truncate AndAnd Trim   OldPassword Abs Sleep OrOr LTrim   RandomBytes Ceil Lock LogicXor RTrim   SHA1 Floor ReleaseLock BitOp Rpad   SHA2 Log AnyValue IsTrueOp BitLength   Char Format FromDays DayOfWeek Timestamp   CharLength FromBase64 Hour DayOfYear AddTime   FindInSet InsertFunc Minute Week ConvertTz   Field Instr Second WeekDay MakeTime   MakeSet LoadFile MicroSecond WeekOfYear PeriodAdd   Oct Lpad Month Year PeriodDiff   Quote Date MonthName YearWeek Quarter   Bin DateDiff Now FromUnixTime SecToTime   Elt TimeDiff DayName GetFormat SubTime   ExportSet DateFormat DayOfMonth StrToDate TimeFormat   UTCTim ToSeconds TimestampDiff DateArith Extract   UnixTimestamp UTCTimestamp UTCDate Time CurrentTime   ToDays TimestampAdd TimeToSec CurrentDate SysDate    二.</description>
    </item>
    
    <item>
      <title>TiDB Internal (I) - Data Storage</title>
      <link>https://pingcap.com/blog/2017-07-11-tidbinternal1/</link>
      <pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-11-tidbinternal1/</guid>
      <description>From Li SHEN: shenli@pingcap.com 
Table of Content  Foreword Storing data Key-Value RocksDB Raft Region MVCC Transaction Miscellaneous  Foreword: Database, operating system and compiler are known as the three big systems and regarded as the footstone of the whole computer software. Among them, database supports the businesses and is closer to the application layer. After decades of development, progress keeps emerging in this field.
Many people must have used databases of different kinds, but few have the experience of developing one, especially a distributed database.</description>
    </item>
    
    <item>
      <title>TiDB Internal (II) - Computing</title>
      <link>https://pingcap.com/blog/2017-07-11-tidbinternal2/</link>
      <pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-11-tidbinternal2/</guid>
      <description>From Li SHEN: shenli@pingcap.com
Table of Content  Mapping the Relational Model to the Key-Value Model Metadata Management Architecture of SQL on Key-Value SQL Computing Distributed SQL Operation Architecture of the SQL Layer Summary  My last blog introduces the way that TiDB stores data, which is also the basic concepts of TiKV. In this article, I’ll elaborate on how TiDB uses the bottom layer Key-Value to store data, maps the relational model to the Key-Value model and performs SQL computing.</description>
    </item>
    
    <item>
      <title>TiDB Best Practice</title>
      <link>https://pingcap.com/blog-cn/tidb-best-practice/</link>
      <pubDate>Wed, 05 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-best-practice/</guid>
      <description>本文档用于总结在使用 TiDB 时候的一些最佳实践，主要涉及 SQL 使用、OLAP/OLTP 优化技巧，特别是一些 TiDB 专有的优化开关。 建议先阅读讲解 TiDB 原理的三篇文章(讲存储，说计算，谈调度)，再来看这篇文章。
前言 数据库是一个通用的基础组件，在开发过程中会考虑到多种目标场景，在具体的业务场景中，需要根据业务的实际情况对数据的参数或者使用方式进行调整。
TiDB 是一个兼容 MySQL 协议和语法的分布式数据库，但是由于其内部实现，特别是支持分布式存储以及分布式事务，使得一些使用方法和 MySQL 有所区别。
基本概念 TiDB 的最佳实践与其实现原理密切相关，建议读者先了解一些基本的实现机制，包括 Raft、分布式事务、数据分片、负载均衡、SQL 到 KV 的映射方案、二级索引的实现方法、分布式执行引擎。下面会做一点简单的介绍，更详细的信息可以参考 PingCAP 公众号以及知乎专栏的一些文章。
Raft Raft 是一种一致性协议，能提供强一致的数据复制保证，TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功，这样即使丢掉少数副本，也能保证系统中还有最新的数据。比如最大 3 副本的话，每次写入 2 副本才算成功，任何时候，只丢失一个副本的情况下，存活的两个副本中至少有一个具有最新的数据。
相比 Master-Slave 方式的同步，同样是保存三副本，Raft 的方式更为高效，写入的延迟取决于最快的两个副本，而不是最慢的那个副本。所以使用 Raft 同步的情况下，异地多活成为可能。在典型的两地三中心场景下，每次写入只需要本数据中心以及离得近的一个数据中心写入成功就能保证数据的一致性，而并不需要三个数据中心都写成功。但是这并不意味着在任何场景都能构建跨机房部署的业务，当写入量比较大时候，机房之间的带宽和延迟成为关键因素，如果写入速度超过机房之间的带宽，或者是机房之间延迟过大，整个 Raft 同步机制依然无法很好的运转。
分布式事务 TiDB 提供完整的分布式事务，事务模型是在 Google Percolator 的基础上做了一些优化。具体的实现大家可以参考这篇文章。这里只说两点：
 乐观锁
TiDB 的事务模型采用乐观锁，只有在真正提交的时候，才会做冲突检测，如果有冲突，则需要重试。这种模型在冲突严重的场景下，会比较低效，因为重试之前的操作都是无效的，需要重复做。举一个比较极端的例子，就是把数据库当做计数器用，如果访问的并发度比较高，那么一定会有严重的冲突，导致大量的重试甚至是超时。但是如果访问冲突并不十分严重，那么乐观锁模型具备较高的效率。所以在冲突严重的场景下，推荐在系统架构层面解决问题，比如将计数器放在 Redis 中。
 事务大小限制
由于分布式事务要做两阶段提交，并且底层还需要做 Raft 复制，如果一个事务非常大，会使得提交过程非常慢，并且会卡住下面的 Raft 复制流程。为了避免系统出现被卡住的情况，我们对事务的大小做了限制：
 单条 KV entry 不超过 6MB KV entry 的总条数不超过 30w KV entry 的总大小不超过 100MB  在 Google 的 Cloud Spanner 上面，也有类似的限制。</description>
    </item>
    
    <item>
      <title>Weekly update (June 26 ~ July 02, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-04-tidb-weekly/</link>
      <pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Support priority options in the select statement. Add the GetOwnerID interface in OwnerManager. Add some columns in mysql.db: Make it compatible with MySQL. Add the IsolationLevel option in the coprocessor request to TiKV. Add the priority option in Key-Value request to TiKV. Support the RenameTable statement without the To keyword.  Fixed  Fix a bug in the update statement like update T set a = 8, b = a.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.51】百度统一分布式计算框架 Bigflow (内附 PPT 下载链接)</title>
      <link>https://pingcap.com/meetup/meetup-2017-07-01/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-07-01/</guid>
      <description> 今天的 Meetup，我们邀请到了滴滴地图事业部专家工程师王聪老师，为大家分享《百度统一分布式计算框架 Bigflow 》。
 讲师介绍：王聪，滴滴地图事业部专家工程师，前百度基础架构部工程师，主要工作方向为分布式计算与流式计算，在百度负责计算表示层 Bigflow 与流式计算引擎 Flink。
活动现场听得很专注的小伙伴们，桑拿天也阻止不了大家的学习热情。
王聪老师首先展示了分布式计算在百度的发展例程，他介绍百度在 2003 年建立了自己的分布式搜索系统。08 年引入 hadoop，09 年底搭建了大规模的机器学习平台，当时用的是 MPI。10 年百度自研了两套流式计算引擎，主要用来完成点击流与展现流的 join。
基于多引擎并存、跨引擎成本高、升级困难这几个痛点，最终开发了一款叫做 Bigflow 的计算框架，Bigflow 希望用户使用我们提供的 API 写代码，Bigflow 将作业进行计划的优化和翻译，并提交到计算引擎之上。对于这样的思路，有一种说法“计算机领域的任何问题，都可以通过增加一个额外的中间层来解决”。在这里 Bigflow 就是架在用户与引擎之间的中间层。
以下是新鲜出炉的 PPT 节选，尽情享用~
附：完整 PPT 链接
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Refactoring the Built-in Functions in TiDB</title>
      <link>https://pingcap.com/blog/2017-06-27-refactor-builtin/</link>
      <pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-06-27-refactor-builtin/</guid>
      <description>In order to accelerate expression evaluation, we recently refactored its framework. This tutorial will show you how to use the new computational framework to rewrite or add a built-in function in TiDB.
Table of Content  The overall process Example  Take a look at builtin_string.go Refine the existing TestLength() method Test the implementation of LENGTH at the SQL level   Before refactoring&amp;hellip; After refactoring&amp;hellip; Appendix  The overall process   Select any function to your interest from the expression directory, assuming the function is named XX.</description>
    </item>
    
    <item>
      <title>Weekly update (June 19 ~ June 25, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-26-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repositories.
Added  JSON type:  Tiny cleanup. Fix a bug in JSON path_expr. Fix a bug in unquote. Make json_unquote compatiable with MySQL Code cleanup.   Fixed  Fix failed test cases on the ppc64le platform Fix a bug when naming table with the auto_increment column. Use UTC time to compose index key for timestamp column.</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（2）- 火焰图</title>
      <link>https://pingcap.com/blog-cn/flame-graph/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/flame-graph/</guid>
      <description>在前一篇文章，我们简单提到了 perf，实际 perf 能做的事情远远不止这么少，这里就要好好介绍一下，我们在 TiKV 性能调优上面用的最多的工具 - 火焰图。
火焰图，也就是 FlameGraph，是超级大牛 Brendan Gregg 捣鼓出来的东西，主要就是将 profile 工具生成的数据进行可视化处理，方便开发人员查看。我第一次知道火焰图，应该是来自 OpenResty 的章亦春介绍，大家可以详细去看看这篇文章动态追踪技术漫谈。
之前，我的所有工作在很长一段时间几乎都是基于 Go 的，而 Go 原生提供了很多相关的 profile 工具，以及可视化方法，所以我没怎么用过火焰图。但开始用 Rust 开发 TiKV 之后，我就立刻傻眼了，Rust 可没有官方的工具来做这些事情，怎么搞？自然，我们就开始使用火焰图了。
使用火焰图非常的简单，我们仅仅需要将代码 clone 下来就可以了，我通常喜欢将相关脚本扔到 /opt/FlameGraph 下面，后面也会用这个目录举例说明。
一个简单安装的例子：
wget https://github.com/brendangregg/FlameGraph/archive/master.zip unzip master.zip sudo mv FlameGraph-master/ /opt/FlameGraph CPU 对于 TiKV 来说，性能问题最开始关注的就是 CPU，毕竟这个是一个非常直观的东西。
当我们发现 TiKV CPU 压力很大的时候，通常会对 TiKV 进行 perf，如下：
perf record -F 99 -p tikv_pid -g -- sleep 60 perf script &amp;gt; out.perf 上面，我们对一个 TiKV 使用 99 HZ 的频繁采样 60 s，然后生成对应的采样文件。然后我们生成火焰图：</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 为 TiDB 重构 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function/</guid>
      <description>这是十分钟成为 TiDB Contributor 系列的第二篇文章，让大家可以无门槛参与大型开源项目，感谢社区为 TiDB 带来的贡献，也希望参与 TiDB Community 能为你的生活带来更多有意义的时刻。
为了加速表达式计算速度，最近我们对表达式的计算框架进行了重构，这篇教程为大家分享如何利用新的计算框架为 TiDB 重写或新增 built-in 函数。对于部分背景知识请参考这篇文章，本文将首先介绍利用新的表达式计算框架重构 built-in 函数实现的流程，然后以一个函数作为示例进行详细说明，最后介绍重构前后表达式计算框架的区别。
重构 built-in 函数整体流程  在 TiDB 源码 expression 目录下选择任一感兴趣的函数，假设函数名为 XX
 重写 XXFunctionClass.getFunction() 方法
 该方法参照 MySQL 规则，根据 built-in 函数的参数类型推导函数的返回值类型 根据参数的个数、类型、以及函数的返回值类型生成不同的函数签名，关于函数签名的详细介绍见文末附录  实现该 built-in 函数对应的所有函数签名的 evalYY() 方法，此处 YY 表示该函数签名的返回值类型
 添加测试：
 在 expression 目录下，完善已有的 TestXX() 方法中关于该函数实现的测试 在 executor 目录下，添加 SQL 层面的测试  运行 make dev，确保所有的 test cast 都能跑过
  示例 这里以重写 LENGTH() 函数的 PR 为例，进行详细说明</description>
    </item>
    
    <item>
      <title>Weekly update (June 12 ~ June 18, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-20-tidb-weekly/</link>
      <pubDate>Tue, 20 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories.
Added  Refactor the optimizer:  Refactor ranger/statistic: calculate the range and row count of non pk column.  JSON type:  Support generated column:](https://github.com/pingcap/tidb/pull/3431) Support the JSON type in the cast expression.  Generated column:  Support basic generated column. Prevent modifying generated column. Add GeneratedExpr in ColumnInfo.  Support using clause in join statement.</description>
    </item>
    
    <item>
      <title>深入了解 gRPC：协议</title>
      <link>https://pingcap.com/blog-cn/grpc/</link>
      <pubDate>Sun, 18 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc/</guid>
      <description>经过很长一段时间的开发，TiDB 终于发了 RC3。RC3 版本对于 TiKV 来说最重要的功能就是支持了 gRPC，也就意味着后面大家可以非常方便的使用自己喜欢的语言对接 TiKV 了。
gRPC 是基于 HTTP/2 协议的，要深刻理解 gRPC，理解下 HTTP/2 是必要的，这里先简单介绍一下 HTTP/2 相关的知识，然后在介绍下 gRPC 是如何基于 HTTP/2 构建的。
HTTP/1.x HTTP 协议可以算是现阶段 Web 上面最通用的协议了，在之前很长一段时间，很多应用都是基于 HTTP/1.x 协议，HTTP/1.x 协议是一个文本协议，可读性非常好，但其实并不高效，笔者主要碰到过几个问题：
Parser 如果要解析一个完整的 HTTP 请求，首先我们需要能正确的读出 HTTP header。HTTP header 各个 fields 使用 \r\n 分隔，然后跟 body 之间使用 \r\n\r\n 分隔。解析完 header 之后，我们才能从 header 里面的 content-length 拿到 body 的 size，从而读取 body。
这套流程其实并不高效，因为我们需要读取多次，才能将一个完整的 HTTP 请求给解析出来，虽然在代码实现上面，有很多优化方式，譬如：
 一次将一大块数据读取到 buffer 里面避免多次 IO read 读取的时候直接匹配 \r\n 的方式流式解析  但上面的方式对于高性能服务来说，终归还是会有开销。其实最主要的问题在于，HTTP/1.</description>
    </item>
    
    <item>
      <title>来自 PingCAP CEO 的信：说在 B 轮融资完成之际</title>
      <link>https://pingcap.com/blog-cn/series-B-funding/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/series-B-funding/</guid>
      <description>平时技术说得多，今天说点走心的。
从决定出来创业到现在，刚好两年多一点，如果把 PingCAP 比喻成一个孩子的话， 刚是过了蹒跚学步的时期，前方有更大更美好的世界等我们去探索。这两年时间，在一片质疑声之中 ，TiDB 还算顽强的从无到有成长了起来。其实这一切的初心也很简单，最开始只不过是几个不愿妥协的分布式系统工程师对心目中&amp;rsquo;完美&amp;rsquo;的数据库的探索。很欣喜的看到 TiDB 的日渐成熟，周边工具和社区渐渐壮大，我感到由衷的自豪，在这个过程中，也一次又一次的挑战着技术和各自能力的边界，很庆幸能和自己的产品一起成长。
坚持做正确的事，哪怕这看起来是一条更困难的路。TiDB 从诞生的第一天起便决定开源，虽然更多的是商业上的考量，不过里面也有一点点读书人兼济天下的情怀和对传统 Hacker 精神的贯彻。在我们之前，很多人认为分布式 OLTP 和 OLAP 融合几乎是不可能的事情，也有无数的人，其中不乏亲朋好友，劝我们说在国内做这个事情几乎难于登天，而且没有成功的先例。不过我们还是相信一个朴素道理，有价值的技术一定会有它的舞台，另外，任何事情如果没有尝试就打退堂鼓也不是我们的风格。如果没有成功的先例，那就一起来创造先例，做开创者是我们每个人的梦想。说实话，从技术上来说，这个领域是一个非常前沿的领域，大多数时候我们面前是无人区，也很幸运，目前看来技术上和预想的没有出现大的偏差，整个产品和团队也在稳步的前进。
整个团队也从一开始的 3 个人，到今天 63 个志同道合的伙伴结伴前行，又一次很幸运，能凑齐这么一个具有很强战斗力和国际视野的团队，挑战计算机领域最困难和最前沿的课题之一，前方还有无数个迷人的问题等待着被解决，有时候也只能摸索着前进，不过这正是这个事情有意思的地方。谢谢你们，和你们一同工作，是我的荣幸。
到今天，我们很自豪的宣布，已经有数十家客户将 TiDB 使用在各自的生产环境中解决问题，感谢我们早期的铁杆用户和可爱的社区开发者，是你们让 TiDB 一点点的变得更加稳定成熟，随着社区的不断变大，TiDB 正以惊人的速度正向迭代，这就是开源的力量。
最后，PingCAP 也刚顺利的完成了 1500 万美金的 B 轮融资，感谢这轮的领投方华创资本，以及跟投方经纬中国，云启资本，峰瑞资本，险峰华兴。我们的征途是星辰大海，感谢有你们的一路支持。
刘奇、黄东旭、崔秋
PingCAP
2017-6-13</description>
    </item>
    
    <item>
      <title>Weekly update (June 06 ~ June 11, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 52 PRs in the TiDB repositories.
Added  Refactor the optimizer:
 Add an statsProfile interface to propagate statistic information among plans. Implement the statsProfile interface for the Join plan.  JSON type:
 Suport json_set, json_insert, json_replace and json_merge. Support the JSON type in the cast expression.  Use gRPC between TiDB and TiKV.
 Refactor the Analyze executor.
 Add the SubDuration function in util package.</description>
    </item>
    
    <item>
      <title>使用 Ansible 安装部署 TiDB</title>
      <link>https://pingcap.com/blog-cn/deployment-by-ansible/</link>
      <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/deployment-by-ansible/</guid>
      <description>背景知识 TiDB 作为一个分布式数据库，在多个节点分别配置安装服务会相当繁琐，为了简化操作以及方便管理，使用自动化工具来批量部署成为了一个很好的选择。
Ansible 是基于 Python 研发的自动化运维工具，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能，而且使用简单，仅需在管理工作站上安装 Ansible 程序配置被管控主机的 IP 信息，被管控的主机无客户端。基于以上原因，我们选用自动化工具 Ansible 来批量的安装配置以及部署 TiDB。
下面我们来介绍如何使用 Ansible 来部署 TiDB。
TiDB 安装环境配置如下 操作系统使用 CentOS7.2 或者更高版本，文件系统使用 EXT4。
 说明：低版本的操作系统(例如 CentOS6.6 )和 XFS 文件系统会有一些内核 Bug，会影响性能，我们不推荐使用。
    IP Services     192.168.1.101 PD Prometheus Grafana Pushgateway Node_exporter   192.168.1.102 PD TiDB Node_exporter   192.168.1.103 PD TiDB Node_exporter   192.168.1.104 TiKV Node_exporter   192.168.1.105 Tikv Node_exporter   192.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 谈调度</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-3/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-3/</guid>
      <description>为什么要进行调度 先回忆一下第一篇文章提到的一些信息，TiKV 集群是 TiDB 数据库的分布式 KV 存储引擎，数据以 Region 为单位进行复制和管理，每个 Region 会有多个 Replica（副本），这些 Replica 会分布在不同的 TiKV 节点上，其中 Leader 负责读/写，Follower 负责同步 Leader 发来的 raft log。了解了这些信息后，请思考下面这些问题：
 如何保证同一个 Region 的多个 Replica 分布在不同的节点上？更进一步，如果在一台机器上启动多个 TiKV 实例，会有什么问题？ TiKV 集群进行跨机房部署用于容灾的时候，如何保证一个机房掉线，不会丢失 Raft Group 的多个 Replica？ 添加一个节点进入 TiKV 集群之后，如何将集群中其他节点上的数据搬过来? 当一个节点掉线时，会出现什么问题？整个集群需要做什么事情？如果节点只是短暂掉线（重启服务），那么如何处理？如果节点是长时间掉线（磁盘故障，数据全部丢失），需要如何处理？ 假设集群需要每个 Raft Group 有 N 个副本，那么对于单个 Raft Group 来说，Replica 数量可能会不够多（例如节点掉线，失去副本），也可能会 过于多（例如掉线的节点又回复正常，自动加入集群）。那么如何调节 Replica 个数？ 读/写都是通过 Leader 进行，如果 Leader 只集中在少量节点上，会对集群有什么影响？ 并不是所有的 Region 都被频繁的访问，可能访问热点只在少数几个 Region，这个时候我们需要做什么？ 集群在做负载均衡的时候，往往需要搬迁数据，这种数据的迁移会不会占用大量的网络带宽、磁盘 IO 以及 CPU？进而影响在线服务？  这些问题单独拿出可能都能找到简单的解决方案，但是混杂在一起，就不太好解决。有的问题貌似只需要考虑单个 Raft Group 内部的情况，比如根据副本数量是否足够多来决定是否需要添加副本。但是实际上这个副本添加在哪里，是需要考虑全局的信息。整个系统也是在动态变化，Region 分裂、节点加入、节点失效、访问热点变化等情况会不断发生，整个调度系统也需要在动态中不断向最优状态前进，如果没有一个掌握全局信息，可以对全局进行调度，并且可以配置的组件，就很难满足这些需求。因此我们需要一个中心节点，来对系统的整体状况进行把控和调整，所以有了 PD 这个模块。</description>
    </item>
    
    <item>
      <title>Weekly update (May 22 ~ June 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 53 PRs in the TiDB repositories.
Added  Support using After and First to specify column position in the Alter Table Statement.
 Support the password builtin function.
 Support the inet6_ntoa builtin function.
 Support the Extract and Unquote function for Json.
 Support json_{set/insert/replace} and json_merge for Json.
 Support batched Index Lookup Join.
  Fixed  Fix a goroutine leak problem.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.49】TiDB Best Practice</title>
      <link>https://pingcap.com/meetup/meetup-2017-06-03/</link>
      <pubDate>Sat, 03 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-06-03/</guid>
      <description>今日的 Meetup，我司 Engineering VP 申砾同学亲自上阵，为大家分享了《TiDB Best Practice 》，好多使用经验及背后技术实现原理都是首次揭秘（当然，包括彩蛋）。
 本期讲师：申砾，PingCAP Engineering VP，前网易有道词典服务器端核心开发，前奇虎 360 新闻推荐系统 / 地图基础数据与检索系统 Tech Lead。
TiDB 是一个分布式数据库，支持 MySQL 协议以及语法，在一些场景中都可以无缝替换 MySQL，以获得分布式的好处。但是分布式数据库有其自身的特点，想要在业务中用好需要遵循一些实践原则。
本次分享申砾同学首先介绍了 TiDB 的一些关键部分的实现原理，理解这些内部实现有利于理解 TiDB 的外在表现。然后与大家讨论了应用数据库时的典型操作的最佳实践以及要注意的事项，并对 TiDB 的适用场景进行了讲解。
PPT 很干，一点水都挤不出来&amp;hellip;随便放几张你们感受下┑(￣Д ￣)┍
最后，申砾同学还分享了 TiDB 最近的一些项目进展，并首次公开披露 PingCAP 最新动向：独立研发的 TiDB 专用的 Spark Connector 即将上线。
Spark 是当下最流行的大数据分析系统，拥有活跃的社区。PingCAP 希望能够将 TiDB 与 Spark 相结合，通过 Spark 对 TiDB 中存储的数据做实时分析，以融入这个生态。为了保证这个连接过程尽可能的高效，所以除了基本的 JDBC Connector 之外，便有了 TiDB 专用的 Spark Connector。
附：完整 PPT 链接
彩蛋来啦 视频：Demo of Spark on TiDB</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（1）</title>
      <link>https://pingcap.com/blog-cn/iostat-perf-strace/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/iostat-perf-strace/</guid>
      <description>使用 iostat 定位磁盘问题 在一个性能测试集群，我们选择了 AWS c3.4xlarge 机型，主要是为了在一台机器的两块盘上面分别跑 TiKV。在测试一段时间之后，我们发现有一台 TiKV 响应很慢，但是 RocksDB 并没有相关的 Stall 日志，而且慢查询也没有。
于是我登上 AWS 机器，使用 iostat -d -x -m 5 命令查看，得到如下输出：
Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 xvdb 8.00 12898.00 543.00 579.00 31.66 70.15 185.84 51.93 54.39 7.03 98.79 0.60 66.80 xvdc 0.00 0.00 206.00 1190.</description>
    </item>
    
    <item>
      <title>Rust in TiKV</title>
      <link>https://pingcap.com/blog/2017-05-27-rust-in-tikv/</link>
      <pubDate>Sat, 27 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-27-rust-in-tikv/</guid>
      <description>This is the speech Siddon Tang gave at the 1st Rust Meetup in Beijing on April 16, 2017.
(Email: tl@pingcap.com)
Table of Content 
 What&amp;rsquo;s TiKV We need a language with&amp;hellip; Why not C++? Why not Go? So we turned to Rust&amp;hellip; TiKV Timeline TiKV Architecture Multi-Raft Scale out A simple write flow Key technologies Future plan  Hello everyone, today I will talk about how we use Rust in TiKV.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说计算</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-2/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-2/</guid>
      <description>关系模型到 Key-Value 模型的映射 在这我们将关系模型简单理解为 Table 和 SQL 语句，那么问题变为如何在 KV 结构上保存 Table 以及如何在 KV 结构上运行 SQL 语句。 假设我们有这样一个表的定义：
CREATE TABLE User { ID int, Name varchar(20), Role varchar(20), Age int, PRIMARY KEY (ID)， Key idxAge (age) }; SQL 和 KV 结构之间存在巨大的区别，那么如何能够方便高效地进行映射，就成为一个很重要的问题。一个好的映射方案必须有利于对数据操作的需求。那么我们先看一下对数据的操作有哪些需求，分别有哪些特点。
对于一个 Table 来说，需要存储的数据包括三部分：
 表的元信息 Table 中的 Row 索引数据  表的元信息我们暂时不讨论，会有专门的章节来介绍。 对于 Row，可以选择行存或者列存，这两种各有优缺点。TiDB 面向的首要目标是 OLTP 业务，这类业务需要支持快速地读取、保存、修改、删除一行数据，所以采用行存是比较合适的。
对于 Index，TiDB 不止需要支持 Primary Index，还需要支持 Secondary Index。Index 的作用的辅助查询，提升查询性能，以及保证某些 Constraint。查询的时候有两种模式，一种是点查，比如通过 Primary Key 或者 Unique Key 的等值条件进行查询，如 select name from user where id=1; ，这种需要通过索引快速定位到某一行数据；另一种是 Range 查询，如 select name from user where age &amp;gt; 30 and age &amp;lt; 35;，这个时候需要通过idxAge索引查询 age 在 20 和 30 之间的那些数据。Index 还分为 Unique Index 和 非 Unique Index，这两种都需要支持。</description>
    </item>
    
    <item>
      <title>A Brief Introduction of TiDB</title>
      <link>https://pingcap.com/blog/2017-05-23-perconalive17/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-23-perconalive17/</guid>
      <description>This is the speech Edward Huang gave at Percona Live - Open Source Database Conference 2017.
The slides are here.
 Speaker introduction What would you do when… TiDB Project - Goal Sofware Stack Safe Split Scale Out ACID Transaction Distributed SQL TiDB SQL Layer Overview What Happens behind a query Distributed Join (HashJoin) Tools Matter Use Cases Sysbench Roadmap  Speaker introduction  As one of the three co-founders of PingCAP, I feel honored that PingCAP was once again invited to the Percona Live Conference.</description>
    </item>
    
    <item>
      <title>Migration from MySQL to TiDB to handle tens of millions of rows of data per day</title>
      <link>https://pingcap.com/blog/2017-05-22-Comparison-between-MySQL-and-TiDB-with-tens-of-millions-of-data-per-day/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-22-Comparison-between-MySQL-and-TiDB-with-tens-of-millions-of-data-per-day/</guid>
      <description>Table of content  Background MySQL, our first choice Look for new solutions TiDB, give it a go Feedbacks from TiDB  Background GAEA is a mobile gaming provider and aims to develop high-quality games for international players. GAEA uses its GaeaAD system to support the cross-platform real-time advertising system. GaeaAD performs a real-time match between the advertising data and the information reported by the game SDK. In other words, GaeaAD conducts a real-time analysis based on the data of the advertisements on different advertising channels and the amount of players brought by the corresponding channels, with the purpose of displaying and optimizing the conversion effects of advertising within minutes.</description>
    </item>
    
    <item>
      <title>Weekly update (May 15 ~ May 21, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-22-tidb-weekly/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-22-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 31 PRs in the TiDB repositories.
Added  Use etcd to elect DDL job leader.
 Support Load Data with specified column list.
 Add the following builtin functions:
 umcompress and uncompressdlength convert_tz period-diff  Support the Json type and Json data encoding/decoding.
 Add a Jenkins CI in Pull Request.
 Add the EvalDuration and EvalTime interface for expressions.</description>
    </item>
    
    <item>
      <title>Weekly update (May 08 ~ May 14, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-15-tidb-weekly/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-15-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Add builtin function uncompress and uncompressdlength, convert_tz, period-diff
 Fill data into information_schema.key_column_usage.
 Add Open interface for Executor.
 Show warnings for Load Data statement.
 Support Json type and functions in parser.
 Support top-n operator in new planner.
  Fixed  Consider session variable time_zone for timestamp datum.
 Fix data race problem in IndexLookup Executor.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说存储</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-1/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-1/</guid>
      <description>引言 数据库、操作系统和编译器并称为三大系统，可以说是整个计算机软件的基石。其中数据库更靠近应用层，是很多业务的支撑。这一领域经过了几十年的发展，不断的有新的进展。
很多人用过数据库，但是很少有人实现过一个数据库，特别是实现一个分布式数据库。了解数据库的实现原理和细节，一方面可以提高个人技术，对构建其他系统有帮助，另一方面也有利于用好数据库。
研究一门技术最好的方法是研究其中一个开源项目，数据库也不例外。单机数据库领域有很多很好的开源项目，其中 MySQL 和 PostgreSQL 是其中知名度最高的两个，不少同学都看过这两个项目的代码。但是分布式数据库方面，好的开源项目并不多。 TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于分布式数据库自身的复杂性，很多人并不能很好的理解整个项目，所以我希望能写一些文章，自顶向上，由浅入深，讲述 TiDB 的一些技术原理，包括用户可见的技术以及大量隐藏在 SQL 界面后用户不可见的技术点。
保存数据 数据库最根本的功能是能把数据存下来，所以我们从这里开始。
保存数据的方法很多，最简单的方法是直接在内存中建一个数据结构，保存用户发来的数据。比如用一个数组，每当收到一条数据就向数组中追加一条记录。这个方案十分简单，能满足最基本，并且性能肯定会很好，但是除此之外却是漏洞百出，其中最大的问题是数据完全在内存中，一旦停机或者是服务重启，数据就会永久丢失。
为了解决数据丢失问题，我们可以把数据放在非易失存储介质（比如硬盘）中。改进的方案是在磁盘上创建一个文件，收到一条数据，就在文件中 Append 一行。OK，我们现在有了一个能持久化存储数据的方案。但是还不够好，假设这块磁盘出现了坏道呢？我们可以做 RAID （Redundant Array of Independent Disks），提供单机冗余存储。如果整台机器都挂了呢？比如出现了火灾，RAID 也保不住这些数据。我们还可以将存储改用网络存储，或者是通过硬件或者软件进行存储复制。到这里似乎我们已经解决了数据安全问题，可以松一口气了。But，做复制过程中是否能保证副本之间的一致性？也就是在保证数据不丢的前提下，还要保证数据不错。保证数据不丢不错只是一项最基本的要求，还有更多令人头疼的问题等待解决：
 能否支持跨数据中心的容灾？ 写入速度是否够快？ 数据保存下来后，是否方便读取？ 保存的数据如何修改？如何支持并发的修改？ 如何原子地修改多条记录？  这些问题每一项都非常难，但是要做一个优秀的数据存储系统，必须要解决上述的每一个难题。 为了解决数据存储问题，我们开发了 TiKV 这个项目。接下来我向大家介绍一下 TiKV 的一些设计思想和基本概念。
Key-Value 作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。简单来讲，可以将 TiKV 看做一个巨大的 Map，其中 Key 和 Value 都是原始的 Byte 数组，在这个 Map 中，Key 按照 Byte 数组总的原始二进制比特位比较顺序排列。 大家这里需要对 TiKV 记住两点：
 这是一个巨大的 Map，也就是存储的是 Key-Value pair 这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是我们可以 Seek 到某一个 Key 的位置，然后不断的调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value  讲了这么多，有人可能会问了，这里讲的存储模型和 SQL 中表是什么关系？在这里有一件重要的事情要说四遍：</description>
    </item>
    
    <item>
      <title>基于 Tile 连接 Row-Store 和 Column-Store</title>
      <link>https://pingcap.com/blog-cn/tile-row-store/</link>
      <pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tile-row-store/</guid>
      <description>在之前的 Kudu 的文章里面，我已经提到过，行列混存是一个非常有意思的研究方向，因为不同的存储方式有不同的针对应用场景，但作为技术人员，折腾是天性，所以大家都在研究如何融合行存和列存，让一个服务能尽量满足大部分应用需求，而这也是 TiDB 在努力的方向。
在 Kudu Paper 里面说到，Kudu 首先在 mem 里面使用行存，但刷到硬盘之后，则使用的是列存，这当然是一个可以尝试的方式，但我觉得应该还有更多种的解决方式，于是找到了 CMU 的 Peloton 以及相关的 Paper，觉得有必要研究记录一下。
Storage Model 很多时候，我喜欢用行存和列存，但看 Paper 的时候，发现都喜欢使用 NSM 和 DSM 来说明，这里就简单说明一下。
NSM NSM 是 N-ary storage model 的简称，当然就是通常的行存了。NSM 主要针对 OLTP 场景，因为需要高性能的随机写入，NSM 的存储方式如下：
NSM 不适用需要读取大量数据，并分析特定 column 的场景，因为 NSM 需要把整个 record 给读出来，在拿到对应的 column 数据分析，数据数据量很大，整个开销会很大。
DSM DSM 是 decomposition storage model 的简称，也就是列存。DSM 主要针对 OLAP 场景，因为需要对一些特定的 column 进行快速扫描分析，DSM 的存储方式如下：
DSM 当然就不适用与需要频繁随机更新的情况，因为任何写入，DSM 需要将 record 分开写入到不同的地方，写开销会很大。
FSM 为了解决这个问题，就有了一个 FSM flexible storage model 来融合 NSM 和 DSM，在 Peloton 里面，它把这套系统叫做 HTAP (Hybrid Transactional/Analytical Processing)，</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.48】分布式对象存储面临的挑战</title>
      <link>https://pingcap.com/meetup/meetup-2017-05-13/</link>
      <pubDate>Sat, 13 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-05-13/</guid>
      <description> 今天的 Meetup，我们请到了来自白山云的张炎泼老师，为大家分享《分布式对象存储面临的挑战》。
 本期讲师：张炎泼 (xp)
30 年软件开发经验，物理系背叛者，设计师眼中的美工，bug maker，vim 死饭，悬疑片脑残粉。曾就职新浪，美团。现在白山云，不是白云山。
在本次分享中，张炎泼老师从：海量小文件如何存储、如何节省存储成本、如何实现数据的自动恢复，三个方面，为大家进行了详细讲解。
以下是本期 PPT 节选
附：完整 PPT 下载链接
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Kudu - 一个融合低延迟写入和高性能分析的存储系统</title>
      <link>https://pingcap.com/blog-cn/kudu/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/kudu/</guid>
      <description>Kudu 是一个基于 Raft 的分布式存储系统，它致力于融合低延迟写入和高性能分析这两种场景，并且能很好的嵌入到 Hadoop 生态系统里面，跟其他系统譬如 Cloudera Impala，Apache Spark 等对接。
Kudu 很类似 TiDB。最开始，TiDB 是为了 OLTP 系统设计的，但后来发现我们 OLAP 的功能也越来越强大，所以就有了融合 OLTP 和 OLAP 的想法，当然这条路并不是那么容易，我们还有很多工作要做。因为 Kudu 的理念跟我们类似，所以我也很有兴趣去研究一下它，这里主要是依据 Kudu 在 2015 发布的 paper，因为 Kudu 是开源的，并且在不断的更新，所以现在代码里面一些实现可能还跟 paper 不一样了，但这里仅仅先说一下我对 paper 的理解，实际的代码我后续研究了在详细说明。
为什么需要 Kudu？ 结构化数据存储系统在 Hadoop 生态系统里面，通常分为两类：
 静态数据，数据通常都是使用二进制格式存放到 HDFS 上面，譬如 Apache Avro，Apache Parquet。但无论是 HDFS 还是相关的系统，都是为高吞吐连续访问数据这些场景设计的，都没有很好的支持单独 record 的更新，或者是提供好的随机访问的能力。
 动态数据，数据通常都是使用半结构化的方式存储，譬如 Apache HBase，Apache Cassandra。这些系统都能低延迟的读写单独的 record，但是对于一些像 SQL 分析这样需要连续大量读取数据的场景，显得有点捉紧见拙。
  上面的两种系统，各有自己的侧重点，一类是低延迟的随机访问特定数据，而另一类就是高吞吐的分析大量数据。之前，我们并没有这样的系统可以融合上面两种情况，所以通常的做法就是使用 pipeline，譬如我们非常熟悉的 Kafka，通常我们会将数据快速写到 HBase 等系统里面，然后通过 pipeline，在导出给其它分析系统。虽然我们在一定层面上面，我们其实通过 pipeline 来对整个系统进行了解耦，但总归要维护多套系统。而且数据更新之后，并不能直接实时的进行分析处理，有延迟的开销。所以在某些层面上面，并不是一个很好的解决方案。</description>
    </item>
    
    <item>
      <title>Weekly update (May 01 ~ May 07, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-08-tidb-weekly/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Add builtin function is_ipv4_mapped, makedate, utc_time
 Enable privilege checking by default. You could also disable privilege checking through --privilege=false.
 Support Analyze Index statement: after adding an index, we could run this statement to analyze the newly added index.
 Add Trigger_priv column in mysql.user system table.
 Add coveralls in CI.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.47】分布式定时任务中间件架构 Elastic-Job 的两种实现</title>
      <link>https://pingcap.com/meetup/meetup-2017-05-06/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-05-06/</guid>
      <description> 今天的 Meetup ，我们请到了当当架构部负责人张亮，大家分享了《分布式定时任务中间件架构 Elastic-Job 的两种实现》。
 本期讲师：张亮
当当架构部负责人，主要负责分布式中间件以及私有云平台的搭建。致力于开源，目前主导两个开源项目 elastic-job 和 sharding-jdbc。擅长以 java 为主分布式架构以及以 Mesos 为主的云平台方向，推崇优雅代码，对如何写出具有展现力的代码有较多研究。
今日帝都依然大风，但小伙伴们学习的热情丝毫未减哦~
在本次分享中，张亮老师从分布式定时任务中间件的适用场景，轻量级去中心化架构方案以及基于 Mesos 的中心化架构方案，三个方面为大家进行了详细讲解。
在互联网应用中，各式各样的定时任务存于系统的各个角落，我们希望由一个平台统一将这些作业管理起来。然而，一旦平台中运行大量的作业，发现异常作业并手动处理难免会感到繁琐，同时人工处理还会带来很多其他的额外成本。如何最大限度的减少人工干预？
高可用可以让作业在被系统发现宕机之后能自动切换。而弹性化可以认为是高可用的进阶版本，在高可用的同时还能够提升效率和充分利用资源。对于动态的扩容和缩容，通常采用分片的方式实现。
去中心化架构是指所有的作业节点都是对等的，优点是轻量级，部署成本低；缺点则是，如果各作业服务器时钟不一致会产生同一作业的不同分片运行有先有后，缺乏统一调度，并且不能跨语言。
中心化架构将系统分为调度节点和执行节点，可以解决服务器时间差以及跨语言的问题；缺点是部署和运维稍复杂。
Elastic-Job 最初的版本分离于当当内部的应用框架 ddframe，是一个纯 Java 实现的分布式方案，参照 dubbo 的方式，提供无中心化解决方案。
如今，Elastic-Job 已开源近 2 年，截止目前已更新发布18 次，GitHub Star 数近 2000，成绩出色。更有多个开源产品衍生自 Elastic-Job。
应小伙伴们的强烈要求，张亮老师临时加场 Demo 演示。
最后，还有超多第一手爆料，是属于现场听讲小伙伴们的专属福利 ✌️ 很心动？下周六，老时间，老地点，PingCAP 第 48 期 Infra Meetup 等你呦！
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Weekly update (April 24 ~ April 30, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-02-tidb-weekly/</link>
      <pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Add builtin function truncate, makedate, utc_time
 Add pre-commit hook.
 Add a plan for Analyze.
 Add a check list about the things that contributors should think about before sending a PR.
 Support ENGINE option with partition option in table definition.
 Add code review guide.
  Fixed  Fix bug in converting string to hex/bit.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.46】MySQL 5.7 的特性及实践</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-22/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-22/</guid>
      <description>今天的 Meetup，我们邀请到了熊猫直播 DBA 杨尚刚老师，为大家分享《MySQL 5.7 的特性及实践》~
  讲师介绍：杨尚刚，熊猫直播高级 DBA，负责后端数据库平台建设和架构设计。前新浪高级数据库工程师，负责新浪微博核心数据库架构改造优化，以及数据库相关的服务器存储选型设计。
 2015 年最重磅的当属 MySQL 5.7 GA 的发布，号称 160 万只读 QPS，大有赶超 NoSQ L趋势。
不过官方的硬件测试环境是很高的，所以这个 160 万 QPS 对于大家测试来说，可能还比较遥远，所以实际测试的结果可能会失望。但是，至少我们看到了基于同样测试环境，MySQL 5.7 在性能上的改进，对于多核利用的改善。
本次分享中，杨老师讲解了 MySQL 5.7 在运维、优化器 Server 层、InnoDB 层等方面的优化，以及 MySQL 未来的发展趋势。
运维方面  动态修改 Buffer Pool
 MySQL redo log大小
 innodb_file_per_table
 query cache
 SQL_Mode
 binlog_rows_query_log_events
 max_execution_time
 replication info in tables
 innodb_numa_interleave
 动态修改 replication filter</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：Cloud-Native 的分布式数据库架构与实践</title>
      <link>https://pingcap.com/blog-cn/talk-cloud-native/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-cloud-native/</guid>
      <description>4 月 19 日，我司 CTO 黄东旭同学在全球云计算开源大会上，发表了《Cloud-Native 的分布式数据库架构与实践》主题演讲，以下为演讲实录。
实录 大家好，今天我的题目是 Cloud-Native 与分布式数据库的实践。先简单的介绍一下自己，我是 PingCAP 的联合创始人和 CTO，过去一直在做基础软件领域的工程师，基本上做的所有的东西都是开源。在分享之前我想说一下为什么现在各行各业或者整个技术软件社区一直在重复的再造数据库，现在数据库到底怎么了，为什么这么百花齐放？
 首先随着业务的多种多样，还有不管是传统行业还是互联网行业，业务的迭代速度越来越互联网化，使得整个数据量其实是一直在往上走的；
 第二就是随着 IOT 的设备还有包括像手机、移动互联网蓬勃的发展，终端其实也不再仅仅是传统的 PC 客户端的数据的接入；
 第三方面随着现在 AI 或者大数据分析一些模型或者理论上的突破，使得在大数据上进行计算的手段越来越多样，还有在物理上一些硬件的新的带有保护的内存，各种各样新的物理的设备，越来越多的硬件或者物理上的存储成本持续的降低，使得我们的数据库需要要面对更多的挑战。
  关联数据库理论是上世纪七十年代做出来的东西，现在四十年过去不管是物理的环境还是计算模型都是完全不一样的阶段，还抱着过去这种观念可能并不是一个面向未来的设计。而且今天我的题目是 Cloud-Native，有一个比较大胆的假设，大家在过去三十年的计算平台基本都是在一台 PC 或者一个服务器或者一个手机这样的独立的计算平台，但是未来我觉得一切的服务都应该是分布式的。因为我觉得摩尔定律已经失效了，所以未来的操作系统会是一个大规模分布式的操作系统，在上面跑的任何的进程，任何的服务都应该是分布式的，在这个假设下怎么去做设计，云其实是这个假设最好的载体。怎么在这个假设上去设计面向云的技术软件，其实是最近我一直在思考的一个问题。其实在这个时代包括面向云的软件，对业务开发来说尽量还是不要太多的改变过去的开发习惯。你看最近大数据的发展趋势，从最传统的关系数据库到过去十年相比，整个改变了用户的编程模型，但是改变到底是好的还是不好的，我个人觉得其实并不是太好。最近这两年大家会看到整个学术圈各种各样的论文都在回归，包括 DB 新时代的软件都会把扩展性和分布式放在第一个要素。
大家可能听到主题会有点蒙，叫 Cloud-Native，Cloud-Native 是什么？其实很早的过去也不是没有人做过这种分布式系统的尝试，最早是 IBM 提出面向服务的软件架构设计，最近热门的 SOA、Micro Service 把自己的服务拆分成小的服务，到现在谷歌一直对外输出一个观点就是 Cloud-Native，就是未来大家的业务看上去的分布式会变成一个更加透明的概念，就是你怎么让分布式的复杂性消失在云的基础设施后，这是 Cloud-Native 更加关心的事情。
这个图是 CNCF 的一个基金会，也是谷歌支持的基金会上扒过来的图。这里面有一个简单的定义，就是 SCALE 作为一等公民，面向 Cloud-Native 的业务必须是弹性伸缩的，不仅能伸也得能缩；第二就是在对于这种 Cloud-Native 业务来说是面向 Micro service 友好；第三就是部署更加的去人工化。
最近大家可能也看到很多各种各样容器化的方案，背后代表的意义是什么？就是整个运维和部署脱离人工，大家可以想象过去十几二十年来，一直以来运维的手段是什么样的。我找了一个运维，去买服务器，买服务器装系统，在上面部署业务。但是现在 Cloud-Native 出现变得非常的自动化，就相当于把人的功能变得更低，这是很有意义的，因为理想中的世界或者未来的世界应该怎么样，一个业务可能会有成百上千的物理节点，如果是人工的去做运维和部署是根本不可能做得到的，所以其实构建整个 Cloud-Native 的基础设施的两个条件：第一个就是存储本身的云化；第二就是运维要和部署的方式必须是云化的。
我就从这两个点说一下我们 TiDB 在上面的一些工作和一些我的思考。
存储本身的云化有几个基本条件，大家过去认为是高可用，主要停留在双活。其实仔细去思考的话，主备的方案是很难保证数据在完全不需要人工的介入情况下数据的一致性可用性的，所以大家会发现最近这几年出来的分布式存储系统的可用性的协议跟复制协议基本都会用类似 Raft/Paxos 基于选取的一致性算法，不会像过去做这种老的复制的方案。
第二就是整个分片的策略，作为分布式系统数据一定是会分片的，数据分片是来做分布式存储唯一的思路，自动分片一定会取代传统的人工分片来去支撑业务。比如传统分片，当你的数据量越来越大，你只能做分库分表或者用中间件，不管你分库分表还是中间件都必须制订自己人工的分辨规则，但是其实在一个真正面向 Cloud 的数据库设计里，任何一种人的介入的东西都是不对的。</description>
    </item>
    
    <item>
      <title>Weekly update (April 10 ~ April 16, 2017)</title>
      <link>https://pingcap.com/weekly/2017-04-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-04-17-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 26 PRs in the TiDB repositories.
Added  Update etcd client in vendor.
 Add builtin function time-to-sec
 Add definition for builtin functions: bit_count, to_base64, right
  Fixed  Fix the error message for data overflow.
 Fix a panic.
 Fix a bug in top-n pushdown.
 Fix a data race bug in session context.
 Fix a bug in name resolver for GroupBy clause.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.45】Rust 专场</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-16/</link>
      <pubDate>Sun, 16 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-16/</guid>
      <description>今天，小伙伴们期待已久的北京 Rust Meetup 终于和大家见面啦！在这场 Rust 社区在中国的首次官方活动中，我们邀请了两位 Rust 团队核心成员，Alex Crichton、Brian Anderson，与我司首席架构师唐刘，共同为大家带来了干货十足的分享内容~第一手现场资料，看这里！
 这一次的 Meetup，小伙伴们都好积极 👏 提前一小时就有入场抢座位的~也是让小编感动到不行~~知道大家都已经迫不及待了，简单的开场之后，我们直接上干货！
Concurrency and asynchronous IO in Rust 并发在当今编程领域是如此重要，然而要想实现并发程序通常会面临数据竞争，竞态，死锁，悬空指针，多次 free 等问题，Alex 在本期 meetup 里给我们讲解了 Rust 是如何用 ownership/borrowing 系统解决这些问题的，其核心思想是:
 A mutable reference cannot be aliased
 A reference cannot outlive its referent
   Alex Crichton，Mozilla 工程师，Rust 核心团队成员。从事 Rust 编程语言方面的工作已有 5 年。在 Mozilla 主要负责 Rust 的标准库、Cargo、异步 I/O 子系统以及 Rust 本身的基础设施。目前在做异步 I/O 栈 Tokio。
 Rust 语言本身只提供了 ownership/borrowing 机制，标准库里提供了 thread，channel，arc，atomic，mutex 等基础设施，但没有提供轻量级协程，这样虽说并发程序写起来比较麻烦，但是不会只局限于一种并发模型。而后，简单介绍了第三方并行库 rayon 和 crossbeam。最后重点讲解了异步 IO 库 futures。</description>
    </item>
    
    <item>
      <title>Weekly update (March 27 ~ April 09, 2017)</title>
      <link>https://pingcap.com/weekly/2017-04-10-tidb-weekly/</link>
      <pubDate>Mon, 10 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-04-10-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 74 PRs in the TiDB repositories.
Added  Support Index Nest Lookup Join operator.#2834, #2945
 Add many builtin functions: quote, is_ipv4, compress, inet_aton, format, bin, random-bytes, sin, inet_ntoa, cos, from_base64, tan, cot, to_days, timestampadd
 Check privileges for show databases/tables statement.
 Calculate distinct information in statistic module.#2947, #2966
 Add a switcher to split large inset transaction into multiple small transactions automatically.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.44】Elasticsearch 运维</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-08/</link>
      <pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-08/</guid>
      <description> 今天的 Meetup，我们邀请到去哪儿网的资深工程师徐磊，为大家分享关于 Elasticsearch 运维的那些事，跟小编一起走进现场吧~~
Elasticsearch 运维 Elasticsearch 在近两年越来越火了，越来越多的公司和团队尝试使用它支撑业务。运维人员如何保证 Elasticsearch 集群的稳定？有哪些必须掌握的优化技巧？
在本次分享中，徐磊老师从数据模型设计，使用技巧，参数优化，监控对比等多个方面为大家分析了 Elasticsearch 的优缺点和运维重点。同时与大家分享了内部的 Elasticsearch 私有云的建设经验。
 徐磊，2015 年加入去哪儿网平台事业部 OPSDEV 团队，负责实时日志系统的建设和运维工作，开源社区贡献者，曾供职于 Red Hat。
 干货节选 来~这里还有讲师的 PPT 节选，一起看看，在 Elasticsearch 中，有哪些要注意的坑吧~~
 PingCAP Infra Meetup
作为一个基础架构领域的前沿技术公司，PingCAP 希望能为国内真正关注技术本身的 Hackers 打造一个自由分享的平台。自 2016 年 3 月 5 日开始，我们定期在周六的上午举办 Infra Meetup，邀请业内大牛与大家深度探讨基础架构领域的前瞻性技术思考与经验。在这里，我们希望提供一个高水准的前沿技术讨论空间，让大家真正感受到自由的开源精神魅力。
 </description>
    </item>
    
    <item>
      <title>Weekly update (March 20 ~ March 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 40 PRs in the TiDB repositories.
Added  Support Sort Merge Join operator.
 Add many builtin functions: degree, insert, instr, any_value, elt, uuid, ord, sin, inet_ntoa, maketime, sha2, quarter
 Add a command line flag to start TiDB without authentication function.
 Support use special comment /*+ */ for optimizer hint.
 Make index serial scan concurrency configurable with system variable.</description>
    </item>
    
    <item>
      <title>如何从零开始参与大型开源项目</title>
      <link>https://pingcap.com/blog-cn/how-to-contribute/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-contribute/</guid>
      <description>写在前面的话 上世纪 70 年代，IBM 发明了关系型数据库。但是随着现在移动互联网的发展，接入设备越来越多，数据量越来越大，业务越来越复杂，传统的数据库显然已经不能满足海量数据存储的需求。虽然目前市场上也不乏分布式数据库模型，但没有品位的文艺青年不是好工程师，我们觉得，不，这些方案都不是我们想要的，它们不够美，鲜少能够把分布式事务与弹性扩展做到完美。
受 Google Spanner/F1 的启发，一款从一开始就选择了开源道路的 TiDB 诞生了。 它是一款代表未来的新型分布式 NewSQL 数据库，它可以随着数据增长而无缝水平扩展，只需要通过增加更多的机器来满足业务增长需求，应用层可以不用关心存储的容量和吞吐，用东旭的话说就是「他自己会生长」。
在开源的世界里，TiDB 和 TiKV 吸引了更多的具有极客气质的开发者，目前已经拥有超过 9000 个 star 和 100 个 contributor，这已然是一个世界顶级开源项目的水准。而成就了这一切的，则是来自社区的力量。
最近我们收到了很多封这样的邮件和留言，大家说：
 谢谢你们，使得旁人也能接触大型开源项目。本身自己是DBA，对数据库方面较干兴趣，也希望自己能逐步深入数据库领域，深入TiDB，为 TiDB 社区贡献更多、更有价值的力量。
 我是一个在校学生，刚刚收到邮件说我成为了 TiDB 的 Contributor，这让我觉得当初没听父母的话坚持了自己喜欢的计算机技术，是个正确的选择，但我还需要更多的历练，直到能完整地展现、表达我的思维。
  这让我感触颇多，因为，应该是我们感谢你们才是啊，没有社区，一个开源项目就成不了一股清泉甚至一汪海洋。 公司的小姑娘说，她觉得还有很多的人想要参与进来的，可工程师团队欠缺平易近人的表达，这个得改。
于是便有了这篇文章以及未来的多篇文章和活动，我们欢迎所有的具有气质的开发者能和 TiDB 一起成长，一起见证数据库领域的革新，改变世界这事儿有时候也不那么难。
我要重点感谢今天这篇文章的作者，来自社区的朱武（GitHub ID:viile ）、小卢（GitHub ID:lwhhhh ）和杨文（GitHub ID: yangwenmai），当在 TiDB Contributor Club 里提到想要做这件事的时候，是他们踊跃地加入了 TiDB Tech Writer 的队伍，高效又专业地完成了下文的编辑，谢谢你们。
一个典型的开源项目是由什么组成的 The Community（社区）  一个项目经常会有一个围绕着它的社区，这个社区由各个承担不同角色的用户组成。
 项目的拥有者：在他们账号中创建项目并拥有它的用户或者组织。
 维护者和合作者：主要做项目相关的工作和推动项目发展，通常情况下拥有者和维护者是同一个人，他们拥有仓库的写入权限。
 贡献者：发起拉取请求 (pull request) 并且被合并到项目里面的人。</description>
    </item>
    
    <item>
      <title>RocksDB 专场分享|PingCAP 第 43 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-25/</link>
      <pubDate>Sat, 25 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-25/</guid>
      <description>RocksDB 专场分享|PingCAP 第 43 期 NewSQL Meetup 2017-03-25 宋昭&amp;amp;赵安安 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (March 13 ~ March 19, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-20-tidb-weekly/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Add system table mysql.stats_meta: used for storing statistic information.
 Add a Restful API to get region info from pd.
 Add a system variable to control the behavior of unfolding subquery in in expression.
 Add many builtin functions: acos, asin, atan, make_set, oct, pi, lpad, radians, exp, ip_v6
  Fixed  Check truncated UTF8 string when casting value.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 42 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-18/</link>
      <pubDate>Sat, 18 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-18/</guid>
      <description>COISF 专场|PingCAP 第 42 期 NewSQL Meetup 2017-03-18 梁堰波 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>十分钟成为 TiDB Contributor 系列 | 添加內建函数</title>
      <link>https://pingcap.com/blog-cn/add-a-built-in-function/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/add-a-built-in-function/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后首先会经过 parser，从文本 parse 成为 AST（抽象语法树），通过 Query Optimizer 生成执行计划，得到一个可以执行的 plan，通过执行这个 plan 即可得到结果，这期间会涉及到如何获取 table 中的数据，如何对数据进行过滤、计算、排序、聚合、滤重以及如何对表达式进行求值。 对于一个 builtin 函数，比较重要的是进行语法解析以及如何求值。其中语法解析部分需要了解如何写 yacc 以及如何修改 TiDB 的词法解析器，较为繁琐，我们已经将这部分工作提前做好，大多数 builtin 函数的语法解析工作已经做完。 对 builtin 函数的求值需要在 TiDB 的表达式求值框架下完成，每个 builtin 函数被认为是一个表达式，用一个 ScalarFunction 来表示，每个 builtin 函数通过其函数名以及参数，获取对应的函数类型以及函数签名，然后通过函数签名进行求值。 总体而言，上述流程对于不熟悉 TiDB 的朋友而言比较复杂，我们对这部分做了些工作，将一些流程性、较为繁琐的工作做了统一处理，目前已经将大多数未实现的 buitlin 函数的语法解析以及寻找函数签名的工作完成，但是函数实现部分留空。换句话说，只要找到留空的函数实现，将其补充完整，即可作为一个 PR。
添加 builtin 函数整体流程  找到未实现的函数
在 TiDB 源码中的 expression 目录下搜索 errFunctionNotExists，即可找到所有未实现的函数，从中选择一个感兴趣的函数，比如 SHA2 函数：
func (b *builtinSHA2Sig) eval(row []types.Datum) (d types.Datum, err error) { return d, errFunctionNotExists.GenByArgs(&amp;#34;SHA2&amp;#34;) } 实现函数签名</description>
    </item>
    
    <item>
      <title>Weekly update (March 06 ~ March 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories.
Added  Add context in exector: prepare for canceling execution.
 Support the KILL statement.
 Support string literal with in the national character set N&#39;literal&#39;.
 Check privilege when running create user statement.
 Add a session variable to prevent eager aggregation.
  Fixed  Clean up pending task when close executor: fix memory leak.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 41 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-11/</link>
      <pubDate>Sat, 11 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-11/</guid>
      <description>COISF 专场|PingCAP 第 41 期 NewSQL Meetup 2017-03-11 杨建军&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Raft 的优化</title>
      <link>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 07 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</guid>
      <description>在分布式领域，为了保证数据的一致性，通常都会使用 Paxos 或者 Raft 来实现。但 Paxos 以其复杂难懂著称，相反 Raft 则是非常简单易懂，所以现在很多新兴的数据库都采用 Raft 作为其底层一致性算法，包括我们的 TiKV。
当然，Raft 虽然简单，但如果单纯的按照 Paper 的方式去实现，性能是不够的。所以还需要做很多的优化措施。本文假定用户已经熟悉并了解过 Raft 算法，所以对 Raft 不会做过多说明。
Simple Request Flow 这里首先介绍一下一次简单的 Raft 流程：
 Leader 收到 client 发送的 request。 Leader 将 request append 到自己的 log。 Leader 将对应的 log entry 发送给其他的 follower。 Leader 等待 follower 的结果，如果大多数节点提交了这个 log，则 apply。 Leader 将结果返回给 client。 Leader 继续处理下一次 request。  可以看到，上面的流程是一个典型的顺序操作，如果真的按照这样的方式来写，那性能是完全不行的。
Batch and Pipeline 首先可以做的就是 batch，大家知道，在很多情况下面，使用 batch 能明显提升性能，譬如对于 RocksDB 的写入来说，我们通常不会每次写入一个值，而是会用一个 WriteBatch 缓存一批修改，然后在整个写入。 对于 Raft 来说，Leader 可以一次收集多个 requests，然后一批发送给 Follower。当然，我们也需要有一个最大发送 size 来限制每次最多可以发送多少数据。</description>
    </item>
    
    <item>
      <title>Weekly update (February 27 ~ March 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-06-tidb-weekly/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-06-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 21 PRs in the TiDB repositories.
Added  Add metrics for related region count for a transaction.
 Record sql_mode in session context.
 Support Show Processlist.
 Add an empty Triggers table in information_schema database.
 Support ANSI_QUOTES sql_mode in parser.
 Support use wildcard as user hostname in grant statement.
 Support the MD5 builtin function.
 Support the SHA/SHA1 builtin function.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 40 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-04/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-04/</guid>
      <description>COISF 专场|PingCAP 第 40 期 NewSQL Meetup 2017-03-04 吴晓飞&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiDB 的正确使用姿势</title>
      <link>https://pingcap.com/blog-cn/how-to-use-tidb/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-use-tidb/</guid>
      <description>最近这几个月，特别是 TiDB RC1 发布后，越来越多的用户已经开始测试起来，也有很多朋友已经在生产环境中使用，我们这边也陆续的收到了很多用户的测试和使用反馈。非常感谢各位小伙伴和早期用户的厚爱，而且看了这么多场景后，也总结出了一些 TiDB 的使用实践 (其实 Spanner 的最佳实践大部分在 TiDB 中也是适用的，MySQL 最佳实践也是），也是借着 Google Cloud Spanner 发布的东风，看了一下 Spanner 官方的一些最佳实践文档，写篇文章讲讲 TiDB 以及分布式关系型数据库的一些正确的使用姿势，当然，时代也在一直发展，TiDB 也在不停的进化，这篇文章基本上只代表近期的一些观察。
 首先谈谈 Schema 设计的一些比较好的经验。由于 TiDB 是一个分布式的数据库，可能在表结构设计的时候需要考虑的事情和传统的单机数据库不太一样，需要开发者能够带着「这个表的数据会分散在不同的机器上」这个前提，才能做更好的设计。
和 Spanner 一样，TiDB 中的一张表的行（Rows）是按照主键的字节序排序的（整数类型的主键我们会使用特定的编码使其字节序和按大小排序一致），即使在 CREATE TABLE 语句中不显式的创建主键，TiDB 也会分配一个隐式的。 有四点需要记住： 1. 按照字节序的顺序扫描的效率是比较高的； 2. 连续的行大概率会存储在同一台机器的邻近位置，每次批量的读取和写入的效率会高； 3. 索引是有序的（主键也是一种索引），一行的每一列的索引都会占用一个 KV Pair，比如，某个表除了主键有 3 个索引，那么在这个表中插入一行，对应在底层存储就是 4 个 KV Pairs 的写入：数据行以及 3 个索引行。 4. 一行的数据都是存在一个 KV Pair 中，不会被切分，这点和类 BigTable 的列式存储很不一样。
表的数据在 TiDB 内部会被底层存储 TiKV 切分成很多 64M 的 Region（对应 Spanner 的 Splits 的概念），每个 Region 里面存储的都是连续的行，Region 是 TiDB 进行数据调度的单位，随着一个 Region 的数据量越来越大和时间的推移，Region 会分裂/合并，或者移动到集群中不同的物理机上，使得整个集群能够水平扩展。</description>
    </item>
    
    <item>
      <title>Weekly update (February 19 ~ February 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 39 PRs in the TiDB repositories.
Added  Support Revoke statement.
 Add rules in parser and empty implementation for unsupported builtin functions: #2667, #2677, #2679
 Support wildcard chars in username or host in Grant statement.
 Add a context arggument for distsql/kv interface: We will use the context to cancel running jobs.
 Support Create Table ... Like statement.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 39 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-02-25/</link>
      <pubDate>Sat, 25 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-02-25/</guid>
      <description>COISF 专场|PingCAP 第 39 期 NewSQL Meetup 2017-02-25 郝立飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Spanner - CAP, TrueTime and Transaction</title>
      <link>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</guid>
      <description>最近非常关注的一件事情就是 Google Spanner Cloud 的发布，这应该算是 NewSQL 又一个里程碑的事件。NewSQL 的概念应该就是在 12 年 Google Spanner 以及 F1 的论文发表之后，才开始慢慢流行，然后就开始有企业尝试根据 paper 做自己的 NewSQL，譬如国外的 CockroachDB 以及国内我们 PingCAP。
Spanner 的论文在很早就发布了，国内也有很多中文翻译，这里笔者只是想聊聊自己对 Spanner 的理解，以及 Spanner 的一些关键技术的实现，以及跟我们自己的 TiDB 的相关对比。
CAP 在分布式领域，CAP 是一个完全绕不开的东西，大家应该早就非常熟悉，这里笔者只是简单的再次说明一下：
 C：一致性，也就是通常说的线性一致性，假设在 T 时刻写入了一个值，那么在 T 之后的读取一定要能读到这个最新的值。 A：完全 100% 的可用性，也就是无论系统发生任何故障，都仍然能对外提供服务。 P：网络分区容忍性。  在分布式环境下面，P 是铁定存在的，也就是只要我们有多台机器，那么网络隔离分区就一定不可避免，所以在设计系统的时候我们就要选择到底是设计的是 AP 系统还是 CP 系统，但实际上，我们只要深入理解下 CAP，就会发现其实有时候系统设计上面没必要这么纠结，主要表现在：
 网络分区出现的概率很低，所以我们没必要去刻意去忽略 C 或者 A。多数时候，应该是一个 CA 系统。 CAP 里面的 A 是 100% 的可用性，但实际上，我们只需要提供 high availability，也就是仅仅需要满足 99.99% 或者 99.999% 等几个 9 就可以了。  Spanner 是一个 CP + HA 系统，官方文档说的可用性是优于 5 个 9 ，稍微小于 6 个 9，也就是说，Spanner 在系统出现了大的故障的情况下面，大概 31s+ 的时间就能够恢复对外提供服务，这个时间是非常短暂的，远远比很多外部的系统更加稳定。然后鉴于 Google 强大的自建网络，P 很少发生，所以 Spanner 可以算是一个 CA 系统。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Lease Read</title>
      <link>https://pingcap.com/blog-cn/lease-read/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/lease-read/</guid>
      <description>Raft log read TiKV 是一个要保证线性一致性的分布式 KV 系统，所谓线性一致性，一个简单的例子就是在 t1 的时间我们写入了一个值，那么在 t1 之后，我们的读一定能读到这个值，不可能读到 t1 之前的值。
因为 Raft 本来就是一个为了实现分布式环境下面线性一致性的算法，所以我们可以通过 Raft 非常方便的实现线性 read，也就是将任何的读请求走一次 Raft log，等这个 log 提交之后，在 apply 的时候从状态机里面读取值，我们就一定能够保证这个读取到的值是满足线性要求的。
当然，大家知道，因为每次 read 都需要走 Raft 流程，所以性能是非常的低效的，所以大家通常都不会使用。
我们知道，在 Raft 里面，节点有三个状态，leader，candidate 和 follower，任何 Raft 的写入操作都必须经过 leader，只有 leader 将对应的 raft log 复制到 majority 的节点上面，我们才会认为这一次写入是成功的。所以我们可以认为，如果当前 leader 能确定一定是 leader，那么我们就可以直接在这个 leader 上面读取数据，因为对于 leader 来说，如果确认一个 log 已经提交到了大多数节点，在 t1 的时候 apply 写入到状态机，那么在 t1 之后后面的 read 就一定能读取到这个新写入的数据。
那么如何确认 leader 在处理这次 read 的时候一定是 leader 呢？在 Raft 论文里面，提到了两种方法。</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 38 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-02-18/</link>
      <pubDate>Sat, 18 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-02-18/</guid>
      <description>COISF 专场|PingCAP 第 38 期 NewSQL Meetup 2017-02-18 刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (February 06 ~ February 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 25 PRs in the TiDB repositories.
Added  Support basic privilege framework: #2423, #2557, #2603, #2607,
 Support ALTER [COLUMN] col_name SET DEFAULT statement.
 Validate column default value when creating table.
 Support ALTER TABLE ... DROP DEFAULT statement.
 Support changing default value and comment in alter table statement.
  Fixed  Fix build on i386.
 Fix output format of prometheus interval log.</description>
    </item>
    
    <item>
      <title>Weekly update (January 23 ~ February 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-05-tidb-weekly/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 43 PRs in the TiDB repositories.
Added  Support information_schema.table_constraints.
 Support the UTC_TIMESTAMP builtin function
 Increase transaction entry count limit.
 Add logs for expensive query and big transaction: 2536, 2545, 2546
  Fixed  Fix GC lifetime metrics.
 Fix primary key name parsing.
 Fix a bug of left outer semi join.
 Fix a bug of exists sub query.</description>
    </item>
    
    <item>
      <title>Weekly update (January 09 ~ January 22, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-24-tidb-weekly/</link>
      <pubDate>Tue, 24 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-24-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 87 PRs in the TiDB repositories.
Added  Support statistic on index data
 Support file sort operator
 Add key prefix length limitation on index
 Support the TIMESTAMPDIFF built-in function.
 Support the CONV built-in function.
 Support the SUBSTR built-in function.
 Support the SIGN built-in function.
 Support the FROM_DAYS built-in function.
 Support the FIELD built-in function.</description>
    </item>
    
    <item>
      <title>TiKV 源码浅析 - PD Scheduler</title>
      <link>https://pingcap.com/blog-cn/pd-scheduler/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pd-scheduler/</guid>
      <description>在前面的文章里面，我们介绍了 PD 一些常用功能，以及它是如何跟 TiKV 进行交互的，这里，我们重点来介绍一下 PD 是如何调度 TiKV 的。
介绍 假设我们只有一个 TiKV，那么根本就无需调度了，因为数据只可能在这一台机器上面，client 也只可能跟这一个 TiKV 进行交互。但我们知道，在分布式存储领域，这样的情况不可能一直持续，因为数据量的增量一定会超过当前机器的物理存储极限，必然我们需要将一部分数据迁移到其他机器上面去。
在之前的文章里面，我们介绍过，TiKV 是通过 range 的方式将数据进行切分的。我们使用 Region 来表示一个数据 range，每个 Region 有多个副本 peer，通常为了安全，我们会使用至少三个副本。
最开始系统初始化的时候，我们只有一个 region，当数据量持续增大，超过了 Region 设置的最大 size（64MB） 阈值的时候，region 就会分裂，生成两个新的 region。region 是 PD 调度 TiKV 的基本单位。当我们新增加一个 TiKV 的时候，PD 就会将原来TiKV 里面的一些 Region 调度到这个新增的 TiKV 上面，这样就能保证整个数据均衡的分布在多个 TiKV 上面。因为一个 Region 通常是 64MB，其实将一个 Region 从一个 TiKV 移动到另一个 TiKV，数据量的变更其实不大，所以我们可以直接使用 Region 的数量来大概的做数据的平衡。譬如，现在假设有六个 TiKV，我们有一百个 region，每个 Region 三个副本 peer，总共三百个 Region peer，我们只要保证每个 TiKV 有五十个左右的 Region peer，就大概知道数据是平衡了。</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 37 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-01-14/</link>
      <pubDate>Sat, 14 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-01-14/</guid>
      <description>COISF 专场|PingCAP 第 37 期 NewSQL Meetup 2017-01-14 杨策&amp;amp;黄华超 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Placement Driver</title>
      <link>https://pingcap.com/blog-cn/placement-driver/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/placement-driver/</guid>
      <description>介绍 Placement Driver (后续以 PD 简称) 是 TiDB 里面全局中心总控节点，它负责整个集群的调度，负责全局 ID 的生成，以及全局时间戳 TSO 的生成等。PD 还保存着整个集群 TiKV 的元信息，负责给 client 提供路由功能。
作为中心总控节点，PD 通过集成 etcd ，自动的支持 auto failover，无需担心单点故障问题。同时，PD 也通过 etcd 的 raft，保证了数据的强一致性，不用担心数据丢失的问题。
在架构上面，PD 所有的数据都是通过 TiKV 主动上报获知的。同时，PD 对整个 TiKV 集群的调度等操作，也只会在 TiKV 发送 heartbeat 命令的结果里面返回相关的命令，让 TiKV 自行去处理，而不是主动去给 TiKV 发命令。这样设计上面就非常简单，我们完全可以认为 PD 是一个无状态的服务（当然，PD 仍然会将一些信息持久化到 etcd），所有的操作都是被动触发，即使 PD 挂掉，新选出的 PD leader 也能立刻对外服务，无需考虑任何之前的中间状态。
初始化 PD 集成了 etcd，所以通常，我们需要启动至少三个副本，才能保证数据的安全。现阶段 PD 有集群启动方式，initial-cluster 的静态方式以及 join 的动态方式。
在继续之前，我们需要了解下 etcd 的端口，在 etcd 里面，默认要监听 2379 和 2380 两个端口。2379 主要是 etcd 用来处理外部请求用的，而 2380 则是 etcd peer 之间相互通信用的。</description>
    </item>
    
    <item>
      <title>Weekly update (January 02 ~ January 08, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-08-tidb-weekly/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 38 PRs in the TiDB repositories.
Added  Add nested loop join.
 Support the UNIX_TIMESTAMP built-in function.
 Support the INTERVAL built-in function.
 Support the FIND_IN_SET built-in function.
 Support the DATEDIFF built-in function.
 Enable pushing down IF expr to TiKV coprocessor
  Fixed  In prepared statement, limit and offset could be parameter marker.
 When creating table, index option could be a list.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 36 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-01-07/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-01-07/</guid>
      <description>COISF 专场|PingCAP 第 36 期 NewSQL Meetup 2017-01-07 蔡杰明&amp;amp;袁进辉 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>About the TiDB Source Code</title>
      <link>https://pingcap.com/blog/2017-01-06-about-the-tidb-source-code/</link>
      <pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-01-06-about-the-tidb-source-code/</guid>
      <description>The target audience of this document is the contributors in the TiDB community. The document aims to help them understand the TiDB project. It covers the system architecture, the code structure, and the execution process.
Table of content  System architecture Overview of the code structure The protocol layer The SQL layer The optimizer The executor The distributed executor  System architecture As is shown in the architecture diagram, the TiDB Server is between the Load Balancer (or Application) and the storage engine layer at the bottom.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - multi-raft 设计与实现</title>
      <link>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</guid>
      <description>概述 本文档主要面向 TiKV 社区开发者，主要介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读文档之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本文档并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。
Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。
Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。
Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region 会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>Weekly update (December 26 ~ January 01, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-01-tidb-weekly/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-01-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Support the CHAR_LENGTH built-in function.
 Support the CRC32 built-in function.
 Support the LEAST built-in function.
  Fixed  Fix a bug in Add Column with invalid default value.
 Fix a bug about parsing string to float.
 Fix a bug when using int and uint as join key.
 Fix a bug in MySQL Protocol layer about prepared statement.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - 如何使用 Raft</title>
      <link>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</guid>
      <description>本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本系列文章并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
 架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。 Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。 Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。 Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>Weekly update (December 19 ~ December 25, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-26-tidb-weekly/</guid>
      <description>New Release TiDB RC1 is released!
Weekly update in TiDB Last week, we landed 34 PRs in the TiDB repositories.
Added  Support the RPAD built-in function..
 Support the show keys from table from database statement.
  Fixed  Retry infinite times if the commit primary key times out.
 Do not push aggregation down to the memory tables.
 Fix a bug about the alter table statement.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 35 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-24/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-24/</guid>
      <description>COISF 专场|PingCAP 第 35 期 NewSQL Meetup 2016-12-24 张頔&amp;amp;黄梦龙 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Adding Built-in Functions</title>
      <link>https://pingcap.com/blog/2016-12-19-adding-built-in-function/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-12-19-adding-built-in-function/</guid>
      <description>This document describes how to add built-in functions to TiDB.
 Background The procedure to add a built-in function Example  Background How is the SQL statement executed in TiDB?
The SQL statement is parsed to an abstract syntax tree (AST) by the parser first and then uses Query Optimizer to generate an execution plan. The plan can then be executed to get the result. This process involves how to access the data in the table, and how to filter, calculate, sort, aggregate, and distinct the data, etc.</description>
    </item>
    
    <item>
      <title>Weekly update (December 12 ~ December 18, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-19-tidb-weekly/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-19-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 32 PRs in the TiDB repositories.
Added  Add the FlagIgnoreTruncate/FlagTruncateAsWarning flag to control the behavior of truncated errors.
 Add the prompt text flag.
 Add the rawkv metrics to profile the rawkv API performance.
 Add a comparable varint encoding/decoding method to make encoded data smaller.
 Support the timediff built-in function.
 Support the following built-in functions: ln(), log(), log2(), log10().</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 34 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-17/</link>
      <pubDate>Sat, 17 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-17/</guid>
      <description>COISF 专场|PingCAP 第 34 期 NewSQL Meetup 2016-12-17 覃左言&amp;amp;申砾 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (December 05 ~ December 11, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 41 PRs in the TiDB repositories.
Added  Support the built-in function: str_to_date. 
 Support built-in function schema().
 Support pushing the case-when expression to TiKV.
 Support changing the type and name of a column.
 Add the `session_variablesandplugins` of memory table to infoschema.
 Make the union all operator run parallelly.
 Support explaining the union statement.
  Fixed  A bug that causes infinite loop.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 33 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-10/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-10/</guid>
      <description>COISF 专场|PingCAP 第 33 期 NewSQL Meetup 2016-12-10 王康&amp;amp;李康 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Subquery Optimization in TiDB</title>
      <link>https://pingcap.com/blog/2016-12-07-Subquery-Optimization-in-TiDB/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-12-07-Subquery-Optimization-in-TiDB/</guid>
      <description>MathJax.Hub.Config({ extensions: [&#34;tex2jax.js&#34;], jax: [&#34;input/TeX&#34;, &#34;output/HTML-CSS&#34;], tex2jax: { inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&#34;\\(&#34;,&#34;\\)&#34;] ], displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&#34;\\[&#34;,&#34;\\]&#34;] ], processEscapes: true }, &#34;HTML-CSS&#34;: { availableFonts: [&#34;TeX&#34;] } });    Introduction to subqueries Subquery is a query within another SQL query. A common subquery is embedded within the FROM clause, for example：
SELECT ID FROM (SELECT * FROM SRC) AS T The subexpressions in the FROM clauses can be processed very well by the general SQL optimizers.</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 信心的毁灭与重建</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-3/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-3/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为下篇。
 -接中篇- ScyllaDB 有一个开源的东西，是专门用来给文件系统做 Failure Injection 的, 名字叫做 CharybdeFS。如果你想测试你的系统，就是文件系统在哪不断出问题，比如说写磁盘失败了，驱动程序分配内存失败了，文件已经存在等等，它都可以测模拟出来。
CharybdeFS: A new fault-injecting file system for software testing
Simulate the following errors:
 disk IO error (EIO) driver out of memory error (ENOMEM) file already exists (EEXIST) disk quota exceeded (EDQUOT)  再来看看 Cloudera，下图是整个 Cloudera 的一个 Failure Injection 的结构。
一边是 Tools，一边是它的整个的 Level 划分。比如说整个 Cluster， Cluster 上面有很多 Host，Host 上面又跑了各种 Service，整个系统主要用于测试 HDFS， HDFS 也是很努力的在做有效的测试。然后每个机器上部署一个 AgenTEST，就用来注射那些可能出现的错误。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——信心的毁灭与重建</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-07/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-07/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Weekly update (November 28 ~ December 04, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories and 6 PRs in the TiDB docs repositories.
Added  Support the built-in function: str_to_date. 
 Refactor the time structure: Introduce a TimeInternal interface to replace the go time representation.
 Add the raw Key-Value API  and make TiKV a raw Key-Value engine.
 Add a bench tool for the raw Key-Value API.</description>
    </item>
    
    <item>
      <title>【现场】COISF 专场 Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-03/</link>
      <pubDate>Sat, 03 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-03/</guid>
      <description>【现场】COISF 专场 Meetup 2016-12-03 COISF PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
COISF Meetup
今天是一期人数爆满的 Meetup。😊 作为 COISF 专场，感谢众多小伙伴与我们一起见证 COISF 的首次亮相。当然，
首场参与是一定会有福利滴。这一期，我们邀请到了一位女神级讲师&amp;ndash;
百度网页搜索部工程师
雷丽媛，为大家讲解
百度文件系统的架构设计；
另外，PingCAP 联合创始人崔秋也有出台，为大家深情
回顾 TiDB 的发展历程 :)
▌开场：COISF Opening Talk
在本环节中，PingCAP
Co-Founde
r 崔秋，百度搜索基础架构团队技术负责人颜世光，以及奇虎 360 基础架构组存储负责人陈宗志
共同为大家介绍了 COISF 的由来和使命，并对目前基金会内的顶级项目进行了简单介绍。
COISF（China Open Infrastructure Software Foundation ）：
中国开放基础软件基金会，其核心技术委员会由 PingCAP、百度、奇虎 360、小米（排名不分先后）等公司的基础软件项目团队组成，致力于促进和发展中国的新一代开源基础软件。目前基金会项目包括：Baidu/BFS、Baidu/Tera、PingCAP/TiDB、PingCAP/TiKV、Qihoo360/Zeppelin 等。
我们认为，一方面开源是软件开发的未来，能更好地促进创新与合作；另一方面未来几十年中国的基础软件必将蓬勃发展，并在世界范围内扮演重要角色。但当前国内有很多优秀的开源软件, 因为文化和语言的藩篱没能融入西方社区, 无法获得足够的关注与支持，导致发展缓慢。我们通过建设中国统一的基础软件开发社区，甄选优秀的项目加入，集中优势资源促进这些项目的快速发展与成熟。
COISF 的使命是：促进中国下一代开源基础软件生态系统的发展。
▌Topic 1
：百度文件系统－面向实时应用的分布式文件系统</description>
    </item>
    
    <item>
      <title>Weekly update (November 21 ~ November 27, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-28-tidb-weekly/</link>
      <pubDate>Mon, 28 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-28-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 44 PRs in the TiDB repositories and 3 PRs in the TiDB docs repositories.
Added  Support creating anonymous index.
 Add the mailing list for TiDB users.
 Support the show events syntax.
  Fixed  Enlarge the Time To Live (TTL)for large transactions.
 Parse float literal using the decimal parser.
 Prevent panic for malformed packets.
 Fix the behavior in the aggregate operator: for the select a, c from t groupby t.</description>
    </item>
    
    <item>
      <title>PingCAP 第 31 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-26/</link>
      <pubDate>Sat, 26 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-26/</guid>
      <description>PingCAP 第 31 期 NewSQL Meetup 2016-11-26 黄华超&amp;amp;邓栓 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 31 期 Meetup，
主题是黄华超分
享的《PD 的实现和演进》以及邓栓分享的《从容器和微服务的发展看基础架构变迁》。
▌Topic 1：
PD 的实现和演进
Lecturer：
黄华超，PingCAP 工程师，曾就职于微信、好赞科技，从事分布式存储相关工作，现负责 PingCAP PD 研发工作。
Content：
本次分享首先介绍了 PD 在 TiDB 集群的作用，以及集群是如何动态扩容缩容的。然后分别讲解了 PD 的各个功能是如何实现的，其中，着重分享了集群调度的相关设计和思考，以及新的标签调度功能。
▌Topic 2
：从容器和微服务的发展看基础架构变迁
Lecturer：
邓栓（Tennix），Rust 中文社区管理员，PingCAP SRE 工程师，负责 TiDB 与 Kubernetes 一体化整合部署方案。
Content：
近些年来容器和微服务的概念变得特别火热，越来越多的互联网公司开始尝试将以前的单体服务迁移到微服务，并且在实践中使用容器来部署服务，容器和微服务也催生了 DevOps，CaaS，Immutable infrastructure，Service orchestration 等概念。今天主要从容器和微服务角度谈了新技术应用和实践给开发者带来了哪些便利和挑战，基础架构发生了哪些改变，并尝试探讨了未来的应用服务会是什么样的架构。</description>
    </item>
    
    <item>
      <title>Percolator 和 TiDB 事务算法</title>
      <link>https://pingcap.com/blog-cn/percolator-and-txn/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/percolator-and-txn/</guid>
      <description>本文先概括的讲一下 Google Percolator 的大致流程。Percolator 是 Google 的上一代分布式事务解决方案，构建在 BigTable 之上，在 Google 内部 用于网页索引更新的业务，原始的论文在此。原理比较简单，总体来说就是一个经过优化的二阶段提交的实现，进行了一个二级锁的优化。TiDB 的事务模型沿用了 Percolator 的事务模型。 总体的流程如下：
读写事务 1) 事务提交前，在客户端 buffer 所有的 update/delete 操作。 2) Prewrite 阶段:
首先在所有行的写操作中选出一个作为 primary，其他的为 secondaries。
PrewritePrimary: 对 primaryRow 写入 L 列(上锁)，L 列中记录本次事务的开始时间戳。写入 L 列前会检查:
 是否已经有别的客户端已经上锁 (Locking)。 是否在本次事务开始时间之后，检查 W 列，是否有更新 [startTs, +Inf) 的写操作已经提交 (Conflict)。  在这两种种情况下会返回事务冲突。否则，就成功上锁。将行的内容写入 row 中，时间戳设置为 startTs。
将 primaryRow 的锁上好了以后，进行 secondaries 的 prewrite 流程:
 类似 primaryRow 的上锁流程，只不过锁的内容为事务开始时间及 primaryRow 的 Lock 的信息。 检查的事项同 primaryRow 的一致。  当锁成功写入后，写入 row，时间戳设置为 startTs。</description>
    </item>
    
    <item>
      <title>TiKV 的 MVCC（Multi-Version Concurrency Control）机制</title>
      <link>https://pingcap.com/blog-cn/mvcc-in-tikv/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mvcc-in-tikv/</guid>
      <description>并发控制简介 事务隔离在数据库系统中有着非常重要的作用，因为对于用户来说数据库必须提供这样一个“假象”：当前只有这么一个用户连接到了数据库中，这样可以减轻应用层的开发难度。但是，对于数据库系统来说，因为同一时间可能会存在很多用户连接，那么许多并发问题，比如数据竞争（data race），就必须解决。在这样的背景下，数据库管理系统（简称 DBMS）就必须保证并发操作产生的结果是安全的，通过可串行化（serializability）来保证。
虽然 Serilizability 是一个非常棒的概念，但是很难能够有效的实现。一个经典的方法就是使用一种两段锁（2PL）。通过 2PL，DBMS 可以维护读写锁来保证可能产生冲突的事务按照一个良好的次序（well-defined) 执行，这样就可以保证 Serializability。但是，这种通过锁的方式也有一些缺点：
 读锁和写锁会相互阻滞（block）。 大部分事务都是只读（read-only）的，所以从事务序列（transaction-ordering）的角度来看是无害的。如果使用基于锁的隔离机制，而且如果有一段很长的读事务的话，在这段时间内这个对象就无法被改写，后面的事务就会被阻塞直到这个事务完成。这种机制对于并发性能来说影响很大。  多版本并发控制（Multi-Version Concurrency Control，以下简称 MVCC） 以一种优雅的方式来解决这个问题。在 MVCC 中，每当想要更改或者删除某个数据对象时，DBMS 不会在原地去删除或这修改这个已有的数据对象本身，而是创建一个该数据对象的新的版本，这样的话同时并发的读取操作仍旧可以读取老版本的数据，而写操作就可以同时进行。这个模式的好处在于，可以让读取操作不再阻塞，事实上根本就不需要锁。这是一种非常诱人的特型，以至于在很多主流的数据库中都采用了 MVCC 的实现，比如说 PostgreSQL，Oracle，Microsoft SQL Server 等。
TiKV 中的 MVCC 让我们深入到 TiKV 中的 MVCC，了解 MVCC 在 TiKV 中是如何 实现 的。
1. Timestamp Oracle(TSO) 因为TiKV 是一个分布式的储存系统，它需要一个全球性的授时服务，下文都称作 TSO（Timestamp Oracle），来分配一个单调递增的时间戳。 这样的功能在 TiKV 中是由 PD 提供的，在 Google 的 Spanner 中是由多个原子钟和 GPS 来提供的。
2. Storage 从源码结构上来看，想要深入理解 TiKV 中的 MVCC 部分，src/storage 是一个非常好的入手点。 Storage 是实际上接受外部命令的结构体。</description>
    </item>
    
    <item>
      <title>Weekly update (November 14 ~ November 20, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-21-tidb-weekly/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-21-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories, 3 PRs in the TiDB docs repositories.
Added  Add a session variable to skip unique constraint check: This could be used when migrating data.
 More metrics for statement counter.
  Fixed  Use reserved keywords as the table/column name.
 Add missing comments in the show table status result.
 Fix a bug that gets duplicate auto_inc ID after truncating table.</description>
    </item>
    
    <item>
      <title>解析 TiDB 在线数据同步工具 Syncer</title>
      <link>https://pingcap.com/blog-cn/tidb-syncer/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-syncer/</guid>
      <description>TiDB 是一个完全分布式的关系型数据库，从诞生的第一天起，我们就想让它来兼容 MySQL 语法，希望让原有的 MySQL 用户 (不管是单机的 MySQL，还是多机的 MySQL Sharding) 都可以在基本不修改代码的情况下，除了可以保留原有的 SQL 和 ACID 事务之外，还可以享受到分布式带来的高并发，高吞吐和 MPP 的高性能。
对于用户来说，简单易用是他们试用的最基本要求，得益于社区和 PingCAP 小伙伴们的努力，我们提供基于 Binary 和 基于 Kubernetes 的两种不同的一键部署方案来让用户可以在几分钟就可以部署起来一个分布式的 TiDB 集群，从而快速地进行体验。 当然，对于用户来说，最好的体验方式就是从原有的 MySQL 数据库同步一份数据镜像到 TiDB 来进行对于对比测试，不仅简单直观，而且也足够有说服力。实际上，我们已经提供了一整套的工具来辅助用户在线做数据同步，具体的可以参考我们之前的一篇文章：TiDB 作为 MySQL Slave 实现实时数据同步, 这里就不再展开了。后来有很多社区的朋友特别想了解其中关键的 Syncer 组件的技术实现细节，于是就有了这篇文章。
首先我们看下 Syncer 的整体架构图, 对于 Syncer 的作用和定位有一个直观的印象。
从整体的架构可以看到，Syncer 主要是通过把自己注册为一个 MySQL Slave 的方式，和 MySQL Master 进行通信，然后不断读取 MySQL Binlog，进行 Binlog Event 解析，规则过滤和数据同步。从工程的复杂度上来看，相对来说还是非常简单的，相对麻烦的地方主要是 Binlog Event 解析和各种异常处理，也是容易掉坑的地方。
为了完整地解释 Syncer 的在线同步实现，我们需要有一些额外的内容需要了解。
###MySQL Replication 我们先看看 MySQL 原生的 Replication 复制方案，其实原理上也很简单：</description>
    </item>
    
    <item>
      <title>通过 raft 的 leader lease 来解决集群脑裂时的 stale read 问题</title>
      <link>https://pingcap.com/blog-cn/stale-read/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/stale-read/</guid>
      <description>问题： 当 raft group 发生脑裂的情况下，老的 raft leader 可能在一段时间内并不知道新的 leader 已经被选举出来，这时候客户端在老的 leader 上可能会读取出陈旧的数据（stale read）。 比如，我们假想一个拥有 5 个节点的 raft group:
其中 Node 5 是当前的 raft leader，当出现网络分区时，在 Node 5 的 raft lease 任期还没结束的一段时间内，Node 5 仍然认为自己是当前 term 的 leader，但是此时，另外一边分区已经在新的 term 中选出了新的 leader。
如果此时，客户端在新的 leader 上更新了某个值 x，此时是可以更新成功的（因为还是可以复制到多数派）。但是在分区的另一端，此时一个客户端去读取 x 的值，Node 5 还会返回老的值，这样就发生了 stale read。
解决方案
引入一个新的概念, region leader。region leader 是一个逻辑上的概念, 任意时刻对于某一个 region 来说, 一定只拥有一个 region leader, 每个 region leader 在任期之内尝试每隔 t 时间间隔, 在 raft group 内部更新一下 region leader 的 lease.</description>
    </item>
    
    <item>
      <title>PingCAP 第 30 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-19/</link>
      <pubDate>Sat, 19 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-19/</guid>
      <description>PingCAP 第 30 期 NewSQL Meetup 2016-11-19 刘锦龙&amp;amp;刘寅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 30 期 Meetup，
主题是墨迹天气气象算法负责人刘锦龙分享的《深度学习，众包数据与短时临近预报系统》以及刘寅分享的《谈谈 TiDB-Binlog 的设计》。
▌Topic 1：深度学习，众包数据与短时临近预报系统
Lecturer：
刘锦龙，北大理论物理博士，墨迹天气气象算法负责人，负责墨迹相关天气预测算法的研发工作，主要方向为机器学习和深度学习。
Content：
深入介绍如何将深度学习的最新技术用于革新传统气象预测的一些研究和应用，以及如何处理从用户获取的众包反馈数据并进而改进天气预报的精准度。
▌Topic 2：
谈谈 TiDB-Binlog 的设计
Lecturer：
刘寅，PingCAP engineer，现负责 TiDB 商业产品开发和自动化运维。
Content：
随着
TiDB
的不断稳定和完善
，
我们也逐步开发了很多
TiDB
周边工具。今天主要介绍了
TiDB-Binlog
设计上的一些考量和实现细节。
TiDB-Binlog 可
实时记录
TiDB
的一切数据变化
，
可以用来做集群的实时备份和恢复
，</description>
    </item>
    
    <item>
      <title>MVCC in TiKV</title>
      <link>https://pingcap.com/blog/2016-11-17-mvcc-in-tikv/</link>
      <pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-17-mvcc-in-tikv/</guid>
      <description>Introduction to concurrency control Transaction isolation is important for database management system. Because database should provide an illusion that the user is the only one who connects to the database, which greatly simplifies application development. But, the concurrency controlling problems like data races must be resolved since there will be a lot of connections to the database. Due to this background, the database management system (DBMS) ensures that the resulting concurrent access patterns are safe, ideally by serializablity.</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/blog-cn/mpp-smp-tidb/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mpp-smp-tidb/</guid>
      <description>今天主要是想把我们 TiDB 做 SQL 性能优化的一些经验和一些思考，就此跟大家探讨一下。题目写的比较大，但是内容还是比较简单。我们做 TiDB 的 SQL 层时，一开始做的很简单，就是通过最简单的 KV 接口(Get/Set/Seek)去存数据、取数据，做一些非常直白、简单的计算。然而后来我们发现，这个方案在性能上不可接受，可能行不通，我们就重新思考了这个事情。
TiDB 的目标是做一个 NewSQL 的 database ，什么是 NewSQL？从 Wikipedia 上我们看到 NewSQL 的定义『NewSQL is a class of modern relational database management systems that seek to provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system.』。首先NewSQL Database 需要能存储海量数据，这点就像一些 NoSQL 数据库一样。然后，能够提供事务的功能。所以 NewSQL 中的计算，主要有两个特点。第一个，就是数据是海量的，这跟 MySQL 传统数据有可能不一样，他们当然可以通过一些 sharding 的方式来进行处理，但是 sharding 之后会损失，比如说你不能跨节点做 Join，没有跨节点事务等。二是，在海量数据情况下，我们还需要对数据进行随时的取用，因为数据存在那，你算不出来就是对用户没有价值、没有意义的，所以我们需要在海量数据的前提下，能够随时把它计算出来。</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-15/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-15/</guid>
      <description>MPP and SMP in TiDB 原创
2016-11-15 申砾 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Travelling Back in Time and Reclaiming the Lost Treasures</title>
      <link>https://pingcap.com/blog/2016-11-15-Travelling-Back-in-Time-and-Reclaiming-the-Lost-Treasures/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-15-Travelling-Back-in-Time-and-Reclaiming-the-Lost-Treasures/</guid>
      <description>About the History Read feature in TiDB Data is the core and is a matter of life and death for every business. So ensuring the data safety is the top priority of every database. From a macro point of view, the safety of data is not only about whether a database is stable enough that no data is lost, but also about whether a sufficient and convenient solution is in place when data is lost because of the business or human errors, for example, to solve the anti-cheat problem in the game industry or to meet the audit requirements in the financing business.</description>
    </item>
    
    <item>
      <title>Weekly update (November 07 ~ November 13, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-14-tidb-weekly/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-14-tidb-weekly/</guid>
      <description>Last week, we landed 25 PRs in the TiDB repositories and 5 PRs in the TiDB docs repositories.
Weekly update in TiDB Added  Support the Alter table modify column statement.
 Support the Drop view statement: parsed but ignored.
 Add metrics for the transaction size.
 A tool for testing the SQL performance.
  Fixed  A bug in the show create table statement.
 A few bugs in optimizer: #1962, #1963, #1966, #1975, #1977.</description>
    </item>
    
    <item>
      <title>PingCAP 第 29 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-12/</link>
      <pubDate>Sat, 12 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-12/</guid>
      <description>PingCAP 第 29 期 NewSQL Meetup 2016-11-12 王振涛&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 29 期 Meetup，主题是映客服务端架构师王振涛分享的《映客直播服务端架构优化之路》以及张金鹏分享的《MySQL 与 TiDB 的事务机制》。
▌ ****
T
o
pic 1：映客直播服务端架构优化之路
Lecture：
王振涛，南开大学计算机硕士毕业，曾先后供职于腾讯、搜狗等互联网公司，拥有多年的服务端研发、面向服务体系结构设计经验，专注于解决海量数据存储和计算带来的分布式、高并发、强一致性等技术难题和挑战。2016 年初加入映客直播，担任服务端架构师，主要负责映客基础平台架构设计、评审和用户体系的研发工作，经历了映客业务快速发展、构建高可用大容量基础服务体系的过程，对分布式计算、微服务、分布式数据库架构、高可用高并发系统设计等方面都有较深刻的理解和实践经验。
Content：
1、介绍了映客服务端架构演进历程；
2、关于服务端技术选型的探索和思考；
3、移动直播典型应用场景分析。
▌ ****
T
o
pi
c 2：MySQL 与 TiDB 的事务机制
Lecture：
张金鹏，PingCAP 核心成员，前百度资深研发工程师／京东数据库专家，《MariaDB 原理和实现》作者。
Content：
在 MySQL 的 InnoDB 存储引擎中，进行写操作时，会将数据修改前的状态纪录在 Undo Log 中，一旦事务，失败利用 Undo Log 来进行回滚，保证事务的原子性。同时 InnoDB 利用 Undo Log 实现了多版本并发控制，InnoDB 的读取操作是不加锁的，事务只能读取到事务开始时已提交的纪录。由于 MySQL 是单机数据库，所有很方便的纪录所有活跃的事务 ID，Purge 线程根据当前活跃的事务情况来定期清理 Undo Log 中过期版本的数据。InnoDB 的事务支持 read uncommitted、read committed、repeatable read、serializable 四种事务隔离级别，InnoDB 通过 next-key lock 来解决 repeatable read 隔离级别下的幻读现象。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 错误注入</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-2/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为中篇。
 -接上篇- 当然测试可能会让你代码变得没有那么漂亮，举个例子：
这是知名的 Kubernetes 的代码，就是说它有一个 DaemonSetcontroller，这 controller 里面注入了三个测试点，比如这个地方注入了一个 handler ，你可以认为所有的注入都是 interface。比如说你写一个简单的 1+1=2 的程序，假设我们写一个计算器，这个计算器的功能就是求和，那这就很难注入错误。所以你必须要在你正确的代码里面去注入测试逻辑。再比如别人 call 你的这个 add 的 function，然后你是不是有一个 error？这个 error 的问题是它可能永远不会返回一个 error，所以你必须要人肉的注进去，然后看应用程序是不是正确的行为。说完了加法，再说我们做一个除法。除法大家知道可能有处理异常，那上面是不是能正常处理呢？上面没有，上面写着一个比如说 6 ÷ 3，然后写了一个 test，coverage 100%，但是一个除零异常，系统就崩掉了，所以这时候就需要去注入错误。大名鼎鼎的 Kubernetes 为了测试各种异常逻辑也采用类似的方式，这个结构体不算长，大概是十几个成员，然后里面就注入了三个点，可以在里面注入错误。
那么在设计 TiDB 的时候，我们当时是怎么考虑 test 这个事情的？首先一个百万级的 test 不可能由人肉来写，也就是说你如果重新定义一个自己的所谓的 SQL 语法，或者一个 query language，那这个时候你需要构建百万级的 test，即使全公司去写，写个两年都不够，所以这个事情显然是不靠谱的。但是除非说我的 query language 特别简单，比如像 MongoDB 早期的那种，那我一个“大于多少”的这种，或者 equal 这种条件查询特别简单的，那你确实是不需要构建这种百万级的 test。但是如果做一个 SQL 的 database 的话，那是需要构建这种非常非常复杂的 test 的。这时候这个 test 又不能全公司的人写个两年，对吧？所以有什么好办法呢？MySQL 兼容的各种系统都是可以用来 test 的，所以我们当时兼容 MySQL 协议，那意味着我们能够取得大量的 MySQL test。不知道有没有人统计过 MySQL 有多少个 test，产品级的 test 很吓人的，千万级。然后还有很多 ORM， 支持 MySQL 的各种应用都有自己的测试。大家知道，每个语言都会 build 自己的 ORM，然后甚至是一个语言的 ORM 都有好几个。比如说对于 MySQL 可能有排第一的、排第二的，那我们可以把这些全拿过来用来测试我们的系统。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——错误注入</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-10/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Deep Dive into TiKV</title>
      <link>https://pingcap.com/blog/2016-11-09-Deep-Dive-into-TiKV/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-09-Deep-Dive-into-TiKV/</guid>
      <description>Table of Content  About TiKV Architecture Protocol Raft Placement Driver (PD) Transaction Coprocessor Key processes analysis  Key-Value operation Membership Change Split   About TiKV TiKV (The pronunciation is: /&amp;lsquo;taɪkeɪvi:/ tai-K-V, etymology: titanium) is a distributed Key-Value database which is based on the design of Google Spanner, F1, and HBase, but it is much simpler without dependency on any distributed file system.
Architecture  Placement Driver (PD): PD is the brain of the TiKV system which manages the metadata about Nodes, Stores, Regions mapping, and makes decisions for data placement and load balancing.</description>
    </item>
    
    <item>
      <title>Weekly update (October 31 ~ November 06, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-07-tidb-weekly/</link>
      <pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-07-tidb-weekly/</guid>
      <description>Weekly update (October 31 ~ November 06, 2016) Last week, we landed 42 PRs in the TiDB repositories and 29 PRs in the TiKV repositories.
New release TiDB Beta 4 Weekly update in TiDB Added  The aggregation info to the explain statement.
 Support the show processlist syntax. TiDB supports mydumper now.
 Support the show create database statement.
 Support the buildin function from_unixtime.
 Push down the aggregation operator to the position before join.</description>
    </item>
    
    <item>
      <title>PingCAP 第 28 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-05/</link>
      <pubDate>Sat, 05 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-05/</guid>
      <description>PingCAP 第 28 期 NewSQL Meetup 2016-11-05 时延军&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第
28 期 Meetup，主题是 TalkingData 数据经理时延军分享的《Spark 架构设计要点剖析》以及韩飞分享的《Performing group-by before join》。
▌ ****
T
opi
c 1：Spark 架构设计要点剖析
Lecture：
时延军，TalkingData 数据经理，负责领域工程数据平台架构和研发，曾在 COMODO 中国负责基础数据平台建设，在车语传媒考拉 FM 负责后端数据平台架构（支持离线+实时分析处理）。推崇工程师文化，热爱开源，乐于分享，兴趣广泛，熟悉大数据技术生态，擅长软件系统架构、分布式计算系统设计。
Content：
1、RDD 特性，RDD 是如何抽象数据集的；
2、详解 Spark 基本架构；
3、Spark 内部核心组件及其交互；
4、逻辑执行计划与物理执行计划；
5、Spark 资源管理与任务调度。
▌ ****
T
opic
2：Performing group-by before join</description>
    </item>
    
    <item>
      <title>TiDB 作为 MySQL Slave 实现实时数据同步</title>
      <link>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</guid>
      <description>由于 TiDB 本身兼容绝大多数的 MySQL 语法，所以对于绝大多数业务来说，最安全的切换数据库方式就是将 TiDB 作为现有数据库的从库接在主 MySQL 库的后方，这样对业务方实现完全没有侵入性下使用 TiDB 对现有的业务进行备份，应对未来数据量或者并发量增长带来的单点故障风险，如需上线 TiDB，也只需要简单的将业务的主 MySQL 地址指向 TiDB 即可。
下面我们详细介绍了如何将 MySQL 的数据迁移到 TiDB，并将 TiDB 作为 MySQL 的 Slave 进行数据同步。
这里我们假定 MySQL 以及 TiDB 服务信息如下:
+------------------+-------------+----------------------------------------+ | Name | Address | Port | User | Password | +------------------+-------------+----------------------------------------+ | MySQL | 127.0.0.1 | 3306 | root | | | TiDB | 127.0.0.1 | 4000 | root | | +------------------+-------------+--------+-----------+-------------------+ 使用 checker 进行 Schema 检查 在迁移之前，我们可以使用 TiDB 的 checker 工具，checker 是我们开发的一个小工具，用于检测目标 MySQL 库中的表的表结构是否支持无缝的迁移到 TiDB，TiDB 支持绝大多数的 MySQL 常用的原生数据类型，所以大多数情况 checker 的返回应该是 ok。如果 check 某个 table schema 失败，表明 TiDB 当前并不支持，我们不能对该 table 里面的数据进行迁移。checker 包含在 TiDB 工具集里面，我们可以直接下载。</description>
    </item>
    
    <item>
      <title>How to write a good commit message</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-01/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-01/</guid>
      <description>How to write a good commit message 原创
2016-11-01 金坤 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 理念</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-1/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-1/</guid>
      <description>本话题系列文章整理自 PingCAP NewSQL Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为上篇。
 今天主要是介绍分布式系统测试。对于 PingCAP 目前的现状来说，我们是觉得做好分布式系统测试比做一个分布式系统更难。就是你把它写出来不是最难的，把它测好才是最难的。大家肯定会觉得有这么夸张吗？那我们先从一个最简单的、每个人都会写的 Hello world 开始。
A simple “Hello world” is a miracle We should walk through all of the bugs in:
 Compiler Linker VM (maybe) OS  其实这个 Hello world 能够每次都正确运行已经是一个奇迹了，为什么呢？首先，编译器得没 bug，链接器得没 bug ；然后我们可能跑在 VM 上，那 VM 还得没 bug；并且 Hello world 那还有一个 syscall，那我们还得保证操作系统没有 bug；到这还不算吧，我们还得要硬件没有 bug。所以一个最简单程序它能正常运行起来，我们要穿越巨长的一条路径，然后这个路径里面所有的东西都不能出问题，我们才能看到一个最简单的 Hello world。
但是分布式系统里面呢，就更加复杂了。比如大家现在用的很典型的微服务。假设你提供了一个微服务，然后在微服务提供的功能就是输出一个 Hello world ，然后让别人来 Call。
A RPC “Hello world” is a miracle We should walk through all of the bugs in:</description>
    </item>
    
    <item>
      <title>Weekly update (October 24 ~ October 30, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-31-tidb-weekly/</link>
      <pubDate>Mon, 31 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-31-tidb-weekly/</guid>
      <description>Weekly update (October 24 ~ October 30, 2016) Last week, we landed 24 PRs in the TiDB repositories and 28 PRs in the TiKV repositories.
Notable changes to TiDB  Support coalesce/case when pushing down on local storage。
 Support showing indexes in the table syntax.
 Split eval.go into some smaller files to make code cleaner.
 Fix a bug about truncating data.
 Fix the mysql version number format.</description>
    </item>
    
    <item>
      <title>PingCAP 第 27 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-29/</link>
      <pubDate>Sat, 29 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-29/</guid>
      <description>PingCAP 第 27 期 NewSQL Meetup 2016-10-29 付力力&amp;amp;刘寅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 27 期 Meetup，主题是
神策数
据联合创始人&amp;amp;首席架构师付力力分享的《Impala 在用户行为分析中的应用与优化》以及刘寅分享的《How we build CI/CD for TiDB at scale》。
▌ ****
T
opic 1
：
Impala 在用户行为分析中的应用与优化
多冷的天都不能阻止技术童鞋们浓厚的求知欲 :-D
Lecture：
付力力，神策数据联合创始人&amp;amp;首席架构师，曾任百度、豌豆荚资深研发工程师，熟悉大规模数据处理、数据仓库、OLAP 数据库等领域。
Content：
 介绍用户行为分析的典型应用场景；
 简单介绍 Impala 的架构和实现；
 使用 Impala 进行用户行为分析的基本做法；
 针对特定场景对 Impala 进行的一些优化和改造。</description>
    </item>
    
    <item>
      <title>Weekly update (October 17 ~ October 23, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-24-tidb-weekly/</link>
      <pubDate>Mon, 24 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-24-tidb-weekly/</guid>
      <description>Weekly update (October 17 ~ October 23, 2016) Last week, we landed 30 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Set the concurrency for the SQL executor using the Set statement
 Convert the Limit+Sort operator to the TopN operator on local storage
 Fix the gotouinue leak problem
 Support the logic/bitwise operator on local storage
 Support creating user without password</description>
    </item>
    
    <item>
      <title>PingCAP 第 26 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-22/</link>
      <pubDate>Sat, 22 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-22/</guid>
      <description>PingCAP 第 26 期 NewSQL Meetup 2016-10-22 张成远&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 26 期 Meetup，主题是
开源项目 speedy 作者
张成远分享的《京东分布式数据库实践》以及刘奇分享的《深度探索分布式系统测试》。 我司 CEO 亲自出台，现场不时传来三观碎一地的声音
┑(￣Д ￣)┍
另外，本周初次试水直播 (✿◡‿◡)
▌ ****
T
opic 1
：
京东分布式数据库实践
Lecture：
张成远，《Mariadb 原理与实现》作者，开源项目 speedy 作者。目前就职于京东数据库系统研发团队，负责京东分布式数据库系统架构与研发工作，主导了京东分布式数据库系统在公司的落地及大规模推广。擅长高性能服务器开发，擅长分布式数据库/存储/缓存等大规模分布式系统架构。
Content：
 介绍京东分布式数据库的设计与实现；
 介绍去 oracle 的发展历程以及遇到的一些坑；
 如何做到高效的运维监控等。
  ▌ ****
T</description>
    </item>
    
    <item>
      <title>Building a Reliable Large-Scale Distributed Database - Principles and Practice</title>
      <link>https://pingcap.com/blog-cn/talk-principles-practice/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-principles-practice/</guid>
      <description>大家好，我叫申砾，是 PingCAP Tech Leader，负责 TiDB 技术相关的工作。我曾就职网易有道、360 搜索，主要在做垂直搜索相关的事情，现在主要关注分布式计算/存储领域。过去的一年半时间我在 PingCAP 做分布式关系数据库 TiDB。目前我们的整个项目已经开源了大概一年时间，获得了不少关注。在 Github 上 Star 数量超过 5k，并且 Contributor 数量为 50+，拥有一个活跃的社区，在国内和国际上都有一定的知名度。 今天主要想和大家分享一下我们在做一款开源的分布式数据库产品过程中得到的一些经验和体会，包括技术上、产品上以及开源社区方面的内容，不会涉及太多技术上的细节。
数据库现状 近年来，随着移动互联网、物联网、人工智能等技术的兴起，我们已经进入了一个信息爆炸的大数据时代，需要处理和分析的数据越来越多，这些数据如何保存、如何应用是一个重要的问题。
传统的 SQL 数据库一般通过中间件、分库分表等方案获得 Scale 的能力。但是这些方案仍然很难做到对应用透明且保证数据均匀分布，同时也无法支持一致性的跨节点事务、JOIN 等操作。在进行扩容的时候往往需要人工介入，随着集群规模的增大，维护和扩展的复杂度呈指数级上升。
以 Google 的 BigTable 论文为开端，涌现出了一大批 NoSQL 方案。这些方案致力于解决扩展性，而牺牲一致性。如果采用 NoSQL 方案替换原有关系型数据库，往往要涉及大规模的业务重构，这相当于将数据库层的计算逻辑复杂度转嫁给业务层，同时还要损失掉事务等特性。
以上两种方案都没有完美地解决高可用的问题，跨机房多活、故障恢复、扩容经常都需要繁重的人工介入。
最近几年，人们希望有一种既有 SQL/NoSQL 的优点，又能避免他们的不足的新型数据库，于是提出了 NewSQL 的概念。Google 发布的 Spanner/F1，算是第一个真正在大规模业务上验证过的分布式数据库，向业界证明了 NewSQL 这条道路的正确性。TiDB 作为 Google Spanner/F1 的开源实现，正是业界盼望已久的 NewSQL 开源数据库。
什么是 NewSQL 并不是所有号称 NewSQL 的数据库都是 NewSQL。我们认为作为 NewSQL 数据库需要有下面几点特性：
首先是 Scale。这点上我想大家都深有体会，不管什么数据解决方案，最基本的要求就是能有足够的能力，保存用户所有的数据。
第二是事务。ACID Transaction，这个东西如果业务不需要，就感觉不到；一旦你的业务有这种需求，就能体会到它的重要性了。事实证明这个需求是广泛存在的，Google 的 BigTable 没有提供事务，结果内部很多业务都有需求，于是各个组造了一堆轮子，Jeff Dean 看不下去，出来说他最大的错误就是没有给 BigTable 提供事务。</description>
    </item>
    
    <item>
      <title>回到过去，找回遗失的珍宝 - TiDB 的历史读功能</title>
      <link>https://pingcap.com/blog-cn/time-travel/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/time-travel/</guid>
      <description>数据作为业务的核心，关系着整个业务的生死，所以对于数据库来说，数据的安全性是放在首位的，从宏观角度来看，安全性不仅仅在于的数据库本身足够稳定不会主动的丢失数据，有的时候更是对业务本身甚至人为失误造成损失是否有足够且便捷的应对方案，例如在游戏行业中经常遇到的反作弊(作弊玩家回档)问题，对于金融业务的审计需求等等，如果在数据库层面上提供相关机制，会让业务开发的工作量和复杂度减少很多。
传统的方案会定期备份数据，几天一次，甚至一天一次，把数据全量备份。当意外发生的时候，可以用来还原。但是用备份数据还原，代价还是非常大的，所有备份时间点后的数据都会丢失，你绝对不希望走到这一步。另外全量备份带来的存储和计算资源的额外开销，对于企业来说也是一笔不小的成本。
可是这种事情是无法完全避免的，我们所有的人都会犯错。对于一个快速迭代的业务，应用的代码不可能做到全面充分的测试，很可能因为应用逻辑的 Bug 导致数据写错，或者被恶意用户找到 bug，当你发现问题时，可以立即把应用回滚到旧版本，但是写错的数据却会一直留在数据库里。
出现这种问题的时候，你该怎么办？你只知道有些数据不对了，但是对的数据是什么，你不知道。如果能回到过去，找回之前的数据该多好。
TiDB 针对这样的需求和场景支持历史版本的读取，所以可以将错误的版本之前的数据取出来，将损失降到最低。
如何使用 TiDB 的历史读功能 使用这个功能非常简单，只需要执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;2016-10-10 09:30:11.123&amp;quot;
这个 session variable 的名字是 TiDB 里定义的 tidb_snapshot, 值是一个时间的字符串，精确到毫秒，执行了这个语句之后，之后这个客户端发出的所有读请求，读到的都是这个时间点看到的数据，这时是不能进行写操作的，因为历史是无法改变的。如果想退出历史读模式，读取最新数据，只需要再次执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;&amp;quot;
把 tidb_snapshot 设置成空字符串就可以了。
即使在那个历史时间点后，发生了 Schema 更改也没有关系，TiDB 会使用当时的 Schema 执行 SQL 请求。
TiDB 历史读功能和其他数据库的比较 这个功能 MySQL 并不支持，但是在其他的数据库里，比如 Oracle, PostgreSQL 里有类似的功能，叫做历史表(Temporial Table)，是一个SQL 标准。使用的方法是需要你用特殊的建表语法，额外创建一张历史表，历史表比原表多了两个系统定义的字段，代表有效时间，这多出的两个字段是系统维护的。当原表更新数据的时候，系统会把旧版本数据插入到历史表里，当你查询历史数据时，需要用一个特殊的语法指定历史时间，得到需要的结果。
TiDB 和其他数据库的历史表功能相比，主要有以下两个优势：
1，系统默认支持
如果不是默认的行为，我们通常不会特意去建一张历史表，到真正需要用到的时候，你会发现历史表没有创建。
2，使用方便
不需要额外建一张表，不需要用特殊的语法查询。
3，全局视角，而不是以表为单位
TiDB 即使执行了 Drop Table, Drop Database 这样的操作，也可以读到旧的数据。</description>
    </item>
    
    <item>
      <title>How we build TiDB</title>
      <link>https://pingcap.com/blog/2016-10-17-how-we-build-tidb/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-10-17-how-we-build-tidb/</guid>
      <description>This is the speech Max Liu gave at Percona Live Open Source Database Conference 2016. 
The slides are here.
 Speaker introduction Why another database? What to build? How to design?  The principles or the philosophy  Disaster recovery Easy to use The community and ecosystem  Loose coupling – the logical architecture The alternatives  How to develop  The architecture TiKV core technologies  TiKV software stack Placement Driver Raft MVCC Transaction  TiDB core technologies  Mapping table data to Key-Value store Predicate push-down Schema changes   How to test?</description>
    </item>
    
    <item>
      <title>Weekly update (October 01 ~ October 16, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-17-tidb-weekly/</guid>
      <description>Weekly update (October 01 ~ October 16, 2016) Last week, we landed 27 PRs in the TiDB repositories and 32 PRs in the TiKV repositories.
Notable changes to TiDB  Support projection elimination so that the executor can run faster when it is not necessary to have a projection layer.
 Write DDL binlog to file.
 Convert sort and limit to top-n in the query planning phrase.
 Support reading history data even if the schema changes.</description>
    </item>
    
    <item>
      <title>PingCAP 第 25 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-15/</link>
      <pubDate>Sat, 15 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-15/</guid>
      <description>PingCAP 第 25 期 NewSQL Meetup 2016-10-15 武毅&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 25 期 Meetup，顶着帝都的大雾霾，依然来了很多小伙伴。这一次我们有换新场地噢，但不变的是分享内容依然满满干货。本周的主题分别是
百分点
集团高级架构师武毅分享的《分布式数据处理在个性化系统的应用》以及张金鹏分享的《TiKV 性能优化》。
▌ ****
T
opic 1
：
分布式数据处理在个性化系统的应用
Lecture：
武毅，现任百分点集团高级架构师，负责大数据平台基础架构的设计与研发，曾参与个性化推荐系统等多个大型系统的设计和开发。Linux 爱好者，活跃于 GitHub，Ubuntu 等社区，重点关注分布式技术，平台技术。
Content：
相信大家也都在各自的领域用到过不同的分布式存储／计算开源工具，本周我们分享了一些在运营个性化系统时使用分布式存储／计算工具遇到的坑和经验。
▌ ****
T
opic 2
：
TiKV 性能优化
Content：
RocksDB 的 Column Families 之间会共享 WAL，但是又有各自的 memtables 和 sst files，共享 WAL 使得实现跨 CF 的 atomic 操作变成可能，不同 CF 的 memtables 和 sst files 是分离开的，这样我们可以将不同类型的数据分别存放在不同的 CF 内，根据数据的性质给 CF 定制不同配置，使数据的写入和访问达到最佳状态。</description>
    </item>
    
    <item>
      <title>How do we build TiDB</title>
      <link>https://pingcap.com/blog-cn/how-do-we-build-tidb/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-do-we-build-tidb/</guid>
      <description>首先我们聊聊 Database 的历史，在已经有这么多种数据库的背景下我们为什么要创建另外一个数据库；以及说一下现在方案遇到的困境，说一下 Google Spanner 和 F1，TiKV 和 TiDB，说一下架构的事情，在这里我们会重点聊一下 TiKV。因为我们产品的很多特性是 TiKV 提供的，比如说跨数据中心的复制，Transaction，auto-scale。
再聊一下为什么 TiKV 用 Raft 能实现所有这些重要的特性，以及 scale，MVCC 和事务模型。东西非常多，我今天不太可能把里面的技术细节都描述得特别细，因为几乎每一个话题都可以找到一篇或者是多篇论文。但讲完之后我还在这边，所以详细的技术问题大家可以单独来找我聊。
后面再说一下我们现在遇到的窘境，就是大家常规遇到的分布式方案有哪些问题，比如 MySQL Sharding。我们创建了无数 MySQL Proxy，比如官方的 MySQL proxy，Youtube 的 Vitess，淘宝的 Cobar、TDDL,以及基于 Cobar 的 MyCAT，金山的 Kingshard，360 的 Atlas，京东的 JProxy，我在豌豆荚也写了一个。可以说，随便一个大公司都会造一个MySQL Sharding的方案。
为什么我们要创建另外一个数据库？ 昨天晚上我还跟一个同学聊到，基于 MySQL 的方案它的天花板在哪里，它的天花板特别明显。有一个思路是能不能通过 MySQL 的 server 把 InnoDB 变成一个分布式数据库，听起来这个方案很完美，但是很快就会遇到天花板。因为 MySQL 生成的执行计划是个单机的，它认为整个计划的 cost 也是单机的，我读取一行和读取下一行之间的开销是很小的，比如迭代 next row 可以立刻拿到下一行。实际上在一个分布式系统里面，这是不一定的。
另外，你把数据都拿回来计算这个太慢了，很多时候我们需要把我们的 expression 或者计算过程等等运算推下去，向上返回一个最终的计算结果，这个一定要用分布式的 plan，前面控制执行计划的节点，它必须要理解下面是分布式的东西，才能生成最好的 plan，这样才能实现最高的执行效率。
比如说你做一个 sum，你是一条条拿回来加，还是让一堆机器一起算，最后给我一个结果。 例如我有 100 亿条数据分布在 10 台机器上，并行在这 10 台 机器我可能只拿到 10 个结果，如果把所有的数据每一条都拿回来，这就太慢了，完全丧失了分布式的价值。聊到 MySQL 想实现分布式，另外一个实现分布式的方案是什么，就是 Proxy。但是 Proxy 本身的天花板在那里，就是它不支持分布式的 transaction，它不支持跨节点的 join，它无法理解复杂的 plan，一个复杂的 plan 打到 Proxy 上面，Proxy 就傻了，我到底应该往哪一个节点上转发呢，如果我涉及到 subquery sql 怎么办？所以这个天花板是瞬间会到，在传统模型下面的修改，很快会达不到我们的要求。</description>
    </item>
    
    <item>
      <title>Weekly update (September 26 ~ September 30, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-30-tidb-weekly/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-30-tidb-weekly/</guid>
      <description>Weekly update (September 26 ~ September 30, 2016) Last week, we landed 17 PRs in the TiDB repositories and 13 PRs in the TiKV repositories.
Notable changes to TiDB  Make the GC alive time configurable so that users can keep the deleted data as long as they want. Add the metrics for all kinds of statements to provide more information for insights. Improve the kv package test coverage. Record the processed row count during DDL so that users can track the progress of DDL.</description>
    </item>
    
    <item>
      <title>Weekly update (September 19 ~ September 25, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-26-tidb-weekly/</guid>
      <description>Weekly update (September 19 ~ September 25, 2016) Last week, we landed 20 PRs in the TiDB repositories and 24 PRs in the TiKV repositories.
Notable changes to TiDB  Support DML binlog. Support reading the history data. Add more metrics to distsql, DDL, and store. Replace the vendor tool with glide. Improve test coverage. Code cleanup. Improve the test code by splitting a big test file into smaller files.</description>
    </item>
    
    <item>
      <title>PingCAP 第 24 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-24/</link>
      <pubDate>Sat, 24 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-24/</guid>
      <description>PingCAP 第 24 期 NewSQL Meetup 2016-09-24 杜川&amp;amp;杨哲 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 24 期 Meetup，主题是阿里云 ODPS 研发工程师杜川分享的《LLVM 简介及其在大规模 OLAP 中的应用》以及来自小米云平台的杨哲分享的《阻塞访问数据库的相关问题》。
▌ ****
T
opic 1
：LLVM 简介及其在大规模 OLAP 中的应用
Lecture：
杜川，阿里云 ODPS 研发工程师，分布式数据库爱好者，重点关注 SQL 运行时优化以及 Code Generation 技术。
Content：
LLVM 是一个开源的编译器框架及生态链，已在工业界得到广泛的应用（著名的 Clang 编译器就是基于LLVM实现的）。因其前后端分离，模块化等优势，近年来被引入数据库领域，作为 JIT Code Generation 的工具，并吸引了越来越多的关注。本次分享介绍了 LLVM，及其在大规模 OLAP 中的应用。
▌ ****</description>
    </item>
    
    <item>
      <title>Weekly update (September 12 ~ September 18, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-19-tidb-weekly/</link>
      <pubDate>Mon, 19 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-19-tidb-weekly/</guid>
      <description>Weekly update (September 12 ~ September 18, 2016) Last week, we landed 18 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Add the Prometheus metrics and support push. Support the streaming aggregation operator. Rename xapi to distsql to improve readability. Add git hash to the TiDB server status API. Improve test coverage in the abstract syntax tree (AST). Enable the division operator for the distributed SQL statements.</description>
    </item>
    
    <item>
      <title>Weekly update (September 05 ~ September 11, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-12-tidb-weekly/</guid>
      <description>Weekly update (September 05 ~ September 11, 2016) Last week, we landed 20 PRs in the TiDB repositories and 32 PRs in the TiKV repositories..
Notable changes to TiDB  Support mydumper Use MySQL standard error code in the DDL execution results Use heap sort operator to handle the statements with Limit and Orderby Add support for the CLIENT_CONNECT_ATTRS Add the constant propagation support to the SQL optimizer Optimize the index scan executor to improve the performance Optimize the distributed SQL API protocol to improve the performance Fix several bugs.</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：分布式数据库模式与反模式</title>
      <link>https://pingcap.com/blog-cn/talk-tidb-pattern/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-tidb-pattern/</guid>
      <description>我叫黄东旭，是 PingCAP 的联合创始人兼 CTO，也是本场论坛的主持人。我原来在 MSRA，后来到了网易、豌豆荚。跟在座的大部分数据分析师不太一样的是，我是一个数据库开发，虽然是 CTO，但是还在写代码。
同时，我也是一些用的比较广泛的分布式的开源软件的作者。比如说我们做的 TiDB、TiKV 这些大型的分布式关系型数据库的项目。
我们现在正在做一个 OLTP 的数据库，主要 focus 在大数据的关系型数据库的存储和可扩展性，还有关系的模型，以及在线交易型数据库上的应用。
所以，今天整个数据库的模式和反模式，我都会围绕着如何在一个海量的并发，海量的数据存储的容量上，去做在线实时的数据库业务的一些模式来讲。并从数据库的开发者角度，来为大家分享怎样写出更加适合数据库的一些程序。
基础软件的发展趋势 一开始我先简单介绍一下，现在我认为的一些基础软件上的发展趋势。
开源 第一点，开源是一个非常大的趋势。大家可以看到一些比较著名的基础软件，基本都是开源的，比如 Docker，比如 k8s。甚至在互联网公司里面用的非常多的软件，像 MySQL、Hadoop 等这种新一代的大数据处理的数据库等基础软件，也大多是开源的。其实这背后的逻辑非常简单：在未来其实你很难去将你所有的技术软件都用闭源, 因为开源会慢慢组成一个生态，而并不是被某一个公司绑定住。比如国家经常说去 IOE，为什么？很大的原因就是基本上你的业务是被基础软件绑死的，这个其实是不太好的一个事情。而且现在跟过去二十年前不一样，无论是开源软件的质量，还是社区的迭代速度，都已经是今非昔比，所以基本上开源再也不是低质低量的代名词，在互联网公司已经被验证很多次了。
分布式 第二，分布式会渐渐成为主流的趋势。这是为什么？这个其实也很好理解，因为随着数据量越来越大，大家可以看到，随着现在的硬件发展，我感觉摩尔定律有渐渐失效的趋势。所以单个节点的计算资源或者计算能力，它的增长速度是远比数据的增长速度要慢的。在这种情况下，你要完成业务，存储数据，要应对这么大的并发，只有一种办法就是横向的扩展。横向的扩展，分布式基本是唯一的出路。scale-up 和 scale-out 这两个选择其实我是坚定的站在 scale-out 这边。当然传统的关系数据库都会说我现在用的 Oracle，IBM DB2，他们现在还是在走 scale-up 的路线，但是未来我觉得 scale-out 的方向会渐渐成为主流。 碎片化
碎片化 第三，就是整个基础软件碎片化。现在看上去会越来越严重。但是回想在十年前、二十年前，大家在写程序的时候，我上面一层业务，下面一层数据库。但是现在你会发现，随着可以给你选择的东西越来越多，可以给你在开源社区里面能用到的组件越来越多，业务越来越复杂，你会发现，像缓存有一个单独的软件，比如 redis，队列又有很多可以选择的，比如说 zeromq, rabbitmq, celery 各种各样的队列；数据库有 NoSQL、HBase，关系型数据库有 MySQL 、PG 等各种各样的基础软件都可以选。但是就没有一个非常好东西能够完全解决自己的问题。所以这是一个碎片化的现状。
微服务 第四，是微服务的模式兴起。其实这个也是最近两年在软件架构领域非常火的一个概念。这个概念的背后思想，其实也是跟当年的 SOA 是一脉相承的。就是说一个大的软件项目，其实是非常难去 handle 复杂度的，当你业务变得越来越大以后，维护成本和开发成本会随着项目的代码量呈指数级别上升的。所以现在比较流行的就是，把各个业务之间拆的非常细，然后互相之间尽量做到无状态，整个系统的复杂度可以控制，是由很多比较简单的小的组件组合在一起，来对外提供服务的。
这个服务看上去非常美妙，一会儿会说有什么问题。最典型的问题就是，当你的上层业务都拆成无状态的小服务以后，你会发现原有的逻辑需要有状态的存储服务的时候你是没法拆的。我所有的业务都分成一小块，每一小块都是自己的数据库或者数据存储。比如说一个简单的 case，我每一个小部分都需要依赖同一个用户信息服务，这个信息服务会变成整个系统的一个状态集中的点，如果这个点没有办法做弹性扩展或者容量扩展的话，就会变成整个系统很致命的单点。
所以现在整个基础软件的现状，特别在互联网行业是非常典型的几个大的趋势。我觉得大概传统行业跟互联网行业整合，应该在三到五年，这么一个时间。所以互联网行业遇到的今天，可能就是传统行业，或者其他的行业会遇到的明天。所以，通过现在整个互联网里面，在数据存储、数据架构方面的一些比较新的思想，我们就能知道如何去做这个程序的设计，应对明天数据的量级。
现有存储系统的痛点 其实今天主要的内容是讲存储系统，存储系统现在有哪些痛点？其实我觉得在座的各位应该也都能切身的体会到。
弹性扩展 首先，大数据量级下你如何实现弹性扩展？因为我们今天主要讨论的是 OLTP ，是在线的存储服务，并不是离线分析的服务。所以在线的存储服务，它其实要做到的可用性、一致性，是要比离线的分析业务强得多的。但是在这种情况下，你们怎样做到业务无感知的弹性扩展，你的数据怎么很好的满足现有的高并发、大吞吐，还有数据容量的方案。
可用性 第二，在分布式的存储系统下，你的应用的可用性到底是如何去定义，如何去保证？其实这个也很好理解，因为在大规模的分布式系统里面，任何一个节点，任何一个数据中心或者支架都有可能出现硬件的故障，软件的故障，各种各样的故障，但这个时候你很多业务是并没有办法停止，或者并没有办法去容忍 Down time 的。所以在一个新的环境之下，你如何对你系统的可用性做定义和保证，这是一个新的课题。一会儿我会讲到最新的研究方向和成果。</description>
    </item>
    
    <item>
      <title>PingCAP 第 23 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-10/</link>
      <pubDate>Sat, 10 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-10/</guid>
      <description>PingCAP 第 23 期 NewSQL Meetup 2016-09-10 金坤&amp;amp;黄华超 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 23 期 Meetup，主题是金坤分享的《
How to write a good commit message
》以及黄华超分享的《QuorumKV：微信分布式 KV 存储系统》。
【T
opic 1】
How to write a good commit message
Content：
This talk about writing good commit messages aims to act as the beginning of a series of talks about writing quality technical content.</description>
    </item>
    
    <item>
      <title>Weekly update (August 29 ~ September 04, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-05-tidb-weekly/</guid>
      <description>Weekly update (August 29 ~ September 04, 2016) Last week, we landed 29 PRs in the TiDB repositories and 24 PRs in the TiKV repositories.
Notable changes to TiDB  Support the unhex and the ceiling/ceil functions Improve the Parser to handle \r\n. Solve the potential concurrency issues Support Load Data Use the Pipeline model to filter data through indexes to improve the performance Improve the code to reduce memory allocation and improve the performance Fix several bugs.</description>
    </item>
    
    <item>
      <title>PingCAP 第 22 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-03/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-03/</guid>
      <description>PingCAP 第 22 期 NewSQL Meetup 2016-09-03 宋昭&amp;amp;张帅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 22 期 Meetup，主题是
360 基础架构组研发工程师
宋昭
分享的《360 开发的大容量 redis -pika》以及 美团云工程师
张帅
分享的《分布式对象存储系统设计介绍》。
▌ ****
T
opic 1：36
0 开发的大容量 redis -pika
Lecture：
宋昭，360 基础架构组研发工程师。专注于分布式存储领域，目前负责 360 开源项目 pika 相关的设计和开发工作。
Content：
目前 pika 在 360 内部大量使用，有 300 多实例，主要解决大容量的 redis（400G,800G）场景；在外部，被微博、美团、万达电商、garena、apus 等使用于线上核心系统中。本次分享主要介绍 pika 的系统设计和实现。</description>
    </item>
    
    <item>
      <title>TiKV 事务模型概览，Google Spanner 开源实现</title>
      <link>https://pingcap.com/blog-cn/tidb-transaction-model/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-transaction-model/</guid>
      <description>随着时代的发展，应用和数据的规模越来越大。然而在这个一切都可以水平扩展的时代，你会发现，大多数应用的最下层的关系型数据库，竟然难以找到一个优雅易用的水平扩展解决方案，一直以来不得不依赖静态 Sharding ，牺牲掉事务，然后在业务层各种 Workarounds。作为后端开发者应该深有体会。
层出不穷的 NoSQL 看似解决了数据水平扩展的问题，但是由于跨行事务的缺失和接口的局限，在很多业务中落地还是需要付出很多代价的。最近 Google 基础设施的神人 Jeff Dean 在一次采访中回顾自己作为工程师最大的后悔是什么的问题时提到，他最后悔的事情是没有在 BigTable 中加入跨行事务模型，以至于后来各种各样的团队尝试在 BigTable 上不停的造事务的轮子，但其实这个特性应该是由 BigTable 提供。同样的观点也在他后来的论文中反复提到过。
Google 2012 年在 OSDI 上发表了 Spanner，作为 BigTable 的下一代产品，最主要的特性就是支持跨行事务和在分布式场景上实现 Serializable 的事务隔离级别。我们在2015年底从零开始按照论文做 Spanner 的开源实现 TiKV，于近期开源，和 Spanner 一样，也是一个支持分布式事务和水平扩展的 KV 数据库。一个分布式数据库涉及的技术面非常广泛，今天我们主要探讨的是 TiKV 的 MVCC（多版本并发控制） 和 Transaction 实现。
MVCC 其实并不是一个老的概念了，在传统的单机关系型数据库使用 MVCC 技术来规避大量的悲观锁的使用，提高并发事务的读写性能。值得注意的是 MVCC 只是一个思想，并不是某个特定的实现，它表示每条记录都有多个版本的，互相不影响，以一个 kv 数据库为例从逻辑上的一行的表示就并不是
Record := {key, value} 而是
Record := {key, value, version} 支持分布式 MVCC 在 KV 系统中比较著名的应该是在 BigTable。在 TiKV 中我们的整个事务模型是构建在一个分布式 MVCC 的基础之上：
可以看到，整个 TiKV 的底层本地存储是依赖了 RocksDB，RocksDB 是一个单机的嵌入式 KV 数据库，是一个 LSM Tree的实现，是 Facebook 基于 LevelDB 的修改版本，其特点是写入性能特别好，数据存储是有序的 KV Pairs，对于有序 key 的迭代的场景访问效率较高。</description>
    </item>
    
    <item>
      <title>Weekly update (August 22 ~ August 28, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-29-tidb-weekly/</link>
      <pubDate>Mon, 29 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-29-tidb-weekly/</guid>
      <description>Weekly update (August 22 ~ August 28, 2016) Last week, we landed 26 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Support the MySQL SetOption Command and Multiple Statements. Support filter push-down for the Time/Decimal type. Support converting OuterJoin to InnerJoin by using Null Reject. Support multiple-thread Hash Join. Support Garbage Collector. Optimize the code to improve the Performance. Fix several bugs.</description>
    </item>
    
    <item>
      <title>PingCAP 第 21 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-27/</link>
      <pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-27/</guid>
      <description>PingCAP 第 21 期 NewSQL Meetup 2016-08-27 韩飞&amp;amp;申砾 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 21 期 Meetup，主题是韩飞分享的《An Introduction to Join-Reorder in TiDB》以及申砾分享的《MPP and SMP in TiDB》。
▌ ****
Topic 1
：
An Introduction to Join-Reorder in TiDB
Content：
本次分享详细介绍了 TiDB 中 Join-Reorder 的流程。包括 Join-Reorder 的动机，outer-join 的 reorder 局限性和解决办法。为了解决某些 outer join re-association 的问题，我们可以引入的新算子 Generalized outerJoin。最后介绍了通过为 Join Query 建立 Query Graph 进行启发式搜索和动态规划的</description>
    </item>
    
    <item>
      <title>Weekly update (August 13 ~ August 21, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-22-tidb-weekly/</link>
      <pubDate>Mon, 22 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-22-tidb-weekly/</guid>
      <description>Weekly update (August 13 ~ August 21, 2016) Last week, we landed 26 PRs in the TiDB repositories and 15 PRs in the TiKV repositories.
Notable changes to TiDB  Upgrade the query optimizer. Upgrade the lexer. Replace golang protobuf with gogo protobuf. Optimize the distributed executor. Repair the Time and Decimal types to improve the compatibility with MySQL. Support the Set names binary statement. Support Covering Index. Optimize the table scanning when the condition is false constant.</description>
    </item>
    
    <item>
      <title>PingCAP 第 20 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-20/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-20/</guid>
      <description>PingCAP 第 20 期 NewSQL Meetup 2016-08-20 雷丽媛&amp;amp;温文鎏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 20 期 Meetup，主题是百度网页搜索部工程师雷丽媛分享的《搜索引擎背后的万亿量级存储系统 Tera 》以及温文鎏分享的《Cloudtable：分布式强一致的 KV 存储系统》。
【
To
pic 1
】
搜索引擎背后的万亿量级存储系统 Tera
近景福利：
今日的美女讲师 :)
Lecture：
雷丽媛，百度网页搜索部工程师。专注于分布式存储领域，目前负责百度结构化数据存储和分布式文件系统的相关工作。
Content：
介绍支撑搜索引擎核心的海量存储——Tera 的设计与实现
【 ****
Topic 2
】
Cloudtable：分布式强一致的 KV 存储系统
Content：
如何搭建一个适用于互联网公司业务的大容量分布式强一致性 KV 存储系统?
通过结合分布式一致性协议 Raft，嵌入式存储引擎 RocksDB，HBASE 的架构和接口，YY 云存储团队在过去的两年开发了 Cloudtable 存储系统，它是一个分布式强一致性的 KV 存储系统。今天，前 YY 云存储工程师温文鎏分享了他们在构建 Cloudtbable 系统的实践和经验。</description>
    </item>
    
    <item>
      <title>基于 Raft 构建弹性伸缩的存储系统的一些实践</title>
      <link>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</guid>
      <description>最近几年来，越来越多的文章介绍了 Raft 或者 Paxos 这样的分布式一致性算法，且主要集中在算法细节和日志同步方面的应用。但是呢，这些算法的潜力并不仅限于此，基于这样的分布式一致性算法构建一个完整的可弹性伸缩的高可用的大规模存储系统，是一个很新的课题，我结合我们这一年多以来在 TiKV 这样一个大规模分布式数据库上的实践，谈谈其中的一些设计和挑战。
本次分享的主要内容是如何使用 Raft 来构建一个可以「弹性伸缩」存储。其实最近这两年也有很多的文章开始关注类似 Paxos 或者 Raft 这类的分布式一致性算法，但是主要内容还是在介绍算法本身和日志复制，但是对于如何基于这样的分布式一致性算法构建一个大规模的存储系统介绍得并不多，我们目前在以 Raft 为基础去构建一个大规模的分布式数据库 TiKV ，在这方面积累了一些第一手的经验，今天和大家聊聊类似系统的设计，本次分享的内容不会涉及很多 Raft 算法的细节，大家有个 Paxos 或者 Raft 的概念，知道它们是干什么的就好。
##先聊聊 Scale 其实一个分布式存储的核心无非两点，一个是 Sharding 策略，一个是元信息存储，如何在 Sharding 的过程中保持业务的透明及一致性是一个拥有「弹性伸缩」能力的存储系统的关键。如果一个存储系统，只有静态的数据 Sharding 策略是很难进行业务透明的弹性扩展的，比如各种 MySQL 的静态路由中间件（如 Cobar）或者 Twemproxy 这样的 Redis 中间件等，这些系统都很难无缝地进行 Scale。 ##Sharding 的几种策略 在集群中的每一个物理节点都存储若干个 Sharding 单元，数据移动和均衡的单位都是 Sharding 单元。策略主要分两种，一种是 Range 另外一种是 Hash。针对不同类型的系统可以选择不同的策略，比如 HDFS 的Datanode 的数据分布就是一个很典型的例子：
###首先是 Range Range 的想法比较简单粗暴，首先假设整个数据库系统的 key 都是可排序的，这点其实还是蛮普遍的，比如 HBase 中 key 是按照字节序排序，MySQL 可以按照自增 ID 排序，其实对于一些存储引擎来说，排序其实是天然的，比如 LSM-Tree 或者 BTree 都是天然有序的。Range 的策略就是一段连续的 key 作为一个 Sharding 单元：</description>
    </item>
    
    <item>
      <title>Weekly update (August 05 ~ August 12, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-12-tidb-weekly/</link>
      <pubDate>Fri, 12 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-12-tidb-weekly/</guid>
      <description>Weekly update (August 05 ~ August 12, 2016) Last week, we landed 20 PRs in the TiDB repositories and 11 PRs in the TiKV repositories.
Notable changes to TiDB  Rewrite Lexer and improve the speed of parsing SQL texts by 40%. Add a command line flag for log output file and rotate log files regularly. Optimize the 2 phase commit process and adopt faster methods to clear locks. Optimize the execution speed of the Insert On Duplicate Update statement.</description>
    </item>
    
    <item>
      <title>TiDB 优化器实现的基础 -- 统计信息的收集</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-11/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-11/</guid>
      <description>TiDB 优化器实现的基础 &amp;ndash; 统计信息的收集 原创
2016-08-11 周昱行 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>PingCAP 第 19 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-06/</link>
      <pubDate>Sat, 06 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-06/</guid>
      <description>PingCAP 第 19 期 NewSQL Meetup 2016-08-06 方君&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 19 期 Meetup，主题是百度基础架构部工程师方君分享的《
What&amp;rsquo;s New in Spark 2.0
》以及韩飞分享 的《An Overview of Cost Based Optimization and Join Reorder》。
▌ ****
Topic 1
：What&amp;rsquo;s New in Spark 2.0
Lecture：
方君，百度基础架构部工程师，专注于分布式计算与流式计算领域，目前在百度负责 Spark 计算平台和计算表示层的相关工作。
Content:
 DataSet API Performance Optimization Structure Streaming  ▌ ****</description>
    </item>
    
    <item>
      <title>Weekly update (July 30 ~ August 05, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-05-tidb-weekly/</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-05-tidb-weekly/</guid>
      <description>Weekly update (July 30 ~ August 05, 2016) Last week, we landed 28 PRs in the TiDB repositories and 32 PRs in the TiKV repositories.
Notable changes to TiDB  Add support for constant folding in the SQL optimizer. Optimize the query speed of the secondary index. In certain scenarios, only the data in the index needs to be read. Use dynamic programing to decide the join path for multiple tables.</description>
    </item>
    
    <item>
      <title>云时代数据库的核心特点</title>
      <link>https://pingcap.com/blog-cn/cloud-native-db/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cloud-native-db/</guid>
      <description>引言 最近几年，随着云计算相关技术的发展，各种不同类型的云层出不穷，服务越来越多不同类型的企业业务，传统企业也渐渐开始探索上云的道路。在云上，作为业务最核心的数据库，相比之前的传统方案会有哪些变化呢？在正式聊云时代的数据库特点之前，我们需要了解一下目前云时代架构发生的变化。
畅想一下，未来的服务都跑在云端，任何的服务资源都可以像水电煤一样按需选购。从 IaaS 层的容器/虚拟机，到 PaaS 层的数据库，缓存和计算单元，再到 SaaS 层的不同类型的应用，我们只需要根据自身业务特点进行资源选配，再也不用担心应用服务支撑不住高速的业务增长，因为在云上一切都是弹性伸缩的。有了可靠的基础软件架构，我们就可以把更多精力放到新业务的探索，新模式的创新，就有可能产生更多不一样的新场景，从而催生更强大能力的云端服务，这是一件多么 cool 的事情。
当然，理想要一步一步实现，未来的基础软件栈到底会怎样呢？社区在这方面正在进行积极地探索，其中最有代表性的就是基于容器（以 Docker 为代表）的虚拟化技术和微服务（Microservice）。
在云时代，一切都应该是可伸缩的，使用 k8s（Kubernetes）在保证资源平衡的前提下，通过 Docker 部署我们依托于容器的微服务模块，我们不用关心服务到底跑在哪里，只需要关心我们需要多少服务资源。Docker 提供了极大的便利性，一次构建，到处运行，我们可以很好地解决开发、测试和上线的环境一致性问题。（如果不能很好地保证测试和实际上线环境的一致性，则很有可能需要花费远超过开发的时间去发现和修复问题。）k8s 更是在 Docker 构建的基础上增加了更多的云特性，包括 Docker 的升级，高可用和弹性伸缩等等。 关于 Docker/k8s 相关的讨论已经很多了，因为时间关系，关于具体的细节就不再展开。我们只需要了解，有了它，可以很轻松地解决服务的安装和部署。
下面再聊聊微服务，微服务将一个服务拆分成相对独立的更小的子服务单元，不同的子服务单元之间通过统一的接口（HTTP/RPC 等）进行数据交互。
相比于传统的解决方案，这种架构有很多的优点。
 更好的开发效率和可维护性。微服务将一个单独的服务进行更细力度的拆分，每一个子服务单元专注于更小的功能模块，可以更好地根据业务建立对应的数据模型，降低复杂度，使得开发变得更轻松，维护和部署变得更加友好. 更好的可扩展性。每个不同的子服务单元相互独立，彼此之间没有任何依赖，所以可以根据业务的具体需要，灵活地部署多个子服务单元进行水平扩展。 更强的容错性。当其中一个子服务出现故障的时候，可以通过辅助的负载均衡工具，自动路由到其他的子服务，不会影响整体服务的可用性.  当然，微服务也不是一个银弹，相对来说，这种方案会使整体系统的设计更加复杂，同时也加大了网络的延迟，对整个系统测试的复杂度也会更高。
Docker 提供的隔离型和可移植性，与微服务是一种天然的契合，微服务将整个软件进行拆分和解耦，而通过 Docker/k8s 可以很自然地做到独立的部署，高可用和容错性，似乎一切都可以完美地运转起来。但是真的是这样么？我们是不是忽略了什么？
是的，我们在讨论前面的问题的时候忽略了一个很重要的东西：状态。
从整个技术发展的角度来看，微服务是一个非常有意义的探索。每个人都期望着每个微服务的子服务都是无状态的，这样我可以自由地启停和伸缩，没有任何的心智负担，但是现实的业务情况是什么样的呢？比如一个电商网站，用户正在下单购买一件商品，此时平台是通过订单子服务的 A 应用来提供服务的，突然，因为机器故障，订单子服务的 A 应用不可用了，改由订单子服务的 B 应用提供服务，那么它是必须要知道刚才用户的订单信息的，否则正在访问自己订单页面的用户会发现自己的订单信息突然不见了。虽然我们尽量想把子服务设计成无状态的，但是很多时候状态都是不可避免的，我们不得不通过存储层保存状态，业界最主要的还是各种数据库，包括 RDBMS 和 NoSQL，比如使用 MySQL、MongoDB、HBase、Cassandra 等，特别是有些场景还要考虑数据一致性问题的时候，更加重了对存储层的依赖。
由此可见，云计算时代系统的架构发生了巨大的变化，这一方面为用户提供了更优秀的特性，另一方面也对云计算的组件提出了更高的要求。数据库作为云计算最基础的组件之一，也需要适应这种架构的变化。（这里我们主要关注 SQL 数据库，云时代的数据库以下简称云数据库。）
那么云数据库主要有一些什么样的特点呢？我认为主要有以下几点。 弹性伸缩 传统的数据库方案，常见的会选用 Oracle，MySQL，PostgreSQL。在云时代，数据量的规模有爆发性的增长，传统的数据库很容易遇到单机的存储瓶颈，不得不选用一些集群方案，常见的比如 Oracle RAC、 MySQL Sharding 等，而这些集群方案或多或少都有一些不令人满意的地方。
比如说，Oracle RAC 通过共享存储的硬件方案解决集群问题，这种方式基本上只能通过停机换用更大的共享内存硬件来解决扩容问题，RAC 节点过多会带来更多的并发问题，同样也会带来更高的成本。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</guid>
      <description>子查询简介 子查询是嵌套在另一个查询中的 SQL 表达式，比较常见的是嵌套在 FROM 子句中，如 SELECT ID FROM (SELECT * FROM SRC) AS T。对于出现在 FROM 中的子表达式，一般的 SQL 优化器都会处理的很好。但是当子查询出现在 WHERE 子句或 SELECT 列表中时，优化的难度就会大大增加，因为这时子查询可以出现在表达式中的任何位置，如 CASE...WHEN... 子句等。
对于不在 FROM 子句出现的子查询，分为“关联子查询”(Correlated Subquery) 和“非关联子查询”。关联子查询是指子查询中存在外部引用的列，例如：
SELECT * FROM SRC WHERE EXISTS(SELECT * FROM TMP WHERE TMP.id = SRC.id) 对于非关联子查询，我们可以在 plan 阶段进行预处理，将其改写成一个常量。因此，本文只考虑关联子查询的优化。
一般来说，子查询语句分为三种：
 标量子查询（Scalar Subquery），如(SELECT&amp;hellip;) + (SELECT&amp;hellip;)
 集合比较（Quantified Comparision），如T.a = ANY(SELECT&amp;hellip;)
 存在性测试（Existential Test），如NOT EXISTS(SELECT&amp;hellip;)，T.a IN (SELECT&amp;hellip;)
  对于简单的存在性测试类的子查询，一般的做法是将其改写成 SEMI-JOIN。但是很少有文献给出通用性的算法，指出什么样的查询可以“去关联化”。对于不能去关联化的子查询，数据库的做法通常是使用类似 Nested Loop 的方式去执行，称为 correlated execution。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-01/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-01/</guid>
      <description>TiDB 中的子查询优化技术 原创
2016-08-01 韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>PingCAP 第 18 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-30/</link>
      <pubDate>Sat, 30 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-30/</guid>
      <description>PingCAP 第 18 期 NewSQL Meetup 2016-07-30 常冰琳&amp;amp;张阳 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 18 期 Meetup，主题是小米云平台工程师常冰琳分享的《Kudu 的设计思想和具体实现》以及张阳分享的《Kubernetes in PingCAP》。
▌ ****
Topic 1
：Kudu 的设计思想和具体实现
lecture：
常冰琳 小米云平台工程师，长期专注于 Hadoop 生态的分布式计算框架，Kudu PMC&amp;amp;Commiter, Hadoop Nativetask 项目发起者(已合入 Hadoop)。目前在小米负责 SQL 类数据分析平台，利用 Impala 和 Kudu 搭建实时数据分析云服务。
Content：
本次分享将简单介绍 Kudu 的设计思想和具体实现，以及小米作为 Kudu 最早用户的一些实践经验。
 设计目标
 数据模型，分区和副本设计
 Tablet 存储设计</description>
    </item>
    
    <item>
      <title>Weekly update (July 23 ~ July 29, 2016)</title>
      <link>https://pingcap.com/weekly/2016-07-29-tidb-weekly/</link>
      <pubDate>Fri, 29 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-07-29-tidb-weekly/</guid>
      <description>Weekly update (July 23 ~ July 29, 2016) Last week, we landed 27 PRs in the TiDB repositories and 34 PRs in the TiKV repositories.
Notable changes to TiDB  Support cost based query optimization. Set the new query optimizer as default to improve the speed of complex queries. Meanwhile, a start-up parameter is provided to switch to the old query optimizer. Use Varint to encode the Column Value with integer type and Column ID, which saves storage space significantly.</description>
    </item>
    
    <item>
      <title>PingCAP 第 17 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-23/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-23/</guid>
      <description>PingCAP 第 17 期 NewSQL Meetup 2016-07-23 崔秋 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 17 期 Meetup，主题是崔秋
分享的《How does TiKV auto-balance work?》
。
▌ ****
Topic
：
How does TiKV auto-balance work?
TiDB
最近发布了
Beta
版本，相比传统的关系型数据库，
TiDB
具有在线弹性伸缩，高可用和强一致性，一致性的分布式事务和
MySQL
协议兼容性等特性，特别适用于大规模高并发的海量数据场景。
本次交流主要介绍了 TiKV 的 Balance Scheduler 框架和算法实现演进，对于大家主要关注的 TiKV 集群的在线弹性扩容实现细节和 TiKV Balance 中在线服务高可用的问题，进行了深度的探讨。
在 TiKV 里面，数据是按照 Range 进行存放的，称为一个 Region。PD(Placement Driver) 负责整个 TiKV 集群的管理和调度。</description>
    </item>
    
    <item>
      <title>Weekly update (July 17 ~ July 22, 2016)</title>
      <link>https://pingcap.com/weekly/2016-07-23-tidb-weekly/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-07-23-tidb-weekly/</guid>
      <description>Weekly update (July 17 ~ July 22, 2016) Last week, we landed 22 PRs in the TiDB repositories and 15 PRs in the TiKV repositories.
Notable changes to TiDB  Refactor the query optimizer to imporve the query efficiency for Join and SubQuery Add distributed SQL support for aggregate functions Improve the stability of the TiDB service Refactor the Decimal codes to improve the compatibility with MySQL Optimize the TiDB compatibility and performance for Zabbix Enhance the performance and the Sysbench result is improved significantly  Notable changes to TiKV  Add asynchronous scheduler support for higher throughput and better performance, see Benchmark.</description>
    </item>
    
    <item>
      <title>PingCAP 第 16 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-16/</link>
      <pubDate>Sat, 16 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-16/</guid>
      <description>PingCAP 第 16 期 NewSQL Meetup 2016-07-16 田琪&amp;amp;孟圣智 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 16 期 Meetup，主题是
来自京东的田琪分享的《Cool Extensions of Raft for NewSQL》，以及
来自百度的孟圣智分享的《基于 Ceph 构建文件共享服务的实践》 。
▌ ****
Topic
1
：Cool Extensions of Raft for NewSQL
lecturer：
田琪，京东数据库系统部负责人，开源 docker 镜像存储系统 speedy 作者，
TiDB committer, etcd contributor
Topic summary:
主要分享了 Raft 协议在 etcd 中的实现，与 etcd 在 Raft 协议方面近期更新地比较重要的特性，以及引进这些特性的缘由。</description>
    </item>
    
    <item>
      <title>PingCAP 第15期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-09/</link>
      <pubDate>Sat, 09 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-09/</guid>
      <description>PingCAP 第15期 NewSQL Meetup 2016-07-09 申砾&amp;amp;周昱行 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第15期 Meetup ，主题是申砾分享
的《TiDB 存储模型变更》以及周昱行
分享的《TiDB 优化器统计信息的采集》
。
▌
Part 1
：《TiDB 存储模型变更》
TiDB 在 Key-Value 存储模型之上，将一行数据拆分成多个 Key-Value pair。这样做有利于列较多并且 update 较为频繁的业务场景，同时对 Online Schema 变更较为友好。但是这种存储模型对于需要读取/写入大量 row 的业务场景并不适用。为此我们修改了 TiDB 的存储模型，将一行内需要频繁修改和很少修改的数据存储在不同的 column family 中，以更好地适应不同热度的数据,以及生存期差别比较大的数据。同时，非常有效地适配了读写放大以及空间放大的问题。
▌Part 2：
《TiDB 优化器统计信息的采集》
统计信息是实现基于代价的优化（CBO）的必要条件，本期为大家介绍 TiDB 收集统计信息使用的采样算法和直方图生成算法。
PingCAP Meetup</description>
    </item>
    
    <item>
      <title>PingCAP 第14期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-02/</link>
      <pubDate>Sat, 02 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-02/</guid>
      <description>PingCAP 第14期 NewSQL Meetup 2016-07-02 马涛&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第14期 Meetup ，主题是酷克数据联合创始人
马涛
分享的《HashData 数据仓库的动态缩容扩容实现》以及 PingCAP 联合创始人兼 CEO 刘奇针对近日发布的 TiDB Beta 版进行的现场 Demo 演示。
▌
Part 1
：《 HashData 数据仓库的动态缩容扩容实现》
讲师：马涛，酷克数据联合创始人，数据库领域从业近10年，最初 Pivotal HAWQ 项目成员，06年至11年就职人大金仓做内核开发。目前主要负责 OLAP 系统内核和外围云化工作。
通过对比 Greenplum，Dynamo 和 HashData 的当前实现，为大家简单介绍数据处理系统动态缩容扩容的实现。阐述数据系统缩容和扩容的需求集合和设计方案，深入介绍 HashData 选择的设计、目前实现和后续改进。
▌
Part 2
：
《 TiDB Beta 版现场 Demo 演示》</description>
    </item>
    
    <item>
      <title>PingCAP 第13期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-25/</link>
      <pubDate>Sat, 25 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-25/</guid>
      <description>PingCAP 第13期 NewSQL Meetup 2016-06-25 闫宇&amp;amp;崔秋 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第13期 Meetup ，主题是百度资深研发工程师、百度 BAC 存储负责人闫宇分享的《 百度 redis3 生产环境实践》以及 PingCAP 联合创始人崔秋分享的《TiKV Auto Balance 》。
▌
Topic 1
：
《百度 redis3 生产环境实践》
讲师：
闫宇，百度资深研发工程师，百度 BAC 存储负责人
**
（百度 BAC 的 redis3 服务目前机器规模达到1400台左右，总数据量接近100T，日 pv 超过1500亿，用户涵盖了百度贴吧、百度糯米、手机百度等百度内部几百个业务线。）
内容方向：
1）介绍百度BAC的 redis3 服务的整体架构；
2）交流在 redis3 实践中的一些经验。
以下为本次分享的干货PPT：
▌
Topic 2：
《TiKV Auto Balance》</description>
    </item>
    
    <item>
      <title>PingCAP 第12期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-18/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-18/</guid>
      <description>PingCAP 第12期 NewSQL Meetup 2016-06-18 张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第12期 Meetup ，主题是
张金鹏分享的《 rocksdb 日志分析和性能调优经验 》。
▌张金鹏
《 rocksdb 日志分析和性能调优经验 》
首先和大家一起分享如何分析 rocksdb 的 LOG，包括观察 compaction 相关的统计信息。
例如每个 level 导致的 compaction 个数，每个 compaction job 的平均持续时长，compaction 导致的 read 总量和 write 量，以及写放大等；也可以观察整个系统是否有 stall 情况，持续多长时间，时间占比是多少等；另外，还有跟踪某个具体的 compaction job 的 input files 组成，output files，以及 compacting 过程中 drop 掉的 key 个数等信息。</description>
    </item>
    
    <item>
      <title>TiDB 下推 API 实现细节 - Union Scan</title>
      <link>https://pingcap.com/blog-cn/tidb-api-union-scan/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-api-union-scan/</guid>
      <description>TiDB 集群的架构分为上层的 SQL 层和底层的 KV 层，SQL 层通过调用 KV 层的 API 读写数据，由于 SQL 层的节点和 KV 层节点通常不在一台机器上，所以，每次调用 KV 的 API 都是一次 RPC, 而往往一个普通的 Select 语句的执行，需要调用几十到几十万次 KV 的接口，这样的结果就是性能非常差，绝大部分时间都消耗在 RPC 上。
为了解决这个问题，TiDB 实现了下推 API，把一部分简单的 SQL 层的执行逻辑下推到 KV 层执行，让 KV 层可以理解 Table 和 Column，可以批量读取多行结果，可以用 Where 里的 Expression 对结果进行过滤, 可以计算聚合函数，大幅减少了 RPC 次数和数据的传输量。
TiDB 的下推 API 通过把 SQL 层的计算下推到 KV 层，大幅减少 RPC 次数和数据传输量，使性能得到数量级的提升。但是当我们一开始启用下推 API 的时候，发现了一个问题，就是当事务写入了数据，但是还未提交的时候，又执行了 Select 操作。
这个时候，刚刚写入的未提交的脏数据读不到，得到的结果是错误的，比如我们在一个空表 t 执行：
begin; insert t values (1); select * from t; 这时我们期待的结果是一条记录 “1”，但是启用下推 API 后得到的结果是空。</description>
    </item>
    
    <item>
      <title>PingCAP 第11期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-04/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-04/</guid>
      <description>PingCAP 第11期 NewSQL Meetup 2016-06-04 黄梦龙&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第11期 Meetup ，
主题是黄梦龙分享的《 TiKV 的结构化存储模型优化》和张金鹏分享的《深入解析 LevelDB 》。
▌黄梦龙
《 TiKV 的结构化存储模型优化》
目前 TiKV 的存储模型是简单的纯 Key-Value，在存储 SQL 结构化数据的过程中会产生比较严重的读写放大问题。我们计划为 TiKV 添加类似于 Hbase 的 ColumnFamily 机制，以使得 TiKV 与 TiDB 成为更加完美的搭档。大家对其中的实现细节，以及各种方案的优缺点进行了探讨。
▌张金鹏
《深入解析 LevelDB 》
首先介绍了 LevelDB 的整体架构，以及 LSM Tree 这一数据库中非常经典的结构。之后对 LevelDB 的写和读的流程进行分析，同时介绍 LevelDB 的 snapshot 功能的实现原理，以及 iterator 内部实现，和 iterator 存在的潜在问题。最后介绍 LevelDB 的 compaction 过程，以及存在的问题。</description>
    </item>
    
    <item>
      <title>PingCAP 第10期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-05-28/</link>
      <pubDate>Sat, 28 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-05-28/</guid>
      <description>PingCAP 第10期 NewSQL Meetup 2016-05-28 刘奇&amp;amp;周昱行 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第10期 Meetup ，跟京东小伙伴就
Raft group 中出现网络隔离时的 stale read 的问题做了充分讨论交流。之后进行的
分享主题是《 TiKV 的网络模拟测试》和《 TiDB 的条件下推优化》。
▌随机讨论
Raft group 中出现网络隔离时，会有stale read 的问题。目前我们考虑采用 region leader 的方案，保证在出现网络隔离的情况下，也能保证读的正确性。大家对其中的实现细节，以及各种方案的优缺点进行了讨论。
▌刘奇
《 TiKV 的网络模拟测试》
TiKV 如何做分布式系统测试。目前已经构建了一套测试框架，提供设置网络延迟、网络隔离、节点掉线等功能，用于构建测试用例。
▌周昱行
《 TiDB 的条件下推优化》
使用基于 Row 的 Merge 算法，解决存在脏数据时，使用 TiDB 下推 API 优化的问题。
TiDB 的下推 API 相比基础的 API 对读性能有着几个数量级的提升，任何无法使用下推 API 的操作的请求，性能都慢到完全无法接受的程度。</description>
    </item>
    
    <item>
      <title>PingCAP 第9期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-05-21/</link>
      <pubDate>Sat, 21 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-05-21/</guid>
      <description>PingCAP 第9期 NewSQL Meetup 2016-05-21 韩飞&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第9期 NewSQL Meetup ，分享主题是韩飞的《 SQL 子查询优化》和刘奇的《 TiKV MVCC 和 GC 实现》。
▌韩飞 《 SQL 子查询优化》
分享 SQL subqueries 的变换和优化问题。
关联子查询的优化是 SQL 优化中很重要的一部分，一般的执行方式方式是 correlated execution，但是可以通过引入 Apply 算子形式化证明所有的子查询都可以改写成 Join 的不同形式。在分布式场景下，Join 可以比 correlated execution 有更多的优化空间。
▌刘奇
《 TiKV MVCC 和 GC 实现》
详细分析了 TiKV 的 MVCC 机制, 事务模型，并进一步介绍了 percolator 事务模型的特点，以及对 GC 的影响。另外讲解了 TiKV 对 percolator 事务模型的改进, 以及 TiKV 的 GC 算法，和如何支持长时间的数据库备份和分析操作。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/blog-cn/cases/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cases/TOC/</guid>
      <description> 用户案例 目录  互联网  转转 摩拜单车 易果集团 特来电 同程旅游 去哪儿网 饿了么（一） 饿了么（二） 今日头条 G7 二维火 客如云 凤凰网 零氪科技 一面数据 Mobikok 猿辅导  游戏  西山居 游族网络 盖娅互娱 株式会社 FUNYOURS JAPAN  金融  北京银行 Ping++ 360 金融  大型企业  海航易建 威锐达测控 万达网络科技集团   </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/README/</guid>
      <description>TiDB 中文技术文档 目录  关于 TiDB  TiDB 简介 TiDB 整体架构 TiDB 核心特性  TiDB 快速入门  快速入门指南 SQL 基本操作  TiDB 用户文档  TiDB 数据库管理 TiDB 服务 TiDB 进程启动参数 TiDB 数据目录 TiDB 系统数据库 TiDB 系统变量 TiDB 专用系统变量和语法 TiDB 服务器日志文件 TiDB 访问权限管理 TiDB 用户账户管理 使用加密连接 SQL 优化 理解 TiDB 执行计划 统计信息 语言结构 字面值 数据库、表、索引、列和别名 关键字和保留字 用户变量 表达式语法 注释语法 字符集和时区 字符集支持 字符集配置 时区 数据类型 数值类型 日期和时间类型 字符串类型 JSON 数据类型 枚举类型 集合类型 数据类型默认值 函数和操作符 函数和操作符概述 表达式求值的类型转换 操作符 控制流程函数 字符串函数 数值函数与操作符 日期和时间函数 位函数和操作符 Cast 函数和操作符 加密和压缩函数 信息函数 JSON 函数 GROUP BY 聚合函数 其他函数 精度数学 SQL 语句语法 数据定义语句 (DDL) 数据操作语句 (DML) 事务语句 数据库管理语句 Prepared SQL 语句语法 实用工具语句 TiDB SQL 语法图 JSON 支持 Connectors 和 API TiDB 事务隔离级别 错误码与故障诊断 与 MySQL 兼容性对比 TiDB 内存控制 慢查询日志 高级功能 历史数据回溯 垃圾回收 (GC)  TiDB 运维文档  软硬件环境需求 部署集群 Ansible 部署方案（强烈推荐） 离线 Ansible 部署方案 Docker 部署方案 Docker Compose 部署方案 跨机房部署方案 配置集群 参数解释 TiDB 配置项解释 使用 Ansible 变更组件配置 开启 TLS 验证 生成自签名证书 监控集群 整体监控框架概述 重要监控指标详解 组件状态 API &amp;amp; 监控 扩容缩容 集群扩容缩容方案 使用 Ansible 扩容缩容 升级 升级组件版本 TiDB 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/README/</guid>
      <description>TiDB Documentation Documentation List  About TiDB  TiDB Introduction TiDB Architecture  Quick Start  TiDB Quick Start Guide Basic SQL Statements Bikeshare Example Database  TiDB User Guide  TiDB Server Administration The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The Proprietary System Variables and Syntax in TiDB The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections SQL Optimization Understand the Query Execution Plan Introduction to Statistics Language Structure Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax Globalization Character Set Support Character Set Configuration Time Zone Support Data Types Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values Functions and Operators Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math SQL Statement Syntax Data Definition Statements Data Manipulation Statements Transactions Database Administration Statements Prepared SQL Statement Syntax Utility Statements TiDB SQL Syntax Diagram JSON Functions and Generated Column Connectors and APIs TiDB Transaction Isolation Levels Error Codes and Troubleshooting Compatibility with MySQL TiDB Memory Control Slow Query Log Advanced Usage Read Data From History Versions Garbage Collection (GC)  TiDB Operations Guide  Hardware and Software Requirements Deploy Ansible Deployment (Recommended) Offline Deployment Using Ansible Docker Deployment Docker Compose Deployment Cross-Region Deployment Kubernetes Deployment Configure Configuration Flags Configuration File Description Modify Component Configuration Using Ansible Enable TLS Authentication Generate Self-signed Certificates Monitor Overview of the Monitoring Framework Key Metrics Monitor a TiDB Cluster Scale Scale a TiDB Cluster Scale Using Ansible Upgrade Upgrade the Component Version TiDB 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/deployment/</guid>
      <description>Build for deployment Overview Note: The easiest way to deploy TiDB is to use TiDB Ansible, see Ansible Deployment.
Before you start, check the supported platforms and prerequisites first.
Building and installing TiDB components You can use the build script to build and install TiDB components in the bin directory.
You can use the update script to update all the TiDB components to the latest version.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/development/</guid>
      <description>Build For Development Overview If you want to develop the TiDB project, you can follow this guide.
Before you begin, check the supported platforms and prerequisites first.
Build TiKV  Get TiKV source code from GitHub
git clone https://github.com/pingcap/tikv.git cd tikv Run all unit tests:
make test Build in release mode:
make release  Build TiDB  Make sure the GOPATH environment is set correctly.
 Get the TiDB source code.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/requirements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/requirements/</guid>
      <description>Build requirements Supported platforms The following table lists TiDB support for common architectures and operating systems.
   Architecture Operating System Status     AMD64 Linux Ubuntu (14.04+) Stable   AMD64 Linux CentOS (7+) Stable   AMD64 Mac OSX Experimental    Prerequisites  Go 1.9+ Rust nightly version GCC 4.8+ with static library CMake 3.1+  The check requirement script can help you check prerequisites and install the missing ones automatically.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/op-guide/pd-api-v1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/pd-api-v1/</guid>
      <description>Placement Driver API  /*! jQuery v3.1.0 | (c) jQuery Foundation | jquery.org/license */ !function(a,b){&#34;use strict&#34;;&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return b(a)}:b(a)}(&#34;undefined&#34;!=typeof window?window:this,function(a,b){&#34;use strict&#34;;var c=[],d=a.document,e=Object.getPrototypeOf,f=c.slice,g=c.concat,h=c.push,i=c.indexOf,j={},k=j.toString,l=j.hasOwnProperty,m=l.toString,n=m.call(Object),o={};function p(a,b){b=b||d;var c=b.createElement(&#34;script&#34;);c.text=a,b.head.appendChild(c).parentNode.removeChild(c)}var q=&#34;3.1.0&#34;,r=function(a,b){return new r.fn.init(a,b)},s=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,t=/^-ms-/,u=/-([a-z])/g,v=function(a,b){return b.toUpperCase()};r.fn=r.prototype={jquery:q,constructor:r,length:0,toArray:function(){return f.call(this)},get:function(a){return null!=a?a=0&amp;&amp;c0&amp;&amp;b-1 in a)}var x=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u=&#34;sizzle&#34;+1*new Date,v=a.document,w=0,x=0,y=ha(),z=ha(),A=ha(),B=function(a,b){return a===b&amp;&amp;(l=!0),0},C={}.hasOwnProperty,D=[],E=D.pop,F=D.push,G=D.push,H=D.slice,I=function(a,b){for(var c=0,d=a.length;c+~]|&#34;+K+&#34;)&#34;+K+&#34;*&#34;),S=new RegExp(&#34;=&#34;+K+&#34;*([^\\]&#39;\&#34;]*?)&#34;+K+&#34;*\\]&#34;,&#34;g&#34;),T=new RegExp(N),U=new RegExp(&#34;^&#34;+L+&#34;$&#34;),V={ID:new RegExp(&#34;^#(&#34;+L+&#34;)&#34;),CLASS:new RegExp(&#34;^\\.(&#34;+L+&#34;)&#34;),TAG:new RegExp(&#34;^(&#34;+L+&#34;|[*])&#34;),ATTR:new RegExp(&#34;^&#34;+M),PSEUDO:new RegExp(&#34;^&#34;+N),CHILD:new RegExp(&#34;^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(&#34;+K+&#34;*(even|odd|(([+-]|)(\\d*)n|)&#34;+K+&#34;*(?:([+-]|)&#34;+K+&#34;*(\\d+)|))&#34;+K+&#34;*\\)|)&#34;,&#34;i&#34;),bool:new RegExp(&#34;^(?:&#34;+J+&#34;)$&#34;,&#34;i&#34;),needsContext:new RegExp(&#34;^&#34;+K+&#34;*[+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(&#34;+K+&#34;*((?:-\\d)?\\d*)&#34;+K+&#34;*\\)|)(?=[^-]|$)&#34;,&#34;i&#34;)},W=/^(?:input|select|textarea|button)$/i,X=/^h\d$/i,Y=/^[^{]+\{\s*\[native \w/,Z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,$=/[+~]/,_=new RegExp(&#34;\\\\([\\da-f]{1,6}&#34;+K+&#34;?|(&#34;+K+&#34;)|.)&#34;,&#34;ig&#34;),aa=function(a,b,c){var d=&#34;0x&#34;+b-65536;return d!==d||c?b:d10|55296,1023&amp;d|56320)},ba=/([\0-\x1f\x7f]|^-?\d)|^-$|[^\x80-\uFFFF\w-]/g,ca=function(a,b){return b?&#34;\0&#34;===a?&#34;\ufffd&#34;:a.slice(0,-1)+&#34;\\&#34;+a.charCodeAt(a.length-1).toString(16)+&#34; &#34;:&#34;\\&#34;+a},da=function(){m()},ea=ta(function(a){return a.disabled===!0},{dir:&#34;parentNode&#34;,next:&#34;legend&#34;});try{G.apply(D=H.call(v.childNodes),v.childNodes),D[v.childNodes.length].nodeType}catch(fa){G={apply:D.length?function(a,b){F.apply(a,H.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function ga(a,b,d,e){var f,h,j,k,l,o,r,s=b&amp;&amp;b.ownerDocument,w=b?b.nodeType:9;if(d=d||[],&#34;string&#34;!=typeof a||!a||1!==w&amp;&amp;9!==w&amp;&amp;11!==w)return d;if(!e&amp;&amp;((b?b.ownerDocument||b:v)!==n&amp;&amp;m(b),b=b||n,p)){if(11!==w&amp;&amp;(l=Z.exec(a)))if(f=l[1]){if(9===w){if(!(j=b.getElementById(f)))return d;if(j.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/meetup/list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/list/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/recruit-cn/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/TOC/</guid>
      <description> PingCAP 招聘 目录  Engineering  TiKV 研发工程师 PD 研发工程师 TiDB 研发工程师 分布式系统工程师 TiDB 商业产品开发 - 工具方向 TiDB 商业产品开发 - Cloud 方向 TiDB 商业产品开发 - SRE 方向 TiDB 商业产品开发 - 产品方向  Business  资深行业销售总监 资深售前技术总监 资深渠道合作总监 高级数据库支持工程师  MKT  社区运营  I18N  Technical Writer  Campus  Infrastructure Engineer Technical Writer Marketing Specicalist OPS Engineer HR Management Trainee Infrastructure Engineer Intern HR Intern Technical Writer Intern  General &amp;amp; Administrative  出纳 招聘主管 行政前台   </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/recruit-cn/join/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/join/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/recruit-cn/qa/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/qa/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/site-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/site-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://pingcap.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aggregate (GROUP BY) Functions</title>
      <link>https://pingcap.com/docs/sql/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/aggregate-group-by-functions/</guid>
      <description>Aggregate (GROUP BY) Functions This document describes details about the supported aggregate functions in TiDB.
Aggregate (GROUP BY) function descriptions This section describes the supported MySQL group (aggregate) functions in TiDB.
   Name Description     COUNT() Return a count of the number of rows returned   COUNT(DISTINCT) Return the count of a number of different values   SUM() Return the sum   AVG() Return the average value of the argument   MAX() Return the maximum value   MIN() Return the minimum value   GROUP_CONCAT() Return a concatenated string     Unless otherwise stated, group functions ignore NULL values.</description>
    </item>
    
    <item>
      <title>Backup and Restore</title>
      <link>https://pingcap.com/docs/op-guide/backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/backup-restore/</guid>
      <description>Backup and Restore About This document describes how to back up and restore the data of TiDB. Currently, this document only covers full backup and restoration.
Here we assume that the TiDB service information is as follows:
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    Use the following tools for data backup and restoration:
 mydumper: to export data from TiDB loader: to import data into TiDB  Download TiDB toolset (Linux) # Download the tool package.</description>
    </item>
    
    <item>
      <title>Bikeshare Example Database</title>
      <link>https://pingcap.com/docs/bikeshare-example-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/bikeshare-example-database/</guid>
      <description>Bikeshare Example Database Examples used in the TiDB manual use System Data from Capital Bikeshare, released under the Capital Bikeshare Data License Agreement.
Download all data files The system data is available for download in .zip files organized per year. Downloading and extracting all files requires approximately 3GB of disk space. To download all files for years 2010-2017 using a bash script:
mkdir -p bikeshare-data &amp;amp;&amp;amp; cd bikeshare-data for YEAR in 2010 2011 2012 2013 2014 2015 2016 2017; do wget https://s3.</description>
    </item>
    
    <item>
      <title>Bit Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/bit-functions-and-operators/</guid>
      <description> Bit Functions and Operators In TiDB, the usage of bit functions and operators is similar to MySQL. See Bit Functions and Operators.
Bit functions and operators
   Name Description     BIT_COUNT() Return the number of bits that are set as 1   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   &amp;lt;&amp;lt; Left shift   &amp;gt;&amp;gt; Right shift    </description>
    </item>
    
    <item>
      <title>Bit-value Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-bit-value/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-bit-value/</guid>
      <description>Bit-value Literals 位值字面值用 b 或者 0b 做前缀，后接以 0 跟 1 组成的二进制数字。其中 0b 是区分大小写的，0B 是会报错的。
合法的 Bit-value：
 b&amp;rsquo;01&amp;rsquo; B&amp;rsquo;01&amp;rsquo; 0b01  非法的 Bit-value：
 b&amp;rsquo;2&amp;rsquo; (2 不是二进制数值, 必须为 0 或 1) 0B01 (0B 必须是小写 0b)  默认情况，位值字面值是一个二进制字符串。
Bit-value 是作为二进制返回的，所以输出到 MySQL Client 可能会显示不出来，如果要转换为可打印的字符，可以使用内建函数 BIN() 或者 HEX()：
CREATE TABLE t (b BIT(8)); INSERT INTO t SET b = b&amp;#39;00010011&amp;#39;; INSERT INTO t SET b = b&amp;#39;1110&amp;#39;; INSERT INTO t SET b = b&amp;#39;100101&amp;#39;; mysql&amp;gt; SELECT b+0, BIN(b), HEX(b) FROM t; +------+--------+--------+ | b+0 | BIN(b) | HEX(b) | +------+--------+--------+ | 19 | 10011 | 13 | | 14 | 1110 | E | | 37 | 100101 | 25 | +------+--------+--------+ 3 rows in set (0.</description>
    </item>
    
    <item>
      <title>Boolean Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-boolean/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-boolean/</guid>
      <description> Boolean Literals 常量 TRUE 和 FALSE 等于 1 和 0，它是大小写不敏感的。
mysql&amp;gt; SELECT TRUE, true, tRuE, FALSE, FaLsE, false; +------+------+------+-------+-------+-------+ | TRUE | true | tRuE | FALSE | FaLsE | false | +------+------+------+-------+-------+-------+ | 1 | 1 | 1 | 0 | 0 | 0 | +------+------+------+-------+-------+-------+ 1 row in set (0.00 sec)</description>
    </item>
    
    <item>
      <title>Cast Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/cast-functions-and-operators/</guid>
      <description>Cast Functions and Operators    Name Description     BINARY Cast a string to a binary string   CAST() Cast a value as a certain type   CONVERT() Cast a value as a certain type    Cast functions and operators enable conversion of values from one data type to another.
For details, see here.</description>
    </item>
    
    <item>
      <title>Cast 函数和操作符</title>
      <link>https://pingcap.com/docs-cn/sql/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/cast-functions-and-operators/</guid>
      <description> Cast 函数和操作符 Cast 函数和操作符用于将某种数据类型的值转换为另一种数据类型。TiDB 中该函数和操作符的使用方法与 MySQL基本一致，详情参见: Cast Functions and Operators.
Cast 函数和操作符表    函数和操作符名 功能描述     BINARY 将一个字符串转换成一个二进制字符串   CAST() 将一个值转换成一个确定类型   CONVERT() 将一个值转换成一个确定类型    </description>
    </item>
    
    <item>
      <title>Character Set Configuration</title>
      <link>https://pingcap.com/docs/sql/character-set-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/character-set-configuration/</guid>
      <description>Character Set Configuration Currently, TiDB only supports the utf8 character set, which is the equivalent to utf8mb4 in MySQL. Since MySQL 5.7 defaults to latin1, this difference is documented under default differences between TiDB and MySQL.
For more information, see Character Set Configuration in MySQL.</description>
    </item>
    
    <item>
      <title>Character Set Support</title>
      <link>https://pingcap.com/docs/sql/character-set-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/character-set-support/</guid>
      <description>Character Set Support A character set is a set of symbols and encodings. A collation is a set of rules for comparing characters in a character set.
Currently, TiDB supports the following character sets:
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>Comment Syntax</title>
      <link>https://pingcap.com/docs/sql/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/comment-syntax/</guid>
      <description>Comment Syntax TiDB supports three comment styles:
 Use # to comment a line. Use -- to comment a line, and this style requires at least one whitespace after --. Use /* */ to comment a block or multiple lines.  Example:
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>Compatibility with MySQL</title>
      <link>https://pingcap.com/docs/sql/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/mysql-compatibility/</guid>
      <description>Compatibility with MySQL TiDB supports the majority of the MySQL 5.7 syntax, including cross-row transactions, JOIN, subquery, and so on. You can connect to TiDB directly using your own MySQL client. If your existing business is developed based on MySQL, you can replace MySQL with TiDB to power your application without changing a single line of code in most cases.
TiDB is compatible with most of the MySQL database management &amp;amp; administration tools such as PHPMyAdmin, Navicat, MySQL Workbench, and so on.</description>
    </item>
    
    <item>
      <title>Configuration Flags</title>
      <link>https://pingcap.com/docs/op-guide/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/configuration/</guid>
      <description>Configuration Flags TiDB, TiKV and PD are configurable using command-line flags and environment variables.
TiDB The default TiDB ports are 4000 for client requests and 10080 for status report.
--advertise-address  The IP address on which to advertise the apiserver to the TiDB server Default: &amp;ldquo;&amp;rdquo; This address must be reachable by the rest of the TiDB cluster and the user.  --binlog-socket  The TiDB services use the unix socket file for internal connections, such as the Pump service Default: &amp;ldquo;&amp;rdquo; You can use &amp;ldquo;/tmp/pump.</description>
    </item>
    
    <item>
      <title>Connect with us</title>
      <link>https://pingcap.com/docs/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/community/</guid>
      <description> Connect with us  Twitter: @PingCAP Reddit: https://www.reddit.com/r/TiDB/ Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Mailing list: Google Group  </description>
    </item>
    
    <item>
      <title>Connectors and APIs</title>
      <link>https://pingcap.com/docs/sql/connection-and-APIs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/connection-and-APIs/</guid>
      <description>Connectors and APIs Database Connectors provide connectivity to the TiDB server for client programs. APIs provide low-level access to the MySQL protocol and MySQL resources. Both Connectors and the APIs enable you to connect and execute MySQL statements from another language or environment, including ODBC, Java (JDBC), Perl, Python, PHP, Ruby and C.
TiDB is compatible with all Connectors and APIs of MySQL (5.6, 5.7), including:
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  Connect to TiDB using MySQL Connectors Oracle develops the following APIs and TiDB is compatible with all of them:</description>
    </item>
    
    <item>
      <title>Contact Us</title>
      <link>https://pingcap.com/contact-us/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/contact-us/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Control Flow Functions</title>
      <link>https://pingcap.com/docs/sql/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/control-flow-functions/</guid>
      <description> Control Flow Functions    Name Description     CASE Case operator   IF() If/else construct   IFNULL() Null if/else construct   NULLIF() Return NULL if expr1 = expr2    </description>
    </item>
    
    <item>
      <title>Cross-Region Deployment</title>
      <link>https://pingcap.com/docs/op-guide/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/location-awareness/</guid>
      <description>Cross-Region Deployment Overview PD schedules according to the topology of the TiKV cluster to maximize the TiKV&amp;rsquo;s capability for disaster recovery.
Before you begin, see Deploy TiDB Using Ansible (Recommended) and Deploy TiDB Using Docker.
TiKV reports the topological information TiKV reports the topological information to PD according to the startup parameter or configuration of TiKV.
Assuming that the topology has three structures: zone &amp;gt; rack &amp;gt; host, use lables to specify the following information:</description>
    </item>
    
    <item>
      <title>Data Definition Statements</title>
      <link>https://pingcap.com/docs/sql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/ddl/</guid>
      <description>Data Definition Statements DDL (Data Definition Language) is used to define the database structure or schema, and to manage the database and statements of various objects in the database.
CREATE DATABASE syntax CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ... create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name The CREATE DATABASE statement is used to create a database, and to specify the default properties of the database, such as the default character set and validation rules.</description>
    </item>
    
    <item>
      <title>Database Administration Statements</title>
      <link>https://pingcap.com/docs/sql/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/admin/</guid>
      <description>Database Administration Statements TiDB manages the database using a number of statements, including granting privileges, modifying system variables, and querying database status.
Privilege management See Privilege Management.
SET statement The SET statement has multiple functions and forms.
Assign values to variables SET variable_assignment [, variable_assignment] ... variable_assignment: user_var_name = expr | param_name = expr | local_var_name = expr | [GLOBAL | SESSION] system_var_name = expr | [@@global. | @@session. | @@] system_var_name = expr You can use the above syntax to assign values to variables in TiDB, which include system variables and user-defined variables.</description>
    </item>
    
    <item>
      <title>Date and Time Functions</title>
      <link>https://pingcap.com/docs/sql/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/date-and-time-functions/</guid>
      <description>Date and Time Functions The usage of date and time functions is similar to MySQL. For more information, see here.
Date/Time functions
   Name Description     ADDDATE() Add time values (intervals) to a date value   ADDTIME() Add time   CONVERT_TZ() Convert from one time zone to another   CURDATE() Return the current date   CURRENT_DATE(), CURRENT_DATE Synonyms for CURDATE()   CURRENT_TIME(), CURRENT_TIME Synonyms for CURTIME()   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP Synonyms for NOW()   CURTIME() Return the current time   DATE() Extract the date part of a date or datetime expression   DATE_ADD() Add time values (intervals) to a date value   DATE_FORMAT() Format date as specified   DATE_SUB() Subtract a time value (interval) from a date   DATEDIFF() Subtract two dates   DAY() Synonym for DAYOFMONTH()   DAYNAME() Return the name of the weekday   DAYOFMONTH() Return the day of the month (0-31)   DAYOFWEEK() Return the weekday index of the argument   DAYOFYEAR() Return the day of the year (1-366)   EXTRACT() Extract part of a date   FROM_DAYS() Convert a day number to a date   FROM_UNIXTIME() Format Unix timestamp as a date   GET_FORMAT() Return a date format string   HOUR() Extract the hour   LAST_DAY Return the last day of the month for the argument   LOCALTIME(), LOCALTIME Synonym for NOW()   LOCALTIMESTAMP, LOCALTIMESTAMP() Synonym for NOW()   MAKEDATE() Create a date from the year and day of year   MAKETIME() Create time from hour, minute, second   MICROSECOND() Return the microseconds from argument   MINUTE() Return the minute from the argument   MONTH() Return the month from the date passed   MONTHNAME() Return the name of the month   NOW() Return the current date and time   PERIOD_ADD() Add a period to a year-month   PERIOD_DIFF() Return the number of months between periods   QUARTER() Return the quarter from a date argument   SEC_TO_TIME() Converts seconds to &amp;lsquo;HH:MM:SS&amp;rsquo; format   SECOND() Return the second (0-59)   STR_TO_DATE() Convert a string to a date   SUBDATE() Synonym for DATE_SUB() when invoked with three arguments   SUBTIME() Subtract times   SYSDATE() Return the time at which the function executes   TIME() Extract the time portion of the expression passed   TIME_FORMAT() Format as time   TIME_TO_SEC() Return the argument converted to seconds   TIMEDIFF() Subtract time   TIMESTAMP() With a single argument, this function returns the date or datetime expression; with two arguments, the sum of the arguments   TIMESTAMPADD() Add an interval to a datetime expression   TIMESTAMPDIFF() Subtract an interval from a datetime expression   TO_DAYS() Return the date argument converted to days   TO_SECONDS() Return the date or datetime argument converted to seconds since Year 0   UNIX_TIMESTAMP() Return a Unix timestamp   UTC_DATE() Return the current UTC date   UTC_TIME() Return the current UTC time   UTC_TIMESTAMP() Return the current UTC date and time   WEEK() Return the week number   WEEKDAY() Return the weekday index   WEEKOFYEAR() Return the calendar week of the date (1-53)   YEAR() Return the year   YEARWEEK() Return the year and week    For details, see here.</description>
    </item>
    
    <item>
      <title>Date 和 Time 字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-date-and-time-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-date-and-time-literals/</guid>
      <description>Date and Time Literals Date 跟 Time 字面值有几种格式，例如用字符串表示，或者直接用数字表示。在 TiDB 里面，当 TiDB 期望一个 Date 的时候，它会把 &#39;2017-08-24&#39;， &#39;20170824&#39;，20170824 当做是 Date。
TiDB 的 Date 值有以下几种格式：
 &#39;YYYY-MM-DD&#39; 或者 &#39;YY-MM-DD&#39;，这里的 - 分隔符并不是严格的，可以是任意的标点符号。比如 &#39;2017-08-24&#39;，&#39;2017&amp;amp;08&amp;amp;24&#39;， &#39;2012@12^31&#39; 都是一样的。唯一需要特别对待的是 &amp;lsquo;.&amp;rsquo; 号，它被当做是小数点，用于分隔整数和小数部分。 Date 和 Time 部分可以被 &amp;rsquo;T&amp;rsquo; 分隔，它的作用跟空格符是一样的，例如 2017-8-24 10:42:00 跟 2017-8-24T10:42:00 是一样的。 &#39;YYYYMMDDHHMMSS&#39; 或者 &#39;YYMMDDHHMMSS&#39;，例如 &#39;20170824104520&#39; 和 &#39;170824104520&#39; 被当做是 &#39;2017-08-24 10:45:20&#39;，但是如果你提供了一个超过范围的值，例如&#39;170824304520&#39;，那这就不是一个有效的 Date 字面值。 YYYYMMDDHHMMSS 或者 YYMMDDHHMMSS 注意这里没有单引号或者双引号，是一个数字。例如 20170824104520表示为 &#39;2017-08-24 10:45:20&#39;。  DATETIME 或者 TIMESTAMP 值可以接一个小数部分，用来表示微秒（精度最多到小数点后 6 位），用小数点 .</description>
    </item>
    
    <item>
      <title>Deploy TiDB Offline Using Ansible</title>
      <link>https://pingcap.com/docs/op-guide/offline-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/offline-ansible-deployment/</guid>
      <description>Deploy TiDB Offline Using Ansible This guide describes how to deploy a TiDB cluster offline using Ansible.
Prepare Before you start, make sure that you have:
 A download machine
 The machine must have access to the Internet in order to download TiDB-Ansible, TiDB and related packages. For Linux operating system, it is recommended to install CentOS 7.3 or later.  Several target machines and one Control Machine</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Ansible</title>
      <link>https://pingcap.com/docs/op-guide/ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/ansible-deployment/</guid>
      <description>Deploy TiDB Using Ansible This guide describes how to deploy a TiDB cluster using Ansible. For the production environment, it is recommended to deploy TiDB using Ansible.
Overview Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiDB cluster which includes PD, TiDB, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Docker</title>
      <link>https://pingcap.com/docs/op-guide/docker-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/docker-deployment/</guid>
      <description>Deploy TiDB Using Docker This page shows you how to manually deploy a multi-node TiDB cluster on multiple machines using Docker.
To learn more, see TiDB architecture and Software and Hardware Requirements.
Preparation Before you start, make sure that you have:
 Installed the latest version of Docker Pulled the latest images of TiDB, TiKV and PD from Docker Hub. If not, pull the images using the following commands:</description>
    </item>
    
    <item>
      <title>Enable TLS Authentication</title>
      <link>https://pingcap.com/docs/op-guide/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/security/</guid>
      <description>Enable TLS Authentication Overview This document describes how to enable TLS authentication in the TiDB cluster. The TLS authentication includes the following two conditions:
 The mutual authentication between TiDB components, including the authentication among TiDB, TiKV and PD, between TiKV Control and TiKV, between PD Control and PD, between TiKV peers, and between PD peers. Once enabled, the mutual authentication applies to all components, and it does not support applying to only part of the components.</description>
    </item>
    
    <item>
      <title>Encryption and Compression Functions</title>
      <link>https://pingcap.com/docs/sql/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/encryption-and-compression-functions/</guid>
      <description> Encryption and Compression Functions    Name Description     MD5() Calculate MD5 checksum   PASSWORD() Calculate and return a password string   RANDOM_BYTES() Return a random byte vector   SHA1(), SHA() Calculate an SHA-1 160-bit checksum   SHA2() Calculate an SHA-2 checksum   AES_DECRYPT() Decrypt using AES   AES_ENCRYPT() Encrypt using AES   COMPRESS() Return result as a binary string   UNCOMPRESS() Uncompress a string compressed   UNCOMPRESSED_LENGTH() Return the length of a string before compression   CREATE_ASYMMETRIC_PRIV_KEY() Create private key   CREATE_ASYMMETRIC_PUB_KEY() Create public key   CREATE_DH_PARAMETERS() Generate shared DH secret   CREATE_DIGEST() Generate digest from string   ASYMMETRIC_DECRYPT() Decrypt ciphertext using private or public key   ASYMMETRIC_DERIVE() Derive symmetric key from asymmetric keys   ASYMMETRIC_ENCRYPT() Encrypt cleartext using private or public key   ASYMMETRIC_SIGN() Generate signature from digest   ASYMMETRIC_VERIFY() Verify that signature matches digest    </description>
    </item>
    
    <item>
      <title>Error Codes and Troubleshooting</title>
      <link>https://pingcap.com/docs/sql/error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/error/</guid>
      <description>Error Codes and Troubleshooting This document describes the problems encountered during the use of TiDB and provides the solutions.
Error codes TiDB is compatible with the error codes in MySQL, and in most cases returns the same error code as MySQL. In addition, TiDB has the following unique error codes:
   Error code Description Solution     8001 The memory used by the request exceeds the threshold limit for the TiDB memory usage.</description>
    </item>
    
    <item>
      <title>Expression Syntax</title>
      <link>https://pingcap.com/docs/sql/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/expression-syntax/</guid>
      <description>Expression Syntax The following rules define the expression syntax in TiDB. You can find the definition in parser/parser.y. The syntax parsing in TiDB is based on Yacc.
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>Function and Operator Reference</title>
      <link>https://pingcap.com/docs/sql/functions-and-operators-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/functions-and-operators-reference/</guid>
      <description>Function and Operator Reference The usage of the functions and operators in TiDB is similar to MySQL. See Functions and Operators in MySQL.
In SQL statements, expressions can be used on the ORDER BY and HAVING clauses of the SELECT statement, the WHERE clause of SELECT/DELETE/UPDATE statements, and SET statements.
You can write expressions using literals, column names, NULL, built-in functions, operators and so on.</description>
    </item>
    
    <item>
      <title>GROUP BY 聚合函数</title>
      <link>https://pingcap.com/docs-cn/sql/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/aggregate-group-by-functions/</guid>
      <description>GROUP BY 聚合函数 GROUP BY 聚合函数功能描述 本节介绍 TiDB 中支持的 MySQL GROUP BY 聚合函数。
   函数名 功能描述     COUNT() 返回检索到的行的数目   COUNT(DISTINCT) 返回不同值的数目   SUM() 返回和   AVG() 返回平均值   MAX() 返回最大值   MIN() 返回最小值   GROUP_CONCAT() 返回连接的字符串     Note:
 除非另有说明，否则组函数默认忽略 NULL 值。 如果在不包含 GROUP BY 子句的语句中使用组函数，则相当于对所有行进行分组。详情参阅 TiDB 中的 GROUP BY。   GROUP BY 修饰符 TiDB 目前不支持任何 GROUP BY 修饰符，将来会提供支持，详情参阅 #4250。</description>
    </item>
    
    <item>
      <title>Generate Self-signed Certificates</title>
      <link>https://pingcap.com/docs/op-guide/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/generate-self-signed-certificates/</guid>
      <description>Generate Self-signed Certificates Overview This document describes how to generate self-signed certificates using cfssl.
Assume that the topology of the instance cluster is as follows:
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    Download cfssl Assume that the host is x86_64 Linux:</description>
    </item>
    
    <item>
      <title>HR Management Trainee</title>
      <link>https://pingcap.com/recruit-cn/campus/campus-2019-hr-management-trainee/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/campus-2019-hr-management-trainee/</guid>
      <description>人力资源管培生 岗位职责：
 与 Team 小伙伴一起制定公司招聘计划并实施落地，搭建人才地图；
 与 Team 小伙伴一起搭建组织发展、绩效评估体系，进行员工关系管理及入、离、调、转等；
 与 Team 小伙伴一起搭建与完善公司培训体系，进行人才梯队建设及重点人才培养，企业文化宣传、落地等；
 与 Team 小伙伴一起为业务体系提供专业的人力资源支持与服务。
  任职要求：
 对人力资源及 High Tech 有强烈的好奇心；
 积极主动，具备较好的逻辑思维能力及强烈的求知欲，乐于不断接受新的挑战；
 英语好，善于与人交流和收集信息，有计算机相关知识或互联网公司实习经验的优先。
  待遇：
8K - 15K，13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>Home</title>
      <link>https://pingcap.com/en/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/en/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to become a contributor</title>
      <link>https://pingcap.com/tidb-planet/become-a-contributor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/become-a-contributor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Information Functions</title>
      <link>https://pingcap.com/docs/sql/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/information-functions/</guid>
      <description> Information Functions In TiDB, the usage of information functions is similar to MySQL. For more information, see Information Functions.
Information function descriptions    Name Description     CONNECTION_ID() Return the connection ID (thread ID) for the connection   CURRENT_USER(), CURRENT_USER Return the authenticated user name and host name   DATABASE() Return the default (current) database name   FOUND_ROWS() For a SELECT with a LIMIT clause, the number of the rows that are returned if there is no LIMIT clause   LAST_INSERT_ID() Return the value of the AUTOINCREMENT column for the last INSERT   SCHEMA() Synonym for DATABASE()   SESSION_USER() Synonym for USER()   SYSTEM_USER() Synonym for USER()   USER() Return the user name and host name provided by the client   VERSION() Return a string that indicates the MySQL server version   TIDB_VERSION() Return a string that indicates the TiDB server version    </description>
    </item>
    
    <item>
      <title>Infrastructure Engineer</title>
      <link>https://pingcap.com/recruit-cn/campus/campus-2019-infrastructure-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/campus-2019-infrastructure-engineer/</guid>
      <description>Infrastructure Engineer 职位描述：
如果你：
 内心不安，喜欢挑战和创新；
 熟悉分布式系统，大数据或者数据库领域；
 想和简单有爱的 PingCAP 的工程师们一起做世界级的开源项目。
  那么你就是我们要找的人。
在分布式数据库领域有很多迷人的问题需要去解决，如果你对任何一个问题感到无比的好奇，想要深挖究竟，都可以来和我们聊聊。
 想深入理解业界最前沿的分布式数据库 Spanner 的设计和思考，如何从 0 到 1 落地实现；
 如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能；
 如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务；
 如何实现一个高效的分布式事务管理器，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠；
 如何基于一致性的 Raft 协议实现快速稳定的数据复制和自动故障恢复，确保数据安全；
 如何在一个 PR 提交之后，快速验证千万级别的 tests 是否全部通过，性能有没有显著提升；
 &amp;hellip;&amp;hellip;
  待遇：
15K - 20K + 期权, 13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京，上海，广州，杭州、深圳、成都</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Ansible</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-ansible/</guid>
      <description>Install and Deploy TiKV Using Ansible This guide describes how to install and deploy TiKV using Ansible. Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiKV cluster which includes PD, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Binary Files</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-binary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-binary/</guid>
      <description>Install and Deploy TiKV Using Binary Files This guide describes how to deploy a TiKV cluster using binary files.
 To quickly understand and try TiKV, see Deploy the TiKV cluster on a single machine. To try TiKV out and explore the features, see Deploy the TiKV cluster on multiple nodes for testing.  Deploy the TiKV cluster on a single machine This section describes how to deploy TiKV on a single machine installed with the Linux system.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-docker/</guid>
      <description>Install and Deploy TiKV Using Docker This guide describes how to deploy a multi-node TiKV cluster using Docker.
Prerequisites Make sure that Docker is installed on each machine.
For more details about prerequisites, see Hardware and Software Requirements.
Deploy the TiKV cluster on multiple nodes Assume that you have 6 machines with the following details:
   Name Host IP Services Data Path     Node1 192.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker Compose</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-docker-compose/</guid>
      <description>Install and Deploy TiKV Using Docker Compose This guide describes how to quickly deploy a TiKV testing cluster using Docker Compose on a single machine.
 Note: Currently, this installation method only supports the Linux system.
 Prerequisites Make sure you have installed the following items on your machine:
 Docker (17.06.0 or later) and Docker Compose
sudo yum install docker docker-compose Helm
curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash Git
sudo yum install git  Install and deploy  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>Introduction to Statistics</title>
      <link>https://pingcap.com/docs/sql/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/statistics/</guid>
      <description>Introduction to Statistics Based on the statistics, the TiDB optimizer chooses the most efficient query execution plan. The statistics collect table-level and column-level information.
 The statistics of a table include the total number of rows and the number of updated rows. The statistics of a column include the number of different values, the number of NULL, the histogram, and the Count-Min Sketch of the column.  Collect statistics Manual collection You can run the ANALYZE statement to collect statistics.</description>
    </item>
    
    <item>
      <title>JSON Functions</title>
      <link>https://pingcap.com/docs/sql/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/json-functions/</guid>
      <description> JSON Functions    Function Name and Syntactic Sugar Description     JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) Return data from a JSON document, selected from the parts of the document matched by the path arguments   JSON_UNQUOTE(json_val) Unquote JSON value and return the result as a utf8mb4 string   JSON_TYPE(json_val) Return a utf8mb4 string indicating the type of a JSON value   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) Insert or update data in a JSON document and return the result   JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) Insert data into a JSON document and return the result   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) Replace existing values in a JSON document and return the result   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) Remove data from a JSON document and return the result   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) Merge two or more JSON documents and return the merged result   JSON_OBJECT(key, val[, key, val] &amp;hellip;) Evaluate a (possibly empty) list of key-value pairs and return a JSON object containing those pairs   JSON_ARRAY([val[, val] &amp;hellip;]) Evaluate a (possibly empty) list of values and return a JSON array containing those values   -&amp;gt; Return value from JSON column after evaluating path; the syntactic sugar of JSON_EXTRACT(doc, path_literal)   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; the syntactic sugar of JSON_UNQUOTE(JSONJSON_EXTRACT(doc, path_literal))    </description>
    </item>
    
    <item>
      <title>JSON Functions and Generated Column</title>
      <link>https://pingcap.com/docs/sql/json-functions-generated-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/json-functions-generated-column/</guid>
      <description>JSON Functions and Generated Column About To be compatible with MySQL 5.7 or later and better support the document store, TiDB supports JSON in the latest version. In TiDB, a document is a set of Key-Value pairs, encoded as a JSON object. You can use the JSON datatype in a TiDB table and create indexes for the JSON document fields using generated columns. In this way, you can flexibly deal with the business scenarios with uncertain schema and are no longer limited by the read performance and the lack of support for transactions in traditional document databases.</description>
    </item>
    
    <item>
      <title>JSON 函数及 Generated Column</title>
      <link>https://pingcap.com/docs-cn/sql/json-functions-generated-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/json-functions-generated-column/</guid>
      <description>JSON 函数及 Generated Column 概述 为了在功能上兼容 MySQL 5.7 及以上，同时更好地支持文档类型存储，我们在最新版本的 TiDB 中加入了 JSON 的支持。TiDB 所支持的文档是指以 JSON 为编码类型的键值对的组合。用户可以在 TiDB 的表中使用 JSON 类型的字段，同时以生成列（generated column）的方式为 JSON 文档内部的字段建立索引。基于此，用户可以很灵活地处理那些 schema 不确定的业务，同时不必受限于传统文档数据库糟糕的读性能及匮乏的事务支持。
JSON 功能介绍 TiDB 的 JSON 主要参考了 MySQL 5.7 的用户接口。例如，可以创建一个表，包含一个 JSON 字段来存储那些复杂的信息：
CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON ); 当我们向表中插入数据时，便可以这样处理那些模式不确定的数据了：
INSERT INTO person (name, address_info) VALUES (&amp;#34;John&amp;#34;, &amp;#39;{&amp;#34;city&amp;#34;: &amp;#34;Beijing&amp;#34;}&amp;#39;); 就这么简单！直接在 JSON 字段对应的位置上，放一个合法的 JSON 字符串，就可以向表中插入 JSON 了。TiDB 会解析这个文本，然后以一种更加紧凑、易于访问的二进制形式来保存。</description>
    </item>
    
    <item>
      <title>JSON 相关的函数和语法糖</title>
      <link>https://pingcap.com/docs-cn/sql/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/json-functions/</guid>
      <description> JSON 相关的函数和语法糖    函数或语法糖 功能描述     JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) 从 JSON 文档中解出某一路径对应的子文档   JSON_UNQUOTE(json_val) 去掉 JSON 文档外面的引号   JSON_TYPE(json_val) 检查某 JSON 文档内部内容的类型   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中为某一路径设置子文档   JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中在某一路径下插入子文档   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) 替换 JSON 文档中的某一路径下的子文档   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) 移除 JSON 文档中某一路径下的子文档   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) 将多个 JSON 文档合并成一个文档，其类型为数组   JSON_OBJECT(key, val[, key, val] &amp;hellip;) 根据一系列 K/V 对创建一个 JSON 文档   JSON_ARRAY([val[, val] &amp;hellip;]) 根据一系列元素创建一个 JSON 文档   -&amp;gt; JSON_EXTRACT(doc, path_literal) 的语法糖   -&amp;gt;&amp;gt; JSON_UNQUOTE(JSONJSON_EXTRACT(doc, path_literal)) 的语法糖    </description>
    </item>
    
    <item>
      <title>Key Metrics</title>
      <link>https://pingcap.com/docs/op-guide/dashboard-overview-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/dashboard-overview-info/</guid>
      <description>Key Metrics If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see Overview of the Monitoring Framework .
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
For routine operations, you can get an overview of the component (PD, TiDB, TiKV) status and the entire cluster from the Overview dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Keywords and Reserved Words</title>
      <link>https://pingcap.com/docs/sql/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/keywords-and-reserved-words/</guid>
      <description>Keywords and Reserved Words Keywords are words that have significance in SQL. Certain keywords, such as SELECT, UPDATE, or DELETE, are reserved and require special treatment for use as identifiers such as table and column names. For example, as table names, the reserved words must be quoted with backquotes:
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Literal Values</title>
      <link>https://pingcap.com/docs/sql/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/literal-values/</guid>
      <description>Literal Values This document describes String literals, Numeric literals, NULL values, Hexadecimal literals, Date and time literals, Boolean literals, and Bit-value literals.
String literals A string is a sequence of bytes or characters, enclosed within either single quote &#39; or double quote &amp;quot; characters. For example:
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; Quoted strings placed next to each other are concatenated to a single string. The following lines are equivalent:
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; If the ANSI_QUOTES SQL MODE is enabled, string literals can be quoted only within single quotation marks because a string quoted within double quotation marks is interpreted as an identifier.</description>
    </item>
    
    <item>
      <title>Loader Instructions</title>
      <link>https://pingcap.com/docs/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/loader/</guid>
      <description>Loader Instructions What is Loader? Loader is a data import tool to load data to TiDB.
Download the Binary.
Why did we develop Loader? Since tools like mysqldump will take us days to migrate massive amounts of data, we used the mydumper/myloader suite to multi-thread export and import data. During the process, we found that mydumper works well. However, as myloader lacks functions of error retry and savepoint, it is inconvenient for us to use.</description>
    </item>
    
    <item>
      <title>Loader 使用文档</title>
      <link>https://pingcap.com/docs-cn/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/loader/</guid>
      <description>Loader 使用文档 Loader 简介 Loader 是由 PingCAP 开发的数据导入工具，用于向 TiDB 中导入数据。
Binary 下载
为什么我们要做这个工具 当数据量比较大的时候，如果用 mysqldump 这样的工具迁移数据会比较慢。我们尝试了 mydumper/myloader 套件，能够多线程导出和导入数据。在使用过程中，mydumper 问题不大，但是 myloader 由于缺乏出错重试、断点续传这样的功能，使用起来很不方便。所以我们开发了 loader，能够读取 mydumper 的输出数据文件，通过 MySQL protocol 向 TiDB/MySQL 中导入数据。
Loader 有哪些优点  多线程导入
 支持表级别的并发导入，分散写入热点
 支持对单个大表并发导入，分散写入热点
 支持 mydumper 数据格式
 出错重试
 断点续导
 通过 system variable 优化 TiDB 导入数据速度
  使用方法 注意事项 请勿使用 loader 导入 MySQL 实例中 mysql 系统数据库到下游 TiDB。
如果 mydumper 使用 -m 参数，会导出不带表结构的数据，这时 loader 无法导入数据。</description>
    </item>
    
    <item>
      <title>Marketing Specialist</title>
      <link>https://pingcap.com/recruit-cn/campus/campus-2019-marketing-specialist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/campus-2019-marketing-specialist/</guid>
      <description>市场专员 岗位职责：
 市场营销策略的战术执行和专项营销活动的支持，包括品牌、社区、营销类活动的信息收集，执行和活动后传播及效果汇总；
 协助社区的用户运营和内容运营，构建及完善社区成员关系网，提升活跃度；
 跟踪和分析市场运营数据及媒体指标，负责市场类标准信息的定期更新和整理分类；
 周边衍生品的开发及制作，管理供应商，以及物料的日常分发管理。
  任职要求：
 计算机、市场营销、语言类专业，对编程有基础或有了解者优先；
 具有较强的逻辑思维能力、协调能力与文字功底；
 良好的沟通技能及团队合作能力，做事细致，责任感强。
  加分项：
熟悉技术开源社区，对社区需求有敏感性。
待遇：
8K - 15K，13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>Migrate Data from MySQL to TiDB</title>
      <link>https://pingcap.com/docs/op-guide/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/migration/</guid>
      <description>Migrate Data from MySQL to TiDB Use the mydumper / loader tool to export and import all the data You can use mydumper to export data from MySQL and loader to import the data into TiDB.
 Note: Although TiDB also supports the official mysqldump tool from MySQL for data migration, it is not recommended to use it. Its performance is much lower than mydumper / loader and it takes much time to migrate large amounts of data.</description>
    </item>
    
    <item>
      <title>Migration Overview</title>
      <link>https://pingcap.com/docs/op-guide/migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/migration-overview/</guid>
      <description>Migration Overview Overview This document describes how to migrate data from MySQL to TiDB in detail.
See the following for the assumed MySQL and TiDB server information:
   Name Address Port User Password     MySQL 127.0.0.1 3306 root *   TiDB 127.0.0.1 4000 root *    Scenarios  To import all the history data. This needs the following tools:
 Checker: to check if the shema is compatible with TiDB.</description>
    </item>
    
    <item>
      <title>Milestones</title>
      <link>https://pingcap.com/tidb-planet/milestones/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/milestones/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Miscellaneous Functions</title>
      <link>https://pingcap.com/docs/sql/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/miscellaneous-functions/</guid>
      <description> Miscellaneous Functions    Name Description     ANY_VALUE() Suppress ONLY_FULL_GROUP_BY value rejection   SLEEP() Sleep for a number of seconds   UUID() Return a Universal Unique Identifier (UUID)   VALUES() Defines the values to be used during an INSERT   INET_ATON() Return the numeric value of an IP address   INET_NTOA() Return the IP address from a numeric value   INET6_ATON() Return the numeric value of an IPv6 address   INET6_NTOA() Return the IPv6 address from a numeric value   IS_IPV4() Whether argument is an IPv4 address   IS_IPV4_COMPAT() Whether argument is an IPv4-compatible address   IS_IPV4_MAPPED() Whether argument is an IPv4-mapped address   IS_IPV6() Whether argument is an IPv6 address   GET_LOCK() Get a named lock   RELEASE_LOCK() Releases the named lock    </description>
    </item>
    
    <item>
      <title>Monitor a TiDB Cluster</title>
      <link>https://pingcap.com/docs/op-guide/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/monitor/</guid>
      <description>Monitor a TiDB Cluster Currently there are two types of interfaces to monitor the state of the TiDB cluster:
 Using the HTTP interface to get the internal information of a component, which is called the component state interface. Using Prometheus to record the detailed information of the various operations in the components, which is called the Metrics interface.  The component state interface You can use this type of interface to monitor the basic information of the component.</description>
    </item>
    
    <item>
      <title>NULL Values</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-null-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-null-values/</guid>
      <description>NULL Values NULL 代表数据为空，它是大小写不敏感的，与 \N(大小写敏感) 同义。
需要注意的是 NULL 跟 0 并不一样，跟空字符串 &#39;&#39; 也不一样。</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://pingcap.com/news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/news/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Numeric Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/numeric-functions-and-operators/</guid>
      <description> Numeric Functions and Operators This document describes the arithmetic operators and mathematical functions.
Arithmetic operators    Name Description     + Addition operator   - Minus operator   * Multiplication operator   / Division operator   DIV Integer division   %, MOD Modulo operator   - Change the sign of the argument    Mathematical functions    Name Description     POW() Return the argument raised to the specified power   POWER() Return the argument raised to the specified power   EXP() Raise to the power of   SQRT() Return the square root of the argument   LN() Return the natural logarithm of the argument   LOG() Return the natural logarithm of the first argument   LOG2() Return the base-2 logarithm of the argument   LOG10() Return the base-10 logarithm of the argument   PI() Return the value of pi   TAN() Return the tangent of the argument   COT() Return the cotangent   SIN() Return the sine of the argument   COS() Return the cosine   ATAN() Return the arc tangent   ATAN2(), ATAN() Return the arc tangent of the two arguments   ASIN() Return the arc sine   ACOS() Return the arc cosine   RADIANS() Return argument converted to radians   DEGREES() Convert radians to degrees   MOD() Return the remainder   ABS() Return the absolute value   CEIL() Return the smallest integer value not less than the argument   CEILING() Return the smallest integer value not less than the argument   FLOOR() Return the largest integer value not greater than the argument   ROUND() Round the argument   RAND() Return a random floating-point value   SIGN() Return the sign of the argument   CONV() Convert numbers between different number bases   TRUNCATE() Truncate to specified number of decimal places   CRC32() Compute a cyclic redundancy check value    </description>
    </item>
    
    <item>
      <title>Numeric Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-numeric-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-numeric-literals/</guid>
      <description>Numeric Literals 数值字面值包括 integer 跟 Decimal 类型跟浮点数字面值。
integer 可以包括 . 作为小数点分隔，数字前可以有 - 或者 + 来表示正数或者负数。
精确数值字面值可以表示为如下格式：1, .2, 3.4, -5, -6.78, +9.10.
科学记数法也是被允许的，表示为如下格式：1.2E3, 1.2E-3, -1.2E3, -1.2E-3。
更多细节</description>
    </item>
    
    <item>
      <title>OPS Engineer</title>
      <link>https://pingcap.com/recruit-cn/campus/campus-2019-ops-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/campus-2019-ops-engineer/</guid>
      <description>数据库工程师 岗位职责:
 负责对客户进行 TiDB 项目实施、技术支持，包括配置管理、升级、扩容、备份、数据迁移等工作；
 负责用户 TiDB 集群监控、故障响应、问题跟踪及性能分析处理；
 负责与用户进行需求沟通、技术培训，介绍 TiDB 的原理、使用方式、最佳实践等；
 研究 TiDB，对某细分方向，如 TiDB 自动化管理、SQL 优化、故障诊断等有持续产出和贡献。
  任职要求:
 以“折腾” Linux 为乐；
 掌握一门基础编程语言，如 C/C++/Go/Rust/…… 等；
 熟练掌握一门脚本语言，如 Shell/Python/Perl/…… 等；
 高度的责任心、良好的沟通技巧和团队合作精神。
  加分项:
 拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历；
 熟悉一种关系型数据库的（如 MySQL ）配置、备份、优化、监控、管理；
 良好的适应和学习能力对自己不设限，挑战如：数据可视化，监控告警 DevOPS，商业/工具产品设计等方向。
  待遇：
8K - 15K，14薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>Operators</title>
      <link>https://pingcap.com/docs/sql/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/operators/</guid>
      <description>Operators This document describes the operators precedence, comparison functions and operators, logical operators, and assignment operators.
 Operator precedence Comparison functions and operators Logical operators Assignment operators     Name Description     AND, &amp;amp;&amp;amp; Logical AND   = Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)   := Assign a value   BETWEEN &amp;hellip; AND &amp;hellip; Check whether a value is within a range of values   BINARY Cast a string to a binary string   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   CASE Case operator   DIV Integer division   / Division operator   = Equal operator   &amp;lt;=&amp;gt; NULL-safe equal to operator   &amp;gt; Greater than operator   &amp;gt;= Greater than or equal operator   IS Test a value against a boolean   IS NOT Test a value against a boolean   IS NOT NULL NOT NULL value test   IS NULL NULL value test   -&amp;gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT())   &amp;lt;&amp;lt; Left shift   &amp;lt; Less than operator   &amp;lt;= Less than or equal operator   LIKE Simple pattern matching   - Minus operator   %, MOD Modulo operator   NOT, !</description>
    </item>
    
    <item>
      <title>Overview of TiKV</title>
      <link>https://pingcap.com/docs/tikv/tikv-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/tikv-overview/</guid>
      <description>Overview of TiKV TiKV (The pronunciation is: /&amp;lsquo;taɪkeɪvi:/ tai-K-V, etymology: titanium) is a distributed Key-Value database which is based on the design of Google Spanner and HBase, but it is much simpler without dependency on any distributed file system.
As the storage layer of TiDB, TiKV can work separately and does not depend on the SQL layer of TiDB. To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API.</description>
    </item>
    
    <item>
      <title>Overview of the TiDB Monitoring Framework</title>
      <link>https://pingcap.com/docs/op-guide/monitor-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/monitor-overview/</guid>
      <description>Overview of the Monitoring Framework The TiDB monitoring framework adopts two open source projects: Prometheus and Grafana. TiDB uses Prometheus to store the monitoring and performance metrics and Grafana to visualize these metrics.
About Prometheus in TiDB As a time series database, Prometheus has a multi-dimensional data model and flexible query language. As one of the most popular open source projects, many companies and organizations have adopted Prometheus, and the project has a very active community.</description>
    </item>
    
    <item>
      <title>PD Control User Guide</title>
      <link>https://pingcap.com/docs/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/pd-control/</guid>
      <description>PD Control User Guide As a command line tool of PD, PD Control obtains the state information of the cluster and tunes the cluster.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-ctl   Note: Generally, you don&amp;rsquo;t need to compile source code as the PD Control tool already exists in the released Binary or Docker.</description>
    </item>
    
    <item>
      <title>PD Control 使用说明</title>
      <link>https://pingcap.com/docs-cn/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/pd-control/</guid>
      <description>PD Control 使用说明 PD Control 是 PD 的命令行工具，用于获取集群状态信息和调整集群。
源码编译  Go Version 1.9 以上 在 PD 项目根目录使用 make 命令进行编译，生成 bin/pd-ctl  简单例子 单命令模式：
./pd-ctl store -d -u http://127.0.0.1:2379 交互模式：
./pd-ctl -u http://127.0.0.1:2379 使用环境变量：
export PD_ADDR=http://127.0.0.1:2379 ./pd-ctl 使用TLS加密：
./pd-ctl -u https://127.0.0.1:2379 --cacert=&amp;#34;path/to/ca&amp;#34; --cert=&amp;#34;path/to/cert&amp;#34; --key=&amp;#34;path/to/key&amp;#34; 命令行参数(flags) --pd,-u  指定 PD 的地址 默认地址: http://127.0.0.1:2379 环境变量: PD_ADDR  --detach,-d  使用单命令行模式(不进入 readline) 默认值: false  &amp;ndash;cacert  指定 PEM 格式的受信任 CA 的证书文件路径 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;cert  指定 PEM 格式的 SSL 证书文件路径 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;key  指定 PEM 格式的 SSL 证书密钥文件路径，即 --cert 所指定的证书的私钥 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;version,-V  打印版本信息并退出 默认值: false  命令(command) cluster 用于显示集群基本信息。</description>
    </item>
    
    <item>
      <title>PD Recover User Guide</title>
      <link>https://pingcap.com/docs/tools/pd-recover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/pd-recover/</guid>
      <description>PD Recover User Guide PD Recover is a disaster recovery tool of PD, used to recover the PD cluster which cannot start or provide services normally.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-recover  Usage This section describes how to recover a PD cluster which cannot start or provide services normally.</description>
    </item>
    
    <item>
      <title>PD Recover 使用文档</title>
      <link>https://pingcap.com/docs-cn/tools/pd-recover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/pd-recover/</guid>
      <description> PD Recover 使用文档 PD Recover 是对 PD 进行灾难性恢复的工具，用于恢复无法正常启动或服务的 PD 集群。
源码编译  Go Version 1.9 以上 在 PD 项目根目录使用 make 命令进行编译，生成 bin/pd-recover  使用方法 参数说明 -alloc-id uint 指定比原集群已分配过的 ID 更大的数 -cacert string 指定 PEM 格式的受信任 CA 的证书文件路径 -cert string 指定 PEM 格式的 SSL 证书文件路径 -key string 指定 PEM 格式的 SSL 证书密钥文件路径，即 `--cert` 所指定的证书的私钥 -cluster-id uint 指定原集群的 cluster ID -endpoints string 指定 PD 的地址 (default &amp;#34;http://127.0.0.1:2379&amp;#34;) 恢复流程  从当前集群中找到集群的 Cluster ID 和 Alloc ID。一般在 PD，TiKV 或 TiDB 的日志中都可以获取 Cluster ID。已经分配过的 Alloc ID 可以从 PD 日志获得。另外也可以从 PD 的监控面板的 Metadata Information 监控项中获得。在指定 alloc-id 时需指定一个比当前最大的 Alloc ID 更大的值。如果没有途径获取 Alloc ID，可以根据集群中的 Region，Store 数预估一个较大的数，一般可取高几个数量级的数。 停止整个集群，清空 PD 数据目录，重启 PD 集群。 使用 PD recover 进行恢复，注意指定正确的 cluster-id 和合适的 alloc-id。 提示恢复成功后，重启整个集群。  </description>
    </item>
    
    <item>
      <title>PD 研发工程师</title>
      <link>https://pingcap.com/recruit-cn/engineering/pd-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/pd-engineer/</guid>
      <description>PD 研发工程师 岗位职责：
负责 TiDB 集群中心控制组件 Placement Driver (PD) 的开发工作，包括但不限于：
 负责集群全局调度系统的设计，开发，文档撰写；
 负责集群模拟器的开发；
 负责集群可视化系统的开发。
  任职要求：
 三年以上相关领域开发经验，扎实的编程能力，熟悉 C/C++/Go/Java/Python 中的一种；
 对分布式系统的架构和原理有比较深入的了解；
 优秀的发现和解决问题能力，良好的沟通能力，良好的抗压能力，具备团队合作精神。
  加分项：
 精通 Go 语言，能熟练使用 Go pprof 分析和解决性能问题；
 有分布式调度系统相关开发经验；
 有开源项目经历，对前沿技术有浓厚的热情；
 有 Rust 语言开发经验。
  待遇：
20K - 40K，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>Pre-GA release notes</title>
      <link>https://pingcap.com/docs/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/prega/</guid>
      <description> Pre-GA Release Notes On August 30, 2017, TiDB Pre-GA is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Use index scan to handle the where clause with the compare expression which has different types on each side Support the Greedy algorithm based Join Reorder  Many enhancements have been introduced to be more compatible with MySQL Support Natural Join Support the JSON type (Experimental), including the query, update and index of the JSON fields Prune the useless data to reduce the consumption of the executor memory Support configuring prioritization in the SQL statements and automatically set the prioritization for some of the statements according to the query type Completed the expression refactor and the speed is increased by about 30%  Placement Driver (PD):  Support manually changing the leader of the PD cluster  TiKV:  Use dedicated Rocksdb instance to store Raft log Use DeleteRange to speed up the deleting of replicas Coprocessor now supports more pushdown operators Improve the performance and stability  TiDB Connector for Spark Beta Release:  Implement the predicates pushdown Implement the aggregation pushdown Implement range pruning Capable of running full set of TPC+H except for one query that needs view support  </description>
    </item>
    
    <item>
      <title>Precision Math</title>
      <link>https://pingcap.com/docs/sql/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/precision-math/</guid>
      <description>Precision Math The precision math support in TiDB is consistent with MySQL. For more information, see Precision Math in MySQL.
Numeric types The scope of precision math for exact-value operations includes the exact-value data types (integer and DECIMAL types) and exact-value numeric literals. Approximate-value data types and numeric literals are handled as floating-point numbers.
Exact-value numeric literals have an integer part or fractional part, or both. They may be signed.</description>
    </item>
    
    <item>
      <title>Prepared SQL Statement Syntax</title>
      <link>https://pingcap.com/docs/sql/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/prepare/</guid>
      <description>Prepared SQL Statement Syntax TiDB supports server-side Prepared statements, which can reduce the load of statement parsing and query optimization and improve execution efficiency. You can use Prepared statements in two ways: application programs and SQL statements.
Use application programs Most MySQL Drivers support Prepared statements, such as MySQL Connector/C. You can call the Prepared statement API directly through the Binary protocol.
Use SQL statements You can also implement Prepared statements using PREPARE, EXECUTE and DEALLOCATE PREPARE.</description>
    </item>
    
    <item>
      <title>Prepared SQL 语句语法</title>
      <link>https://pingcap.com/docs-cn/sql/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/prepare/</guid>
      <description>Prepared SQL 语句语法 TiDB 支持服务器端的 Prepared 语句，这种方式可以降低语句解析以及查询优化的开销，提高执行效率。有两种方式可以使用 Prepared 语句：
通过应用程序 大多数 MySQL Driver 都支持 Prepared 语句，比如 MySQL Connector/C。这种方式可以通过 Binary 协议直接调用 Prepared 语句 API。
通过 SQL 语句 通过 PREPARE，EXECUTE 以及 DEALLOCATE PREPARE 这三个语句也可以实现 Prepared 语句，这种方式不如第一种方式效率高，但是不需要写程序即可使用。
PREPARE 语句 PREPARE stmt_name FROM preparable_stmt PREPARE 语句对 preparable_stmt 做预处理（语法解析、语义检查、查询优化）并将其处理结果命名为 stmt_name，后面的操作可以通过 stmt_name 来引用。处理好的语句可以通过 EXECUTE 语句执行或者是通过 DEALLOCATE PREPARE 语句释放。
EXECUTE 语句 EXECUTE stmt_name [USING @var_name [, @var_name] ...] EXECUTE 语句执行名字为 stmt_name 的预处理语句。如果预处理语句中有参数，则可以通过 USING 子句中的 User Variable 列表给参数赋值。</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://pingcap.com/privacy-policy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/privacy-policy/</guid>
      <description>PINGCAP PRIVACY POLICY Effective Date: October 10, 2018
PingCAP obtains and uses personal information about individuals to enhance our ability to deliver the highest level of service, but we also recognize that you expect us to treat this information appropriately. This privacy policy explains how PingCAP uses, shares and protects personal information that it collects on pingcap.com and any related mobile applications and websites operated by PingCAP (&amp;ldquo;Site&amp;rdquo;).
By visiting the Site or purchasing, enrolling in or using our product and services, you agree to this Privacy Policy, as it may be amended from time to time.</description>
    </item>
    
    <item>
      <title>Privilege Management</title>
      <link>https://pingcap.com/docs/sql/privilege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/privilege/</guid>
      <description>Privilege Management TiDB&amp;rsquo;s privilege management system is implemented according to the privilege management system in MySQL. It supports most of the syntaxes and privilege types in MySQL. If you find any inconsistency with MySQL, feel free to open an issue.
Examples User account operation TiDB user account names consist of a user name and a host name. The account name syntax is &#39;user_name&#39;@&#39;host_name&#39;.
 The user_name is case sensitive. The host_name can be a host name or an IP address.</description>
    </item>
    
    <item>
      <title>Reading Data from History Versions</title>
      <link>https://pingcap.com/docs/op-guide/history-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/history-read/</guid>
      <description>Reading Data From History Versions This document describes how TiDB reads data from the history versions, how TiDB manages the data versions, as well as an example to show how to use the feature.
Feature description TiDB implements a feature to read history data using the standard SQL interface directly without special clients or drivers. By using this feature, - Even when data is updated or removed, its history versions can be read using the SQL interface.</description>
    </item>
    
    <item>
      <title>Release Notes</title>
      <link>https://pingcap.com/docs/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rn/</guid>
      <description> TiDB Release Notes  2.1 RC3 2.1 RC2 2.0.7 2.1 RC1 2.0.6 2.0.5 2.1 Beta 2.0.4 2.0.3 2.0.2 2.0.1 2.0 2.0 RC5 2.0 RC4 2.0 RC3 2.0 RC1 1.1 Beta 1.0.8 1.0.7 1.1 Alpha 1.0.6 1.0.5 1.0.4 1.0.3 1.0.2 1.0.1 1.0 Pre-GA RC4 RC3 RC2 RC1  </description>
    </item>
    
    <item>
      <title>Release Notes</title>
      <link>https://pingcap.com/tidb-planet/release-notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/release-notes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scale a TiDB cluster</title>
      <link>https://pingcap.com/docs/op-guide/horizontal-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/horizontal-scale/</guid>
      <description>Scale a TiDB cluster Overview The capacity of a TiDB cluster can be increased or reduced without affecting online services.
 Note: If your TiDB cluster is deployed using Ansible, see Scale the TiDB Cluster Using TiDB-Ansible.
 The following part shows you how to add or delete PD, TiKV or TiDB nodes.
About pd-ctl usage, refer to PD Control User Guide.
PD Assume we have three PD servers with the following details:</description>
    </item>
    
    <item>
      <title>Scale the TiDB Cluster Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/op-guide/ansible-deployment-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/ansible-deployment-scale/</guid>
      <description>Scale the TiDB Cluster Using TiDB-Ansible The capacity of a TiDB cluster can be increased or decreased without affecting the online services.
 Warning: In decreasing the capacity, if your cluster has a mixed deployment of other services, do not perform the following procedures. The following examples assume that the removed nodes have no mixed deployment of other services.
 Assume that the topology is as follows:
   Name Host IP Services     node1 172.</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs-cn/sql/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/schema-object-names/</guid>
      <description>Schema Object Names 在 TiDB 中，包括 database，table，index，column，alias 等等都被认为是 identifier (标识符，之后阐述用英文).
在 TiDB 中，identifier可以被反引号 (`) 包裹，为了阐述方便，我们叫这种情况为 被引用。identifier 也可以不被 ` 包裹。 但是如果一个 identifier 存在一个特殊符号或者是一个保留关键字，那么你必须要 引用 它。
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; 如果ANSI_QUOTES sql mode 被设置了，那么我们认为被双引号 &amp;quot; 包裹的字符串为 identifier。
mysql&amp;gt; CREATE TABLE &amp;#34;test&amp;#34; (a varchar(10)); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a varchar(10))&amp;#34; (total length 35) mysql&amp;gt; SET SESSION sql_mode=&amp;#39;ANSI_QUOTES&amp;#39;; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs/sql/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/schema-object-names/</guid>
      <description>Schema Object Names Some objects names in TiDB, including database, table, index, column, alias, etc., are known as identifiers.
In TiDB, you can quote or unquote an identifier. If an identifier contains special characters or is a reserved word, you must quote it whenever you refer to it. To quote, use the backtick (`) to wrap the identifier. For example:
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; If the ANSI_QUOTES SQL mode is enabled, you can also quote identifiers within double quotation marks(&amp;ldquo;):</description>
    </item>
    
    <item>
      <title>Slow Query Log</title>
      <link>https://pingcap.com/docs/sql/slow-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/slow-query/</guid>
      <description>Slow Query Log The slow query log is a record of SQL statements that took a long time to perform.
A problematic SQL statement can increase the pressure on the entire cluster, resulting in a longer response time. To solve this problem, you can use the slow query log to identify the problematic statements and thus improve the performance.
Obtain the log By grep the keyword SLOW_QUERY in the log file of TiDB, you can obtain the logs of statements whose execution time exceeds slow-threshold.</description>
    </item>
    
    <item>
      <title>Software and Hardware Requirements</title>
      <link>https://pingcap.com/docs/op-guide/recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/recommendation/</guid>
      <description>Software and Hardware Requirements About As an open source distributed NewSQL database with high performance, TiDB can be deployed in the Intel architecture server and major virtualization environments and runs well. TiDB supports most of the major hardware networks and Linux operating systems.
Linux OS version requirements    Linux OS Platform Version     Red Hat Enterprise Linux 7.3 or later   CentOS 7.3 or later   Oracle Enterprise Linux 7.</description>
    </item>
    
    <item>
      <title>String Functions</title>
      <link>https://pingcap.com/docs/sql/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/string-functions/</guid>
      <description> String Functions    Name Description     ASCII() Return numeric value of left-most character   CHAR() Return the character for each integer passed   BIN() Return a string containing binary representation of a number   HEX() Return a hexadecimal representation of a decimal or string value   OCT() Return a string containing octal representation of a number   UNHEX() Return a string containing hex representation of a number   TO_BASE64() Return the argument converted to a base-64 string   FROM_BASE64() Decode to a base-64 string and return result   LOWER() Return the argument in lowercase   LCASE() Synonym for LOWER()   UPPER() Convert to uppercase   UCASE() Synonym for UPPER()   LPAD() Return the string argument, left-padded with the specified string   RPAD() Append string the specified number of times   TRIM() Remove leading and trailing spaces   LTRIM() Remove leading spaces   RTRIM() Remove trailing spaces   BIT_LENGTH() Return length of argument in bits   CHAR_LENGTH() Return number of characters in argument   CHARACTER_LENGTH() Synonym for CHAR_LENGTH()   LENGTH() Return the length of a string in bytes   OCTET_LENGTH() Synonym for LENGTH()   INSERT() Insert a substring at the specified position up to the specified number of characters   REPLACE() Replace occurrences of a specified string   SUBSTR() Return the substring as specified   SUBSTRING() Return the substring as specified   SUBSTRING_INDEX() Return a substring from a string before the specified number of occurrences of the delimiter   MID() Return a substring starting from the specified position   LEFT() Return the leftmost number of characters as specified   RIGHT() Return the specified rightmost number of characters   INSTR() Return the index of the first occurrence of substring   LOCATE() Return the position of the first occurrence of substring   POSITION() Synonym for LOCATE()   REPEAT() Repeat a string the specified number of times   CONCAT() Return concatenated string   CONCAT_WS() Return concatenate with separator   REVERSE() Reverse the characters in a string   SPACE() Return a string of the specified number of spaces   FIELD() Return the index (position) of the first argument in the subsequent arguments   ELT() Return string at index number   EXPORT_SET() Return a string such that for every bit set in the value bits, you get an on string and for every unset bit, you get an off string   MAKE_SET() Return a set of comma-separated strings that have the corresponding bit in bits set   FIND_IN_SET() Return the index position of the first argument within the second argument   FORMAT() Return a number formatted to specified number of decimal places   ORD() Return character code for leftmost character of the argument   QUOTE() Escape the argument for use in an SQL statement    String comparison functions    Name Description     LIKE Simple pattern matching   NOT LIKE Negation of simple pattern matching   STRCMP() Compare two strings    Regular expressions    Name Description     REGEXP Pattern matching using regular expressions   RLIKE Synonym for REGEXP   NOT REGEXP Negation of REGEXP    </description>
    </item>
    
    <item>
      <title>String Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-string-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-string-literals/</guid>
      <description>String Literals String Literals 是一个 bytes 或者 characters 的序列，两端被单引号 &#39; 或者双引号 &amp;quot; 包围，例如：
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; 如果字符串是连续的，会被合并为一个独立的 string。以下表示是一样的：
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; 如果 ANSI_QUOTES SQL MODE 开启了，那么只有单引号内的会被认为是 String Literals，对于双引号内的字符串，会被认为是一个 identifier。
binary string 是一串 bytes 组成的字符串，每一个 binary string 有一个叫做 binary 的 character set 和 collation。一个非二进制的字符串是一个由字符组成的字符串，它有除 binary 外的 character set和与之兼容的 collation。
对于两种字符串类型，比较都是基于每个字符的数值。对于 binary string 而言，比较单元就是字节，对于非二进制的字符串，那么单元就是字符，而有的字符集支持多字节字符。
一个 String Literal 可以拥有一个可选的 character set introducer 和 COLLATE clause，可以用来指派特定的字符集跟 collation（TiDB 对此只是做了语法上的兼容，并不实质做处理)。</description>
    </item>
    
    <item>
      <title>Success Stories</title>
      <link>https://pingcap.com/success-stories/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/success-stories/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Syncer User Guide</title>
      <link>https://pingcap.com/docs/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/syncer/</guid>
      <description>Syncer User Guide About Syncer Syncer is a tool used to import data incrementally. It is a part of the TiDB enterprise toolset. To obtain Syncer, see Download the TiDB enterprise toolset.
Syncer architecture Download the TiDB enterprise toolset (Linux) # Download the tool package. wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # Check the file integrity. If the result is OK, the file is correct. sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # Extract the package.</description>
    </item>
    
    <item>
      <title>Syncer 使用文档</title>
      <link>https://pingcap.com/docs-cn/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/syncer/</guid>
      <description>Syncer 使用文档 Syncer 简介 Syncer 是一个数据导入工具，能方便地将 MySQL 的数据增量导入到 TiDB。
Syncer 属于 TiDB 企业版工具集，如何获取可参考下载 TiDB 企业版工具集。
Syncer 架构 下载 TiDB 企业版工具集 (Linux) # 下载 tool 压缩包 wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-enterprise-tools-latest-linux-amd64.tar.gz cd tidb-enterprise-tools-latest-linux-amd64 Syncer 部署位置 Syncer 可以部署在任一台可以连通对应的 MySQL 和 TiDB 集群的机器上，推荐部署在 TiDB 集群。
Syncer 增量导入数据示例 使用前请详细阅读 Syncer 同步前预检查
设置同步开始的 position 设置 Syncer 的 meta 文件, 这里假设 meta 文件是 syncer.meta:</description>
    </item>
    
    <item>
      <title>Technical Writer</title>
      <link>https://pingcap.com/recruit-cn/campus/campus-2019-technical-writer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/campus-2019-technical-writer/</guid>
      <description>Technical Writer Qualifications:
 Bachelor&amp;rsquo;s degree or above in software, computer science or engineering relevant majors with an understanding of the software industry;
 Excellent command of both written and oral English;
 Experience and passion in writing software relevant topics;
 Experience in marketing research is a strong plus;
 An excellent communicator with a clear and concise writing style;
 Detail-oriented with sharp eyes and good troubleshooting skills;</description>
    </item>
    
    <item>
      <title>Technical Writer</title>
      <link>https://pingcap.com/recruit-cn/i18n/technical-writer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/i18n/technical-writer/</guid>
      <description>Technical Writer Qualifications:
 Bachelor&amp;rsquo;s degree or above in software, computer science or engineering relevant majors with an understanding of the software industry;
 Excellent command of both written and oral English;
 Experience and passion in writing software relevant topics;
 Experience in marketing research is a strong plus;
 An excellent communicator with a clear and concise writing style;
 Detail-oriented with sharp eyes and good troubleshooting skills;</description>
    </item>
    
    <item>
      <title>Technical Writer Intern</title>
      <link>https://pingcap.com/recruit-cn/campus/technical-writer-intern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/technical-writer-intern/</guid>
      <description>Technical Writer Intern Qualifications:
 Bachelor&amp;rsquo;s degree or above in software, computer science or engineering relevant majors with an understanding of the software industry;
 Excellent command of both written and oral English;
 Experience and passion in writing software relevant topics;
 Experience in marketing research is a strong plus;
 An excellent communicator with a clear and concise writing style;
 Detail-oriented with sharp eyes and good troubleshooting skills;</description>
    </item>
    
    <item>
      <title>Terms of Service</title>
      <link>https://pingcap.com/terms-of-service/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/terms-of-service/</guid>
      <description>Terms of Service Last Updated: October 10, 2018
By using PingCAP.com and any of PingCAP’s associated mobile applications and websites (“the Site”), you agree to be bound by these Terms of Service and to use the Site in accordance with these Terms of Service and our Privacy Policy. These Terms of Service constitute a binding legal contract between you and PingCAP and govern your use of the Site.
We reserve the right to change these Terms of Service or to impose new conditions on use of the Site, from time to time, in which case we will post the revised Terms of Service on this Site and update the “Last Updated” date to reflect the date of the changes.</description>
    </item>
    
    <item>
      <title>The Proprietary System Variables and Syntaxes in TiDB</title>
      <link>https://pingcap.com/docs/sql/tidb-specific/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/tidb-specific/</guid>
      <description>The Proprietary System Variables and Syntaxes in TiDB On the basis of MySQL variables and syntaxes, TiDB has defined some specific system variables and syntaxes to optimize performance.
System variable Variables can be set with the SET statement, for example:
set @@tidb_distsql_scan_concurrency = 10 If you need to set the global variable, run:
set @@global.tidb_distsql_scan_concurrency = 10 tidb_snapshot  Scope: SESSION Default value: &amp;ldquo;&amp;rdquo; This variable is used to set the time point at which the data is read by the session.</description>
    </item>
    
    <item>
      <title>The System Variables</title>
      <link>https://pingcap.com/docs/sql/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/variable/</guid>
      <description>The System Variables The system variables in MySQL are the system parameters that modify the operation of the database runtime. These variables have two types of scope, Global Scope and Session Scope. TiDB supports all the system variables in MySQL 5.7. Most of the variables are only supported for compatibility and do not affect the runtime behaviors.
Set the system variables You can use the SET statement to change the value of the system variables.</description>
    </item>
    
    <item>
      <title>The TiDB Command Options</title>
      <link>https://pingcap.com/docs/sql/server-command-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/server-command-option/</guid>
      <description>The TiDB Command Options This document describes the startup options and TiDB server configuration files.
TiDB startup options When you start TiDB processes, you can specify some program options.
TiDB supports a lot of startup options. Run the following command to get a brief introduction:
./tidb-server --help Run the following command to get the version:
./tidb-server -V The complete descriptions of startup options are as follows.
-L  Log level Default: &amp;ldquo;info&amp;rdquo; Optional values: debug, info, warn, error or fatal  -P  TiDB service monitor port Default: &amp;ldquo;4000&amp;rdquo; TiDB uses this port to accept requests from the MySQL client  --binlog-socket  TiDB uses the unix socket file to accept the internal connection, such as the PUMP service.</description>
    </item>
    
    <item>
      <title>The TiDB Server</title>
      <link>https://pingcap.com/docs/sql/tidb-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/tidb-server/</guid>
      <description>The TiDB Server TiDB refers to the TiDB database management system. This document describes the basic management functions of the TiDB cluster.
TiDB cluster startup configuration You can set the service parameters using the command line or the configuration file, or both. The priority of the command line parameters is higher than the configuration file. If the same parameter is set in both ways, TiDB uses the value set using command line parameters.</description>
    </item>
    
    <item>
      <title>The TiDB System Database</title>
      <link>https://pingcap.com/docs/sql/system-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/system-database/</guid>
      <description>The TiDB System Database The TiDB System Database is similar to MySQL, which contains tables that store information required by the server when it runs.
Grant system tables These system tables contain grant information about user accounts and their privileges:
 user: user accounts, global privileges, and other non-privilege columns db: database-level privileges tables_priv: table-level privileges columns_priv: column-level privileges  Server-side help system tables Currently, the help_topic is NULL.</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes 2017 年 10 月 16 日，TiDB 发布 GA 版（TiDB 1.0）。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB:  SQL 查询优化器
 调整代价模型 Analyze 下推 函数签名下推  优化内部数据格式，减小中间结果大小
 提升 MySQL 兼容性
 支持 NO_SQL_CACHE 语法，控制存储引擎对缓存的使用
 重构 Hash Aggregator 算子，降低内存使用
 支持 Stream Aggragator 算子
  PD:  支持基于读流量的热点调度 支持设置 Store 权重，以及基于权重的调度  TiKV:  Coprocessor 支持更多下推函数 支持取样操作下推 支持手动触发数据 Compact，用于快速回收空间 提升性能和稳定性 增加 Debug API，方便调试  TiSpark Beta Release:  支持可配置框架 支持 ThriftSever/JDBC 和 Spark SQL 脚本入口  源码地址 源码地址</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes On October 16, 2017, TiDB 1.0 is now released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Analyze pushdown Function signature pushdown  Optimize the internal data format to reduce the interim data size Enhance the MySQL compatibility Support the NO_SQL_CACHE syntax and limit the cache usage in the storage engine Refactor the Hash Aggregator operator to reduce the memory usage Support the Stream Aggregator operator  PD:  Support read flow based balancing Support setting the Store weight and weight based balancing  TiKV:  Coprocessor now supports more pushdown functions Support pushing down the sampling operation Support manually triggering data compact to collect space quickly Improve the performance and stability Add a Debug API for debugging TiSpark Beta Release: Support configuration framework Support ThriftSever/JDBC and Spark SQL  Acknowledgement Special thanks to the following enterprises and teams!</description>
    </item>
    
    <item>
      <title>TiDB 1.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/101/</guid>
      <description>TiDB 1.0.1 Release Notes On November 1, 2017, TiDB 1.0.1 is released with the following updates:
TiDB:  Support canceling DDL Job. Optimize the IN expression. Correct the result type of the Show statement. Support log slow query into a separate log file. Fix bugs.  TiKV:  Support flow control with write bytes. Reduce Raft allocation. Increase coprocessor stack size to 10MB. Remove the useless log from the coprocessor.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/102/</guid>
      <description> TiDB 1.0.2 Release Notes On November 13, 2017, TiDB 1.0.2 is released with the following updates:
TiDB:  Optimize the cost estimation of index point query Support the Alter Table Add Column (ColumnDef ColumnPosition) syntax Optimize the queries whose where conditions are contradictory Optimize the Add Index operation to rectify the progress and reduce repetitive operations Optimize the Index Look Join operator to accelerate the query speed for small data size Fix the issue with prefix index judgment  Placement Driver (PD):  Improve the stability of scheduling under exceptional situations  TiKV:  Support splitting table to ensure one region does not contain data from multiple tables Limit the length of a key to be no more than 4 KB More accurate read traffic statistics Implement deep protection on the coprocessor stack Fix the LIKE behavior and the do_div_mod bug  </description>
    </item>
    
    <item>
      <title>TiDB 1.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/103/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/103/</guid>
      <description>TiDB 1.0.3 Release Notes On November 28, 2017, TiDB 1.0.3 is released with the following updates:
TiDB  Optimize the performance in transaction conflicts scenario Add the TokenLimit option in the config file Output the default database in slow query logs Remove the DDL statement from query duration metrics Optimize the query cost estimation Fix the index prefix issue when creating tables Support pushing down the expressions for the Float type to TiKV Fix the issue that it is slow to add index for tables with discrete integer primary index Reduce the unnecessary statistics updates Fix a potential issue during the transaction retry  PD  Support adding more types of schedulers using API  TiKV  Fix the deadlock issue with the PD client Fix the issue that the wrong leader value is prompted for NotLeader Fix the issue that the chunk size is too large in the coprocessor  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/104/</guid>
      <description>TiDB 1.0.4 Release Notes On December 11, 2017, TiDB 1.0.4 is released with the following updates:
TiDB  Speed up the loading of the statistics when starting the tidb-server Improve the performance of the show variables statement Fix a potential issue when using the Add Index statement to handle the combined indexes Fix a potential issue when using the Rename Table statement to move a table to another database Accelerate the effectiveness for the Alter/Drop User statement  TiKV  Fix a possible performance issue when a snapshot is applied  Fix the performance issue for reverse scan after removing a lot of data Fix the wrong encoded result for the Decimal type under special circumstances  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/105/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/105/</guid>
      <description>TiDB 1.0.5 Release Notes On December 26, 2017, TiDB 1.0.5 is released with the following updates:
TiDB  Add the max value for the current Auto_Increment ID in the Show Create Table statement. Fix a potential goroutine leak. Support outputting slow queries into a separate file. Load the TimeZone variable from TiKV when creating a new session. Support the schema state check so that the Show Create Tableand Analyze statements process the public table/index only.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/106/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/106/</guid>
      <description>TiDB 1.0.6 Release Notes On January 08, 2018, TiDB 1.0.6 is released with the following updates:
TiDB:  Support the Alter Table Auto_Increment syntax Fix the bug in Cost Based computation and the Null Json issue in statistics Support the extension syntax to shard the implicit row ID to avoid write hot spot for a single table Fix a potential DDL issue Consider the timezone setting in the curtime, sysdate and curdate functions Support the SEPARATOR syntax in the GROUP_CONCAT function Fix the wrong return type issue of the GROUP_CONCAT function.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/107/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/107/</guid>
      <description>TiDB 1.0.7 Release Notes On January 22, 2018, TiDB 1.0.7 is released with the following updates:
TiDB:  Optimize the FIELD_LIST command Fix data race of the information schema Avoid adding read-only statements to history Add the session variable to control the log query Fix the resource leak issue in statistics Fix the goroutine leak issue Add schema info API for the http status server Fix an issue about IndexJoin Update the behavior when RunWorker is false in DDL Improve the stability of test results in statistics Support PACK_KEYS syntax for the CREATE TABLE statement Add row_id column for the null pushdown schema to optimize performance  PD:  Fix possible scheduling loss issue in abnormal conditions Fix the compatibility issue with proto3 Add the log  TiKV:  Support Table Scan Support the remote mode in tikv-ctl Fix the format compatibility issue of tikv-ctl proto Fix the loss of scheduling command from PD Add timeout in Push metric  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/releases/108/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/108/</guid>
      <description>TiDB 1.0.8 Release Notes On February 11, 2018, TiDB 1.0.8 is released with the following updates:
TiDB:  Fix issues in the Outer Join result in some scenarios Optimize the performance of the InsertIntoIgnore statement Fix the issue in the ShardRowID option Add limitation (Configurable, the default value is 5000) to the DML statements number within a transaction Fix an issue in the Table/Column aliases returned by the Prepare statement Fix an issue in updating statistics delta Fix a panic error in the Drop Column statement Fix an DML issue when running the Add Column After statement Improve the stability of the GC process by ignoring the regions with GC errors Run GC concurrently to accelerate the GC process Provide syntax support for the CREATE INDEX statement  PD:  Reduce the lock overheat of the region heartbeats Fix the issue that a hot region scheduler selects the wrong Leader  TiKV:  Use DeleteFilesInRanges to clear stale data and improve the TiKV starting speed Using Decimal in Coprocessor sum Sync the metadata of the received Snapshot compulsorily to ensure its safety  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes 2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB：  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确地估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT IGNORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD：  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 Region size Fix 了一些调度的 bug  TiKV：  支持 Raft learner 优化 Raft Snapshot，减少 I/O 开销 支持 TLS 优化 RocksDB 配置，提升性能 优化 Coprocessor count (*) 和点查 unique index 的性能 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 tikv-ctl 的功能 Region 支持按 table 进行分裂 支持 Delete Range 功能 支持设置 snapshot 导致的 I/O 上限 完善流控机制  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes On January 19, 2018, TiDB 1.1 Alpha is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  SQL parser  Support more syntax  SQL query optimizer  Use more compact structure to reduce statistics info memory usage Speed up loading statistics info when starting tidb-server Provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of queries using unique index more accurately Support more complex conditions to make full use of index  SQL executor  Refactor all executor operators using Chunk architecture, improve the execution performance of analytical statements and reduce memory usage Optimize performance of the INSERT IGNORE statement Push down more types and functions to TiKV Support more SQL_MODE Optimize the Load Data performance to increase the speed by 10 times Optimize the Use Database performance Support statistics on the memory usage of physical operators  Server  Support the PROXY protocol   PD:  Add more APIs Support TLS Add more cases for scheduling Simulator Schedule to adapt to different Region sizes Fix some bugs about scheduling  TiKV:  Support Raft learner Optimize Raft Snapshot and reduce the I/O overhead Support TLS Optimize the RocksDB configuration to improve performance Optimize count (*) and query performance of unique index in Coprocessor Add more failpoints and stability test cases Solve the reconnection issue between PD and TiKV Enhance the features of the data recovery tool tikv-ctl Support splitting according to table in Region Support the Delete Range feature Support setting the I/O limit caused by snapshot Improve the flow control mechanism  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/11beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/11beta/</guid>
      <description>TiDB 1.1 Beta Release Notes 2018 年 2 月 24 日，TiDB 发布 1.1 Beta 版。该版本在 1.1 Alpha 版的基础上，对 MySQL 兼容性、系统稳定性做了很多改进。
TiDB  添加更多监控项, 优化日志 兼容更多 MySQL 语法 在 information_schema 中支持显示建表时间 提速包含 MaxOneRow 算子的查询 控制 Join 产生的中间结果集大小，进一步减少 Join 的内存使用 增加 tidb_config session 变量，输出当前 TiDB 配置 修复 Union 和 Index Join 算子中遇到的 panic 问题 修复 Sort Merge Join 算子在部分场景下结果错误的问题 修复 Show Index 语句显示正在添加过程中的索引的问题 修复 Drop Stats 语句失败的问题 优化 SQL 引擎查询性能，Sysbench 的 Select/OLTP 测试结果提升 10% 使用新的执行引擎提升优化器中的子查询计算速度；相比 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/releases/11beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/11beta/</guid>
      <description>TiDB 1.1 Beta Release Notes On February 24, 2018, TiDB 1.1 Beta is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  Add more monitoring metrics and refine the log Compatible with more MySQL syntax Support displaying the table creating time in information_schema Optimize queries containing the MaxOneRow operator Configure the size of intermediate result sets generated by Join, to further reduce the memory used by Join Add the tidb_config session variable to output the current TiDB configuration Fix the panic issue in the Union and Index Join operators Fix the wrong result issue of the Sort Merge Join operator in some scenarios Fix the issue that the Show Index statement shows indexes that are in the process of adding Fix the failure of the Drop Stats statement Optimize the query performance of the SQL engine to improve the test result of the Sysbench Select/OLTP by 10% Improve the computing speed of subqueries in the optimizer using the new execution engine; compared with TiDB 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/2rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/2rc1/</guid>
      <description> TiDB 2.0 RC1 Release Notes 2018 年 3 月 9 日，TiDB 发布 2.0 RC1 版。该版本在上一版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  支持限制单条 SQL 语句使用内存的大小，减少程序 OOM 风险 支持下推流式聚合算子到 TiKV 支持配置文件的合法性检测 支持 HTTP API 获取 TiDB 参数信息 Parser 兼容更多 MySQL 语法 提升对 Navicat 的兼容性 优化器提升，提取多个 OR 条件的公共表达式，选取更优执行计划 优化器提升，在更多场景下将子查询转换成 Join 算子，选取更优查询计划 使用 Batch 方式 Resolve Lock，提升垃圾回收速度 修复 Boolean 类型的字段长度，提升兼容性 优化 Add Index 操作，所有的读写操作采用低优先级，减小对在线业务的影响  PD  优化检查 Region 状态的代码逻辑，提升程序性能 优化异常情况下日志信息输出，便于调试 修复监控中关于 TiKV 节点磁盘空间不足情况的统计 修复开启 TLS 时健康检查接口误报的问题 修复同时添加副本数量可能超过配置阈值的问题，提升程序稳定性  TiKV  修复 PD leader 切换，gRPC call 没被 cancel 的问题 对重要配置进行保护，第一次设置之后不允许变更 增加获取 metrics 的 gRPC API 启动时候，检查是否使用 SSD 使用 ReadPool 优化读性能，raw get 测试性能提升 30% 完善 metrics，优化 metrics 的使用  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc1/</guid>
      <description> TiDB 2.0 RC1 Release Notes On March 9, 2018, TiDB 2.0 RC1 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support limiting the memory usage by a single SQL statement, to reduce the risk of OOM Support pushing the Stream Aggregate operator down to TiKV Support validating the configuration file Support obtaining the information of TiDB configuration through HTTP API Compatible with more MySQL syntax in Parser Improve the compatibility with Navicat Improve the optimizer and extract common expressions with multiple OR conditions, to choose better query plan Improve the optimizer and convert subqueries to Join operators in more scenarios, to choose better query plan Resolve Lock in the Batch mode to increase the garbage collection speed Fix the length of Boolean field to improve compatibility Optimize the Add Index operation and give lower priority to all write and read operations, to reduce the impact on online business  PD:  Optimize the logic of code used to check the Region status to improve performance Optimize the output of log information in abnormal conditions to facilitate debugging Fix the monitor statistics that the disk space of TiKV nodes is not enough Fix the wrong reporting issue of the health interface when TLS is enabled Fix the issue that concurrent addition of replicas might exceed the threshold value of configuration, to improve stability  TiKV:  Fix the issue that gRPC call is not cancelled when PD leaders switch Protect important configuration which cannot be changed after initial configuration Add gRPC APIs used to obtain metrics Check whether SSD is used when you start the cluster Optimize the read performance using ReadPool, and improve the performance by 30% in the raw get test Improve metrics and optimize the usage of metrics  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/2rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/2rc3/</guid>
      <description> TiDB 2.0 RC3 Release Notes 2018 年 3 月 23 日，TiDB 发布 2.0 RC3 版。该版本在 2.0 RC2 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  修复部分场景下 MAX/MIN 结果不正确的问题 修复部分场景下 Sort Merge Join 结果未按照 Join Key 有序的问题 修复边界条件下 uint 和 int 比较的错误 完善浮点数类型的长度和精度检查，提升 MySQL 兼容性 完善时间类型解析报错日志，添加更多错误信息 完善内存控制，新增对 IndexLookupExecutor 的内存统计 优化 ADD INDEX 的执行速度，部分场景下速度大幅度提升 GROUP BY 子句为空时使用 Stream Aggregation 算子，提升速度 支持通过 STRAIGHT_JOIN 来关闭优化器的 Join Reorder 优化 ADMIN SHOW DDL JOBS 输出更详细的 DDL 任务状态信息 支持 ADMIN SHOW DDL JOB QUERIES 查询当前正在运行的 DDL 任务的原始语句 支持 ADMIN RECOVER INDEX 命令，用于灾难恢复情况下修复索引数据 ADD INDEX 操作变更为低优先级，降低对线上业务影响 支持参数为 JSON 类型的 SUM/AVG 等聚合函数 支持配置文件修改 lower_case_table_names 系统变量，用于支持 OGG 数据同步工具 提升对 Navicat 管理工具的兼容性 支持在 CRUD 操作中使用隐式的行 ID  PD  支持 Region Merge，合并数据删除后产生的空 Region 或小 Region 添加副本时忽略有大量 pending peer 的节点，提升恢复副本及下线的速度 优化有大量空 Region 时产生的频繁调度问题 优化不同 label 中资源不均衡的场景中 leader balance 调度的速度 添加更多异常 Region 的统计  TiKV  支持 Region Merge Raft snapshot 流程完成之后立刻通知 PD，加速调度 增加 Raw DeleteRange API 增加 GetMetric API 减缓 RocksDB sync 文件造成的 I/O 波动 优化了对 delete 掉数据的空间回收机制 完善数据恢复工具 tikv-ctl 解决了由于 snapshot 导致下线节点慢的问题 Coprocessor 支持 streaming 支持 Readpool，raw_get/get/batch_get 性能提升 30% 支持配置 Coprocessor 请求超时时间 Coprocessor 支持 streaming aggregation 上报 Region heartbeat 时携带时间信息 限制 snapshot 文件的空间使用，防止占用过多磁盘空间 对长时间不能选出 leader 的 Region 进行记录上报 加速启动阶段的垃圾清理工作 根据 compaction 事件及时更新对应 Region 的 size 信息 对 scan lock 的大小进行限制，防止请求超时 使用 DeleteRange 加速 Region 删除 支持在线修改 RocksDB 的参数  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc3/</guid>
      <description> TiDB 2.0 RC3 Release Notes On March 23, 2018, TiDB 2.0 RC3 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Fix the wrong result issue of MAX/MIN in some scenarios Fix the issue that the result of Sort Merge Join does not show in order of Join Key in some scenarios Fix the error of comparison between uint and int in boundary conditions Optimize checks on length and precision of the floating point type, to improve compatibility with MySQL Improve the parsing error log of time type and add more error information Improve memory control and add statistics about IndexLookupExecutor memory Optimize the execution speed of ADD INDEX to greatly increase the speed in some scenarios Use the Stream Aggregation operator when the GROUP BY substatement is empty, to increase the speed Support closing the Join Reorder optimization in the optimizer using STRAIGHT_JOIN Output more detailed status information of DDL jobs in ADMIN SHOW DDL JOBS Support querying the original statements of currently running DDL jobs using ADMIN SHOW DDL JOB QUERIES Support recovering the index data using ADMIN RECOVER INDEX for disaster recovery Attach a lower priority to the ADD INDEX operation to reduce the impact on online business Support aggregation functions with JSON type parameters, such as SUM/AVG Support modifying the lower_case_table_names system variable in the configuration file, to support the OGG data synchronization tool Improve compatibility with the Navicat management tool Support using implicit RowID in CRUD operations  PD:  Support Region Merge, to merge empty Regions or small Regions after deleting data Ignore the nodes that have a lot of pending peers during adding replicas, to improve the speed of restoring replicas or making nodes offline Fix the frequent scheduling issue caused by a large number of empty Regions Optimize the scheduling speed of leader balance in scenarios of unbalanced resources within different labels Add more statistics about abnormal Regions  TiKV:  Support Region Merge Inform PD immediately once the Raft snapshot process is completed, to speed up balancing Add the Raw DeleteRange API Add the GetMetric API Reduce the I/O fluctuation caused by RocksDB sync files Optimize the space reclaiming mechanism after deleting data Improve the data recovery tool tikv-ctl Fix the issue that it is slow to make nodes down caused by snapshot Support streaming in Coprocessor Support Readpool and increase the raw_get/get/batch_get by 30% Support configuring the request timeout of Coprocessor Support streaming aggregation in Coprocessor Carry time information in Region heartbeats Limit the space usage of snapshot files to avoid consuming too much disk space Record and report the Regions that cannot elect a leader for a long time Speed up garbage cleaning when starting the server Update the size information about the corresponding Region according to compaction events Limit the size of scan lock to avoid request timeout Use DeleteRange to speed up Region deletion Support modifying RocksDB parameters online  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/2rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/2rc4/</guid>
      <description> TiDB 2.0 RC4 Release Notes 2018 年 3 月 30 日，TiDB 发布 2.0 RC4 版。该版本在 2.0 RC3 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  支持 SHOW GRANTS FOR CURRENT_USER(); 修复 UnionScan 里的 Expression 没有 Clone 的问题 支持 SET TRANSACTION 语法 修复 copIterator 中潜在的 goroutine 泄露问题 修复 admin check table 对包含 null 的 unique index 误判的问题 支持用科学计数法显示浮点数 修复 binary literal 计算时的类型推导 修复解析 CREATE VIEW 语句的问题 修复语句中同时包含 ORDER BY 和 LIMIT 0 时 panic 的问题 提升 DecodeBytes 执行性能 优化 LIMIT 0 为 TableDual，避免无用的执行计划构建  PD  支持手动 split Region，可用于处理单 Region 热点的问题 修复 pdctl 运行 config show all 不显示 label property 的问题 metrics 及代码结构相关的优化  TiKV  限制接收 snapshot 时的内存使用，解决极端情况下的 OOM 可以配置 Coprocessor 在遇到 warnings 时的行为 TiKV 支持导数据模式 支持 Region 从正中间分裂 提升 CI test 的速度 使用 crossbeam channel 改善 TiKV 在被隔离的情况下由于 leader missing 输出太多日志的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc4/</guid>
      <description> TiDB 2.0 RC4 Release Notes On March 30, 2018, TiDB 2.0 RC4 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support SHOW GRANTS FOR CURRENT_USER(); Fix the issue that the Expression in UnionScan is not cloned Support the SET TRANSACTION syntax Fix the potential goroutine leak issue in copIterator Fix the issue that admin check table misjudges the unique index including null Support displaying floating point numbers using scientific notation Fix the type inference issue during binary literal computing Fix the issue in parsing the CREATE VIEW statement Fix the panic issue when one statement contains both ORDER BY and LIMIT 0 Improve the execution performance of DecodeBytes Optimize LIMIT 0 to TableDual, to avoid building useless execution plans  PD:  Support splitting Region manually to handle the hot spot in a single Region Fix the issue that the label property is not displayed when pdctl runs config show all Optimize metrics and code structure  TiKV:  Limit the memory usage during receiving snapshots, to avoid OOM in extreme conditions Support configuring the behavior of Coprocessor when it encounters warnings Support importing the data pattern in TiKV Support splitting Region in the middle Increase the speed of CI test Use crossbeam channel Fix the issue that too many logs are output caused by leader missing when TiKV is isolated  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC5 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/2rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/2rc5/</guid>
      <description> TiDB 2.0 RC5 Release Notes 2018 年 4 月 17 日，TiDB 发布 2.0 RC5 版。该版本在 RC4 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  修复应用 Top-N 下推规则的问题 修复对包含 NULL 值的列的行数估算 修复 Binary 类型的 0 值 修复事务内的 BatchGet 问题 回滚 Add Index 操作的时候，清除清除已写入的数据，减少空间占用 优化 insert on duplicate key update 语句性能，提升 10 倍以上 修复 UNIX_TIMESTAMP 函数返回结果类型问题返回结果类型问题 修复在添加 NOT NULL 列的过程中，插入 NULL 值的问题 Show Process List 语句支持显示执行语句的内存占用 修复极端情况下 Alter Table Modify Column 出错问题 支持通过 Alter 语句设置 table comment  PD  添加 Raft Learner 支持 优化 Balance Region Scheduler，减少调度开销 调整默认 schedule-limit 配置 修复频繁分配 ID 问题 修复添加调度兼容性问题  TiKV  tikv-ctl 支持 compact 指定的 Region Raw KV 支持 Batch Put、Batch Get、Batch Delete 和 Batch Scan 解决太多 snapshot 导致的 OOM 问题 Coprocessor 返回更详细的错误信息 支持通过 tikv-ctl 动态修改 TiKV 的 block-cache-size 进一步完善 importer 功能 简化 ImportSST::Upload 接口 设置 gRPC 的 keepalive 属性 tikv-importer 作为独立的 binary 从 TiKV 中分离出来 统计 Coprocessor 每个 scan range 命令扫描了多少行数据 解决在 macOS 系统上的编译问题 优化 metric 相关的内容 解决 snapshot 相关的一个潜在 bug 解决误用了一个 RocksDB metric 的问题 Coprocessor 支持 overflow as warning 选项  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc5/</guid>
      <description> TiDB 2.0 RC5 Release Notes On April 17, 2018, TiDB 2.0 RC5 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB  Fix the issue about applying the Top-N pushdown rule Fix the estimation of the number of rows for the columns that contain NULL values Fix the zero value of the Binary type Fix the BatchGet issue within a transaction Clean up the written data while rolling back the Add Index operation, to reduce consumed space Optimize the insert on duplicate key update statement to improve the performance by 10 times Fix the issue about the type of the results returned by the UNIX_TIMESTAMP function Fix the issue that the NULL value is inserted while adding NOT NULL columns Support showing memory usage of the executing statements in the Show Process List statement Fix the issue that Alter Table Modify Column reports an error in extreme conditions Support setting the table comment using the Alter statement  PD  Add support for Raft Learner Optimize the Balance Region Scheduler to reduce scheduling overhead Adjust the default value of schedule-limit configuration Fix the issue of allocating ID frequently Fix the compatibility issue when adding a new scheduler  TiKV  Support the Region specified by compact in tikv-ctl Support Batch Put, Batch Get, Batch Delete and Batch Scan in the RawKVClient Fix the OOM issue caused by too many snapshots Return more detailed error information in Coprocessor Support dynamically modifying the block-cache-size in TiKV through tikv-ctl Further improve importer Simplify the ImportSST::Upload interface Configure the keepalive property of gRPC Split tikv-importer from TiKV as an independent binary Provide statistics about the number of rows scanned by each scan range in Coprocessor Fix the compilation issue on the macOS system Fix the issue of misusing a RocksDB metric Support the overflow as warning option in Coprocessor  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.0ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.0ga/</guid>
      <description>TiDB 2.0 Release Notes On April 27, 2018, TiDB 2.0 GA is released! Compared with TiDB 1.0, this release has great improvement in MySQL compatibility, SQL optimizer, executor, and stability.
TiDB  SQL Optimizer  Use more compact data structure to reduce the memory usage of statistics information Speed up loading statistics information when starting a tidb-server process Support updating statistics information dynamically [experimental] Optimize the cost model to provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of point queries more accurately Support analyzing more complex conditions to make full use of indexes Support manually specifying the Join order using the STRAIGHT_JOIN syntax Use the Stream Aggregation operator when the GROUP BY clause is empty to improve the performance Support using indexes for the MAX/MIN function Optimize the processing algorithms for correlated subqueries to support decorrelating more types of correlated subqueries and transform them to Left Outer Join Extend IndexLookupJoin to be used in matching the index prefix  SQL Execution Engine  Refactor all operators using the Chunk architecture, improve the execution performance of analytical queries, and reduce memory usage.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 Upgrade Guide</title>
      <link>https://pingcap.com/docs/op-guide/tidb-v2-upgrade-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/tidb-v2-upgrade-guide/</guid>
      <description>TiDB 2.0 Upgrade Guide This document describes how to upgrade from TiDB 1.0 or TiDB 2.0 RC version to TiDB 2.0 GA version.
Install Ansible and dependencies in the Control Machine TiDB-Ansible release-2.0 depends on Ansible 2.4.2 or later, and is compatible with the latest Ansible 2.5. In addition, TiDB-Ansible release-2.0 depends on the Python module: jinja2&amp;gt;=2.9.6 and jmespath&amp;gt;=0.9.0.
To make it easy to manage dependencies, use pip to install Ansible and its dependencies.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/2.0ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/2.0ga/</guid>
      <description>TiDB 2.0 Release Notes 2018 年 4 月 27 日，TiDB 发布 2.0 GA 版。相比 1.0 版本，该版本对 MySQL 兼容性、系统稳定性、优化器和执行器做了很多改进。
TiDB  SQL 优化器  精简统计信息数据结构，减小内存占用 加快进程启动时加载统计信息速度 支持统计信息动态更新 [experimental] 优化代价模型，对代价估算更精准 使用 Count-Min Sketch 更精确地估算点查的代价 支持分析更复杂的条件，尽可能充分的使用索引 支持通过 STRAIGHT_JOIN 语法手动指定 Join 顺序 GROUP BY子句为空时使用 Stream Aggregation 算子，提升性能 支持使用索引计算 Max/Min 函数 优化关联子查询处理算法，支持将更多类型的关联子查询解关联并转化成 Left Outer Join 扩大 IndexLookupJoin 的使用范围，索引前缀匹配的场景也可以使用该算法  SQL 执行引擎  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用，显著提升 TPC-H 结果 支持 Streaming Aggregation 算子下推 优化 Insert Into Ignore 语句性能，提升 10 倍以上 优化 Insert On Duplicate Key Update 语句性能，提升 10 倍以上 下推更多的数据类型和函数到 TiKV 计算 优化 Load Data 性能，提升 10 倍以上 支持对物理算子内存使用进行统计，通过配置文件以及系统变量指定超过阈值后的处理行为 支持限制单条 SQL 语句使用内存的大小，减少程序 OOM 风险 支持在 CRUD 操作中使用隐式的行 ID 提升点查性能  Server  支持 Proxy Protocol 添加大量监控项, 优化日志 支持配置文件的合法性检测 支持 HTTP API 获取 TiDB 参数信息 使用 Batch 方式 Resolve Lock，提升垃圾回收速度 支持多线程垃圾回收 支持 TLS  兼容性  支持更多 MySQL 语法 支持配置文件修改 lower_case_table_names 系统变量，用于支持 OGG 数据同步工具 提升对 Navicat 的兼容性 在 Information_Schema 中支持显示建表时间 修复部分函数/表达式返回类型和 MySQL 不同的问题 提升对 JDBC 兼容性 支持更多的 SQL_MODE  DDL  优化 Add Index 的执行速度，部分场景下速度大幅度提升 Add Index 操作变更为低优先级，降低对线上业务影响 Admin Show DDL Jobs 输出更详细的 DDL 任务状态信息 支持 Admin Show DDL Job Queries JobID 查询当前正在运行的 DDL 任务的原始语句 支持 Admin Recover Index 命令，用于灾难恢复情况下修复索引数据 支持通过 Alter 语句修改 Table Options   PD  增加 Region Merge 支持，合并数据删除后产生的空 Region [experimental] 增加 Raft Learner 支持 [experimental] 调度器优化  调度器适应不同的 Region size 提升 TiKV 宕机时数据恢复的优先级和恢复速度 提升下线 TiKV 节点搬迁数据的速度 优化 TiKV 节点空间不足时的调度策略，尽可能防止空间不足时磁盘被写满 提升 balance-leader scheduler 的调度效率 减少 balance-region scheduler 调度开销 优化 hot-region scheduler 的执行效率  运维接口及配置  增加 TLS 支持 支持设置 PD leader 优先级 支持基于 label 配置属性 支持配置特定 label 的节点不调度 Region leader 支持手动 Split Region，可用于处理单 Region 热点的问题 支持打散指定 Region，用于某些情况下手动调整热点 Region 分布 增加配置参数检查规则，完善配置项的合法性较验  调试接口  增加 Drop Region 调试接口 增加枚举各个 PD health 状态的接口  统计相关  添加异常 Region 的统计 添加 Region 隔离级别的统计 添加调度相关 metrics  性能优化  PD leader 尽量与 etcd leader 保持同步，提升写入性能 优化 Region heartbeat 性能，现可支持超过 100 万 Region   TiKV  功能  保护关键配置，防止错误修改 支持 Region Merge [experimental] 添加 Raw DeleteRange API 添加 GetMetric API 添加 Raw Batch Put，Raw Batch Get，Raw Batch Delete 和 Raw Batch Scan 给 Raw KV API 增加 Column Family 参数，能对特定 Column Family 进行操作 Coprocessor 支持 streaming 模式，支持 streaming 聚合 支持配置 Coprocessor 请求的超时时间 心跳包携带时间戳 支持在线修改 RocksDB 的一些参数，包括 block-cache-size 大小等 支持配置 Coprocessor 遇到某些错误时的行为 支持以导数据模式启动，减少导数据过程中的写放大 支持手动对 region 进行对半 split 完善数据修复工具 tikv-ctl Coprocessor 返回更多的统计信息，以便指导 TiDB 的行为 支持 ImportSST API，可以用于 SST 文件导入 [experimental] 新增 TiKV Importer 二进制，与 TiDB Lightning 集成用于快速导入数据 [experimental]  性能  使用 ReadPool 优化读性能，raw_get/get/batch_get 提升 30% 提升 metrics 的性能 Raft snapshot 处理完之后立即通知 PD，加快调度速度 解决 RocksDB 刷盘导致性能抖动问题 提升在数据删除之后的空间回收 加速启动过程中的垃圾清理过程 使用 DeleteFilesInRanges 减少副本迁移时 I/O 开销  稳定性  解决在 PD leader 发送切换的情况下 gRPC call 不返回问题 解决由于 snapshot 导致下线节点慢的问题 限制搬移副本临时占用的空间大小 如果有 Region 长时间没有 Leader，进行上报 根据 compaction 事件及时更新统计的 Region size 限制单次 scan lock 请求的扫描的数据量，防止超时 限制接收 snapshot 过程中的内存占用，防止 OOM 提升 CI test 的速度 解决由于 snapshot 太多导致的 OOM 问题 配置 gRPC 的 keepalive 参数 修复 Region 增多容易 OOM 的问题   TiSpark TiSpark 使用独立的版本号，现为 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 升级操作指南</title>
      <link>https://pingcap.com/docs-cn/op-guide/tidb-v2-upgrade-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/tidb-v2-upgrade-guide/</guid>
      <description>TiDB 2.0 升级操作指南 本文档适用于从 TiDB 1.0 版本或 TiDB 2.0 rc 版本升级到 TiDB 2.0 GA 版本。
在中控机器上安装 Ansible 及其依赖 TiDB-Ansible release-2.0 版本依赖 Ansible 2.4.2 及以上版本，兼容最新的 Ansible 2.5 版本，另依赖 Python 模块：jinja2&amp;gt;=2.9.6 和 jmespath&amp;gt;=0.9.0。为方便管理依赖，新版本使用 pip 安装 Ansible 及其依赖，可参照在中控机器上安装 Ansible 及其依赖 进行安装。离线环境参照在中控机器上离线安装 Ansible 及其依赖。
安装完成后，可通过以下命令查看版本：
$ ansible --version ansible 2.5.2 $ pip show jinja2 Name: Jinja2 Version: 2.9.6 $ pip show jmespath Name: jmespath Version: 0.9.0  注意：请务必按以上文档安装 Ansible 及其依赖。确认 Jinja2 版本是否正确，否则启动 Grafana 时会报错。确认 jmespath 版本是否正确，否则滚动升级 TiKV 时会报错。</description>
    </item>
    
    <item>
      <title>TiDB 2.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/201/</guid>
      <description> TiDB 2.0.1 Release Notes On May 16, 2018, TiDB 2.0.1 is released. Compared with TiDB 2.0.0 (GA), this release has great improvement in MySQL compatibility and system stability.
TiDB  Update the progress of Add Index to the DDL job information in real time Add the tidb_auto_analyze_ratio session variable to control the threshold value of automatic statistics update Fix an issue that not all residual states are cleaned up when the transaction commit fails Fix a bug about adding indexes in some conditions Fix the correctness related issue when DDL modifies surface operations in some concurrent scenarios Fix a bug that the result of LIMIT is incorrect in some conditions Fix a capitalization issue of the ADMIN CHECK INDEX statement to make its index name case insensitive Fix a compatibility issue of the UNION statement Fix a compatibility issue when inserting data of TIME type Fix a goroutine leak issue caused by copIteratorTaskSender in some conditions Add an option for TiDB to control the behaviour of Binlog failure Refactor the Coprocessor slow log to distinguish between the scenario of tasks with long processing time and long waiting time Log nothing when meeting MySQL protocol handshake error, to avoid too many logs caused by the load balancer Keep Alive mechanism Refine the “Out of range value for column” error message Fix a bug when there is a subquery in an Update statement Change the behaviour of handling SIGTERM, and do not wait for all queries to terminate anymore  PD  Add the Scatter Range scheduler to balance Regions with the specified key range Optimize the scheduling of Merge Region to prevent the newly split Region from being merged Add Learner related metrics Fix the issue that the scheduler is mistakenly deleted after restart Fix the error that occurs when parsing the configuration file Fix the issue that the etcd leader and the PD leader are not synchronized Fix the issue that Learner still appears after it is closed Fix the issue that Regions fail to load because the packet size is too large  TiKV  Fix the issue that SELECT FOR UPDATE prevents others from reading Optimize the slow query log Reduce the number of thread_yield calls Fix the bug that raftstore is accidentally blocked when generating the snapshot Fix the issue that Learner cannot be successfully elected in special conditions Fix the issue that split might cause dirty read in extreme conditions Correct the default value of the read thread pool configuration Speed up Delete Range  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.1 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/201/</guid>
      <description> TiDB 2.0.1 Release Notes 2018 年 5 月 16 日，TiDB 发布 2.0.1 版。该版本在 2.0.0 (GA) 版的基础上，对 MySQL 兼容性、系统稳定性做出了改进。
TiDB  实时更新 Add Index 的进度到 DDL 任务信息中 添加 Session 变量 tidb_auto_analyze_ratio 控制统计信息自动更新阈值 修复当事务提交失败时可能未清理所有的残留状态的问题 修复加索引在部分情况下的 Bug 修复 DDL 修改表面操作在某些并发场景下的正确性问题 修复某些情况下 LIMIT 结果不正确的问题 修复 ADMIN CHECK INDEX 语句索引名字区分大小写问题 修复 UNION 语句的兼容性问题 修复插入 TIME 类型数据的兼容性问题 修复某些情况下 copIteratorTaskSender 导致的 goroutine 泄漏问题 增加一个选项，用于设置 TiDB 在写 Binlog 失败的情况下的行为 优化 Coprocessor 慢请求日志格式，区分处理时间长与排队时间长的任务 MySQL 协议握手阶段发生错误不打印日志，避免 KeepAlive 造成大量日志 优化 Out of range value for column 的错误信息 修复 Update 语句中遇到子查询导致结果错误的问题 调整 TiDB 进程处理 SIGTERM 的行为，不等待正在执行的 Query 完成  PD  添加 Scatter Range 调度，调度指定 Key Range 包含的 Region 优化 Merge Region 调度，使新分裂不久的 Region 不能被合并 添加 learner 相关的 metrics 修复重启误删 scheduler 的问题 修复解析配置文件出错问题 修复 etcd leader 和 PD leader 不同步的问题 修复关闭 learner 情况下还有 learner 出现的问题 修复读取包过大造成 load Regions 失败的问题  TiKV  修复 SELECT FOR UPDATE 阻止其他人读的问题 优化慢查询的日志 减少 thread_yield 的调用次数 修复生成 snapshot 会意外阻塞 raftstore 的 bug 修复特殊情况下开启 learner 无法选举成功的问题 修复极端情况下分裂可能导致的脏读问题 修正读线程池的配置默认值 修正删大数据表会影响写性能的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/202/</guid>
      <description> TiDB 2.0.2 Release Notes On May 21, 2018, TiDB 2.0.2 is released. Compared with TiDB 2.0.1, this release has great improvement in system stability.
TiDB  Fix the issue of pushing down the Decimal division expression Support using the USE INDEX syntax in the Delete statement Forbid using the shard_row_id_bits feature in columns with Auto-Increment Add the timeout mechanism for writing Binlog  PD  Make the balance leader scheduler filter the disconnected nodes Modify the timeout of the transfer leader operator to 10s Fix the issue that the label scheduler does not schedule when the cluster Regions are in an unhealthy state Fix the improper scheduling issue of evict leader scheduler  TiKV  Fix the issue that the Raft log is not printed Support configuring more gRPC related parameters Support configuring the timeout range of leader election Fix the issue that the obsolete learner is not deleted Fix the issue that the snapshot intermediate file is mistakenly deleted  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.2 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/202/</guid>
      <description> TiDB 2.0.2 Release Notes 2018 年 5 月 21 日，TiDB 发布 2.0.2 版。该版本在 2.0.1 版的基础上，对系统稳定性做出了改进。
TiDB  修复 Decimal 除法内置函数下推的问题 支持 Delete 语句中使用 USE INDEX 的语法 禁止在带有 Auto-Increment 的列中使用 shard_row_id_bits 特性 增加写入 Binlog 的超时机制  PD  使 balance leader scheduler 过滤失连节点 更改 transfer leader operator 的超时时间为 10 秒 修复 label scheduler 在集群 Regions 不健康状态下不调度的问题 修复 evict leader scheduler 调度不当的问题  TiKV  修复 Raft 日志没有打出来的问题 支持配置更多 gRPC 相关参数 支持配置选举超时的取值范围 修复过期 learner 没有删掉的问题 修复 snapshot 中间文件被误删的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/203/</guid>
      <description> TiDB 2.0.3 Release Notes On June 1, 2018, TiDB 2.0.3 is released. Compared with TiDB 2.0.2, this release has great improvement in system compatibility and stability.
TiDB  Support modifying the log level online Support the COM_CHANGE_USER command Support using the TIME type parameters under the binary protocol Optimize the cost estimation of query conditions with the BETWEEN expression Do not display the FOREIGN KEY information in the result of SHOW CREATE TABLE Optimize the cost estimation for queries with the LIMIT clause Fix the issue about the YEAR type as the unique index Fix the issue about ON DUPLICATE KEY UPDATE in conditions without the unique index Fix the compatibility issue of the CEIL function Fix the accuracy issue of the DIV calculation in the DECIMAL type Fix the false alarm of ADMIN CHECK TABLE Fix the panic issue of MAX/MIN under specific expression parameters Fix the issue that the result of JOIN is null in special conditions Fix the IN expression issue when building and querying Range Fix a Range calculation issue when using Prepare to query and Plan Cache is enabled Fix the issue that the Schema information is frequently loaded in abnormal conditions  PD  Fix the panic issue when collecting hot-cache metrics in specific conditions Fix the issue about scheduling of the obsolete Regions  TiKV  Fix the bug that the learner flag mistakenly reports to PD Report an error instead of getting a result if divisor/dividend is 0 in do_div_mod  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.3 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/203/</guid>
      <description> TiDB 2.0.3 Release Notes 2018 年 6 月 1 日，TiDB 发布 2.0.3 版。该版本在 2.0.2 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  支持在线更改日志级别 支持 COM_CHANGE_USER 命令 支持二进制协议情况下使用时间类型参数 优化带 BETWEEN 表达式的查询条件代价估算 在 SHOW CREATE TABLE 里不显示 FOREIGN KEY 信息 优化带 LIMIT 子句的查询代价估算 修复 YEAR 类型作为唯一索引的问题 修复在没有唯一索引的情况下 ON DUPLICATE KEY UPDATE 的问题 修复 CEIL 函数的兼容性问题 修复 DECIMAL 类型计算 DIV 的精度问题 修复 ADMIN CHECK TABLE 误报的问题 修复 MAX/MIN 在特定表达式参数下 panic 的问题 修复特殊情况下 JOIN 结果为空的问题 修复 IN 表达式构造查询 Range 的问题 修复使用 Prepare 方式进行查询且启用 Plan Cache 情况下的 Range 计算问题 修复异常情况下频繁加载 Schema 信息的问题  PD  修复在特定条件下收集 hot-cache metrics 会 panic 的问题 修复对旧的 Region 产生调度的问题  TiKV  修复 learner flag 错误上报给 PD 的 bug 在 do_div_mod 中 divisor/dividend 为 0 时返回错误  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/204/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/204/</guid>
      <description> TiDB 2.0.4 Release Notes On June 15, 2018, TiDB 2.0.4 is released. Compared with TiDB 2.0.3, this release has great improvement in system compatibility and stability.
TiDB  Support the ALTER TABLE t DROP COLUMN a CASCADE syntax Support configuring the value of tidb_snapshot to TSO Refine the display of statement types in monitoring items Optimize the accuracy of query cost estimation Configure the backoff max delay parameter of gRPC Support configuring the memory threshold of a single statement in the configuration file Refactor the error of Optimizer Fix the side effects of the Cast Decimal data Fix the wrong result issue of the Merge Join operator in specific scenarios Fix the issue of converting the Null object to String Fix the issue of casting the JSON type of data to the JSON type Fix the issue that the result order is not consistent with MySQL in the condition of Union + OrderBy Fix the compliance rules issue when the Union statement checks the Limit/OrderBy clause Fix the compatibility issue of the Union All result Fix a bug in predicate pushdown Fix the compatibility issue of the Union statement with the For Update clause Fix the issue that the concat_ws function mistakenly truncates the result  PD  Improve the behavior of the unset scheduling argument max-pending-peer-count by changing it to no limit for the maximum number of PendingPeers  TiKV  Add the RocksDB PerfContext interface for debugging Remove the import-mode parameter Add the region-properties command for tikv-ctl Fix the issue that reverse-seek is slow when many RocksDB tombstones exist Fix the crash issue caused by do_sub Make GC record the log when GC encounters many versions of data  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.4 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/204/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/204/</guid>
      <description> TiDB 2.0.4 Release Notes 2018 年 6 月 15 日，TiDB 发布 2.0.4 版。该版本在 2.0.3 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  支持 ALTER TABLE t DROP COLUMN a CASCADE 语法 支持设置 tidb_snapshot 变量的值为 TSO 优化监控项中语句类型展示 优化查询代价估计精度 设置 gRPC 的 backoff max delay 参数 支持通过配置文件设置单条语句的内存使用阈值 重构 Optimizer 的 error 解决 Cast Decimal 数据的副作用问题 解决特定场景下 Merge Join 算子结果错误的问题 解决转换 Null 对象到 String 的问题 解决 Cast JSON 数据为 JSON 类型的问题 解决 Union + OrderBy 情况下结果顺序和 MySQL 不一致的问题 解决 Union 语句中对 Limit/OrderBy 子句的合法性检查规则问题 解决 Union All 的结果兼容性问题 解决谓词下推中的一个 Bug 解决 Union 语句对 For Update 子句的兼容性问题 解决 concat_ws 函数对结果错误截断的问题  PD  改进 max-pending-peer-count 调度参数未设置时的行为，调整为不限制最大 PendingPeer 的数量  TiKV  新增 RocksDB PerfContext 接口用于调试 移除 import-mode 参数 为 tikv-ctl 添加 region-properties 命令 优化有大量 RocksDB tombstone 时 reverse-seek 过慢的问题 修复 do_sub 导致的崩溃问题 当 GC 遇到有太多版本的数据时记录日志  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/205/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/205/</guid>
      <description> TiDB 2.0.5 Release Notes On July 6, 2018, TiDB 2.0.5 is released. Compared with TiDB 2.0.4, this release has great improvement in system compatibility and stability.
TiDB  New Features  Add the tidb_disable_txn_auto_retry system variable which is used to disable the automatic retry of transactions #6877  Improvements  Optimize the cost calculation of Selection to make the result more accurate #6989 Select the query condition that completely matches the unique index or the primary key as the query path directly #6966 Execute necessary cleanup when failing to start the service #6964 Handle \N as NULL in the Load Data statement #6962 Optimize the code structure of CBO #6953 Report the monitoring metrics earlier when starting the service #6931 Optimize the format of slow queries by removing the line breaks in SQL statements and adding user information #6920 Support multiple asterisks in comments #6858  Bug Fixes  Fix the issue that KILL QUERY always requires SUPER privilege #7003 Fix the issue that users might fail to login when the number of users exceeds 1024 #6986 Fix an issue about inserting unsigned float/double data #6940 Fix the compatibility of the COM_FIELD_LIST command to resolve the panic issue in some MariaDB clients #6929 Fix the CREATE TABLE IF NOT EXISTS LIKE behavior #6928 Fix an issue in the process of TopN pushdown #6923 Fix the ID record issue of the currently processing row when an error occurs in executing Add Index #6903   PD  Fix the issue that replicas migration uses up TiKV disks space in some scenarios Fix the crash issue caused by AdjacentRegionScheduler  TiKV  Fix the potential overflow issue in decimal operations Fix the dirty read issue that might occur in the process of merging  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.5 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/205/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/205/</guid>
      <description> TiDB 2.0.5 Release Notes 2018 年 7 月 6 日，TiDB 发布 2.0.5 版。该版本在 2.0.4 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  New Features  增加一个系统变量 tidb_disable_txn_auto_retry，用于关闭事务自动重试 #6877  Improvements  调整计算 Selection 代价的方式，结果更准确 #6989 查询条件能够完全匹配唯一索引或者主键时，直接选择作为查询路径 #6966 启动服务失败时，做必要的清理工作 #6964 在 Load Data 语句中，将 \N 处理为 NULL #6962 优化 CBO 代码结构 #6953 启动服务时，尽早上报监控数据 #6931 对慢查询日志格式进行优化：去除 SQL 语句中的换行符，增加用户信息 #6920 支持注释中存在多个星号的情况 #6858  Bug Fixes  修复 KILL QUERY 语句权限检查问题 #7003 修复用户数量超过 1024 时可能造成无法登陆的问题 #6986 修复一个写入无符号类型 float/double 数据的问题 #6940 修复 COM_FIELD_LIST 命令的兼容性，解决部分 MariaDB 客户端遇到 Panic 的问题 #6929 修复 CREATE TABLE IF NOT EXISTS LIKE 行为 #6928 修复一个 TopN 下推过程中的问题 #6923 修复 Add Index 过程中遇到错误时当前处理的行 ID 记录问题 #6903   PD  修复某些场景下副本迁移导致 TiKV 磁盘空间耗尽的问题 修复 AdjacentRegionScheduler 导致的崩溃问题  TiKV  修复 decimal 运算中潜在的溢出问题 修复 merge 过程中可能发生的脏读问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/206/</guid>
      <description> TiDB 2.0.6 Release Notes On August 6, 2018, TiDB 2.0.6 is released. Compared with TiDB 2.0.5, this release has great improvement in system compatibility and stability.
TiDB  Improvements  Make &amp;ldquo;set system variable&amp;rdquo; log shorter to save disk space #7031 Record slow operations during the execution of ADD INDEX in the log, to make troubleshooting easier #7083 Reduce transaction conflicts when updating statistics #7138 Improve the accuracy of row count estimation when the values pending to be estimated exceeds the statistics range #7185 Choose the table with a smaller estimated row count as the outer table for Index Join to improve its execution efficiency #7277 Add the recover mechanism for panics occurred during the execution of ANALYZE TABLE, to avoid that the tidb-server is unavailable caused by abnormal behavior in the process of collecting statistics #7228 Return NULL and the corresponding warning when the results of RPAD/LPAD exceed the value of the max_allowed_packet system variable, compatible with MySQL #7244 Set the upper limit of placeholders count in the PREPARE statement to 65535, compatible with MySQL #7250  Bug Fixes  Fix the issue that the DROP USER statement is incompatible with MySQL behavior in some cases #7014 Fix the issue that statements like INSERT/LOAD DATA meet OOM aftering opening tidb_batch_insert #7092 Fix the issue that the statistics fail to automatically update when the data of a table keeps updating #7093 Fix the issue that the firewall breaks inactive gPRC connections #7099 Fix the issue that prefix index returns a wrong result in some scenarios #7126 Fix the panic issue caused by outdated statistics in some scenarios #7155 Fix the issue that one piece of index data is missed after the ADD INDEX operation in some scenarios #7156 Fix the wrong result issue when querying NULL values using the unique index in some scenarios #7172 Fix the messy code issue of the DECIMAL multiplication result in some scenarios #7212 Fix the wrong result issue of DECIMAL modulo operation in some scenarios #7245 Fix the issue that the UPDATE/DELETE statement in a transaction returns a wrong result under some special sequence of statements #7219 Fix the panic issue of the UNION ALL/UPDATE statement during the process of building the execution plan in some scenarios #7225 Fix the issue that the range of prefix index is calculated incorrectly in some scenarios #7231 Fix the issue that the LOAD DATA statement fails to write the binlog in some scenarios #7242 Fix the wrong result issue of SHOW CREATE TABLE during the execution process of ADD INDEX in some scenarios #7243 Fix the issue that panic occurs when Index Join does not initialize timestamps in some scenarios #7246 Fix the false alarm issue when ADMIN CHECK TABLE mistakenly uses the timezone in the session #7258 Fix the issue that ADMIN CLEANUP INDEX does not clean up the index in some scenarios #7265 Disable the Read Committed isolation level #7282   TiKV  Improvements  Enlarge scheduler&amp;rsquo;s default slots to reduce false conflicts Reduce continuous records of rollback transactions, to improve the Read performance when conflicts are extremely severe Limit the size and number of RocksDB log files, to reduce unnecessary disk usage in long-running condition  Bug Fixes  Fix the crash issue when converting the data type from string to decimal   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.6 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/206/</guid>
      <description> TiDB 2.0.6 Release Notes 2018 年 8 月 6 日，TiDB 发布 2.0.6 版。该版本在 2.0.5 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  Improvements  精简 &amp;ldquo;set system variable&amp;rdquo; 日志的长度，减少日志文件体积 #7031 在日志中记录 ADD INDEX 执行过程中的慢操作，便于定位问题 #7083 减少更新统计信息操作中的事务冲突 #7138 当待估算的值超过统计信息范围时，提高行数估计的准确度 #7185 当使用 Index Join 时，选择行数估计较小的表作为驱动表，提高 Index Join 的执行效率 #7227 为 ANALYZE TABLE 语句执行过程中发生的 panic 添加 recover 机制，避免收集统计信息过程中的异常行为导致 tidb-server 不可用 #7228 当 RPAD/LPAD 的结果超过设置系统变量 max_allowed_packet 时，返回 NULL 和对应的 warning，兼容 MySQL #7244 设置 PREPARE 语句中占位符数量上限为 65535，兼容 MySQL #7250  Bug Fixes  修复某些情况下，DROP USER 语句和 MySQL 行为不兼容的问题 #7014 修复当 tidb_batch_insert 打开后，INSERT/LOAD DATA 等语句在某些场景下 OOM 的问题 #7092 修复某个表的数据持续更新时，其统计信息自动更新失效的问题 #7093 修复防火墙断掉不活跃的 gRPC 连接的问题 #7099 修复某些场景下使用前缀索引结果不正确的问题 #7126 修复某些场景下统计信息过时导致 panic 的问题 #7155 修复某些场景下 ADD INDEX 后索引数据少一条的问题 #7156 修复某些场景下查询唯一索引上的 NULL 值结果不正确的问题 #7172 修复某些场景下 DECIMAL 的乘法结果出现乱码的问题 #7212 修复某些场景下 DECIMAL 的取模运算结果不正确的问题 #7245 修复某些特殊语句序列下在事务中执行 UPDATE/DELETE 语句后结果不正确的问题 #7219 修复某些场景下 UNION ALL/UPDATE 语句在构造执行计划过程中 panic 的问题 #7225 修复某些场景下前缀索引的索引范围计算错误的问题 #7231 修复某些场景下 LOAD DATA 语句不写 binlog 的问题 #7242 修复某些场景下在 ADD INDEX 过程中 SHOW CREATE TABLE 结果不正确的问题 #7243 修复某些场景下 Index Join 因为没有初始化事务时间戳而 panic 的问题 #7246 修复 ADMIN CHECK TABLE 因为误用 session 中的时区而导致误报的问题 #7258 修复 ADMIN CLEANUP INDEX 在某些场景下索引没有清除干净的问题 #7265 禁用 Read Committed 事务隔离级别 #7282   TiKV  Improvements  扩大默认 scheduler slots 值以减少假冲突现象 减少回滚事务的连续标记以提升冲突极端严重下的读性能 限制 RocksDB log 文件的大小和个数以减少长时间运行下不必要的磁盘占用  Bug Fixes  修复字符串转 Decimal 时出现的 crash   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/207/</guid>
      <description> TiDB 2.0.7 Release Notes On September 7, 2018, TiDB 2.0.7 is released. Compared with TiDB 2.0.6, this release has great improvement in system compatibility and stability.
TiDB  New Feature  Add the PROCESSLIST table in information_schema #7286  Improvement  Collect more details about SQL statement execution and output the information in the SLOW QUERY log #7364 Drop the partition information in SHOW CREATE TABLE #7388 Improve the execution efficiency of the ANALYZE statement by setting it to the RC isolation level and low priority #7500 Speed up adding a unique index #7562 Add an option of controlling the DDL concurrency #7563  Bug Fixes  Fix the issue that USE INDEX(PRIMARY) cannot be used in a table whose primary key is an integer #7298 Fix the issue that Merge Join and Index Join output incorrect results when the inner row is NULL #7301 Fix the issue that Join outputs an incorrect result when the chunk size is set too small #7315 Fix the panic issue caused by a statement of creating a table involving range column #7379 Fix the issue that admin check table mistakenly reports an error of a time-type column #7457 Fix the issue that the data with a default value current_timestamp cannot be queried using the = condition #7467 Fix the issue that the zero-length parameter inserted by using the ComStmtSendLongData command is mistakenly parsed to NULL #7508 Fix the issue that auto analyze is repeatedly executed in specific scenarios #7556 Fix the issue that the parser cannot parse a single line comment ended with a newline character #7635   TiKV  Improvement  Open the dynamic-level-bytes parameter in an empty cluster by default, to reduce space amplification  Bug Fix  Update approximate size and approximate keys count of a Region after Region merging   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.7 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/207/</guid>
      <description> TiDB 2.0.7 Release Notes 2018 年 9 月 7 日，TiDB 发布 2.0.7 版。该版本在 2.0.6 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  New Feature  在 information_schema 里添加 PROCESSLIST 表 #7286  Improvements  收集更多语句执行细节，并输出在 SLOW QUERY 日志里 #7364 SHOW CREATE TABLE 不再输出分区信息 #7388 通过设置 RC 隔离级别和低优先级优化 ANALYZE 语句执行效率 #7500 加速 ADD UNIQUE INDEX #7562 增加控制 DDL 并发度的选项 #7563  Bug Fixes  修复 PRIMARY KEY 为整数的表，无法使用 USE INDEX(PRIMARY) 的问题 #7298 修复 Merge Join 和 Index Join 在 inner row 为 NULL 时输出多余结果的问题 #7301 修复 chunk size 设置过小时，Join 输出多余结果的问题 #7315 修复建表语句中包含 range column 语法导致 panic 的问题 #7379 修复 admin check table 对时间类型的列误报的问题 #7457 修复以默认值 current_timestamp 插入的数据无法用 = 条件查询到的问题 #7467 修复以 ComStmtSendLongData 命令插入空字符串参数被误解析为 NULL 的问题 #7508 修复特定场景下 auto analyze 不断重复执行的问题 #7556 修复 parser 无法解析以换行符结尾的单行注释的问题 #7635   TiKV  Improvement  空集群默认打开 dynamic-level-bytes 参数减少空间放大  Bug Fix  在 Region merge 之后更新 Region 的 approximate size 和 keys   </description>
    </item>
    
    <item>
      <title>TiDB 2.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/21beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/21beta/</guid>
      <description>TiDB 2.1 Beta Release Notes 2018 年 6 月 29 日，TiDB 发布 2.1 Beta 版。相比 2.0 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  优化 Index Join 选择范围，提升执行性能 优化关联子查询，下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升 在 UPDATE、DELETE 语句中支持 Index Hint 和 Join Hint 优化器 Hint TIDM_SMJ 在没有索引可用的情况下可生效 支持更多函数下推：ABS/CEIL/FLOOR/IS TRUE/IS FALSE 在常量折叠过程中特殊处理函数 IF 和 IFNULL 优化 EXPLAIN 语句输出格式  SQL 执行引擎  实现并行 Hash Aggregate 算子，部分场景下能提高 Hash Aggregate 计算性能 350% 实现并行 Project 算子，部分场景下性能提升达 74% 并发地读取 Hash Join 的 Inner 表和 Outer 表的数据，提升执行性能 修复部分场景下 INSERT … ON DUPLICATE KEY UPDATE … 结果不正确的问题 修复 CONCAT_WS/FLOOR/CEIL/DIV 内建函数的结果不正确的问题  Server  添加 HTTP API 打散 table 的 Regions 在 TiKV 集群中的分布 添加 auto_analyze_ratio 系统变量控制自动 analyze 的阈值 添加 HTTP API 控制是否打开 general log 添加 HTTP API 在线修改日志级别 在 general log 和 slow query log 中添加 user 信息 支持 Server side cursor  兼容性  支持更多 MySQL 语法 BIT 聚合函数支持 ALL 参数 支持 SHOW PRIVILEGES 语句  DML  减少 INSERT INTO SELECT 语句的内存占用 修复 Plan Cache 的性能问题 添加 tidb_retry_limit 系统变量控制事务自动重试的次数 添加 tidb_disable_txn_auto_retry 系统变量控制事务是否自动重试 修复写入 time 类型的数据精度问题 支持本地冲突事务排队，优化冲突事务性能 修复 UPDATE 语句的 Affected Rows 优化 insert ignore on duplicate key update 语句性能 优化 Create Table 语句的执行速度 优化 Add index 的速度，在某些场景下速度大幅提升 修复 Alter table add column 增加列超过表的列数限制的问题 修复在某些异常情况下 DDL 任务重试导致 TiKV 压力增加的问题 修复在某些异常情况下 TiDB 不断重载 Schema 信息的问题  DDL  Show Create Table 不再输出外键相关的内容 支持 select tidb_is_ddl_owner() 语句，方便判断 TiDB 是否为 DDL Owner 修复某些场景下 YEAR 类型删除索引的问题 修复并发执行场景下的 Rename table 的问题 支持 ALTER TABLE FORCE 语法 支持 ALTER TABLE RENAME KEY TO 语法 admin show ddl jobs 输出信息中添加表名、库名等信息   PD  PD 节点间开启 Raft PreVote，避免网络隔离后恢复时产生的重新选举 优化 Balance Scheduler 频繁调度小 Region 的问题 优化热点调度器，在流量统计信息抖动时适应性更好 region merge 调度时跳过数据行数较多的 Region 默认开启 raft learner 功能，降低调度时出现宕机导致数据不可用的风险 pd-recover 移除 max-replica 参数 增加 Filter相关的 metrics 修复 tikv-ctl unsafe recovery 之后 Region 信息没更新的问题 修复某些场景下副本迁移导致 TiKV 磁盘空间耗尽的问题 兼容性提示  由于新版本存储引擎更新，不支持在升级后回退至 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/releases/21beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21beta/</guid>
      <description>TiDB 2.1 Beta Release Notes On June 29, 2018, TiDB 2.1 Beta is released! Compared with TiDB 2.0, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Optimize the selection range of Index Join to improve the execution performance Optimize correlated subquery, push down Filter, and extend the index range, to improve the efficiency of some queries by orders of magnitude Support Index Hint and Join Hint in the UPDATE and DELETE statements Validate Hint TIDM_SMJ when no available index exists Support pushdown of the ABS, CEIL, FLOOR, IS TRUE, and IS FALSE functions Handle the IF and IFNULL functions especially in the constant folding process  SQL Execution Engine  Implement parallel Hash Aggregate operators and improve the computing performance of Hash Aggregate by 350% in some scenarios Implement parallel Project operators and improve the performance by 74% in some scenarios Read the data of the Inner table and Outer table of Hash Join concurrently to improve the execution performance Fix incorrect results of INSERT … ON DUPLICATE KEY UPDATE … in some scenarios Fix incorrect results of the CONCAT_WS, FLOOR, CEIL, and DIV built-in functions  Server  Add the HTTP API to scatter the distribution of table Regions in the TiKV cluster Add the auto_analyze_ratio system variable to control the threshold value of automatic Analyze Add the HTTP API to control whether to open the general log Add the HTTP API to modify the log level online Add the user information in the general log and the slow query log Support the server side cursor  Compatibility  Support more MySQL syntax Make the bit aggregate function support the ALL parameter Support the SHOW PRIVILEGES statement  DML  Decrease the memory usage of the INSERT INTO SELECT statement Fix the performance issue of PlanCache Add the tidb_retry_limit system variable to control the automatic retry times of transactions Add the tidb_disable_txn_auto_retry system variable to control whether the transaction tries automatically Fix the accuracy issue of the written data of the time type Support the queue of locally conflicted transactions to optimize the conflicted transaction performance Fix Affected Rows of the UPDATE statement Optimize the statement performance of insert ignore on duplicate key update  DDL  Optimize the execution speed of the CreateTable statement Optimize the execution speed of ADD INDEX and improve it greatly in some scenarios Fix the issue that the number of added columns by Alter table add column exceeds the limit of the number of table columns Fix the issue that DDL job retries lead to an increasing pressure on TiKV in abnormal conditions Fix the issue that TiDB continuously reloads the schema information in abnormal conditions Do not output the FOREIGN KEY related information in the result of SHOW CREATE TABLE Support the select tidb_is_ddl_owner() statement to facilitate judging whether TiDB is DDL Owner Fix the issue that the index is deleted in the Year type in some scenarios Fix the renaming table issue in the concurrent execution scenario Support the AlterTableForce syntax Support the AlterTableRenameIndex syntax with FromKey and ToKey Add the table name and database name in the output information of admin show ddl jobs   PD  Enable Raft PreVote between PD nodes to avoid leader reelection when network recovers after network isolation Optimize the issue that Balance Scheduler schedules small Regions frequently Optimize the hotspot scheduler to improve its adaptability in traffic statistics information jitters Skip the Regions with a large number of rows when scheduling region merge Enable raft learner by default to lower the risk of unavailable data caused by machine failure during scheduling Remove max-replica from pd-recover Add Filter metrics Fix the issue that Region information is not updated after tikv-ctl unsafe recovery Fix the issue that TiKV disk space is used up caused by replica migration in some scenarios Compatibility notes  Do not support rolling back to v2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/21rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/21rc1/</guid>
      <description>TiDB 2.1 RC1 Release Notes 2018 年 8 月 24 日，TiDB 发布 2.1 RC1 版。相比 2.1 Beta 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复某些情况下关联子查询去关联后结果不正确的问题 #6972 优化 Explain 输出结果 #7011#7041 优化 IndexJoin 驱动表选择策略#7019 去掉非 PREPARE 语句的 Plan Cache #7040 修复某些情况下 INSERT 语句无法正常解析执行的问题 #7068 修复某些情况下 IndexJoin 结果不正确的问题 #7150 修复某些情况下使用唯一索引不能查询到 NULL 值的问题 #7163 修复 UTF-8 编码情况下前缀索引的范围计算不正确的问题 #7194 修复某些情况下 Project 算子消除导致的结果不正确的问题 #7257 修复主键为整数类型时无法使用 USE INDEX(PRIMARY) 的问题 #7316 修复某些情况下使用关联列无法计算索引范围的问题 #7357  SQL 执行引擎  修复某些情况下夏令时时间计算结果不正确的问题 #6823 重构聚合函数框架，提升 Stream 和 Hash 聚合算子的执行效率 #6852 修复某些情况下 Hash 聚合算子不能正常退出的问题 #6982 修复 BIT_AND/BIT_OR/BIT_XOR 没有正确处理非整型数据的问题 #6994 优化 REPLACE INTO 语句的执行速度，性能提升近 10 倍 #7027 优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半 #7043 修复 UNION 语句整合有符号和无符号型整数结果时与 MySQL 不兼容的问题 #7112 修复 LPAD/RPAD/TO_BASE64/FROM_BASE64/REPEAT 因为申请过多内存导致 TiDB panic 的问题 #7171 #7266 #7409 #7431 修复 MergeJoin/IndexJoin 在处理 NULL 值时结果不正确的问题 #7255 修复某些情况下 Outer Join 结果不正确的问题 #7288 增强 Data Truncated 的报错信息，便于定位出错的数据和表中对应的字段 #7401 修复某些情况下 Decimal 计算结果不正确的问题 #7001 #7113 #7202 #7208 优化点查的查询性能 #6937 禁用 Read Commited 隔离级别，避免潜在的问题 #7211 修复某些情况下 LTRIM/RTRIM/TRIM 结果不正确的问题 #7291 修复 MaxOneRow 算子无法保证返回结果不超过 1 行的问题 #7375 拆分 range 个数过多的 Coprocessor 请求 #7454  统计信息  优化统计信息动态收集机制 #6796 解决数据频繁更新场景下 Auto Analyze 不工作的问题 #7022 减少统计信息动态更新过程中的写入冲突 #7124 优化统计信息不准确情况下的代价估算 #7175 优化 AccessPath 的代价估算策略 #7233  Server  修复加载权限信息时的 bug #6976 修复 Kill 命令对权限的检查过严问题 #6954 解决 Binary 协议中某些数值类型移除的问题 #6922 精简日志输出 #7029 处理 mismatchClusterID 问题 #7053 增加 advertise-address 配置项 #7078 增加 GrpcKeepAlive 选项 #7100 增加连接或者 Token 时间监控 #7110 优化数据解码性能 #7149 INFORMMATION_SCHEMA 中增加 PROCESSLIST 表 #7236 解决权限验证时多条规则可以命中情况下的顺序问题 #7211 将部分编码相关的系统变量默认值改为 UTF-8 #7198 慢查询日志显示更详细的信息 #7302 支持在 PD 注册 tidb-server 的相关信息并通过 HTTP API 获取 #7082  兼容性  支持 Session 变量 warning_count 和 error_count #6945 读取系统变量时增加 Scope 检查 #6958 支持 MAX_EXECUTION_TIME 语法 #7012 支持更多的 SET 语法 #7020 Set 系统变量值过程中增加合法性校验 #7117 增加 Prepare 语句中 PlaceHolder 数量的校验 #7162 支持 set character_set_results = null #7353 支持 flush status 语法 #7369 修复 SET 和 ENUM 类型在 information_schema 里的 column size #7347 支持建表语句里的 NATIONAL CHARACTER 语法 #7378 支持 LOAD DATA 语句的 CHARACTER SET 语法 #7391 修复 SET 和 ENUM类型的 column info #7417 支持 CREATE USER 语句的 IDENTIFIED WITH 语法 #7402 修复 TIMESTAMP 类型计算过程中丢失精度的问题 #7418 支持更多 SYSTEM 变量的合法性验证 #7196 修复 CHAR_LENGTH 函数在计算 binary string 时结果不正确的问题 #7410 修复在包含 GROUP BY 的语句里 CONCAT 结果不正确的问题 #7448 修复 DECIMAL 类型 CAST 到 STRING 类型时，类型长度不准确的问题 #7451  DML  解决 Load Data 语句的稳定性 #6927 解决一些 Batch 操作情况下的内存使用问题 #7086 提升 Replace Into 语句的性能 #7027 修复写入 CURRENT_TIMESTAMP 时，精度不一致的问题 #7355  DDL  改进 DDL 判断 Schema 是否已经同步的方法, 避免某些情况下的误判 #7319 修复在 ADD INDEX 过程中的 SHOW CREATE TABLE 结果 #6993 非严格 sql-mode 模式下, text/blob/json 的默认值可以为空 #7230 修复某些特定场景下 ADD INDEX 的问题 #7142 大幅度提升添加 UNIQUE-KEY 索引操作的速度 #7132 修复 Prefix-index 在 UTF-8 字符集的场景下的截断问题 #7109 增加环境变量 tidb_ddl_reorg_priority 来控制 add-index 操作的优先级 #7116 修复 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc1/</guid>
      <description>TiDB 2.1 RC1 Release Notes On August 24, 2018, TiDB 2.1 RC1 is released! Compared with TiDB 2.1 Beta, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that a wrong result is returned after the correlated subquery is decorrelated in some cases #6972 Optimize the output result of Explain #7011#7041 Optimize the choosing strategy of the outer table for IndexJoin #7019 Remove the Plan Cache of the non-PREPARE statement #7040 Fix the issue that the INSERT statement is not parsed and executed correctly in some cases #7068 Fix the issue that the IndexJoin result is not correct in some cases #7150 Fix the issue that the NULL value cannot be found using the unique index in some cases #7163 Fix the range computing issue of the prefix index in UTF-8 #7194 Fix the issue that result is not correct caused by eliminating the Project operator in some cases #7257 Fix the issue that USE INDEX(PRIMARY) cannot be used when the primary key is an integer #7316 Fix the issue that the index range cannot be computed using the correlated column in some cases #7357  SQL Execution Engine  Fix the issue that the daylight saving time is not computed correctly in some cases #6823 Refactor the aggregation function framework to improve the execution efficiency of the Stream and Hash aggregation operators #6852 Fix the issue that the Hash aggregation operator cannot exit normally in some cases #6982 Fix the issue that BIT_AND/BIT_OR/BIT_XOR does not handle the non-integer data correctly #6994 Optimize the execution speed of the REPLACE INTO statement and increase the performance nearly 10 times #7027 Optimize the memory usage of time type data and decrease the memory usage of the time type data by fifty percent #7043 Fix the issue that the returned result is mixed with signed and unsigned integers in the UNION statement is not compatible with MySQL #7112 Fix the panic issue caused by the too much memory applied by LPAD/RPAD/TO_BASE64/FROM_BASE64/REPEAT #7171 #7266 #7409 #7431 Fix the incorrect result when MergeJoin/IndexJoin handles the NULL value #7255 Fix the incorrect result of Outer Join in some cases #7288 Improve the error message of Data Truncated to facilitate locating the wrong data and the corresponding field in the table #7401 Fix the incorrect result for decimal in some cases #7001 #7113 #7202 #7208 Optimize the point select performance #6937 Prohibit the isolation level of Read Commited to avoid the underlying problem #7211 Fix the incorrect result of LTRIM/RTRIM/TRIM in some cases #7291 Fix the issue that the MaxOneRow operator cannot guarantee that the returned result does not exceed one row #7375 Divide the Coprocessor requests with too many ranges #7454  Statistics  Optimize the mechanism of statistics dynamic collection #6796 Fix the issue that Auto Analyze does not work when data is updated frequently #7022 Decrease the Write conflicts during the statistics dynamic update process #7124 Optimize the cost estimation when the statistics is incorrect #7175 Optimize the AccessPath cost estimation strategy #7233  Server  Fix the bug in loading privilege information #6976 Fix the issue that the Kill command is too strict with privilege check #6954 Fix the issue of removing some binary numeric types #6922 Shorten the output log #7029 Handle the mismatchClusterID issue #7053 Add the advertise-address configuration item #7078 Add the GrpcKeepAlive option #7100 Add the connection or Token time monitor #7110 Optimize the data decoding performance #7149 Add the PROCESSLIST table in INFORMMATION_SCHEMA #7236 Fix the order issue when multiple rules are hit in verifying the privilege #7211 Change some default values of encoding related system variables to UTF-8 #7198 Make the slow query log show more detailed information #7302 Support registering tidb-server related information in PD and obtaining this information by HTTP API #7082  Compatibility  Support Session variables warning_count and error_count #6945 Add Scope check when reading the system variables #6958 Support the MAX_EXECUTION_TIME syntax #7012 Support more statements of the SET syntax #7020 Add validity check when setting system variables #7117 Add the verification of the number of PlaceHolders in the Prepare statement #7162 Support set character_set_results = null #7353 Support the flush status syntax #7369 Fix the column size of SET and ENUM types in information_schema #7347 Support the NATIONAL CHARACTER syntax of statements for creating a table #7378 Support the CHARACTER SET syntax in the LOAD DATA statement #7391 Fix the column information of the SET and ENUM types #7417 Support the IDENTIFIED WITH syntax in the CREATE USER statement #7402 Fix the precision losing issue during TIMESTAMP computing process #7418 Support the validity verification of more SYSTEM variables #7196 Fix the incorrect result when the CHAR_LENGTH function computes the binary string #7410 Fix the incorrect CONCAT result in a statement involving GROUP BY #7448 Fix the imprecise type length issue when casting the DECIMAL type to the STRING type #7451  DML  Fix the stability issue of the Load Data statement #6927 Fix the memory usage issue when performing some Batch operations #7086 Improve the performance of the Replace Into statement #7027 Fix the inconsistent precision issue when writing CURRENT_TIMESTAMP #7355  DDL  Improve the method of DDL judging whether Schema is synchronized to avoid misjudgement in some cases #7319 Fix the SHOW CREATE TABLE result in adding index process #6993 Allow the default value of text/blob/json to be NULL in non-restrict sql-mode #7230 Fix the ADD INDEX issue in some cases #7142 Increase the speed of adding UNIQUE-KEY index operation largely #7132 Fix the truncating issue of the prefix index in UTF-8 character set #7109 Add the environment variable tidb_ddl_reorg_priority to control the priority of the add-index operation #7116 Fix the display issue of AUTO-INCREMENT in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/21rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/21rc2/</guid>
      <description>TiDB 2.1 RC2 Release Notes 2018 年 9 月 14 日，TiDB 发布 2.1 RC2 版。相比 2.1 RC1 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  新版 Planner 设计方案 #7543 提升常量传播优化规则 #7276 增强 Range 的计算逻辑使其能够同时处理多个 IN 或者等值条件 #7577 修复当 Range 为空时，TableScan 的估算结果不正确的问题 #7583 为 UPDATE 语句支持 PointGet 算子 #7586 修复 FirstRow 聚合函数某些情况下在执行过程中 panic 的问题 #7624  SQL 执行引擎  解决 HashJoin 算子在遇到错误的情况下潜在的 DataRace 问题 #7554 HashJoin 算子同时读取内表数据和构建 Hash 表 #7544 优化 Hash 聚合算子性能 #7541 优化 Join 算子性能 #7493、#7433 修复 UPDATE JOIN 在 Join 顺序改变后结果不正确的问题 #7571 提升 Chunk 迭代器的性能 #7585  统计信息  解决重复自动 Analyze 统计信息的问题 #7550 解决统计信息无变化时更新统计信息遇到错误的问题 #7530 Analyze 执行时使用低优先级以及 RC 隔离级别 #7496 支持只在一天中的某个时间段开启统计信息自动更新的功能 #7570 修复统计信息写日志时发生的 panic #7588 支持通过 ANALYZE TABLE WITH BUCKETS 语句配置直方图中桶的个数 #7619 修复更新空的直方图时 panic 的问题 #7640 使用统计信息更新 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc2/</guid>
      <description>TiDB 2.1 RC2 Release Notes On September 14, 2018, TiDB 2.1 RC2 is released. Compared with TiDB 2.1 RC1, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Put forward a proposal of the next generation Planner #7543 Improve the optimization rules of constant propagation #7276 Enhance the computing logic of Range to enable it to handle multiple IN or EQUAL conditions simultaneously #7577 Fix the issue that the estimation result of TableScan is incorrect when Range is empty #7583 Support the PointGet operator for the UPDATE statement #7586 Fix the panic issue during the process of executing the FirstRow aggregate function in some conditions #7624  SQL Execution Engine  Fix the potential DataRace issue when the HashJoin operator encounters an error #7554 Make the HashJoin operator read the inner table and build the hash table simultaneously #7544 Optimize the performance of Hash aggregate operators #7541 Optimize the performance of Join operators #7493, #7433 Fix the issue that the result of UPDATE JOIN is incorrect when the Join order is changed #7571 Improve the performance of Chunk’s iterator #7585  Statistics  Fix the issue that the auto Analyze work repeatedly analyzes the statistics #7550 Fix the statistics update error that occurs when there is no statistics change #7530 Use the RC isolation level and low priority when building Analyze requests #7496 Support enabling statistics auto-analyze on certain period of a day #7570 Fix the panic issue when logging the statistics information #7588 Support configuring the number of buckets in the histogram using the ANALYZE TABLE WITH BUCKETS statement #7619 Fix the panic issue when updating an empty histogram #7640 Update information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/21rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/21rc3/</guid>
      <description>TiDB 2.1 RC3 Release Notes 2018 年 9 月 29 日，TiDB 发布 2.1 RC3 版。相比 2.1 RC2 版本，该版本对系统稳定性、兼容性、优化器以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复语句内包含内嵌的 LEFT OUTER JOIN 时，结果不正确的问题 #7689 增强 JOIN 语句上的 predicate pushdown 优化规则 #7645 修复 UnionScan 算子的 predicate pushdown 优化规则 #7695 修复 Union 算子的 unique key 属性设置不正确的问题 #7680 增强常量折叠的优化规则 #7696 把常量传播后的 filter 是 null 的 data source 优化成 table dual #7756  SQL 执行引擎  优化事务内读请求的性能 #7717 优化部分执行器 Chunk 内存分配的开销 #7540 修复点查全部为 NULL 的列导致数组越界的问题 #7790  Server  修复配置文件里内存配额选项不生效的问题 #7729 添加 tidb_force_priority 系统变量用来整体设置语句执行的优先级 #7694 支持使用 admin show slow 语句来获取 SLOW QUERY LOG #7785  兼容性  修复 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc3/</guid>
      <description>TiDB 2.1 RC3 Release Notes On September 29, 2018, TiDB 2.1 RC3 is released. Compared with TiDB 2.1 RC2, this release has great improvement in stability, compatibility, SQL optimizer, and execution engine.
TiDB  SQL Optimizer  Fix the incorrect result issue when a statement contains embedded LEFT OUTER JOIN #7689 Enhance the optimization rule of predicate pushdown on the JOIN statement #7645 Fix the optimization rule of predicate pushdown for the UnionScan operator #7695 Fix the issue that the unique key property of the Union operator is not correctly set #7680 Enhance the optimization rule of constant folding #7696 Optimize the data source in which the filter is null after propagation to table dual #7756  SQL Execution Engine  Optimize the performance of read requests in a transaction #7717 Optimize the cost of allocating Chunk memory in some executors #7540 Fix the &amp;ldquo;index out of range&amp;rdquo; panic caused by the columns where point queries get all NULL values #7790  Server  Fix the issue that the memory quota in the configuration file does not take effect #7729 Add the tidb_force_priority system variable to set the execution priority for each statement #7694 Support using the admin show slow statement to obtain the slow query log #7785  Compatibility  Fix the issue that the result of charset/collation is incorrect in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB Academy</title>
      <link>https://pingcap.com/tidb-academy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-academy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TiDB Adopters</title>
      <link>https://pingcap.com/docs/adopters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/adopters/</guid>
      <description>TiDB Adopters This is a list of TiDB adopters in various industries.
   Company Industry Success Story     Mobike Ridesharing English; Chinese   Jinri Toutiao Mobile News Platform Chinese   Yiguo.com E-commerce English; Chinese   Yuanfudao.com EdTech English; Chinese   Ele.me Food Delivery English; Chinese   LY.com Travel Chinese   Qunar.com Travel Chinese   Hulu Entertainment    VIPKID EdTech    Lenovo Enterprise Technology    Bank of Beijing Banking    Industrial and Commercial Bank of China Banking    iQiyi Media and Entertainment    Yimian Data Big Data Chinese   Phoenix New Media Media Chinese   Mobikok AdTech Chinese   LinkDoc Technology HealthTech Chinese   G7 Networks Logistics Chinese   360 Finance FinTech Chinese   GAEA Gaming English; Chinese   YOOZOO Games Gaming Chinese   Seasun Games Gaming Chinese   NetEase Games Gaming    FUNYOURS JAPAN Gaming Chinese   Zhaopin.</description>
    </item>
    
    <item>
      <title>TiDB Ansible 常见运维操作</title>
      <link>https://pingcap.com/docs-cn/op-guide/ansible-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/ansible-operation/</guid>
      <description>TiDB Ansible 常见运维操作 启动集群 此操作会按顺序启动整个 TiDB 集群所有组件（包括 PD、TiDB、TiKV 等组件和监控组件）。
$ ansible-playbook start.yml 关闭集群 此操作会按顺序关闭整个 TiDB 集群所有组件（包括 PD、TiDB、TiKV 等组件和监控组件）。
$ ansible-playbook stop.yml 清除集群数据 此操作会关闭 TiDB、Pump、TiKV、PD 服务，并清空 Pump、TiKV、PD 数据目录。
$ ansible-playbook unsafe_cleanup_data.yml 销毁集群 此操作会关闭集群，并清空部署目录，若部署目录为挂载点，会报错，可忽略。
$ ansible-playbook unsafe_cleanup.</description>
    </item>
    
    <item>
      <title>TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/ansible-deployment/</guid>
      <description>TiDB Ansible 部署方案 概述 Ansible 是一款自动化运维工具，TiDB-Ansible 是 PingCAP 基于 Ansible playbook 功能编写的集群部署工具。本文档介绍如何使用 TiDB-Ansible 部署一个完整的 TiDB 集群。
本部署工具可以通过配置文件设置集群拓扑，完成以下各项运维工作：
 初始化操作系统参数 部署 TiDB 集群（包括 PD、TiDB、TiKV 等组件和监控组件） 启动集群 关闭集群 变更组件配置 集群扩容缩容 升级组件版本 清除集群数据 销毁集群   注：对于生产环境，须使用 TiDB-Ansible 部署 TiDB 集群。如果只是用于测试 TiDB 或体验 TiDB 的特性，建议使用 Docker Compose 在单机上快速部署 TiDB 集群。
 准备机器  部署目标机器若干
 建议 4 台及以上，TiKV 至少 3 实例，且与 TiDB、PD 模块不位于同一主机，详见部署建议。 推荐安装 CentOS 7.3 及以上版本 Linux 操作系统，x86_64 架构 (amd64)。 机器之间内网互通。   注：使用 Ansible 方式部署时，TiKV 及 PD 节点数据目录所在磁盘请使用 SSD 磁盘，否则无法通过检测。 如果仅验证功能，建议使用 Docker Compose 部署方案单机进行测试。</description>
    </item>
    
    <item>
      <title>TiDB Architecture</title>
      <link>https://pingcap.com/docs/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/architecture/</guid>
      <description>TiDB Architecture The TiDB platform is comprised of three key components: the TiDB server, the PD server, and the TiKV server. In addition, TiDB also provides the TiSpark component for the complex OLAP requirements.
TiDB server The TiDB server is in charge of the following operations:
 Receiving the SQL requests
 Processing the SQL related logics
 Locating the TiKV address for storing and computing data through Placement Driver (PD)</description>
    </item>
    
    <item>
      <title>TiDB Cloud</title>
      <link>https://pingcap.com/tidb-cloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-cloud/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TiDB Cluster Troubleshooting Guide</title>
      <link>https://pingcap.com/docs/trouble-shooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/trouble-shooting/</guid>
      <description>TiDB Cluster Troubleshooting Guide You can use this guide to help you diagnose and solve basic problems while using TiDB. If your problem is not resolved, please collect the following information and create an issue:
 The exact error message and the operations while the error occurs The state of all the components The error / fatal / panic information in the log of the component that reports the error The configuration and deployment topology The TiDB component related issue in dmesg  For other information, see Frequently Asked Questions (FAQ).</description>
    </item>
    
    <item>
      <title>TiDB Community</title>
      <link>https://pingcap.com/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/community/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TiDB Configuration File Description</title>
      <link>https://pingcap.com/docs/op-guide/tidb-config-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/tidb-config-file/</guid>
      <description>TiDB Configuration File Description The TiDB configuration file supports more options than command line options. You can find the default configuration file in config/config.toml.example and rename it to config.toml.
This document describes the options that are not involved in command line options. For command line options, see here.
split-table  To create a separate Region for each table Default: true It is recommended to set it to false if you need to create a large number of tables  oom-action  To specify the operation when out-of-memory occurs in TiDB Default: &amp;ldquo;log&amp;rdquo; The valid options are &amp;ldquo;log&amp;rdquo; and &amp;ldquo;cancel&amp;rdquo;; &amp;ldquo;log&amp;rdquo; only prints the log, without actual processing; &amp;ldquo;cancel&amp;rdquo; cancels the operation and outputs the log  enable-streaming  To enable the data fetch mode of streaming in Coprocessor Default: false  lower-case-table-names  To configure the value of the lower_case_table_names system variable Default: 2 For details, you can see the MySQL description of this variable Currently, TiDB only supports setting the value of this option to 2.</description>
    </item>
    
    <item>
      <title>TiDB Controller User Guide</title>
      <link>https://pingcap.com/docs/tools/tidb-controller/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tidb-controller/</guid>
      <description>TiDB Controller User Guide TiDB Controller is a command line tool of TiDB, usually used to obtain the status information of TiDB for debugging.
Compile from source code  Compilation environment requirement: Go Version 1.7 or later Compilation procedures: Go to the root directory of the TiDB Controller project, use the make command to compile, and generate tidb-ctl. Compilation documentation: you can find the help files in the doc directory; if the help files are lost or you want to update them, use the make doc command to generate the help files.</description>
    </item>
    
    <item>
      <title>TiDB Controller 使用说明</title>
      <link>https://pingcap.com/docs-cn/tools/tidb-controller/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tidb-controller/</guid>
      <description>TiDB Controller 使用说明 TiDB Controller 是 TiDB 的命令行工具，用于获取 TiDB 状态信息，多用于调试。
源码编译 编译环境要求：Go Version 1.7 以上
编译步骤：在 TiDB Controller 项目根目录，使用 make 命令进行编译，生成 tidb-ctl。
编译文档：帮助文档在 doc 文件夹下，如丢失或需要更新，可通过 make doc 命令生成帮助文档。
使用介绍 tidb-ctl 的使用由命令（包括子命令）、选项和参数组成。命令即不带 - 或者 -- 的字符，选项即带有 - 或者 -- 的字符，参数即命令或选项字符后紧跟的传递给命令和选项的字符。
如：tidb-ctl schema in mysql -n db
 schema: 命令 in: schema 的子命令 mysql: in 的参数 -n: 选项 db: -n 的参数  获取帮助 tidb-ctl -h/--help 用于获取帮助信息。tidb-ctl 由多层命令组成，tidb-ctl 及其所有子命令都可以通过 -h/--help 来获取使用帮助。
连接 tidb-ctl -H/--host { TiDB 服务地址} -P/--port { TiDB 服务端口}</description>
    </item>
    
    <item>
      <title>TiDB Data Manipulation Language</title>
      <link>https://pingcap.com/docs/sql/dml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/dml/</guid>
      <description>TiDB Data Manipulation Language Data manipulation language (DML) is a family of syntax elements used for selecting, inserting, deleting and updating data in a database.
SELECT SELECT is used to retrieve rows selected from one or more tables.
Syntax SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], .</description>
    </item>
    
    <item>
      <title>TiDB Data Type</title>
      <link>https://pingcap.com/docs/sql/datatype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/datatype/</guid>
      <description>TiDB Data Type TiDB supports all the data types in MySQL except the Spatial type, including numeric type, string type, date &amp;amp; time type, and JSON type.
The definition of the data type is: T(M[, D]). In this format:
 T indicates the specific data type. M indicates the maximum display width for integer types. For floating-point and fixed-point types, M is the total number of digits that can be stored (the precision).</description>
    </item>
    
    <item>
      <title>TiDB Deployment on Kubernetes</title>
      <link>https://pingcap.com/docs/op-guide/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/kubernetes/</guid>
      <description>TiDB Deployment on Kubernetes TiDB Operator manages TiDB clusters on Kubernetes and automates tasks related to operating a TiDB cluster. It makes TiDB a truly cloud-native database.
 Warning: Currently, TiDB Operator is work in progress [WIP] and is NOT ready for production. Use at your own risk.
 Google Kubernetes Engine (GKE) The TiDB Operator tutorial for GKE runs directly in the Google Cloud Shell.

Local installation using Docker in Docker Docker in Docker (DinD) runs Docker containers as virtual machines and runs another layer of Docker containers inside the first layer of Docker containers.</description>
    </item>
    
    <item>
      <title>TiDB Docker Compose Deployment</title>
      <link>https://pingcap.com/docs/op-guide/docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/docker-compose/</guid>
      <description>TiDB Docker Compose Deployment This document describes how to quickly deploy a TiDB testing cluster with a single command using Docker Compose.
With Docker Compose, you can use a YAML file to configure application services in multiple containers. Then, with a single command, you can create and start all the services from your configuration.
Prerequisites Make sure you have installed the following items on your machine:
 Git Docker Compose MySQL Client  Deploy TiDB using Docker Compose  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>TiDB Docker 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/docker-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/docker-deployment/</guid>
      <description>TiDB Docker 部署方案 本文介绍如何使用 Docker 部署一个多节点的 TiDB 集群。
 注：对于生产环境，不要使用 Docker 进行部署，而应使用 Ansible 部署 TiDB 集群。
 环境准备 安装 Docker Docker 可以方便地在 Linux / Mac OS / Windows 平台安装，安装方法请参考 Docker 官方文档。
拉取 TiDB 的 Docker 镜像 部署 TiDB 集群主要包括 3 个服务组件:
 TiDB TiKV PD  对应的最新 Docker 镜像可以通过 Docker 官方镜像仓库 获取：
docker pull pingcap/tidb:latest docker pull pingcap/tikv:latest docker pull pingcap/pd:latest 部署一个多节点集群 假设我们打算在 6 台主机上部署一个 TiDB 集群:
   主机名 IP 部署服务 数据盘挂载     host1 192.</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs-cn/FAQ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/FAQ/</guid>
      <description>FAQ 一、 TiDB 介绍、架构、原理 1.1 TiDB 介绍及整体架构 1.1.1 TiDB 整体架构 https://pingcap.com/docs-cn/overview/
1.1.2 TiDB 是什么？ TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。
1.1.3 TiDB 是基于 MySQL 开发的吗？ 不是，虽然 TiDB 支持 MySQL 语法和协议，但是 TiDB 是由 PingCAP 团队完全自主开发的产品。
1.1.4 TiDB、TiKV、Placement Driver (PD) 主要作用？  TiDB 是 Server 计算层，主要负责 SQL 的解析、制定查询计划、生成执行器。 TiKV 是分布式 Key-Value 存储引擎，用来存储真正的数据，简而言之，TiKV 是 TiDB 的存储引擎。 PD 是 TiDB 集群的管理组件，负责存储 TiKV 的元数据，同时也负责分配时间戳以及对 TiKV 做负载均衡调度。  1.</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs/FAQ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/FAQ/</guid>
      <description>TiDB FAQ This document lists the Most Frequently Asked Questions about TiDB.
About TiDB TiDB introduction and architecture What is TiDB? TiDB is a distributed SQL database that features in horizontal scalability, high availability and consistent distributed transactions. It also enables you to use MySQL&amp;rsquo;s SQL syntax and protocol to manage and retrieve data.
What is TiDB&amp;rsquo;s architecture? The TiDB cluster has three components: the TiDB server, the PD (Placement Driver) server, and the TiKV server.</description>
    </item>
    
    <item>
      <title>TiDB Garbage Collection (GC)</title>
      <link>https://pingcap.com/docs/op-guide/gc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/gc/</guid>
      <description>TiDB Garbage Collection (GC) TiDB uses MVCC to control concurrency. When you update or delete data, the original data is not deleted immediately but is kept for a period during which it can be read. Thus the write operation and the read operation are not mutually exclusive and it is possible to read the history versions of the data.
The data versions whose duration exceeds a specific time and that are not used any more will be cleared, otherwise they will occupy the disk space and affect TiDB&amp;rsquo;s performance.</description>
    </item>
    
    <item>
      <title>TiDB Introduction</title>
      <link>https://pingcap.com/docs/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/overview/</guid>
      <description>TiDB Introduction TiDB (The pronunciation is: /&amp;lsquo;taɪdiːbi:/ tai-D-B, etymology: titanium) is an open-source distributed scalable Hybrid Transactional and Analytical Processing (HTAP) database. It features infinite horizontal scalability, strong consistency, and high availability. TiDB is MySQL compatible and serves as a one-stop data warehouse for both OLTP (Online Transactional Processing) and OLAP (Online Analytical Processing) workloads.
 Horizontal scalability
TiDB provides horizontal scalability simply by adding new nodes. Never worry about infrastructure capacity ever again.</description>
    </item>
    
    <item>
      <title>TiDB Memory Control</title>
      <link>https://pingcap.com/docs/sql/tidb-memory-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/tidb-memory-control/</guid>
      <description>TiDB Memory Control Currently, TiDB can track the memory quota of a single SQL query and take actions to prevent OOM (out of memory) or troubleshoot OOM when the memory usage exceeds a specific threshold value. In the TiDB configuration file, you can configure the options as below to control TiDB behaviors when the memory quota exceeds the threshold value:
# Valid options: [&amp;#34;log&amp;#34;, &amp;#34;cancel&amp;#34;] oom-action = &amp;#34;log&amp;#34;  If the configuration item above uses &amp;ldquo;log&amp;rdquo;, when the memory quota of a single SQL query exceeds the threshold value which is controlled by the tidb_mem_quota_query variable, TiDB prints an entry of log.</description>
    </item>
    
    <item>
      <title>TiDB Pre-GA Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/prega/</guid>
      <description> TiDB Pre-GA Release Notes 2017 年 8 月 30 日，TiDB 发布 Pre-GA 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB:  SQL 查询优化器  调整代价模型 优化索引选择，支持不同类型字段比较的索引选择 支持基于贪心算法的 Join Reorder  大量 MySQL 兼容性相关功能 支持 Natural Join 完成 JSON 类型支持 (Experimental)，包括对 JSON 中的字段查询、更新、建索引 裁剪无用数据，减小执行器内存消耗 支持在 SQL 语句中设置优先级，并根据查询类型自动设置部分语句的优先级 完成表达式重构，执行速度提升 30% 左右  PD:  支持手动切换 PD 集群 Leader  TiKV:  Raft Log 使用独立的 RocksDB 实例 使用 DeleteRange 加快删除副本速度 Coprocessor 支持更多运算符下推 提升性能，提升稳定性  TiSpark Beta Release:  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB Quick Start Guide</title>
      <link>https://pingcap.com/docs/QUICKSTART/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/QUICKSTART/</guid>
      <description>TiDB Quick Start Guide As an open source distributed scalable HTAP database, TiDB can be deployed on-premise or in-cloud. The following deployment options are officially supported by PingCAP.
 Ansible Deployment: This guide describes how to deploy TiDB using Ansible. It is strongly recommended for production deployment. Ansible Offline Deployment: If your environment has no access to the internet, you can follow this guide to see how to deploy a TiDB cluster offline using Ansible.</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc1/</guid>
      <description> TiDB RC1 Release Notes 2016 年 12 月 23 日，分布式关系型数据库 TiDB 正式发布 RC1。
TiKV + 提升写入速度 + 降低磁盘空间占用 + 支持百 TB 级别数据 + 提升稳定性，集群规模支持 200 个节点 + 提供 Raw KV API，以及 Golang client PD + PD 调度策略框架优化，策略更加灵活合理 + 添加 label 支持，支持跨 DC 调度 + 提供 PD Controler，方便操作 PD 集群 TiDB + SQL 查询优化器 - 支持 eager aggregate - 更详细的 explain 信息 - union 算子并行化 - 子查询性能优化 - 条件下推优化 - 优化 CBO 框架 + 重构 time 相关类型的实现，提升和 MySQL 的兼容性 + 支持更多的 MySQL 内建函数 + Add Index 语句提速 + 支持用 change column 语句修改列名；支持使用 Alter table 的 modify column 和 change column 完成部分列类型转换 工具 + Loader：兼容 Percona 的 mydumper 数据格式，提供多线程导入、出错重试、断点续传等功能，并且针对 TiDB 有优化 + 开发完成一键部署工具</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc1/</guid>
      <description>TiDB RC1 Release Notes On December 23, 2016, TiDB RC1 is released. See the following updates in this release:
TiKV:  The write speed has been improved. The disk space usage is reduced. Hundreds of TBs of data can be supported. The stability is improved and TiKV can support a cluster with 200 nodes. Supports the Raw KV API and the Golang client.  Placement Driver (PD): + The scheduling strategy framework is optimized and now the strategy is more flexible and reasonable.</description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes 2017 年 3 月 1 日，TiDB 正式发布 RC2 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。对于 OLTP 场景，读取性能提升 60%，写入性能提升 30%。另外提供了权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推  支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息   TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on the compatibility with MySQL, SQL query optimizer, system stability and performance in this version. What’s more, a new permission management mechanism is added and users can control data access in the same way as the MySQL privilege management system.
TiDB:  Query optimizer  Collect column/index statistics and use them in the query optimizer Optimize the correlated subquery Optimize the Cost Based Optimizer (CBO) framework Eliminate aggregation using unique key information Refactor expression evaluation framework Convert Distinct to GroupBy Support the topn operation push-down  Support basic privilege management Add lots of MySQL built-in functions Improve the Alter Table statement and support the modification of table name, default value and comment Support the Create Table Like statement Support the Show Warnings statement Support the Rename Table statement Restrict the size of a single transaction to avoid the cluster blocking of large transactions Automatically split data in the process of Load Data Optimize the performance of the AddIndex and Delete statement Support &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode Improve the monitoring system Fix Bugs Solve the problem of memory leak  PD:  Support location aware replica scheduling Conduct fast scheduling based on the number of region pd-ctl support more features  Add or delete PD Obtain Region information with Key Add or delete scheduler and operator Obtain cluster label information   TiKV:  Support Async Apply to improve the entire write performance Use prefix seek to improve the read performance of Write CF Use memory hint prefix to improve the insert performance of Raft CF Optimize the single read transaction performance Support more push-down expressions Improve the monitoring system Fix Bugs  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc3/</guid>
      <description> TiDB RC3 Release Notes 2017 年 6 月 16 日，TiDB 正式发布 RC3 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了负载均衡调度策略和流程。功能方面进一步完善权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。另外 DDL 的速度也得到显著的提升。 同时为了简化运维工作，开源了 TiDB-Ansible 项目，可以一键部署/升级/启停 TiDB 集群。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推  支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息    TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc3/</guid>
      <description>TiDB RC3 Release Notes On June 20, 2017, TiDB RC4 is released!This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  The privilege management is refined to enable users to manage the data access privileges using the same way as in MySQL. DDL is accelerated. The load balancing policy and process are optimized for performance. TiDB-Ansible is open sourced. By using TiDB-Ansilbe, you can deploy, upgrade, start and shutdown a TiDB cluster with one click.</description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc4/</guid>
      <description> TiDB RC4 Release Notes 2017 年 8 月 4 日，TiDB 正式发布 RC4 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了写入速度，计算任务调度支持优先级，避免分析型大事务影响在线事务。SQL 优化器全新改版，查询代价估算更加准确，且能够自动选择 Join 物理算子。功能方面进一步 MySQL 兼容性。 同时为了更好的支持 OLAP 业务，开源了 TiSpark 项目，可以通过 Spark 读取和分析 TiKV 中的数据。
TiDB:  SQL 查询优化器重构  更好的支持 TopN 查询 支持 Join 算子根据代价自动选择 更完善的 Projection Elimination  Schema 版本检查区分 Table，避免 DDL 干扰其他正在执行的事务 支持 BatchIndexJoin 完善 Explain 语句 提升 Index Scan 性能 大量 MySQL 兼容性相关功能 支持 Json 类型及其操作 支持查询优先级、隔离级别的设置  PD:  支持通过 PD 设置 TiKV location labels 调度优化  支持 PD 主动向 TiKV 下发调度命令 加快 region heartbeat 响应速度 优化 balance 算法  优化数据加载，加快 failover 速度  TiKV:  支持查询优先级设置 支持 RC 隔离级别 完善 Jepsen，提升稳定性 支持 Document Store Coprocessor 支持更多下推函数 提升性能，提升稳定性  TiSpark Beta Release:  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc4/</guid>
      <description>TiDB RC4 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  For performance, the write performance is improved significantly, and the computing task scheduling supports prioritizing to avoid the impact of OLAP on OLTP. The optimizer is revised for a more accurate query cost estimating and for an automatic choice of the Join physical operator based on the cost.</description>
    </item>
    
    <item>
      <title>TiDB Roadmap</title>
      <link>https://pingcap.com/docs/ROADMAP/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/ROADMAP/</guid>
      <description>TiDB Roadmap This document defines the roadmap for TiDB development.
TiDB: Optimizer Refactor Ranger Optimize the cost model Cascades model planner Join Reorder  Statistics Update statistics dynamically according to the query feedback Analyze table automatically Improve the accuracy of Row Count estimation  Execution Engine Push down the Projection operator to the Coprocessor Improve the performance of the HashJoin operator Parallel Operators Projection Aggregation Sort  Compact Row Format to reduce memory usage File Sort  View Window Function Common Table Expression Table Partition Range Partition Hash Partition  Cluster Index New storage row format Query Tracing Improve DDL Speed up Add Index operation Parallel DDL Support locking table Support modifying the column type Supoort modifying the primary key Support multiple DDL operations in a single statement  Support utf8_general_ci collation  TiKV: Raft Region Merge - Merge small Regions together to reduce overhead Local Read Thread - Process read requests in a local read thread Split Region in Batch - Speed up Region split for large Regions Raft Learner - Support Raft learner to smooth the configuration change process Raft Pre-vote - Support Raft pre-vote to avoid unnecessary leader election on network isolation Joint Consensus - Change multi members safely.</description>
    </item>
    
    <item>
      <title>TiDB Robot</title>
      <link>https://pingcap.com/tidb-planet/robot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/robot/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.0.0 vs. v1.0.0</title>
      <link>https://pingcap.com/docs/benchmark/sysbench-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/sysbench-v2/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.0.0 vs. v1.0.0 Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0.
Test version, time, and place TiDB version: v1.0.8 vs. v2.0.0-rc6
Time: April 2018
Place: Beijing, China
Test environment IDC machine
| Type | Name |
| &amp;mdash;&amp;mdash;&amp;ndash; | &amp;mdash;&amp;mdash;&amp;mdash; | | OS | linux (CentOS 7.3.1611) |
| CPU | 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.1 vs. v2.0</title>
      <link>https://pingcap.com/docs/benchmark/sysbench-v3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/sysbench-v3/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.1 vs. v2.0 Test purpose This test aims to compare the performances of TiDB 2.1 and TiDB 2.0 in the OLTP scenario.
Test version, time, and place TiDB version: v2.1.0-rc.2 vs. v2.0.6
Time: September, 2018
Place: Beijing, China
Test environment IDC machine:
| Type | Name |
| :-: | :-: | | OS | Linux (CentOS 7.3.1611) | | CPU | 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench 性能对比测试报告 - v2.0.0 对比 v1.0.0</title>
      <link>https://pingcap.com/docs-cn/benchmark/sysbench-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/benchmark/sysbench-v2/</guid>
      <description>TiDB Sysbench 性能对比测试报告 - v2.0.0 对比 v1.0.0 测试目的 对比 TiDB 2.0 版本和 1.0 版本在 OLTP 场景下的性能。
测试版本、时间、地点 TiDB 版本：v1.0.8 Vs v2.0.0-rc6
时间：2018 年 4 月
地点：北京
测试环境 IDC 机器
| 类别 | 名称 |
| :&amp;mdash;&amp;mdash;&amp;ndash;: | :&amp;mdash;&amp;mdash;&amp;mdash;: | | OS | Linux (CentOS 7.3.1611) | | CPU | 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.20GHz | | RAM | 128GB | | DISK | Optane 500GB SSD * 1 |</description>
    </item>
    
    <item>
      <title>TiDB Sysbench 性能对比测试报告 - v2.1 对比 v2.0</title>
      <link>https://pingcap.com/docs-cn/benchmark/sysbench-v3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/benchmark/sysbench-v3/</guid>
      <description>TiDB Sysbench 性能对比测试报告 - v2.1 对比 v2.0 测试目的 对比 TiDB 2.1 版本和 2.0 版本在 OLTP 场景下的性能。
测试版本、时间、地点 TiDB 版本：v2.1.0-rc.2 vs. v2.0.6
时间：2018 年 9 月
地点：北京
测试环境 IDC 机器：
| 类别 | 名称 |
| :-: | :-: | | OS | Linux (CentOS 7.3.1611) | | CPU | 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.20GHz | | RAM | 128GB | | DISK | Optane 500GB SSD * 1 |</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.0</title>
      <link>https://pingcap.com/docs/benchmark/tpch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/tpch/</guid>
      <description>TiDB TPC-H 50G Performance Test Report Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0 in the OLAP scenario.
 Note: Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     172.16.31.2 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.3 Ubuntu 17.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.1</title>
      <link>https://pingcap.com/docs/benchmark/tpch-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/tpch-v2/</guid>
      <description>TiDB TPC-H 50G Performance Test Report V2.1 Test purpose This test aims to compare the performances of TiDB 2.0 and TiDB 2.1 in the OLAP scenario.
 Note: Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     10.0.1.4 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.5 CentOS 7.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G 性能测试报告</title>
      <link>https://pingcap.com/docs-cn/benchmark/tpch-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/benchmark/tpch-v2/</guid>
      <description>TiDB TPC-H 50G 性能测试报告 测试目的 测试 TiDB 在 OLAP 场景下 2.0 和 2.1 版本的性能对比。
 注意：不同的测试环境可能使测试结果发生改变。
 测试环境 测试机器信息  系统信息     机器 IP 操作系统 内核版本 文件系统类型     10.0.1.4 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.5 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.6 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.7 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.8 CentOS 7.5.1804 64bit 3.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G 性能测试报告</title>
      <link>https://pingcap.com/docs-cn/benchmark/tpch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/benchmark/tpch/</guid>
      <description>TiDB TPC-H 50G 性能测试报告 测试目的 测试 TiDB 在 OLAP 场景下 1.0 和 2.0 版本的性能对比。
 注意：不同的测试环境可能使测试结果发生改变。
 测试环境 测试机器信息  系统信息     机器 IP 操作系统 内核版本 文件系统类型     172.16.31.2 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.3 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.4 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.6 CentOS 7.4.1708 64bit 3.10.0-693.11.6.el7.x86_64 ext4   172.16.31.8 CentOS 7.4.1708 64bit 3.</description>
    </item>
    
    <item>
      <title>TiDB Transaction Isolation Levels</title>
      <link>https://pingcap.com/docs/sql/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/transaction-isolation/</guid>
      <description>TiDB Transaction Isolation Levels Transaction isolation is one of the foundations of database transaction processing. Isolation is the I in the acronym ACID (Atomicity, Consistency, Isolation, Durability), which represents the isolation property of database transactions.
The SQL-92 standard defines four levels of transaction isolation: Read Uncommitted, Read Committed, Repeatable Read and Serializable. See the following table for details:
   Isolation Level Dirty Read Nonrepeatable Read Phantom Read Serialization Anomaly     Read Uncommitted Possible Possible Possible Possible   Read Committed Not possible Possible Possible Possible   Repeatable Read Not possible Not possible Not possible in TiDB Possible   Serializable Not possible Not possible Not possible Not possible    TiDB offers the Repeatable Read isolation level.</description>
    </item>
    
    <item>
      <title>TiDB User Account Management</title>
      <link>https://pingcap.com/docs/sql/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-account-management/</guid>
      <description>TiDB User Account Management This document describes how to manage a TiDB user account.
User names and passwords TiDB stores the user accounts in the table of the mysql.user system database. Each account is identified by a user name and the client host. Each account may have a password.
You can connect to the TiDB server using the MySQL client, and use the specified account and password to login:</description>
    </item>
    
    <item>
      <title>TiDB User Guide</title>
      <link>https://pingcap.com/docs/sql/user-manual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-manual/</guid>
      <description>TiDB User Guide TiDB supports the SQL-92 standard and is compatible with MySQL. To help you easily get started with TiDB, TiDB user guide mainly inherits the MySQL document structure with some TiDB specific changes.
TiDB server administration  The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The Proprietary System Variables and Syntax in TiDB The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections  SQL optimization  Understand the Query Execution Plan Introduction to Statistics  Language structure  Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax  Globalization  Character Set Support Character Set Configuration Time Zone  Data types  Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values  Functions and operators  Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Functions Used with Global Transaction IDs [TBD] Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math  SQL statement syntax  Data Definition Statements Data Manipulation Statements Transactions</description>
    </item>
    
    <item>
      <title>TiDB 专用系统变量和语法</title>
      <link>https://pingcap.com/docs-cn/sql/tidb-specific/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/tidb-specific/</guid>
      <description>TiDB 专用系统变量和语法 TiDB 在 MySQL 的基础上，定义了一些专用的系统变量和语法用来优化性能。
System Variable 变量可以通过 SET 语句设置，例如
set @@tidb_distsql_scan_concurrency = 10
如果需要设值全局变量，执行
set @@global.tidb_distsql_scan_concurrency = 10
tidb_snapshot 作用域: SESSION
默认值: 空字符串
这个变量用来设置当前会话期待读取的历史数据所处时刻。 比如当设置为 &amp;ldquo;2017-11-11 20:20:20&amp;rdquo; 时或者一个 TSO 数字 &amp;ldquo;400036290571534337&amp;rdquo;，当前会话将能读取到该时刻的数据。
tidb_import_data 作用域: SESSION
默认值: 0
这个变量用来表示当前状态是否为从 dump 文件中导入数据。 当这个变量被设置为 1 时，唯一索引约束不被检查以加速导入速度。 这个变量不对外用，只是给 lightning 使用，请用户不要自行修改。
tidb_opt_agg_push_down 作用域: SESSION
默认值: 0
这个变量用来设置优化器是否执行聚合函数下推到 Join 之前的优化操作。 当查询中聚合操作执行很慢时，可以尝试设置该变量为 1。
tidb_opt_insubquery_unfold 作用域: SESSION
默认值: 0
这个变量用来设置优化器是否执行 in-子查询展开的优化操作。
tidb_build_stats_concurrency 作用域: SESSION
默认值: 4</description>
    </item>
    
    <item>
      <title>TiDB 事务语句</title>
      <link>https://pingcap.com/docs-cn/sql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/transaction/</guid>
      <description>TiDB 事务语句 TiDB 支持分布式事务。涉及到事务的语句包括 Autocommit 变量、 START TRANSACTION/BEGIN、 COMMIT 以及 ROLLBACK。
自动提交 语法：
SET autocommit = {0 | 1} 通过设置 autocommit 的值为 1，可以将当前 Session 设置为自动提交状态，0 则表示当前 Session 为非自动提交状态。默认情况下， autocommit 的值为 1。
在自动提交状态，每条语句运行后，会将其修改自动提交到数据库中。否则，会等到运行 COMMIT 语句或者是 BEGIN 语句的时候，才会将之前的修改提交到数据库。
另外 autocommit 也是一个 System Variable，所以可以通过变量赋值语句修改当前 Session 或者是 Global 的值。
SET @@SESSION.autocommit = {0 | 1}; SET @@GLOBAL.autocommit = {0 | 1}; START TRANSACTION, Begin 语法:
BEGIN; START TRANSACTION; START TRANSACTION WITH CONSISTENT SNAPSHOT; 上述三条语句都是事务开始语句，效果相同。通过事务开始语句可以显式地开始一个新的事务，如果这个时候当前 Session 正在一个事务中间过程中，会将当前事务提交后，开启一个新的事务。</description>
    </item>
    
    <item>
      <title>TiDB 事务隔离级别</title>
      <link>https://pingcap.com/docs-cn/sql/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/transaction-isolation/</guid>
      <description>TiDB 事务隔离级别 事务隔离级别是数据库事务处理的基础，ACID 中 I，即 Isolation，指的就是事务的隔离性。
sql 92标准定义了4种隔离级别，读未提交、读已提交、可重复读、串行化，见下表。
   Isolation Level Dirty Read Nonrepeatable Read Phantom Read Serialization Anomaly     Read uncommitted Possible Possible Possible Possible   Read committed Not possible Possible Possible Possible   Repeatable read Not possible Not possible Not possible in TiDB Possible   Serializable Not possible Not possible Not possible Not possible    TiDB 实现了其中的可重复读。</description>
    </item>
    
    <item>
      <title>TiDB 内存控制文档</title>
      <link>https://pingcap.com/docs-cn/sql/tidb-memory-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/tidb-memory-control/</guid>
      <description>TiDB 内存控制文档 目前 TiDB 已经能够做到追踪单条 SQL 查询过程中的内存使用情况，当内存使用超过一定阈值后也能采取一些操作来预防 OOM 或者排查 OOM 原因。在 TiDB 的配置文件中，我们可以使用如下配置来控制内存使用超阈值时 TiDB 的行为：
# Valid options: [&amp;#34;log&amp;#34;, &amp;#34;cancel&amp;#34;] oom-action = &amp;#34;log&amp;#34;  如果上面的配置项使用的是 &amp;ldquo;log&amp;rdquo;，那么当一条 SQL 的内存使用超过一定阈值（由 session 变量 tidb_mem_quota_query 来控制）后，TiDB 会在 log 文件中打印一条 LOG，然后这条 SQL 继续执行，之后如果发生了 OOM 可以在 log 中找到对应的 SQL。 如果上面的配置项使用的是 &amp;ldquo;cancel&amp;rdquo;，那么当一条 SQL 的内存使用超过一定阈值后，TiDB 会立即中断这条 SQL 的执行并给客户端返回一个 error，error 信息中会详细写明这条 SQL 执行过程中各个占用内存比较多的物理执行算子的内存使用情况。  如何配置一条 SQL 执行过程中的内存使用阈值 目前可通过如下几个 session 变量来控制一条 Query 中的内存使用，大多数用户只需要设置 tidb_mem_quota_query 即可，其他变量是高级配置，大多数用户不需要关心：
   变量名 作用 单位 默认值     tidb_mem_quota_query 配置整条 SQL 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_hashjoin 配置 Hash Join 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_mergejoin 配置 Merge Join 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_sort 配置 Sort 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_topn 配置 TopN 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_indexlookupreader 配置 Index Lookup Reader 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_indexlookupjoin 配置 Index Lookup Join 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30   tidb_mem_quota_nestedloopapply 配置 Nested Loop Apply 的内存使用阈值 Byte 32 &amp;lt;&amp;lt; 30    几个使用例子：</description>
    </item>
    
    <item>
      <title>TiDB 历史数据回溯</title>
      <link>https://pingcap.com/docs-cn/op-guide/history-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/history-read/</guid>
      <description>TiDB 历史数据回溯 本文档用于描述 TiDB 如何读取历史版本数据，包括具体的操作流程以及历史数据的保存策略。
功能说明 TiDB 实现了通过标准 SQL 接口读取历史数据功能，无需特殊的 client 或者 driver。当数据被更新、删除后，依然可以通过 SQL 接口将更新/删除前的数据读取出来。
另外即使在更新数据之后，表结构发生了变化，TiDB 依旧能用旧的表结构将数据读取出来。
操作流程 为支持读取历史版本数据， 引入了一个新的 system variable: tidb_snapshot ，这个变量是 Session 范围有效，可以通过标准的 Set 语句修改其值。其值为文本，能够存储 TSO 和日期时间。TSO 即是全局授时的时间戳，是从 PD 端获取的; 日期时间的格式可以为： “2016-10-08 16:45:26.999”，一般来说可以只写到秒，比如”2016-10-08 16:45:26”。 当这个变量被设置时，TiDB 会用这个时间戳建立 Snapshot（没有开销，只是创建数据结构），随后所有的 Select 操作都会在这个 Snapshot 上读取数据。
 注意：TiDB 的事务是通过 PD 进行全局授时，所以存储的数据版本也是以 PD 所授时间戳作为版本号。在生成 Snapshot 时，是以 tidb_snapshot 变量的值作为版本号，如果 TiDB Server 所在机器和 PD Server 所在机器的本地时间相差较大，需要以 PD 的时间为准。
 当读取历史版本操作结束后，可以结束当前 Session 或者是通过 Set 语句将 tidb_snapshot 变量的值设为 &amp;ldquo;&amp;ldquo;，即可读取最新版本的数据。</description>
    </item>
    
    <item>
      <title>TiDB 商业产品开发 - Cloud 方向</title>
      <link>https://pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/</guid>
      <description>TiDB 商业产品开发 - Cloud 方向 岗位职责：
 TiDB 基于 Kubernetes 平台自动化部署运维工具的开发；
 TiDB 与公有云/私有云平台整合。
  任职要求：
 扎实的编程能力，熟悉 C/C++/Go/Rust/Python 一种编程语言；
 对容器技术有较深入的了解；
 熟悉 Swarm/Mesos/Kubernetes 等容器编排系统中至少一种；
 熟练使用 Linux；
 具备大型分布式系统监控、分析和故障排查等相关经验；
 有国内外公有云平台使用和运维经验；
 良好的沟通能力和技巧。
  加分项：
 熟悉 Ansible/Saltstack 等自动化部署工具；
 为 Docker/Kubernetes 贡献过代码；
 熟悉 BGP、Overlay 网络。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>TiDB 商业产品开发 - SRE 方向</title>
      <link>https://pingcap.com/recruit-cn/engineering/bizdev-sre-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/bizdev-sre-engineer/</guid>
      <description>TiDB 商业产品开发 - SRE 方向 岗位职责：
 管理维护公司内部各种资源，让一切自动化起来；
 Linux 系统调优和诊断工具开发。
  任职要求：
 以“折腾” Linux 为乐；
 掌握一门基础编程语言，如 C/C++/Go/Rust/&amp;hellip;&amp;hellip;
 熟练掌握一门脚本语言，如 Shell/Python/Perl/&amp;hellip;&amp;hellip;
 熟悉 Linux kernel 和各个子系统 (网络、存储，内存，调度、文件系统等)，熟悉内核参数优化和系统 profile 工具；
 熟悉 TCP/IP 基本原理；
 精通路由、交换、防火墙、四层交换等网络技术，有较强的网络安全意识；
 熟悉配置调试主流厂商如华为、Juniper 网络设备，有相关项目实施运维经验；
 责任心强、积极主动，抗压能力强，有良好的沟通能力和团队合作能力。
  加分项：
 熟悉 Systemtap, Perf 等分析调试工具优先考虑；
 有 Cisco, H3C 网络认证者优先考虑。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>TiDB 商业产品开发 - 产品方向</title>
      <link>https://pingcap.com/recruit-cn/engineering/bizdev-fe-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/bizdev-fe-engineer/</guid>
      <description>TiDB 商业产品开发 - 产品设计方向 岗位职责：
 负责为商业产品和工具等开发流畅酷炫富有科技范的前端界面；
 前端组件设计，框架定制和保证快速迭代的速度和质量，探索前端开发新规范和模式。
  任职要求：
 三年以上相关领域开发经验，扎实的编程能力；
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神；
 熟悉 JavaScript/TypeScript 和新语言规范和语法特性 如 ES2015 等；
 精通 webpack 构建，nodejs 脚本开发和常用 prettier、eslint、babel 等配置；
 熟悉 React/Angular/Vue 等现代 Web 前端框架使用和实现原理；
 熟悉富应用 SPA 开发模式，如单向数据流 Flux/Redux，响应式编程 rxjs/cyclejs。
  加分项：
 拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历；
 良好的适应和学习能力对自己不设限，挑战如：数据可视化，监控告警 DevOPS，商业/工具产品设计等方向；
 其他例如您熟悉 Electron、看过 Chromium 源代码、写过一些关于 JavaScript 技术的博客文章&amp;hellip;&amp;hellip;具体不限，我们愿闻其详。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京</description>
    </item>
    
    <item>
      <title>TiDB 商业产品开发 - 工具方向</title>
      <link>https://pingcap.com/recruit-cn/engineering/bizdev-tools-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/bizdev-tools-engineer/</guid>
      <description>TiDB 商业产品开发 - 工具方向 岗位职责：
 TiDB 商业工具开发，完善 TiDB 的周边生态，提升用户使用体验；
 建设高度智能的自动化测试系统，进行各种破坏性测试，验证 TiDB 的可靠性。
  任职要求：
 扎实的编程能力，熟悉 C/C++/Go/Rust 其中一种编程语言；
 熟悉大型分布式系统，具备冷静分析复杂问题能力；
 熟悉常用算法和数据结构；
 深入了解过操作系统和网络；
 良好的沟通能力和技巧，以及抗压能力；
 了解 Automated Reasoning、Static Analysis 等测试方法及工具。
  加分项：
 爱折腾，强烈的 Hack 精神；
 TopCoder、Codeforces 黄色以上。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>TiDB 垃圾回收 (GC)</title>
      <link>https://pingcap.com/docs-cn/op-guide/gc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/gc/</guid>
      <description>TiDB 垃圾回收 (GC) TiDB 采用 MVCC 的方式来进行并发控制。当对数据进行更新或者删除时，原有的数据不会被立刻删除，而是会被保留一段时间，并且在这段时间内这些旧数据仍然可以被读取。这使得写入操作和读取操作不必互斥，并使读取历史数据成为可能。
存在超过一定时间并且不再使用的版本会被清理，否则它们将始终占用硬盘空间，并对性能产生负面影响。TiDB 使用一个垃圾回收 (GC) 机制来清理这些旧数据。
工作方式 TiDB 会周期性地进行 GC。每个 TiDB Server 启动后都会在后台运行一个 gc_worker，每个集群中会有其中一个 gc_worker 被选为 leader，leader 负责维护 GC 的状态并向所有的 TiKV Region leader 发送 GC 命令。
配置与监测方法 GC 相关的配置和运行状态记录在 mysql.tidb 这张系统表中，可以通过 SQL 语句进行检测和配置：
mysql&amp;gt; select VARIABLE_NAME, VARIABLE_VALUE from mysql.tidb; +-----------------------+------------------------------------------------------------------------------------------------+ | VARIABLE_NAME | VARIABLE_VALUE | +-----------------------+------------------------------------------------------------------------------------------------+ | bootstrapped | True | | tidb_server_version | 18 | | tikv_gc_leader_uuid | 58accebfa7c0004 | | tikv_gc_leader_desc | host:ip-172-16-30-5, pid:95472, start at 2018-04-11 13:43:30.</description>
    </item>
    
    <item>
      <title>TiDB 基本操作</title>
      <link>https://pingcap.com/docs-cn/try-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/try-tidb/</guid>
      <description>TiDB 基本操作 成功部署 TiDB 集群之后，便可以在 TiDB 中执行 SQL 语句了。因为 TiDB 兼容 MySQL，你可以使用 MySQL 客户端连接 TiDB，并且大多数情况下可以直接执行 MySQL 语句。
本文介绍 CRUD 操作等基本的 SQL 语句。完整的 SQL 语句列表，参见 TiDB SQL 语法详解。
创建、查看和删除数据库 使用 CREATE DATABASE 语句创建数据库。语法如下：
CREATE DATABASE db_name [options]; 例如，要创建一个名为 samp_db 的数据库，可使用以下语句：
CREATE DATABASE IF NOT EXISTS samp_db; 使用 SHOW DATABASES 语句查看数据库：
SHOW DATABASES; 使用 DROP DATABASE 语句删除数据库，例如：
DROP DATABASE samp_db; 创建、查看和删除表 使用 CREATE TABLE 语句创建表。语法如下：
CREATE TABLE table_name column_name data_type constraint; 例如：</description>
    </item>
    
    <item>
      <title>TiDB 快速入门指南</title>
      <link>https://pingcap.com/docs-cn/QUICKSTART/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/QUICKSTART/</guid>
      <description> TiDB 快速入门指南 作为开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，TiDB 可以部署在本地和云平台上，支持公有云、私有云和混合云。
TiDB 部署方式 你可以根据实际场景或需求，选择相应的方式来部署 TiDB 集群：
 使用 Ansible 部署：如果用于生产环境，须使用 Ansible 部署 TiDB 集群。 使用 Ansible 离线部署：如果部署环境无法访问网络，可使用 Ansible 进行离线部署。 使用 Docker Compose 部署：如果你只是想测试 TiDB、体验 TiDB 的特性，或者用于开发环境，可以使用 Docker Compose 在本地快速部署 TiDB 集群。该部署方式不适用于生产环境。 使用 Docker 部署：你可以使用 Docker 部署 TiDB 集群，但该部署方式不适用于生产环境。  项目源码 TiDB 集群所有组件的源码均可从 GitHub 上直接访问：
 TiDB TiKV PD TiSpark TiDB Operator  </description>
    </item>
    
    <item>
      <title>TiDB 数据库管理</title>
      <link>https://pingcap.com/docs-cn/sql/tidb-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/tidb-server/</guid>
      <description>TiDB 数据库管理 TiDB 服务 TiDB 是指 TiDB 数据库系统，本篇文档涉及到 TiDB 集群的基本管理功能。
TiDB 集群启动配置 可以通过命令行参数或者配置文件设置服务参数，或者是两者一起使用。注意命令行参数的优先级高于配置文件，如果同一个参数两种方式都设置，会以命令行参数中的值为准。具体信息参考这篇文档。
TiDB 数据库系统变量 TiDB 兼容 MySQL 的系统变量，同时定义了一些特有的系统变量用于调整数据库行为，具体信息参考 TiDB 专用系统变量和语法 文档。
TiDB 系统表 和 MySQL 类似，TiDB 中也有系统表，用于存放数据库运行时所需信息。具体信息参考 TiDB 系统数据库文档。
TiDB 数据目录 TiDB 数据存放在存储引擎中，数据目录取决于使用的存储引擎，存储引擎的选择参见 TiDB 启动参数文档。
对于使用本地存储引擎的情况，数据存储在本机硬盘上，目录位置通过 path 参数控制。
对于使用 TiKV 引擎的情况，数据存储在 TiKV 节点上，目录位置通过 data-dir 参数控制。
TiDB 服务器日志文件 TiDB 集群的三个组件（tidb-server、tikv-server、pd-server）默认会将日志输出到标准错误中，并且三个组件都支持设置 --log-file 启动参数 （或者是配置文件中的配置项）将日志输出到文件中。
通过配置文件可以调整日志的行为，具体信息请参见各个组件的配置文件说明。例如： tidb-server 日志配置项。</description>
    </item>
    
    <item>
      <title>TiDB 数据类型</title>
      <link>https://pingcap.com/docs-cn/sql/datatype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/datatype/</guid>
      <description>TiDB 数据类型 概述 TiDB 支持 MySQL 除空间类型之外的所有数据类型，包括数值型类型、字符串类型、时间&amp;amp;日期类型、Json 类型。
数据类型定义一般为 T(M[, D])，其中:
 T 表示具体的类型 M 对于整数类型表示最大显示长度；对于浮点数或者定点数表示精度；对于字符类型表示最大长度。M 的最大值取决于具体的类型。 D 表示浮点数/定点数的小数位长度 对于时间&amp;amp;日期类型中的 TIME、DATETIME 以及 TIMESTAMP，定义中可以包含 Fsp 表示秒的精度，其取值范围是0到6，默认的精度为0  数值类型 概述 TiDB 支持 MySQL 所有的数值类型，按照精度可以分为:
 整数类型（精确值) 浮点类型（近似值) 定点类型（精确值)  整数类型 TiDB 支持 MySQL 所有的整数类型，包括 INTEGER/INT、TINYINT、SMALLINT、MEDIUMINT 以及 BIGINT，完整信息参考这篇文档。
类型定义 语法：
BIT[(M)] &amp;gt; 比特值类型。M 表示比特位的长度，取值范围从1到64，其默认值是1。 TINYINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; TINYINT 类型。有符号数的范围是[-128, 127]。无符号数的范围是[0, 255]。 BOOL, BOOLEAN &amp;gt; 布尔类型，和 TINYINT(1) 等价。零值被认为是 False，非零值认为是 True。在 TiDB 内部，True 存储为1， False 存储为0。 SMALLINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; SMALLINT 类型。有符号数的范围是[-32768, 32767]。无符号数的范围是[0, 65535]。 MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; MEDIUMINT 类型。有符号数的范围是[-8388608, 8388607]。无符号数的范围是[0, 16777215]。 INT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; INT 类型。 有符号数的范围是[-2147483648, 2147483647]。无符号数的范围是[0, 4294967295]。 INTEGER[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; 和 INT 相同。 BIGINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; BIGINT 类型。 有符号数的范围是[-9223372036854775808, 9223372036854775807]。无符号数的范围是[0, 18446744073709551615]。 字段意义:</description>
    </item>
    
    <item>
      <title>TiDB 整体架构</title>
      <link>https://pingcap.com/docs-cn/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/architecture/</guid>
      <description>TiDB 整体架构 要深入了解 TiDB 的水平扩展和高可用特点，首先需要了解 TiDB 的整体架构。TiDB 集群主要包括三个核心组件：TiDB Server，PD Server 和 TiKV Server。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark 组件。
TiDB Server TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。
PD Server Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。
PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。
TiKV Server TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。</description>
    </item>
    
    <item>
      <title>TiDB 核心特性</title>
      <link>https://pingcap.com/docs-cn/features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/features/</guid>
      <description>TiDB 核心特性 本文详细介绍 TiDB 的两大核心特性：水平扩展与高可用。
水平扩展 无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。
高可用 高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。
 TiDB
TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。
 PD
PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。
 TiKV
TiKV 是一个集群，通过 Raft 协议保持数据的一致性（副本数量可配置，默认保存三副本），并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 结点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内（默认 30 分钟）无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点上。</description>
    </item>
    
    <item>
      <title>TiDB 版本发布历史</title>
      <link>https://pingcap.com/docs-cn/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rn/</guid>
      <description> TiDB 版本发布历史 TiDB 历史版本发布声明如下：
 2.1 RC3 2.1 RC2 2.0.7 2.1 RC1 2.0.6 2.0.5 2.1 Beta 2.0.4 2.0.3 2.0.2 2.0.1 2.0 2.0 RC5 2.0 RC4 2.0 RC3 2.0 RC1 1.1 Beta 1.1 Alpha 1.0 Pre-GA RC4 RC3 RC2 RC1  </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/user-manual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-manual/</guid>
      <description> TiDB 用户文档 TiDB 支持 SQL92 标准并兼容 MySQL 语法，为了帮您更好地使用 TiDB, 该文档沿用了 MySQL 大部分的文档结构， 同时针对 TiDB 特有的功能作了详细的描述。
TiDB 数据库管理  TiDB 服务 TiDB 进程启动参数 TiDB 数据目录 TiDB 系统数据库 TiDB 系统变量 TiDB 专用系统变量和语法 TiDB 服务器日志文件 TiDB 访问权限管理 TiDB 用户账户管理 使用加密连接  SQL 优化  理解 TiDB 执行计划 统计信息  语言结构  字面值  字符串字面值 数字字面值 NULL 值 十六进制字面值 date 和 time 字面值 布尔值 bit-val 字面值  数据库、表、索引、列和别名 关键字和保留字 用户变量 表达式语法 注释语法  字符集和时区  字符集支持 字符集配置 时区  数据类型  数值类型 日期和时间类型 字符串类型 JSON 数据类型 数据类型默认值  函数和操作符  函数和操作符概述 表达式求值的类型转换 操作符 控制流程函数 字符串函数 数值函数与操作符 日期和时间函数 位函数和操作符 Cast 函数和操作符 加密和压缩函数 信息函数 JSON 函数 信息函数 全局事务 ID 函数 [TBD] GROUP BY 聚合函数 其他函数 精度数学  SQL 语句语法  数据定义语句(DDL) 数据操作语句(DML) 事务语句 数据库管理语句 Prepared SQL 语句语法 实用工具语句 TiDB SQL 语法图  JSON 支持  JSON 支持  Connectors 和 API  Connectors 和 API  错误码与故障诊断  错误码与故障诊断  与 MySQL 兼容性对比  与 MySQL 兼容性对比  </description>
    </item>
    
    <item>
      <title>TiDB 用户账户管理</title>
      <link>https://pingcap.com/docs-cn/sql/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-account-management/</guid>
      <description>TiDB 用户账户管理 用户名和密码 TiDB 将用户账户存储在 mysql.user 系统表里面。每个账户由用户名和 host 作为标识。每个账户可以设置一个密码。
通过 MySQL 客户端连接到 TiDB 服务器，通过指定的账户和密码登陆：
shell&amp;gt; mysql --port 4000 --user xxx --password 使用缩写的命令行参数则是：
shell&amp;gt; mysql -P 4000 -u xxx -p 添加用户 添加用户有两种方式：
 通过标准的用户管理的 SQL 语句创建用户以及授予权限，比如 CREATE USER 和 GRANT 。 直接通过 INSERT ， UPDATE 和 DELETE 操作授权表。  推荐的方式是使用第一种。第二种方式修改容易导致一些不完整的修改，因此不推荐。还有另一种可选方式是使用第三方工具的图形化界面工具。
下面的例子用 CREATE USER 和 GRANT 语句创建了四个账户：
mysql&amp;gt; CREATE USER &amp;#39;finley&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;some_pass&amp;#39;; mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &amp;#39;finley&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION; mysql&amp;gt; CREATE USER &amp;#39;finley&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;some_pass&amp;#39;; mysql&amp;gt; GRANT ALL PRIVILEGES ON *.</description>
    </item>
    
    <item>
      <title>TiDB 监控框架概述</title>
      <link>https://pingcap.com/docs-cn/op-guide/monitor-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/monitor-overview/</guid>
      <description>TiDB 监控框架概述 TiDB 使用开源时序数据库 Prometheus 作为监控和性能指标信息存储方案，使用 Grafana 作为可视化组件进行展示。
Prometheus 是一个拥有多维度数据模型，灵活的查询语句的时序数据库。Prometheus 作为热门的开源项目，拥有活跃的社区及众多的成功案例。
Prometheus 提供了多个组件供用户使用。目前，我们使用 Prometheus Server，来收集和存储时间序列数据。Client 代码库，在程序中定制需要的 Metric 。Push GateWay 来接收 Client Push 上来的数据，统一供 Prometheus 主服务器抓取。以及 AlertManager 来实现报警机制。其结构如下图：
Grafana 是一个开源的 metric 分析及可视化系统。我们使用 Grafana 来展示 TiDB 的各项性能指标 。如下图所示:</description>
    </item>
    
    <item>
      <title>TiDB 研发工程师</title>
      <link>https://pingcap.com/recruit-cn/engineering/tidb-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/tidb-engineer/</guid>
      <description>TiDB 研发工程师 岗位职责：
 负责分布式数据库查询优化器相关的设计，开发，文档撰写和新人指导；
 负责分布式数据库 SQL 层的设计，开发和性能优化；
 参与分布式数据库底层系统存储系统的设计。
  职位要求：
 三年以上相关领域开发经验，扎实的编程能力，熟悉 C/C++/Go/Java/Python 中的一种；
 对分布式系统的架构和原理有比较深入的了解；
 熟悉 MapReduce/Spark/Hive 等分布式计算框架中的一种或多种；
 熟悉 MySQL/PostgreSQL/Greenplum 等数据库系统实现原理；
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神。
  加分项：
 拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历；
 熟悉 Spark 内核，并阅读过其中的源码；
 熟悉 MySQL/PostgreSQL/Greenplum 的查询引擎，并阅读过其中的源码。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>TiDB 简介</title>
      <link>https://pingcap.com/docs-cn/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/overview/</guid>
      <description>TiDB 简介 TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。
TiDB 具备如下特性：
 高度兼容 MySQL
大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。
 水平弹性扩展
通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。
 分布式事务
TiDB 100% 支持标准的 ACID 事务。
 真正金融级高可用
相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。
 一站式 HTAP 解决方案</description>
    </item>
    
    <item>
      <title>TiDB 系统数据库</title>
      <link>https://pingcap.com/docs-cn/sql/system-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/system-database/</guid>
      <description>TiDB 系统数据库 TiDB 的系统数据库跟 MySQL 类似，里面包含一些服务器运行时需要的信息。
权限系统表 这些系统表里面包含了用户账户以及相应的授权信息：
 user 用户账户，全局权限，以及其它一些非权限的列 db 数据库级别的权限 tables_priv 表级的权限 columns_priv 列级的权限  服务端帮助信息系统表  help_topic 目前为空  统计信息相关系统表  stats_buckets 统计信息的桶 stats_histograms 统计信息的直方图 stats_meta 表的元信息，比如总行数和修改数  GC Worker 相关系统表  gc_delete_range  其它系统表  GLOBAL_VARIABLES 全局系统变量表 tidb 用于 TiDB 在 bootstrap 的时候记录相关版本信息  INFORMATION_SCHEMA 里面的表 INFORMATION_SCHEMA 库里面的表主要是为了兼容 MySQL 而存在，有些第三方软件会查询里面的信息。在目前 TiDB 的实现中，里面大部分只是一些空表。
CHARACTER_SETS Table 提供字符集相关的信息，其实数据是假的。TiDB 默认支持并且只支持 utf8mb4 。
mysql&amp;gt; select * from CHARACTER_SETS; +--------------------|----------------------|-----------------------|--------+ | CHARACTER_SET_NAME | DEFAULT_COLLATE_NAME | DESCRIPTION | MAXLEN | +--------------------|----------------------|-----------------------|--------+ | ascii | ascii_general_ci | US ASCII | 1 | | binary | binary | Binary pseudo charset | 1 | | latin1 | latin1_swedish_ci | cp1252 West European | 1 | | utf8 | utf8_general_ci | UTF-8 Unicode | 3 | | utf8mb4 | utf8mb4_general_ci | UTF-8 Unicode | 4 | +--------------------|----------------------|-----------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>TiDB 路线图</title>
      <link>https://pingcap.com/docs-cn/ROADMAP/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/ROADMAP/</guid>
      <description> TiDB 路线图 TiDB： 优化器 重构 Ranger 代价模型优化 Cascades model planner Join Reorder  统计信息 基于 Query Feedback 动态更新统计信息 自动 Analyze 提升 Row Count 估算精度  执行引擎 下推 Projection 到 Coprocessor 优化 HashJoin 算子执行速度 算子并行化 并行 Projection 并行聚合 并行 Sort  Compact Row Format，节省内存占用 File Sort  View 窗口函数 Common Table Expression 分区表 Range 分区 Hash 分区  聚簇索引 新的 storage row format Query Tracing DDL 改进 Add Index 加速 并行 DDL 支持锁表 支持改变 column 类型 支持修改主键 支持一条语句中多个 DDL 操作  支持 utf8_general_ci collation  TiKV： Raft Region Merge - 合并小的 Region 以减少开销 Local Read Thread - 把读请求放在一个单独的线程处理 批量 Region Split - 加速大的 Region 的分裂 Raft Learner - 支持 Raft learner 使得成员变更过程更加平滑 Raft Pre-voter - 支持 Raft Pre-vote 避免网络隔离带来不必要的选举 Joint Consensus - 安全地进行多个成员变更 多线程 Raftstore - 在多个线程处理不同 Region 的 Raft 逻辑 多线程 Apply Pool - 在多个线程执行不同 Region 已经提交了的命令  Engine Titan - 把大的 key-values 从 LSM-Tree 中分离出来 可拔插的 Engine 接口 - 简化接口逻辑并且提供可扩展性  Storage 在 scheduler 里做流控提前避免 write stall  Transaction 优化事务冲突 分布式 GC - 把 MVCC 垃圾回收的逻辑分布到 TiKV 控制  Coprocessor Streaming - 把大的数据集切成小块返回以减少内存消耗 Chunk Execution - 按 chunk 的方式来处理数据以提高性能 请求跟踪 - 提供单个请求执行的详细信息  Tools TiKV Importer - 通过直接导入 SST 文件的方式加速数据导入  Client 提供 Rust 版本的 TiKV client gRPC 消息批量化 - 减少消息交互的开销   PD： Namespace 完善 不同 Namespace 或者 Table 配置不同的副本策略  Table Region 分散调度 调度支持优先级，更加可控 使用机器学习优化调度 优化 Region 元信息存储 - 把元信息存储在一个独立的存储引擎里  TiSpark： Limit/Order 下推 DAG 接口接入（废除 Select 接口） Index Join 和并行 merge join Data Federation（桥接其他数据源，最好能和社区同步，这个接进来可以比较好扩展 Usecase，如果再做一个 InputFormat 适配就可以接 Hive 和 Presto 这些 Hadoop 上的数仓）  Tools: 集群部署工具 高性能数据导入工具 集群备份和恢复工具 (包括全量+增量备份) 数据在线迁移工具 (Syncer 升级版) 集群诊断和分析工具  </description>
    </item>
    
    <item>
      <title>TiDB 软件和硬件环境要求</title>
      <link>https://pingcap.com/docs-cn/op-guide/recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/recommendation/</guid>
      <description>TiDB 软件和硬件环境要求 概述 TiDB 作为一款开源分布式 NewSQL 数据库，可以很好的部署和运行在 Intel 架构服务器环境及主流虚拟化环境，并支持绝大多数的主流硬件网络。作为一款高性能数据库系统，TiDB 支持主流的 Linux 操作系统环境。
Linux 操作系统版本要求    Linux 操作系统平台 版本     Red Hat Enterprise Linux 7.3 及以上   CentOS 7.3 及以上   Oracle Enterprise Linux 7.3 及以上   Ubuntu LTS 16.04 及以上     注：
 TiDB 只支持 Red Hat 兼容内核 (RHCK) 的 Oracle Enterprise Linux，不支持 Oracle Enterprise Linux 提供的 Unbreakable Enterprise Kernel。 TiDB 在 CentOS 7.</description>
    </item>
    
    <item>
      <title>TiDB 运维文档</title>
      <link>https://pingcap.com/docs-cn/op-guide/op-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/op-guide/</guid>
      <description> TiDB 运维文档 软硬件环境需求  软硬件环境需求  部署集群  Ansible 部署方案 (强烈推荐) 离线 Ansible 部署方案 Docker 部署方案 跨机房部署方案  配置集群  配置参数 使用 Ansible 变更组件配置  监控集群  整体监控框架概述 重要监控指标详解 组件状态 API &amp;amp; 监控  扩容缩容  集群扩容缩容方案 使用 Ansible 扩容缩容  升级  使用 Anisble 升级组件版本 TiDB 2.0 升级操作指南  性能调优  TiKV 性能参数调优  备份与迁移  备份与恢复 数据迁移  全量导入 增量导入   </description>
    </item>
    
    <item>
      <title>TiDB 进程启动参数</title>
      <link>https://pingcap.com/docs-cn/sql/server-command-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/server-command-option/</guid>
      <description>TiDB 进程启动参数 启动 TiDB 进程时，可以指定一些程序启动参数。
TiDB 接受许多的启动参数，执行这个命令可以得到一个简要的说明：
./tidb-server --help 获取版本信息可以使用下面命令：
./tidb-server -V 以下是启动参数的完整描述。
-L  Log 级别 默认: &amp;ldquo;info&amp;rdquo; 可选值包括 debug, info, warn, error 或者 fatal  -P  TiDB 服务监听端口 默认: &amp;ldquo;4000&amp;rdquo; TiDB 服务将会使用这个端口接受 MySQL 客户端发过来的请求  --binlog-socket  TiDB 服务使用 unix socket file 方式接受内部连接，如 PUMP 服务 默认: &amp;ldquo;&amp;rdquo; 譬如使用 &amp;ldquo;/tmp/pump.sock&amp;rdquo; 来接受 PUMP unix socket file 通信  --config  TiDB 配置文件 默认: &amp;ldquo;&amp;rdquo; 配置文件的路径  --lease  Schema 的租约时间，单位：秒 默认: &amp;ldquo;10&amp;rdquo; Schema 的 lease 主要用在 online schema changes 上面。这个值会影响到实际的 DDL 语句的执行时间。大多数情况下，用户不需要修改这个值，除非您清晰的了解 TiDB DDL 的内部实现机制  --host  TiDB 服务监听 host 默认: &amp;ldquo;0.</description>
    </item>
    
    <item>
      <title>TiDB 配置项解释</title>
      <link>https://pingcap.com/docs-cn/op-guide/tidb-config-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/tidb-config-file/</guid>
      <description>TiDB 配置项解释 TiDB 配置文件比命令行参数支持更多的选项。你可以在 config/config.toml.example 找到默认的配置文件，重命名为 config.toml 即可。
本文档只阐述未包含在命令行参数中的参数，命令行参数参见这里。
split-table  为每个 table 建立单独的 Region。 默认: true 如果需要创建大量的表，我们建议把这个参数设置为 false。  oom-action  指定 TiDB 发生 out-of-memory 错误时的操作。 默认: &amp;ldquo;log&amp;rdquo; 现在合法的选项是 [&amp;ldquo;log&amp;rdquo;, &amp;ldquo;cancel&amp;rdquo;]，如果为 &amp;ldquo;log&amp;rdquo;，仅仅是打印日志，不作实质处理。如果为 &amp;ldquo;cancel&amp;rdquo;，我们会取消执行这个操作，并且输出日志。  enable-streaming  开启 coprocessor 的 streaming 获取数据模式。 默认: false  lower-case-table-names  这个选项可以设置 TiDB 的系统变量 lower_case_table_names 的值。 默认: 2 具体可以查看 MySQL 关于这个变量的描述 注意：目前 TiDB 只支持将该选项的值设为 2，即按照大小写来保存表名，按照小写来比较（不区分大小写）。  log 日志相关的配置项。
format  指定日志输出的格式，可选项为 [json, text, console]。 默认: &amp;ldquo;text&amp;rdquo;  disable-timestamp  是否禁止在日志中输出时间戳。 默认: false 如果设置为 true，那么日志里面将不会输出时间戳。  slow-query-file  慢查询日志的文件名。 默认: &amp;ldquo;&amp;rdquo; 设置后，慢查询日志会单独输出到该文件。  slow-threshold  输出慢日志的耗时阈值。 默认: 300ms 当查询大于这个值，就会当做是一个慢查询，输出到慢查询日志。  expensive-threshold  输出 expensive 操作的行数阈值。 默认: 10000 当查询的行数(包括中间结果，基于统计信息)大于这个值，我们就会当成是一个 expensive 的操作，输出一个前缀带有 [EXPENSIVE_QUERY] 的日志。  query-log-max-len  最长的 SQL 输出长度。 默认: 2048 当语句的长度大于 query-log-max-len，将会被截断输出。  log.</description>
    </item>
    
    <item>
      <title>TiDB 集群扩容缩容方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/horizontal-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/horizontal-scale/</guid>
      <description>TiDB 集群扩容缩容方案 概述 TiDB 集群可以在不影响线上服务的情况下动态进行扩容和缩容。
 注：如果使用 Ansible 部署 TiDB 集群，请参考使用 Ansible 扩容缩容。
 下面分别介绍如何增加或者删除 PD，TiKV 以及 TiDB 的节点。
下面用到的 pd-ctl 文档可以参考 pd-control。
PD 假设现在我们有三个 PD 服务，详细信息如下：
   Name ClientUrls PeerUrls     pd1 http://host1:2379 http://host1:2380   pd2 http://host2:2379 http://host2:2380   pd3 http://host3:2379 http://host3:2380    我们可以通过 pd-ctl 来查看当前所有 PD 节点的信息：
./pd-ctl -u http://host1:2379 &amp;gt;&amp;gt; member 动态添加节点 我们可以使用 join 参数，将一个新的 PD 服务加入到现有的 PD 集群里面。 如果我们需要添加 pd4，只需要在 --join 参数里面填入当前 PD 集群任意一个 PD 服务的 client url，比如：</description>
    </item>
    
    <item>
      <title>TiDB 集群故障诊断</title>
      <link>https://pingcap.com/docs-cn/trouble-shooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/trouble-shooting/</guid>
      <description>TiDB 集群故障诊断 当试用 TiDB 遇到问题时，请先参考本篇文档。如果问题未解决，请按文档要求收集必要的信息通过 Github 提供给 TiDB 开发者。
如何给 TiDB 开发者报告错误 当使用 TiDB 遇到问题并且通过后面所列信息无法解决时，请收集以下信息并创建新 Issue:
 具体的出错信息以及正在执行的操作 当前所有组件的状态 出问题组件 log 中的 error/fatal/panic 信息 机器配置以及部署拓扑 dmesg 中 TiDB 组件相关的问题  数据库连接不上 首先请确认集群的各项服务是否已经启动，包括 tidb-server、pd-server、tikv-server。请用 ps 命令查看所有进程是否在。如果某个组件的进程已经不在了，请参考对应的章节排查错误。
如果所有的进程都在，请查看 tidb-server 的日志，看是否有报错？常见的错误包括：
 InfomationSchema is out of date
无法连接 tikv-server，请检查 pd-server 以及 tikv-server 的状态和日志。
 panic
程序有错误，请将具体的 panic log 提供给 TiDB 开发者。
  如果是清空数据并重新部署服务，请确认以下信息：
 pd-server、tikv-server 数据都已清空
tikv-server 存储具体的数据，pd-server 存储 tikv-server 中数据的的元信息。如果只清空 pd-server 或只清空 tikv-server 的数据，会导致两边数据不匹配。</description>
    </item>
    
    <item>
      <title>TiDB 集群监控</title>
      <link>https://pingcap.com/docs-cn/op-guide/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/monitor/</guid>
      <description>TiDB 集群监控 TiDB 集群状态监控目前有两种接口，第一种是通过 HTTP 接口对外汇报组件的信息，我们称之为组件的状态接口；第二种是使用 prometheus 记录组件中各种操作的详细信息，我们称之为 metrics 接口。
组件状态接口 这类接口可以获取组件的一些基本信息，并且可以作为 keepalive 监测接口。另外 PD 的接口可以看到整个 TiKV 集群的详细信息。
TiDB Server TiDB 对外暴露的 HTTP 接口是 http://host:port/status ，默认的端口号是 10080 （可以通过 &amp;ndash;status 参数设置），可以通过访问这个接口获取当前 TiDB Server 的状态，以及判断是否存活。返回结果是 Json 格式：
curl http://127.0.0.1:10080/status { connections: 0, version: &amp;#34;5.5.31-TiDB-1.0&amp;#34;, git_hash: &amp;#34;b99521846ff6f71f06e2d49a3f98fa1c1d93d91b&amp;#34; }  connection: 当前 TiDB Server 上的客户端连接数 version: TiDB 版本号 git_hash: TiDB 当前代码的 Git Hash  PD Server PD API 地址： http://${host}:${port}/pd/api/v1/${api_name}。
其中 port 默认为 2379，各类 api_name 详细信息参见 PD API Doc。</description>
    </item>
    
    <item>
      <title>TiDB-Ansible Common Operations</title>
      <link>https://pingcap.com/docs/op-guide/ansible-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/ansible-operation/</guid>
      <description>TiDB-Ansible Common Operations This guide describes the common operations when you administer a TiDB cluster using TiDB-Ansible.
Start a cluster $ ansible-playbook start.yml This operation starts all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.
Stop a cluster $ ansible-playbook stop.yml This operation stops all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/tools/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog User Guide This document describes how to deploy the Kafka version of TiDB-Binlog. If you need to deploy the local version of TiDB-Binlog, see the TiDB-Binlog user guide for the local version.
About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/tools/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tidb-binlog/</guid>
      <description>TiDB-Binlog User Guide About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages   TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:
The TiDB-Binlog cluster mainly consists of two components:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog 部署方案</title>
      <link>https://pingcap.com/docs-cn/tools/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog 部署方案 本文档介绍如何部署 Kafka 版本的 TiDB-Binlog。如需部署 local 版本的 TiDB-Binlog，可参考 local 版本的 TiDB-Binlog 部署文档。
TiDB-Binlog 简介 TiDB-Binlog 用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB-Binlog 支持以下功能场景:
 数据同步：同步 TiDB 集群数据到其他数据库 实时备份和恢复：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB-Binlog 架构 首先介绍 TiDB-Binlog 的整体架构。
TiDB-Binlog 集群主要分为三个组件：
Pump Pump 是一个守护进程，在每个 TiDB 主机的后台运行。其主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入 Kafka 中。
Drainer Drainer 从 Kafka 中收集 Binlog，并按照 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件。
Kafka &amp;amp; ZooKeeper Kafka 集群用来存储由 Pump 写入的 Binlog 数据，并提供给 Drainer 进行读取。</description>
    </item>
    
    <item>
      <title>TiDB-Binlog 部署方案</title>
      <link>https://pingcap.com/docs-cn/tools/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tidb-binlog/</guid>
      <description>TiDB-Binlog 部署方案 TiDB-Binlog 简介 TiDB-Binlog 用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB-Binlog 支持以下功能场景:
 数据同步: 同步 TiDB 集群数据到其他数据库 实时备份和恢复: 备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB-Binlog 架构 首先介绍 TiDB-Binlog 的整体架构。
TiDB-Binlog 集群主要分为两个组件：
Pump Pump 是一个守护进程，在每个 TiDB 的主机上后台运行。他的主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入磁盘文件
Drainer Drainer 从各个 Pump 节点收集 Binlog，并按照在 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件
TiDB-Binlog 安装 下载官方 Binary  CentOS 7+
# 下载压缩包 wget http://download.pingcap.org/tidb-binlog-local-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-binlog-local-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-binlog-local-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-binlog-local-linux-amd64.</description>
    </item>
    
    <item>
      <title>TiKV Control User Guide</title>
      <link>https://pingcap.com/docs/tools/tikv-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tikv-control/</guid>
      <description>TiKV Control User Guide TiKV Control (tikv-ctl) is a command line tool of TiKV, used to manage the cluster.
When you compile TiKV, the tikv-ctl command is also compiled at the same time. If the cluster is deployed using Ansible, the tikv-ctl binary file exists in the corresponding tidb-ansible/resources/bin directory. If the cluster is deployed using the binary, the tikv-ctl file is in the bin directory together with other files such as tidb-server, pd-server, tikv-server, etc.</description>
    </item>
    
    <item>
      <title>TiKV Control 使用说明</title>
      <link>https://pingcap.com/docs-cn/tools/tikv-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tikv-control/</guid>
      <description>TiKV Control 使用说明 TiKV Control (tikv-ctl) 是随 TiKV 附带的一个简单的管理工具，以下简称 tikv-ctl。
在编译 TiKV 时，tikv-ctl 命令也会同时被编译出来，而通过 Ansible 部署的集群，在对应的 tidb-ansible/resources/bin 目录下也会有这个二进制文件。
通用参数 tikv-ctl 有两种运行模式：远程模式和本地模式。前者通过 --host 选项接受 TiKV 的服务地址作为参数，后者则需要 --db 选项来指定本地 TiKV 数据目录路径。以下如无特殊说明，所有命令都同时支持这两种模式。对于远程模式，如果 TiKV 启用了 SSL，则 tikv-ctl 也需要指定相关的证书文件，例如：
$ tikv-ctl --ca-path ca.pem --cert-path client.pem --key-path client-key.pem --host 127.0.0.1:21060 &amp;lt;subcommands&amp;gt; 某些情况下，tikv-ctl 与 PD 进行通信，而不与 TiKV 通信。此时你需要使用 --pd 选项而非 --host 选项，例如：
$ tikv-ctl --pd 127.0.0.1:2379 compact-cluster store:&amp;#34;127.0.0.1:20160&amp;#34; compact db:KV cf:default range:([], []) success! 除此之外，tikv-ctl 还有两个简单的命令 --to-hex 和 --to-escaped，用于对 key 的形式作简单的变换。一般使用 escaped 形式，示例如下：</description>
    </item>
    
    <item>
      <title>TiKV 性能参数调优</title>
      <link>https://pingcap.com/docs-cn/op-guide/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/tune-tikv/</guid>
      <description>TiKV 性能参数调优 本文档用于描述如何根据机器配置情况来调整 TiKV 的参数，使 TiKV 的性能达到最优。
TiKV 最底层使用的是 RocksDB 做为持久化存储，所以 TiKV 的很多性能相关的参数都是与 RocksDB 相关的。TiKV 使用了两个 RocksDB 实例，默认 RocksDB 实例存储 KV 数据，Raft RocksDB 实例（简称 RaftDB）存储 Raft 数据。
TiKV 使用了 RocksDB 的 Column Families 特性。
 默认 RocksDB 实例将 KV 数据存储在内部的 default、write 和 lock 3 个 CF 内。
 default CF 存储的是真正的数据，与其对应的参数位于 [rocksdb.defaultcf] 项中； write CF 存储的是数据的版本信息（MVCC）以及索引相关的数据，相关的参数位于 [rocksdb.writecf] 项中； lock CF 存储的是锁信息，系统使用默认参数。  Raft RocksDB 实例存储 Raft log。
 default CF 主要存储的是 Raft log，与其对应的参数位于 [raftdb.</description>
    </item>
    
    <item>
      <title>TiKV 研发工程师</title>
      <link>https://pingcap.com/recruit-cn/engineering/tikv-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/tikv-engineer/</guid>
      <description>TiKV 研发工程师 岗位职责：
 负责分布式数据库 TiKV 相关的设计，开发；
 负责构建分布式压力测试框架，稳定性测试框架。
  任职要求：
 三年以上相关领域开发经验，扎实的编程能力，精通 C/C++/Go/Rust 中的一种；
 对分布式系统的架构和原理有比较深入的了解；
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神。
  加分项：
 拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历；
 熟悉 Paxos/Raft 等分布式一致性算法；
 熟悉分布式事务模型；
 熟悉操作系统底层知识，有 TCP/IP、IO 等系统调优经验。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>TiSpark Quick Start Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-quick-start-guide/</guid>
      <description>TiSpark Quick Start Guide To make it easy to try TiSpark, the TiDB cluster installed using TiDB-Ansible integrates Spark, TiSpark jar package and TiSpark sample data by default.
Deployment information  Spark is deployed by default in the spark folder in the TiDB instance deployment directory. The TiSpark jar package is deployed by default in the jars folder in the Spark deployment directory.
spark/jars/tispark-SNAPSHOT-jar-with-dependencies.jar TiSpark sample data and import scripts are deployed by default in the TiDB-Ansible directory.</description>
    </item>
    
    <item>
      <title>TiSpark User Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-user-guide/</guid>
      <description>TiSpark User Guide TiSpark is a thin layer built for running Apache Spark on top of TiDB/TiKV to answer the complex OLAP queries. It takes advantages of both the Spark platform and the distributed TiKV cluster and seamlessly glues to TiDB, the distributed OLTP database, to provide a Hybrid Transactional/Analytical Processing (HTAP) solution to serve as a one-stop solution for both online transactions and analysis.
TiSpark depends on the TiKV cluster and the PD cluster.</description>
    </item>
    
    <item>
      <title>TiSpark 快速入门指南</title>
      <link>https://pingcap.com/docs-cn/tispark/tispark-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tispark/tispark-quick-start-guide/</guid>
      <description>TiSpark 快速入门指南 为了让大家快速体验 TiSpark，通过 TiDB-Ansible 安装的 TiDB 集群中默认已集成 Spark、TiSpark jar 包及 TiSpark sample data。
部署信息  Spark 默认部署在 TiDB 实例部署目录下 spark 目录中 TiSpark jar 包默认部署在 Spark 部署目录 jars 文件夹下：
spark/jars/tispark-SNAPSHOT-jar-with-dependencies.jar
 TiSpark sample data 及导入脚本默认部署在 TiDB-Ansible 目录下：
tidb-ansible/resources/bin/tispark-sample-data
  环境准备 在 TiDB 实例上安装 JDK 在 Oracle JDK 官方下载页面  下载 JDK 1.8 当前最新版，本示例中下载的版本为 jdk-8u141-linux-x64.tar.gz。
解压并根据您的 JDK 部署目录设置环境变量， 编辑 ~/.bashrc 文件，比如：
export JAVA_HOME=/home/pingcap/jdk1.8.0_144 export PATH=$JAVA_HOME/bin:$PATH 验证 JDK 有效性：
$ java -version java version &amp;#34;1.</description>
    </item>
    
    <item>
      <title>TiSpark 用户指南</title>
      <link>https://pingcap.com/docs-cn/tispark/tispark-user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tispark/tispark-user-guide/</guid>
      <description>TiSpark 用户指南 TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP (Hybrid Transactional/Analytical Processing) 的需求。TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)，也需要你搭建一个 Spark 集群。
本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 的相关信息。
概述 TiSpark 是将 Spark SQL 直接运行在分布式存储引擎 TiKV 上的 OLAP 解决方案。其架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查。 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。 除此之外，用户借助 TiSpark 项目可以在 TiDB 上使用 Spark 生态圈提供的多种工具进行数据处理。例如，使用 TiSpark 进行数据分析和 ETL；使用 TiKV 作为机器学习的数据源；借助调度系统产生定时报表等等。  环境准备 现有 TiSpark 版本支持 Spark 2.</description>
    </item>
    
    <item>
      <title>Time Zone Support</title>
      <link>https://pingcap.com/docs/sql/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/time-zone/</guid>
      <description>Time Zone Support The time zone in TiDB is decided by the global time_zone system variable and the session time_zone system variable. The default value of time_zone is SYSTEM. The actual time zone corresponding to System is configured when the TiDB cluster bootstrap is initialized. The detailed logic is as follows:
 Prioritize the use of the TZ environment variable. If the TZ environment variable fails, extract the time zone from the actual soft link address of /etc/localtime.</description>
    </item>
    
    <item>
      <title>Transactions</title>
      <link>https://pingcap.com/docs/sql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/transaction/</guid>
      <description>Transactions TiDB supports distributed transactions. The statements that relate to transactions include the Autocommit variable, START TRANSACTION/BEGIN, COMMIT and ROLLBACK.
Autocommit Syntax:
SET autocommit = {0 | 1} If you set the value of autocommit to 1, the status of the current Session is autocommit. If you set the value of autocommit to 0, the status of the current Session is non-autocommit. The value of autocommit is 1 by default.</description>
    </item>
    
    <item>
      <title>Try TiDB</title>
      <link>https://pingcap.com/docs-cn/op-guide/try-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/try-tidb/</guid>
      <description>Try TiDB TiDB 支持 SQL92 标准并兼容 MySQL 语法，目前已经实现了大多数常用的 MySQL 语法。用户可以直接使用现有的 MySQL 客户端连接。如果现有的业务已经基于 MySQL 开发，大多数情况不需要修改代码即可直接替换单机的 MySQL。
创建数据库 使用 CREATE DATABASE 语句可完成对数据库的创建, 创建命令的格式如下:
CREATE DATABASE 数据库名 [其他选项]; 例如我们需要创建一个名为 samp_db 的数据库, 在命令行下执行以下命令:
CREATE DATABASE IF NOT EXISTS samp_db; 查看 TiDB 中的所有数据库：
SHOW DATABASES; 删除数据库：
DROP DATABASE samp_db; 创建表 使用 CREATE TABLE + 表名 + 列名 + 数据类型 + 约束。具体例子如下：
CREATE TABLE person ( number INT(11), name VARCHAR(255), birthday DATE ); 如果表已存在，则使用关键词 IF NOT EXISTS 可以防止发生错误。</description>
    </item>
    
    <item>
      <title>Try TiDB</title>
      <link>https://pingcap.com/docs/try-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/try-tidb/</guid>
      <description>Try TiDB After you successfully deploy a TiDB cluster, you can run SQL statements in TiDB. Because TiDB is compatible with MySQL, you can use THE MySQL client to connect to TiDB and run MySQL statements directly in most of the cases. For more information, see Compatibility with MySQL.
This page includes some basic SQL statements such as CRUD operations. For a complete list of the statements, see TiDB SQL Syntax Diagram.</description>
    </item>
    
    <item>
      <title>Try Two Types of APIs</title>
      <link>https://pingcap.com/docs/tikv/go-client-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/go-client-api/</guid>
      <description>Try Two Types of APIs To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API. This document uses two examples to guide you through how to use the two APIs in TiKV.
The usage examples are based on the deployment of TiKV using binary files on multiple nodes for test. You can also quickly try the two types of APIs on a single machine.</description>
    </item>
    
    <item>
      <title>Tune TiKV Performance</title>
      <link>https://pingcap.com/docs/op-guide/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/tune-tikv/</guid>
      <description>Tune TiKV Performance This document describes how to tune the TiKV parameters for optimal performance.
TiKV uses RocksDB for persistent storage at the bottom level of the TiKV architecture. Therefore, many of the performance parameters are related to RocksDB. TiKV uses two RocksDB instances: the default RocksDB instance stores KV data, the Raft RocksDB instance (RaftDB) stores Raft logs.
TiKV implements Column Families (CF) from RocksDB.
 The default RocksDB instance stores KV data in the default, write and lock CFs.</description>
    </item>
    
    <item>
      <title>Type Conversion in Expression Evaluation</title>
      <link>https://pingcap.com/docs/sql/type-conversion-in-expression-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/type-conversion-in-expression-evaluation/</guid>
      <description>Type Conversion in Expression Evaluation TiDB behaves the same as MySQL: https://dev.mysql.com/doc/refman/5.7/en/type-conversion.html</description>
    </item>
    
    <item>
      <title>Understand the Query Execution Plan</title>
      <link>https://pingcap.com/docs/sql/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/understanding-the-query-execution-plan/</guid>
      <description>Understand the Query Execution Plan Based on the details of your tables, the TiDB optimizer chooses the most efficient query execution plan, which consists of a series of operators. This document details the execution plan information returned by the EXPLAIN statement in TiDB.
Optimize SQL statements using EXPLAIN The result of the EXPLAIN statement provides information about how TiDB executes SQL queries:
 EXPLAIN works together with SELECT, DELETE, INSERT, REPLACE, and UPDATE.</description>
    </item>
    
    <item>
      <title>Upgrade TiDB Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/op-guide/ansible-deployment-rolling-update/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/ansible-deployment-rolling-update/</guid>
      <description>Upgrade TiDB Using TiDB-Ansible When you perform a rolling update for a TiDB cluster, the service is shut down serially and is started after you update the service binary and the configuration file. If the load balancing is configured in the front-end, the rolling update of TiDB does not impact the running applications. Minimum requirements: pd*3, tidb*2, tikv*3.
 Note: If the binlog is enabled, and Pump and Drainer services are deployed in the TiDB cluster, stop the Drainer service before the rolling update.</description>
    </item>
    
    <item>
      <title>Use Encrypted Connections</title>
      <link>https://pingcap.com/docs/sql/encrypted-connections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/encrypted-connections/</guid>
      <description>Use Encrypted Connections It is recommended to use the encrypted connection to ensure data security because non-encrypted connection might lead to information leak.
The TiDB server supports the encrypted connection based on the TLS (Transport Layer Security). The protocol is consistent with MySQL encrypted connections and is directly supported by existing MySQL clients such as MySQL operation tools and MySQL drivers. TLS is sometimes referred to as SSL (Secure Sockets Layer).</description>
    </item>
    
    <item>
      <title>User Information</title>
      <link>https://pingcap.com/tidb-planet/user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/user/</guid>
      <description></description>
    </item>
    
    <item>
      <title>User-Defined Variables</title>
      <link>https://pingcap.com/docs/sql/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-defined-variables/</guid>
      <description>User-Defined Variables The format of the user-defined variables is @var_name. @var_name consists of alphanumeric characters, _, and $. The user-defined variables are case-insensitive.
The user-defined variables are session specific, which means a user variable defined by one client cannot be seen or used by other clients.
You can use the SET statement to set a user variable:
SET @var_name = expr [, @var_name = expr] ... or
SET @var_name := expr For SET, you can use = or := as the assignment operator.</description>
    </item>
    
    <item>
      <title>Utility Statements</title>
      <link>https://pingcap.com/docs/sql/util/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/util/</guid>
      <description>Utility Statements This document describes the utility statements, including the DESCRIBE, EXPLAIN, and USE statements.
DESCRIBE statement The DESCRIBE and EXPLAIN statements are synonyms, which can also be abbreviated as DESC. See the usage of the EXPLAIN statement.
EXPLAIN statement {EXPLAIN | DESCRIBE | DESC} tbl_name [col_name] {EXPLAIN | DESCRIBE | DESC} [explain_type] explainable_stmt explain_type: FORMAT = format_name format_name: &amp;#34;DOT&amp;#34; explainable_stmt: { SELECT statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement } For more information about the EXPLAIN statement, see Understand the Query Execution Plan.</description>
    </item>
    
    <item>
      <title>Village</title>
      <link>https://pingcap.com/tidb-planet/village/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/tidb-planet/village/</guid>
      <description></description>
    </item>
    
    <item>
      <title>mydumper Instructions</title>
      <link>https://pingcap.com/docs/tools/mydumper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/mydumper/</guid>
      <description>mydumper Instructions What is mydumper? mydumper is a fork of the mydumper project with additional functionality specific to TiDB. It is the recommended method to use for logical backups of TiDB.
Download the Binary.
What enhancements does this contain over regular mydumper?  Uses tidb_snapshot to provide backup consistency instead of FLUSH TABLES WITH READ LOCK
 Includes the hidden _tidb_rowid column in INSERT statements when present
 Allows tidb_snapshot to be configurable (i.</description>
    </item>
    
    <item>
      <title>与 MySQL 兼容性对比</title>
      <link>https://pingcap.com/docs-cn/sql/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/mysql-compatibility/</guid>
      <description>与 MySQL 兼容性对比 TiDB 支持包括跨行事务、JOIN 及子查询在内的绝大多数 MySQL 5.7 的语法，用户可以直接使用现有的 MySQL 客户端连接。如果现有的业务已经基于 MySQL 开发，大多数情况不需要修改代码即可直接替换单机的 MySQL。
包括现有的大多数 MySQL 运维工具（如 PHPMyAdmin, Navicat, MySQL Workbench 等），以及备份恢复工具（如 mysqldump, mydumper/myloader）等都可以直接使用。
不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持或者是表现与 MySQL 有差异。
一些 MySQL 语法在 TiDB 中可以解析通过，但是不会做任何后续的处理，例如 Create Table 语句中 Engine 以及 Partition 选项，都是解析并忽略。更多兼容性差异请参考具体的文档。
不支持的特性  存储过程与函数 视图 触发器 事件 自定义函数 外键约束 全文索引 空间索引 非 utf8 字符集 增加主键 删除主键 SYS schema MySQL 追踪优化器  与 MySQL 有差异的特性 自增 ID TiDB 的自增 ID (Auto Increment ID) 只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。</description>
    </item>
    
    <item>
      <title>人力资源实习生</title>
      <link>https://pingcap.com/recruit-cn/campus/hr-intern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/hr-intern/</guid>
      <description>人力资源实习生 岗位职责：
 协助实施招聘工作，发布招聘广告、进行简历筛选、组织面试，评估候选人并提供初步面试报告，出具综合评价意见；
 协助设计优化招聘流程、面试标准、面试题库，组织实施招聘；
 总结招聘工作中存在的问题，提出优化招聘制度和流程的合理化建议；
 总结和统计招聘工作各项数据，完成招聘分析报告；
 配合完成其它人力资源工作。
  任职要求：
 英语好，善于与人交流和收集信息，有计算机相关知识或互联网公司实习经验的优先；
 认真努力学习，吃苦耐劳，Smart，学习能力强；
 每周至少实习 3 天，可持续实习 3 个月以上。
  待遇：
200 元/天，餐补，零食水果，生日会，Team Building
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>位函数和操作符</title>
      <link>https://pingcap.com/docs-cn/sql/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/bit-functions-and-operators/</guid>
      <description> 位函数和操作符 TiDB 中位函数和操作符的使用方法与 MySQL 基本一致，详情参见: Bit Functions and Operators。
位函数和操作符表
   函数和操作符名 功能描述     BIT_COUNT() 返回参数二进制表示中为 1 的个数   &amp;amp; 位与   ~ 按位取反   | 位或   0 位亦或   &amp;lt;&amp;lt; 左移   &amp;gt;&amp;gt; 右移    </description>
    </item>
    
    <item>
      <title>使用 Docker Compose 快速构建集群</title>
      <link>https://pingcap.com/docs-cn/op-guide/docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/docker-compose/</guid>
      <description>使用 Docker Compose 快速构建集群 本文档介绍如何在单机上通过 Docker Compose 快速一键部署一套 TiDB 测试集群。Docker Compose 可以通过一个 YAML 文件定义多个容器的应用服务，然后一键启动或停止。
 注：对于生产环境，不要使用 Docker Compose 进行部署，而应使用 Ansible 部署 TiDB 集群。
 准备环境 确保你的机器上已安装：
 Docker（17.06.0 及以上版本） Docker Compose Git  快速部署  下载 tidb-docker-compose
git clone https://github.com/pingcap/tidb-docker-compose.git 创建并启动集群
cd tidb-docker-compose &amp;amp;&amp;amp; docker-compose pull # Get the latest Docker images docker-compose up -d 访问集群
mysql -h 127.0.0.1 -P 4000 -u root 访问集群 Grafana 监控页面：http://localhost:3000 默认用户名和密码均为 admin。
集群数据可视化：http://localhost:8010</description>
    </item>
    
    <item>
      <title>使用 TiDB Ansible 升级 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/op-guide/ansible-deployment-rolling-update/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/ansible-deployment-rolling-update/</guid>
      <description>使用 TiDB Ansible 升级 TiDB 集群 滚动升级 TiDB 集群时，会串行关闭服务，更新服务 binary 和配置文件，再启动服务。在前端配置负载均衡的情况下，滚动升级期间不影响业务运行（最小环境 ：pd * 3 、tidb * 2、tikv * 3）。
 注：如果 TiDB 集群开启了 binlog，部署了 Pump 和 Drainer 服务，升级 TiDB 服务时会升级 Pump，请先停止 Drainer 服务再执行滚动升级操作。
 升级组件版本 跨大版本升级，必须更新 tidb-ansible，从 TiDB 1.0 升级到 TiDB 2.0，参考 TiDB 2.0 升级操作指南。小版本升级，也建议更新 tidb-ansible，以获取最新的配置文件模板、特性及 bug 修复。
自动下载 binary  修改 /home/tidb/tidb-ansible/inventory.ini 中的 tidb_version 参数值，指定需要升级的版本号，如从 v2.0.6 升级到 v2.0.7
tidb_version = v2.0.7  注：如果使用 master 分支的 tidb-ansible，tidb_version = latest 保持不变即可，latest 版本的 TiDB 安装包会每日更新。</description>
    </item>
    
    <item>
      <title>使用 TiDB Ansible 扩容缩容 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/op-guide/ansible-deployment-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/ansible-deployment-scale/</guid>
      <description>使用 TiDB Ansible 扩容缩容 TiDB 集群 TiDB 集群可以在不影响线上服务的情况下进行扩容和缩容。以下缩容示例中，被移除的节点没有混合部署其他服务；如果混合部署了其他服务，不能按如下操作。
假设拓扑结构如下所示：
   Name Host IP Services     node1 172.16.10.1 PD1   node2 172.16.10.2 PD2   node3 172.16.10.3 PD3, Monitor   node4 172.16.10.4 TiDB1   node5 172.16.10.5 TiDB2   node6 172.16.10.6 TiKV1   node7 172.16.10.7 TiKV2   node8 172.16.10.8 TiKV3   node9 172.16.10.9 TiKV4    扩容 TiDB/TiKV 节点 例如，如果要添加两个 TiDB 节点（node101、node102），IP 地址为 172.</description>
    </item>
    
    <item>
      <title>使用加密连接</title>
      <link>https://pingcap.com/docs-cn/sql/encrypted-connections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/encrypted-connections/</guid>
      <description>使用加密连接 TiDB 服务端默认采用非加密连接，因而具备监视信道流量能力的第三方可以知悉 TiDB 服务端与客户端之间发送和接受的数据，包括但不限于查询语句内容、查询结果等。若信道是不可信的，例如客户端是通过公网连接到 TiDB 服务端的，则非加密连接容易造成信息泄露，建议使用加密连接确保安全性。
TiDB 服务端支持启用基于 TLS（传输层安全）协议的加密连接，协议与 MySQL 加密连接一致，现有 MySQL 客户端如 MySQL 运维工具和 MySQL 驱动等能直接支持。TLS 的前身是 SSL，因而 TLS 有时也被称为 SSL，但由于 SSL 协议有已知安全漏洞，TiDB 实际上并未支持。TiDB 支持的 TLS/SSL 协议版本为 TLS 1.0、TLS 1.1、TLS 1.2。
使用加密连接后，连接将具有以下安全性质：
 保密性：流量明文无法被窃听； 完整性：流量明文无法被篡改； 身份验证（可选）：客户端和服务端能验证双方身份，避免中间人攻击。  TiDB 的加密连接支持默认是关闭的，必须在 TiDB 服务端通过配置开启加密连接的支持后，才能在客户端中使用加密连接。另外，与 MySQL 一致，TiDB 加密连接是以单个连接为单位的，并且是可选的，因而对于开启了加密连接支持的 TiDB 服务端，客户端既可以选择通过加密连接安全地连接到该 TiDB 服务端，也可以选择使用普通的非加密连接。大部分 MySQL 客户端默认不采用加密连接，因此一般还要显式地要求客户端使用加密连接。
简单来说，要使用加密连接必须同时满足以下两个条件：
 TiDB 服务端配置开启加密连接的支持 客户端指定使用加密连接  配置 TiDB 启用加密连接支持 在启动 TiDB 时，至少需要在配置文件中同时指定 ssl-cert 和 ssl-key 参数，才能使 TiDB 服务端接受加密连接。还可以指定 ssl-ca 参数进行客户端身份验证（请参见配置启用身份验证章节）。</description>
    </item>
    
    <item>
      <title>信息函数</title>
      <link>https://pingcap.com/docs-cn/sql/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/information-functions/</guid>
      <description> 信息函数 TiDB 中信息函数的使用方法与 MySQL 基本一致，详情参见：Information Functions。
信息函数表    函数名 功能描述     CONNECTION_ID() 返回当前连接的连接 ID (线程 ID)   CURRENT_USER(), CURRENT_USER 返回当前用户的用户名和主机名   DATABASE() 返回默认(当前)的数据库名   FOUND_ROWS() 该函数返回对于一个包含 LIMIT 的 SELECT 查询语句，在不包含 LIMIT 的情况下回返回的记录数   LAST_INSERT_ID() 返回最后一条 INSERT 语句中自增列的值   SCHEMA() 与 DATABASE() 同义   SESSION_USER() 与 USER() 同义   SYSTEM_USER() 与 USER() 同义   USER() 返回客户端提供的用户名和主机名   VERSION() 返回当前 MySQL 服务器的版本信息   TIDB_VERSION() 返回当前 TiDB 服务器的版本信息    </description>
    </item>
    
    <item>
      <title>公有云用户 TiDB 数据库服务协议</title>
      <link>https://pingcap.com/cloud-tidb-agreement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cloud-tidb-agreement/</guid>
      <description>公有云用户 TiDB 数据库服务协议 甲方：公有云用户（以下简称“用户”）
乙方：北京平凯星辰科技发展有限公司
甲乙双方经过平等协商，特达成本协议。本协议为甲方与乙方就使用乙方提供的公有云 TiDB 数据库服务达成的协议。
1. 协议的生效 1.1 本协议生效以用户在公有云 TiDB 页面点击购买或者使用生效。
2. 知识产权 2.1 乙方提供的本产品的版权或所有权，归乙方所有。
3. 费用 3.1 费用及结算方式以公有云 TiDB 页面公布的为准。
4. 甲方的权利义务 4.1 甲方应保证使用乙方产品的各项行为均符合国家法律法规的规定。
4.2 甲方有义务为本协议中所涉及产品内容、数据信息及服务内容、销售价格等相关信息严格保密，不得向任何第三方透露。
4.3 甲方同意，若使用乙方产品为第三方服务，乙方不承担甲方和任何第三方的纠纷。
5. 乙方的权利义务 5.1 乙方应为甲方按约提供产品服务。
5.2 乙方有义务为本协议中所涉及产品内容、数据信息及服务内容、销售价格等相关信息严格保密，不得向任何第三方透露。
6. 终止 6.1 出现下列情况之一的，乙方有权在不经事先通知的情况下，立即终止甲方使用乙方产品服务的权利，而无需承担任何责任:
 甲方购买乙方的产品服务且未在规定时间内续费的 甲方严重违反本协议下其他条款之约定，且在乙方通知后尚未纠正的  7. 发票 7.1 乙方承诺为甲方所采购的乙方之产品服务开据增值税发票。</description>
    </item>
    
    <item>
      <title>关于</title>
      <link>https://pingcap.com/about-cn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/about-cn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>关键字和保留字</title>
      <link>https://pingcap.com/docs-cn/sql/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/keywords-and-reserved-words/</guid>
      <description>关键字和保留字 关键字在 SQL 中有特殊的意义， 例如 SELECT，UPDATE，DELETE，在作为表名跟函数名的时候，需要特殊对待，例如作为表名，保留字需要被反引号包住：
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.09 sec) BEGIN 和 END 是关键字， 但不是保留字，所以不需要反引号：
mysql&amp;gt; CREATE TABLE `select` (BEGIN int, END int); Query OK, 0 rows affected (0.09 sec) 有一种特殊情况， 如果使用了限定符 .，那么也不需要用反引号：
mysql&amp;gt; CREATE TABLE test.select (BEGIN int, END int); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>其他函数</title>
      <link>https://pingcap.com/docs-cn/sql/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/miscellaneous-functions/</guid>
      <description> 其他函数    函数名 功能描述     ANY_VALUE() 在 ONLY_FULL_GROUP_BY 模式下，防止带有 GROUP BY 的语句报错   SLEEP() 休眠指定秒数   UUID() 返回通用唯一识别码 (UUID)   VALUES() 定义 INSERT 过程中要用到的值   INET_ATON() 将 IP 地址转换为数值   INET_NTOA() 将数值转换为 IP 地址   INET6_ATON() 将 IPv6 地址转换为数值    INET6_NTOA() 将数值转换为 IPv6 地址   IS_IPV4() 判断参数是否为 IPv4 地址   IS_IPV4_COMPAT() 判断参数是否为兼容 IPv4 的地址   IS_IPV4_MAPPED() 判断参数是否为 IPv4 映射的地址   IS_IPV6() 判断参数是否为 IPv6 地址   GET_LOCK()  获取命名锁，TiDB 出于兼容性支持这个函数，实际上不会做任何操作，这点和 MySQL 有区别   RELEASE_LOCK() 释放命名锁    </description>
    </item>
    
    <item>
      <title>出纳</title>
      <link>https://pingcap.com/recruit-cn/general-administrative/cashier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/general-administrative/cashier/</guid>
      <description>出纳 岗位职责：
 根据公司内部控制制度，检查原始凭证是否合规；
 办理收付结算事宜；
 负责编制资金预算及决算表；
 负责统计项目回款工作；
 登记银行存款日记账和月末编制银行余额调节表，做到日清月结，保证帐实一致；
 按照公司有关制度，催回发票；
 领导交办的其他工作。
  任职要求：
 财经类本科及以上学历；
 有初级职称和从业资格上岗证；
 熟悉银行结算等业务和有关法律制度；
 沟通能力、学习能力、责任心强。
  待遇：
5K -10K，13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>函数和操作符概述</title>
      <link>https://pingcap.com/docs-cn/sql/functions-and-operators-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/functions-and-operators-reference/</guid>
      <description>函数和操作符概述 TiDB 中函数和操作符使用方法与 MySQL 基本一致，详情参见: Functions and Operators。
在 SQL 语句中，表达式可用于诸如 SELECT 语句的 ORDER BY 或 HAVING 子句，SELECT/DELETE/UPDATE 语句的 WHERE 子句，或 SET 语句之类的地方。
可使用字面值，列名，NULL，内置函数，操作符等来书写表达式。</description>
    </item>
    
    <item>
      <title>分布式系统工程师</title>
      <link>https://pingcap.com/recruit-cn/engineering/olap-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineering/olap-engineer/</guid>
      <description>分布式系统工程师 岗位职责：
 负责分布式数据库底层系统存储系统的设计和开发；
 （可选）指导新人，进行代码和设计审核；
 （可选）参与和负责数据库计算层的设计和开发。
  任职要求：
 三年以上相关领域开发经验，扎实的编程能力，熟悉 C/C++；
 对分布式存储系统的架构和原理有比较深入的了解；
 熟悉开源分布式文件系统如 Ceph/HDFS/GlusterFS 等，或 NoSQL 数据库如 Kudu/Cassandra/HBase 等其中的至少一个，并阅读过源代码；
 熟悉分布式系统的性能分析；
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神。
  加分项：
 拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历；
 熟悉分布式计算引擎或数据库，例如 Spark/Greenplumn/Clickhouse，并阅读过其中的源码；
 熟悉分布式系统性能调优。
  待遇：
20K - 40K + 期权，13薪 + 奖金，优秀者可面议
工作地点：
北京，上海，广州，杭州，特别优秀可 Remote</description>
    </item>
    
    <item>
      <title>加密和压缩函数</title>
      <link>https://pingcap.com/docs-cn/sql/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/encryption-and-compression-functions/</guid>
      <description> 加密和压缩函数    函数名 功能描述     MD5()  计算字符串的 MD5 校验和    PASSWORD() 计算并返回密码字符串   RANDOM_BYTES() 返回随机字节向量   SHA1(), SHA()  计算 SHA-1 160 位校验和    SHA2()  计算 SHA-2 校验和    AES_DECRYPT() 使用 AES 解密   AES_ENCRYPT() 使用 AES 加密   COMPRESS() 返回经过压缩的二进制字符串   UNCOMPRESS() 解压缩字符串   UNCOMPRESSED_LENGTH()  返回字符串解压后的长度   CREATE_ASYMMETRIC_PRIV_KEY() 创建私钥   CREATE_ASYMMETRIC_PUB_KEY() 创建公钥   CREATE_DH_PARAMETERS() 创建 DH 共享密钥   CREATE_DIGEST() 从字符串创建摘要   ASYMMETRIC_DECRYPT() 使用公钥或私钥解密密文   ASYMMETRIC_DERIVE() 从非对称密钥导出对称密钥   ASYMMETRIC_ENCRYPT() 使用公钥或私钥加密明文   ASYMMETRIC_SIGN() 从摘要创建签名   ASYMMETRIC_VERIFY() 验证签名字符串是否匹配摘要字符串    </description>
    </item>
    
    <item>
      <title>十六进制字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-hex-decimal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-hex-decimal/</guid>
      <description>十六进制字面值 十六进制字面值是有 X 和 0x 前缀的字符串，后接表示十六进制的数字。注意 0x 是大小写敏感的，不能表示为 0X。
例:
X&amp;#39;ac12&amp;#39; X&amp;#39;12AC&amp;#39; x&amp;#39;ac12&amp;#39; x&amp;#39;12AC&amp;#39; 0xac12 0x12AC 以下是不合法的十六进制字面值：
X&amp;#39;1z&amp;#39; (z 不是合法的十六进制值) 0X12AC (0X 必须用小写的 0x) 对于使用 X&#39;val&#39; 格式的十六进制字面值，val 必须要有一个数字，可以在前面补一个 0 来避免语法错误。
mysql&amp;gt; select X&amp;#39;aff&amp;#39;; ERROR 1105 (HY000): line 0 column 13 near &amp;#34;&amp;#34;hex literal: invalid hexadecimal format, must even numbers, but 3 (total length 13) mysql&amp;gt; select X&amp;#39;0aff&amp;#39;; +---------+ | X&amp;#39;0aff&amp;#39; | +---------+ | | +---------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>参数解释</title>
      <link>https://pingcap.com/docs-cn/op-guide/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/configuration/</guid>
      <description>参数解释 TiDB -V  输出 TiDB 的版本 默认: &amp;ldquo;&amp;rdquo;  --config  配置文件 默认: &amp;ldquo;&amp;rdquo; 如果你指定了配置文件，TiDB 会首先读取配置文件的配置。然后如果对应的配置在命令行参数里面也存在，TiDB 就会使用命令行参数的配置来覆盖配置文件里面的。详细的配置项可以看看这里  --store  用来指定 TiDB 底层使用的存储引擎 默认: &amp;ldquo;mocktikv&amp;rdquo; 你可以选择 mocktikv&amp;rdquo; 或者 &amp;ldquo;tikv&amp;rdquo;。（mocktikv 是本地存储引擎，而 tikv 是一个分布式存储引擎）  --path  对于本地存储引擎 &amp;ldquo;mocktikv&amp;rdquo; 来说，path 指定的是实际的数据存放路径 对于 --store = tikv 时必须指定path，--store = mocktikv 时，如果不指定 path，会使用默认值。 对于 &amp;ldquo;TiKV&amp;rdquo; 存储引擎来说，path 指定的是实际的 PD 地址。假设我们在 192.168.100.113:2379, 192.168.100.114:2379 和 192.168.100.115:2379 上面部署了 PD，那么 path 为 &amp;ldquo;192.168.100.113:2379, 192.168.100.114:2379, 192.168.100.115:2379&amp;rdquo; 默认: &amp;ldquo;/tmp/tidb&amp;rdquo; 我们可以通过 tidb-server --store=mocktikv --path=&amp;quot;&amp;quot; 来启动一个纯内存引擎的 TiDB。  --advertise-address  登录 TiDB 的 IP 地址 默认: &amp;ldquo;&amp;rdquo; 这个 IP 地址必须确保用户和集群中的其他机器都能够访问到。  --host  TiDB 服务监听 host 默认: &amp;ldquo;0.</description>
    </item>
    
    <item>
      <title>备份与恢复</title>
      <link>https://pingcap.com/docs-cn/op-guide/backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/backup-restore/</guid>
      <description>备份与恢复 概述 该文档详细介绍了如何对 TiDB 进行备份恢复。本文档暂时只考虑全量备份与恢复。
这里我们假定 TiDB 服务信息如下：
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    在这个备份恢复过程中，我们会用到下面的工具：
 mydumper 从 TiDB 导出数据 loader 导入数据到 TiDB  下载 TiDB 工具集 (Linux) # 下载 tool 压缩包 wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-enterprise-tools-latest-linux-amd64.tar.gz cd tidb-enterprise-tools-latest-linux-amd64 使用 mydumper/loader 全量备份恢复数据 mydumper 是一个强大的数据备份工具，具体可以参考 https://github.</description>
    </item>
    
    <item>
      <title>字符串函数</title>
      <link>https://pingcap.com/docs-cn/sql/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/string-functions/</guid>
      <description> 字符串函数    函数名 功能描述     ASCII() 返回最左字符的数值   CHAR()  返回由整数的代码值所给出的字符组成的字符串    BIN() 返回一个数的二进制值的字符串表示   HEX() 返回十进制值或字符串值的十六进制表示   OCT() 返回一个数的八进制值的字符串表示   UNHEX() 返回 HEX 表示的数字所代表的字符串   TO_BASE64() 返回转换为 BASE64 的字符串参数   FROM_BASE64() 解码为 BASE64 的字符串并返回结果   LOWER() 返回小写字母的字符   LCASE() 与 LOWER() 功能相同   UPPER() 返回大写字母的字符   UCASE() 与 UPPER() 功能相同   LPAD()  返回左边由指定字符串填充的字符串参数    RPAD()  返回右边由指定字符串填充的字符串参数    TRIM() 删除字符串的前缀和后缀   LTRIM()  删除前面的空格字符    RTRIM() 删除结尾的空格字符   BIT_LENGTH()  返回字符串的位长度    CHAR_LENGTH()  返回字符串的字符长度    CHARACTER_LENGTH() 与 CHAR_LENGTH() 功能相同   LENGTH()  返回字符串的字节长度    OCTET_LENGTH() 与 LENGTH() 功能相同   INSERT() 在指定位置插入一个子字符串，直到指定的字符数   REPLACE() 替换指定的字符串   SUBSTR() 返回指定的子字符串   SUBSTRING() 返回指定的子字符串   SUBSTRING_INDEX() 返回最终定界符左边或右边的子字符串   MID() 返回从指定位置开始的子字符串   LEFT() 返回指定的最左字符   RIGHT() 返回指定的最右字符   INSTR() 返回子字符串的第一个出现位置   LOCATE() 返回子字符串的第一个出现位置，与 INSTR() 的参数位置相反   POSITION() 与 LOCATE() 功能相同   REPEAT() 返回重复指定次数的字符串   CONCAT() 返回连接的字符串   CONCAT_WS() 返回由分隔符连接的字符串   REVERSE() 返回和字符顺序相反的字符串   SPACE() 返回指定数目的空格组成的字符串   FIELD() 返回参数在后续参数中出现的第一个位置   ELT() 返回指定位置的字符串   EXPORT_SET()  返回一个字符串，其中值位中设置的每个位，可以得到一个 on 字符串，而每个未设置的位，可以得到一个 off 字符串    MAKE_SET()  返回一组逗号分隔的字符串，由位集合中具有相应位的字符串组成    FIND_IN_SET() 返回第一个参数在第二个参数中出现的位置   FORMAT() 返回指定小数位数格式的数字   ORD() 返回参数中最左字符的字符代码   QUOTE()  引用一个字符串，返回一个在 SQL 语句中可用作正确转义的数据值的结果     字符串比较函数    函数名 功能描述     LIKE 进行简单模式匹配   NOT LIKE 否定简单模式匹配   STRCMP() 比较两个字符串    正则表达式    表达式名 功能描述     REGEXP 使用正则表达式进行模式匹配   RLIKE 与 REGEXP 功能相同   NOT REGEXP 否定 REGEXP    </description>
    </item>
    
    <item>
      <title>字符集支持</title>
      <link>https://pingcap.com/docs-cn/sql/character-set-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/character-set-support/</guid>
      <description>字符集支持 名词解释，下面的阐述中会交错使用中文或者英文，请互相对照：
 Character Set：字符集 Collation：排序规则  目前 TiDB 支持以下字符集：
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>字符集配置</title>
      <link>https://pingcap.com/docs-cn/sql/character-set-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/character-set-configuration/</guid>
      <description>字符集配置 目前，TiDB 只支持 utf8 字符集，相当于 MySQL 中的 utf8mb4。MySQL 5.7 的默认字符集为 latin1。关于 TiDB 与 MySQL 字符集的区别，在默认设置的区别中有相关说明。
更多细节。</description>
    </item>
    
    <item>
      <title>字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-values/</guid>
      <description>字面值 String Literals String Literals 是一个 bytes 或者 characters 的序列，两端被单引号 &#39; 或者双引号 &amp;quot; 包围，例如：
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; 如果字符串是连续的，会被合并为一个独立的 string。以下表示是一样的：
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; 如果 ANSI_QUOTES SQL MODE 开启了，那么只有单引号内的会被认为是 String Literals，对于双引号内的字符串，会被认为是一个 identifier。
binary string 是一串 bytes 组成的字符串，每一个 binary string 有一个叫做 binary 的 character set 和 collation。一个非二进制的字符串是一个由字符组成的字符串，它有除 binary 外的 character set和与之兼容的 collation。
对于两种字符串类型，比较都是基于每个字符的数值。对于 binary string 而言，比较单元就是字节，对于非二进制的字符串，那么单元就是字符，而有的字符集支持多字节字符。
一个 String Literal 可以拥有一个可选的 character set introducer 和 COLLATE clause，可以用来指派特定的字符集跟 collation（TiDB 对此只是做了语法上的兼容，并不实质做处理)。</description>
    </item>
    
    <item>
      <title>实用工具语句</title>
      <link>https://pingcap.com/docs-cn/sql/util/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/util/</guid>
      <description>实用工具语句 DESCRIBE 语句 DESCRIBE 和 EXPLAIN 是同义词，另外还可以缩写为 DESC。请参考 EXPLAIN 语句的用法。
EXPLAIN 语句 {EXPLAIN | DESCRIBE | DESC} tbl_name [col_name] {EXPLAIN | DESCRIBE | DESC} [explain_type] explainable_stmt explain_type: FORMAT = format_name format_name: &amp;#34;DOT&amp;#34; explainable_stmt: { SELECT statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement } EXPLAIN 语句详细信息参考理解 TiDB 执行计划章节。
除了 MySQL 标准的结果格式之外，TiDB 还支持输出 DotGraph 结果，这时需要指定 FORMAT = &amp;quot;dot&amp;quot;，示例如下：
create table t(a bigint, b bigint); desc format = &amp;#34;dot&amp;#34; select A.</description>
    </item>
    
    <item>
      <title>开启 TLS 验证</title>
      <link>https://pingcap.com/docs-cn/op-guide/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/security/</guid>
      <description>开启 TLS 验证 概述 本文档介绍 TiDB 集群如何开启 TLS 验证，其支持：
 TiDB 组件之间的双向验证，包括 TiDB、TiKV、PD 相互之间，TiKV Control 与 TiKV、PD Control 与 PD 的双向认证，以及 TiKV peer 之间、PD peer 之间。一旦开启，所有组件之间均使用验证，不支持只开启某一部分的验证。 MySQL Client 与 TiDB 之间的客户端对服务器身份的单向验证以及双向验证。  MySQL Client 与 TiDB 之间使用一套证书，TiDB 集群组件之间使用另外一套证书。
TiDB 集群组件间开启 TLS（双向认证） 准备证书 推荐为 TiDB、TiKV、PD 分别准备一个 server 证书，并保证可以相互验证，而它们的各种客户端共用 client 证书。
有多种工具可以生成自签名证书，如 openssl，easy-rsa，cfssl。
这里提供一个使用 cfssl 生成证书的示例：生成自签名证书。
配置证书 TiDB 在 config 文件或命令行参数中设置：
[security] # Path of file that contains list of trusted SSL CAs for connection with cluster components.</description>
    </item>
    
    <item>
      <title>慢查询日志</title>
      <link>https://pingcap.com/docs-cn/sql/slow-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/slow-query/</guid>
      <description>慢查询日志 一条不合理的 SQL 语句会导致整个集群压力增大，响应变慢。对于这种问题，我们需要用慢查询日志来定位有问题的语句，解决性能问题。
获取日志 通过在 TiDB 的日志文件上 grep SLOW_QUERY 这个关键字，可以得到执行时间超过 slow-threshold 的语句日志。
slow-threshold 可以通过配置文件修改，默认是 300ms。如果配置了 slow-query-file，慢查询日志会全部写在这个文件里。
示例 2018/08/20 19:52:08.632 adapter.go:363: [warning] [SLOW_QUERY] cost_time:18.647928814s process_time:1m6.768s wait_time:12m11.212s backoff_time:600ms request_count:2058 total_keys:1869712 processed_keys:1869710 succ:true con:3 user:root@127.0.0.1 txn_start_ts:402329674704224261 database:test table_ids:[31],index_ids:[1], sql:select count(c) from sbtest1 use index (k_1) 字段解析 cost_time 表示执行这个语句花费的时间。只有执行时间超过 slow-threshold 的语句才会输出这个日志。
process_time 表示这个语句在 TiKV 的处理时间之和，因为数据会并行的发到 TiKV 执行，这个值可能会超过 cost_time。
wait_time 表示这个语句在 TiKV 的等待时间之和，因为 TiKV 的 Coprocessor 线程数是有限的，当所有的 Coprocessor 线程都在工作的时候，请求会排队，当队列中有某些请求耗时很长的时候，后面的请求的等待时间都会增加。
backoff_time 表示语句遇到需要重试的错误时在重试前等待的时间，常见的需要重试的错误有以下几种：遇到了 lock、Region 分裂、tikv server is busy。</description>
    </item>
    
    <item>
      <title>招聘主管</title>
      <link>https://pingcap.com/recruit-cn/general-administrative/hr-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/general-administrative/hr-manager/</guid>
      <description>招聘主管 岗位职责：
 负责公司招聘渠道的开拓和维护；
 实施招聘工作，发布招聘广告、进行简历筛选、组织面试，评估候选人并提供初步面试报告，出具综合评价意见；
 负责设计优化招聘流程、面试标准、面试题库，组织实施招聘；
 对招聘渠道开发、维护、拓展，保证人才信息量大、层次丰富、质量高，确保招聘渠道能有效满足公司的用人需求；
 总结招聘工作中存在的问题，提出优化招聘制度和流程的合理化建议；
 总结和统计招聘工作各项数据，完成招聘分析报告；
 配合完成其它人力资源工作。
  任职要求：
 本科以上学历，人力资源相关专业，2 年以上招聘工作经验；
 熟悉 IT 软件、互联网、相关行业人才渠道，有销售类职位猎头招聘经验优先；
 丰富的招聘经验和技巧，熟悉国家相关法律法规；
 良好的职业道德及团队合作意识，良好的亲和力；
 优秀的语言表达能力、沟通协调能力和分析判断力。
  待遇：
10K -20K，13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>控制流程函数</title>
      <link>https://pingcap.com/docs-cn/sql/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/control-flow-functions/</guid>
      <description> 控制流程函数    函数名 功能描述     CASE Case 操作符   IF() 构建 if/else   IFNULL() 构建 Null if/else   NULLIF() 如果 expr1 = expr2，返回 NULL    </description>
    </item>
    
    <item>
      <title>操作符</title>
      <link>https://pingcap.com/docs-cn/sql/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/operators/</guid>
      <description>操作符    操作符名 功能描述     AND, &amp;amp;&amp;amp; 逻辑与   = 赋值 (可用于 SET 语句中, 或用于 UPDATE 语句的 SET 中 )   := 赋值   BETWEEN ... AND ... 判断值满足范围   BINARY 将一个字符串转换为一个二进制字符串   &amp;amp; 位与   ~ 位非   \| 位或   ^ 按位异或   CASE case 操作符   DIV 整数除   / 除法   = 相等比较   &amp;lt;=&amp;gt; 空值安全型相等比较   &amp;gt; 大于   &amp;gt;= 大于或等于   IS 判断一个值是否等于一个布尔值   IS NOT 判断一个值是否不等于一个布尔值   IS NOT NULL 非空判断   IS NULL 空值判断   &amp;lt;&amp;lt; 左移   &amp;lt; 小于   &amp;lt;= 小于或等于   LIKE 简单模式匹配   - 减   %, MOD 求余   NOT, !</description>
    </item>
    
    <item>
      <title>数值函数与操作符</title>
      <link>https://pingcap.com/docs-cn/sql/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/numeric-functions-and-operators/</guid>
      <description> 数值函数与操作符 算术操作符    操作符名 功能描述     + 加号   - 减号   * 乘号   / 除号   DIV 整数除法   %, MOD 模运算，取余   - 更改参数符号    数学函数    函数名 功能描述     POW() 返回参数的指定乘方的结果值   POWER() 返回参数的指定乘方的结果值   EXP() 返回 e（自然对数的底）的指定乘方后的值   SQRT() 返回非负数的二次方根   LN() 返回参数的自然对数   LOG() 返回第一个参数的自然对数   LOG2() 返回参数以 2 为底的对数   LOG10() 返回参数以 10 为底的对数   PI() 返回 pi 的值   TAN() 返回参数的正切值   COT() 返回参数的余切值   SIN() 返回参数的正弦值   COS() 返回参数的余弦值   ATAN() 返回参数的反正切值   ATAN2(), ATAN() 返回两个参数的反正切值   ASIN() 返回参数的反正弦值   ACOS() 返回参数的反余弦值   RADIANS() 返回由度转化为弧度的参数   DEGREES() 返回由弧度转化为度的参数   MOD() 返回余数   ABS() 返回参数的绝对值   CEIL() 返回不小于参数的最小整数值   CEILING() 返回不小于参数的最小整数值   FLOOR() 返回不大于参数的最大整数值   ROUND() 返回参数最近似的整数或指定小数位数的数值   RAND() 返回一个随机浮点值   SIGN() 返回参数的符号   CONV() 不同数基间转换数字，返回数字的字符串表示   TRUNCATE() 返回被舍位至指定小数位数的数字   CRC32()  计算循环冗余码校验值并返回一个 32 位无符号值     </description>
    </item>
    
    <item>
      <title>数据定义语言</title>
      <link>https://pingcap.com/docs-cn/sql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/ddl/</guid>
      <description>数据定义语言 DDL（Data Definition Language）用于定义和管理数据库以及数据库中各种对象的语句。
CREATE DATABASE 语法 CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ... create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name CREATE DATABASE 用于创建数据库，并可以指定数据库的默认属性（如数据库默认字符集,校验规则。CREATE SCHEMA 跟 CREATE DATABASE 操作效果一样。
当创建已存在的数据库且不指定使用 IF NOT EXISTS 时会报错。
create_specification 选项用于指定数据库具体的 CHARACTER SET 和 COLLATE。目前这个选项只是语法支持。
DROP DATABASE 语法 DROP {DATABASE | SCHEMA} [IF EXISTS] db_name DROP DATABASE 用于删除指定数据库以及它其中的所用表格。
IF EXISTS 用于防止当数据库不存在时发生错误。
CREATE TABLE 语法 CREATE TABLE [IF NOT EXISTS] tbl_name (create_definition,.</description>
    </item>
    
    <item>
      <title>数据库开发实习生</title>
      <link>https://pingcap.com/recruit-cn/campus/infrastructure-engineer-intern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/infrastructure-engineer-intern/</guid>
      <description>数据库开发实习生 职位描述：
你能从工作中学习到什么？
 如何构建一个分布式关系数据库；
 如何将其包装成为一套完整的商业产品；
 亲身参与以上过程，并实践你所掌握的开发技术；
  任职要求：
 熟悉常用的开发语言，熟悉 Golang/Rust 优先；
 熟悉分布式系统/数据库系统优先；
 有开源项目实践经历优先；
 实习优秀者有机会转正，并有机会获得期权。
  待遇
300 元/8 小时，餐补，水果零食，生日会，Team Building
联系方式：
hire@pingcap.com
工作地点
北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>数据库管理语句</title>
      <link>https://pingcap.com/docs-cn/sql/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/admin/</guid>
      <description>数据库管理语句 TiDB 可以通过一些语句对数据库进行管理，包括设置权限、修改系统变量、查询数据库状态。
权限管理 参考权限管理文档。
SET 语句 SET 语句有多种作用和形式：
设置变量值 SET variable_assignment [, variable_assignment] ... variable_assignment: user_var_name = expr | param_name = expr | local_var_name = expr | [GLOBAL | SESSION] system_var_name = expr | [@@global. | @@session. | @@] system_var_name = expr 这种语法可以设置 TiDB 的变量值，包括系统变量以及用户定义变量。对于用户自定义变量，都是会话范围的变量；对于系统变量，通过 @@global. 或者是 GLOBAL 设置的变量为全局范围变量，否则为会话范围变量，具体参考系统变量一章。
SET CHARACTER 语句和 SET NAMES SET {CHARACTER SET | CHARSET} {&amp;#39;charset_name&amp;#39; | DEFAULT} SET NAMES {&amp;#39;charset_name&amp;#39; [COLLATE &amp;#39;collation_name&amp;#39;] | DEFAULT} 这个语句设置这三个会话范围的系统变量：character_set_client，character_set_results，character_set_connection 设置为给定的字符集。目前 character_set_connection 变量的值和 MySQL 有所区别，MySQL 将其设置为 character_set_database 的值。</description>
    </item>
    
    <item>
      <title>数据操作语言</title>
      <link>https://pingcap.com/docs-cn/sql/dml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/dml/</guid>
      <description>TiDB 数据操作语言 数据操作语言 (Data Manipulation Language, DML) 用于帮助用户实现对数据库的基本操作，比如查询、写入、删除和修改数据库中的数据。
TiDB 支持的数据操作语言包括 Select，Insert，Delete，Update 和 Replace。
Select 语句 Select 语句用于从数据库中查询数据。
语法定义 SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], ...] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [FOR UPDATE | LOCK IN SHARE MODE]] 语法元素说明    语法元素 说明     ALL、DISTINCT、DISTINCTROW 查询结果集中可能会包含重复值。指定 DISTINCT/DISTINCTROW 则在查询结果中过滤掉重复的行；指定 ALL 则列出所有的行。默认为 ALL。   HIGH_PRIORITY 该语句为高优先级语句，TiDB 在执行阶段会优先处理这条语句   SQL_CACHE、SQL_NO_CACHE、SQL_CALC_FOUND_ROWS TiDB 出于兼容性解析这三个语法，但是不做任何处理   STRAIGHT_JOIN STRAIGHT_JOIN 会强制优化器按照 FROM 子句中所使用的表的顺序做联合查询。当优化器选择的 Join 顺序并不优秀时，你可以使用这个语法来加速查询的执行   select_expr 投影操作列表，一般包括列名、表达式，或者是用 &amp;lsquo;*&amp;rsquo; 表示全部列   FROM table_references 表示数据来源，数据来源可以是一个表（select * from t;）或者是多个表 (select * from t1 join t2;) 或者是0个表 (select 1+1 from dual;, 等价于 select 1+1;)   WHERE where_condition Where 子句用于设置过滤条件，查询结果中只会包含满足条件的数据   GROUP BY GroupBy 子句用于对查询结果集进行分组   HAVING where_condition Having 子句与 Where 子句作用类似，Having 子句可以让过滤 GroupBy 后的各种数据，Where 子句用于在聚合前过滤记录。   ORDER BY OrderBy 子句用于指定结果排序顺序，可以按照列、表达式或者是 select_expr 列表中某个位置的字段进行排序。   LIMIT Limit 子句用于限制结果条数。Limit 接受一个或两个数字参数，如果只有一个参数，那么表示返回数据的最大行数；如果是两个参数，那么第一个参数表示返回数据的第一行的偏移量（第一行数据的偏移量是 0），第二个参数指定返回数据的最大条目数。   FOR UPDATE 对查询结果集所有数据上读锁，以监测其他事务对这些的并发修改。TiDB 使用乐观事务模型在语句执行期间不会检测锁冲突，在事务的提交阶段才会检测事务冲突，如果执行 Select For Update 期间，有其他事务修改相关的数据，那么包含 Select For Update 语句的事务会提交失败。   LOCK IN SHARE MODE TiDB 出于兼容性解析这个语法，但是不做任何处理    Insert 语句 Insert 语句用于向数据库中插入数据，TiDB 兼容 MySQL Insert 语句的所有语法。</description>
    </item>
    
    <item>
      <title>数据迁移</title>
      <link>https://pingcap.com/docs-cn/op-guide/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/migration/</guid>
      <description>数据迁移 使用 mydumper/loader 全量导入数据 mydumper 是一个更强大的数据迁移工具，具体可以参考 https://github.com/maxbube/mydumper。
你可以使用 mydumper 从 MySQL 导出数据，然后用 loader 将其导入到 TiDB 里面。
 注意：虽然 TiDB 也支持使用 MySQL 官方的 mysqldump 工具来进行数据的迁移工作，但相比于 mydumper / loader，性能会慢很多，大量数据的迁移会花费很多时间，这里我们并不推荐。
 mydumper/loader 全量导入数据最佳实践 为了快速的迁移数据 (特别是数据量巨大的库)，可以参考下面建议
 mydumper 导出数据至少要拥有 SELECT，RELOAD，LOCK TABLES 权限 使用 mydumper 导出来的数据文件尽可能的小，最好不要超过 64M，可以设置参数 -F 64 loader的 -t 参数可以根据 tikv 的实例个数以及负载进行评估调整，例如 3个 tikv 的场景，此值可以设为 3 *（1 ～ n)；当 tikv 负载过高，loader 以及 tidb 日志中出现大量 backoffer.maxSleep 15000ms is exceeded 可以适当调小该值，当 tikv 负载不是太高的时候，可以适当调大该值。  某次导入示例，以及相关的配置  mydumper 导出后总数据量 214G，单表 8 列，20 亿行数据 集群拓扑  TIKV * 12 TIDB * 4 PD * 3  mydumper -F 设置为 16, loader -t 参数 64  结果：导入时间 11 小时左右，19.</description>
    </item>
    
    <item>
      <title>数据迁移概述</title>
      <link>https://pingcap.com/docs-cn/op-guide/migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/migration-overview/</guid>
      <description>数据迁移概述 概述 该文档详细介绍了如何将 MySQL 的数据迁移到 TiDB。
这里我们假定 MySQL 以及 TiDB 服务信息如下：
   Name Address Port User Password     MySQL 127.0.0.1 3306 root *   TiDB 127.0.0.1 4000 root *    在这个数据迁移过程中，我们会用到下面四个工具:
 checker 检查 schema 能否被 TiDB 兼容 mydumper 从 MySQL 导出数据 loader 导入数据到 TiDB syncer 增量同步 MySQL 数据到 TiDB  两种迁移场景  第一种场景：只全量导入历史数据 （需要 checker + mydumper + loader）； 第二种场景：全量导入历史数据后，通过增量的方式同步新的数据 （需要 checker + mydumper + loader + syncer）。该场景需要提前开启 binlog 且格式必须为 ROW。  MySQL 开启 binlog 注意： 只有上文提到的第二种场景才需要在 dump 数据之前先开启 binlog</description>
    </item>
    
    <item>
      <title>新版 TiDB-Binlog 部署方案</title>
      <link>https://pingcap.com/docs-cn/tools/new-tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/new-tidb-binlog/</guid>
      <description>新版 TiDB-Binlog 部署方案  新版 TiDB-Binlog 尚未发布正式版，本文档用于测试环境部署。
 使用 tidb-ansible 部署 TiDB-Binlog 下载 tidb-ansible 以 tidb 用户登录中控机并进入 /home/tidb 目录，使用以下命令 tidb-ansible new-tidb-binlog 分支，默认的文件夹名称为 tidb-ansible。
$ git clone -b new-tidb-binlog https://github.com/pingcap/tidb-ansible.git 部署 pump 修改 tidb-ansible/inventory.ini 文件  设置 enable_binlog = True，表示 TiDB 集群开启 binlog。  ## binlog trigger enable_binlog = True  为 pump_servers 主机组添加部署机器 IP。  ## Binlog Part [pump_servers] 172.16.10.72 172.16.10.73 172.16.10.74 默认 pump 保留 5 天数据，如需修改可修改 tidb-ansible/conf/pump.yml 文件中 gc 变量值，并取消注释，如修改为 7。</description>
    </item>
    
    <item>
      <title>新闻报道</title>
      <link>https://pingcap.com/news-cn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/news-cn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>日期和时间函数</title>
      <link>https://pingcap.com/docs-cn/sql/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/date-and-time-functions/</guid>
      <description> 日期和时间函数 TiDB 中日期和时间函数的使用方法与 MySQL 基本一致，详情参见: Date and Time Functions.
日期时间函数表    函数名 功能描述     ADDDATE() 将时间间隔添加到日期上   ADDTIME() 时间数值相加   CONVERT_TZ() 转换时区   CURDATE() 返回当前日期   CURRENT_DATE(), CURRENT_DATE 与 CURDATE() 同义   CURRENT_TIME(), CURRENT_TIME 与 CURTIME() 同义   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP 与 NOW() 同义   CURTIME() 返回当前时间   DATE() 从日期或日期/时间表达式中提取日期部分   DATE_ADD() 将时间间隔添加到日期上   DATE_FORMAT() 返回满足指定格式的日期/时间   DATE_SUB() 从日期减去指定的时间间隔   DATEDIFF() 返回两个日期间隔的天数   DAY() 与 DAYOFMONTH() 同义   DAYNAME() 返回星期名称   DAYOFMONTH() 返回参数对应的天数部分(1-31)   DAYOFWEEK() 返回参数对应的星期下标   DAYOFYEAR() 返回参数代表一年的哪一天 (1-366)   EXTRACT() 提取日期/时间中的单独部分   FROM_DAYS() 将天数转化为日期   FROM_UNIXTIME() 将 Unix 时间戳格式化为日期   GET_FORMAT() 返回满足日期格式的字符串   HOUR() 提取日期/时间表达式中的小时部分   LAST_DAY 返回参数中月份的最后一天   LOCALTIME(), LOCALTIME 与 NOW() 同义   LOCALTIMESTAMP, LOCALTIMESTAMP() 与 NOW() 同义   MAKEDATE() 根据给定的年份和一年中的天数生成一个日期   MAKETIME() 根据给定的时、分、秒生成一个时间   MICROSECOND() 返回参数的微秒部分   MINUTE() 返回参数的分钟部分   MONTH() 返回参数的月份部分   MONTHNAME() 返回参数的月份名称   NOW() 返回当前日期和时间   PERIOD_ADD() 在年-月表达式上添加一段时间(数个月)   PERIOD_DIFF() 返回间隔的月数   QUARTER() 返回参数对应的季度(1-4)   SEC_TO_TIME() 将秒数转化为 &amp;lsquo;HH:MM:SS&amp;rsquo; 的格式   SECOND() 返回秒数(0-59)   STR_TO_DATE() 将字符串转化为日期   SUBDATE() 当传入三个参数时作为 DATE_SUB() 的同义   SUBTIME() 从一个时间中减去一段时间   SYSDATE() 返回该方法执行时的时间   TIME() 返回参数的时间表达式部分   TIME_FORMAT() 格式化时间   TIME_TO_SEC() 返回参数对应的秒数   TIMEDIFF() 返回时间间隔   TIMESTAMP() 传入一个参数时候,该方法返回日期或日期/时间表达式, 传入两个参数时候, 返回参数的和   TIMESTAMPADD() 在日期/时间表达式上增加一段时间间隔   TIMESTAMPDIFF() 从日期/时间表达式中减去一段时间间隔   TO_DAYS() 将参数转化对应的天数(从第 0 年开始)   TO_SECONDS() 将日期或日期/时间参数转化为秒数(从第 0 年开始)   UNIX_TIMESTAMP() 返回一个 Unix 时间戳   UTC_DATE() 返回当前的 UTC 日期   UTC_TIME() 返回当前的 UTC 时间   UTC_TIMESTAMP() 返回当前的 UTC 日期和时间   WEEK() 返回参数所在的一年中的星期数   WEEKDAY() 返回星期下标   WEEKOFYEAR() 返回参数在日历中对应的一年中的星期数   YEAR() 返回参数对应的年数   YEARWEEK() 返回年数和星期数    </description>
    </item>
    
    <item>
      <title>日期和时间类型</title>
      <link>https://pingcap.com/docs-cn/sql/date-and-time-types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/date-and-time-types/</guid>
      <description>日期和时间类型 用于表示日期和时间类型的值是 DATE，TIME，DATETIME，TIMESTAMP 和 YEAR。每一种类型都有自己的有效值的范围，也有一个零值用于表示它是一个无效的值。TIMESTAMP 类型有个自动更新的行为，后面介绍。
处理日期和时间类型时，请记住下面这些：
 尽管 TiDB 尝试解释不同的格式，日期部分必须是按 年-月-日 的顺序（比如，&amp;rsquo;98-09-04&amp;rsquo;），而不是 月-日-年 或者 日-月-年 的顺序。 日期值中包含两位数字的年份是有歧义的，TiDB 按下面规则解释：  范围在 70-99 之间的被转换成 1970-1999 范围在 00-69 之间的被转换成 2000-2069  如果上下文里面需要的是一个数值，TiDB 自动将日期或时间值转换成数值类型，反之亦然。 如果 TiDB 遇到一个日期或时间值是超过表示范围的，或者无效的，会自动将它转换为该类型的零值。 设置不同的 SQL mode 可以改变 TiDB 的行为。 TiDB 允许 DATE 和 DATETIME 列中出现月份或者日为零的值，比如 &amp;lsquo;2009-00-00&amp;rsquo; 或 &amp;lsquo;2009-01-00&amp;rsquo;。如果这种日期参与计算，比如函数 DATE_SUB() 或者 DATE_ADD()，得到的结果可能会不正确。 TiDB 允许存储零值 &amp;lsquo;0000-00-00&amp;rsquo;，有时候这会比 NULL 值更方便一些。  下面的表格里面显示了不同类型的零值：
   Date Type &amp;ldquo;Zero&amp;rdquo; Value     DATE &amp;lsquo;0000-00-00&amp;rsquo;   TIME &amp;lsquo;00:00:00&amp;rsquo;   DATETIME &amp;lsquo;0000-00-00 00:00:00&amp;rsquo;   TIMESTAMP &amp;lsquo;0000-00-00 00:00:00&amp;rsquo;   YEAR 0000    DATE，DATETIME 和 TIMESTAMP 类型 DATE，DATETIME，TIMESTAMP 类型都是相关的。这里描述它们的共同点和区别。</description>
    </item>
    
    <item>
      <title>时区支持</title>
      <link>https://pingcap.com/docs-cn/sql/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/time-zone/</guid>
      <description>时区支持 TiDB 使用的时区由 time_zone 全局变量和 session 变量决定。time_zone 的默认值是 System，System 对应的实际时区在 TiDB 集群 bootstrap 初始化时设置。具体逻辑如下:
 优先使用 TZ 环境变量 如果失败，则从 /etc/localtime 的实际软链地址提取。 如果上面两种都失败则使用 UTC 作为系统时区。  在运行过程中可以修改全局时区：
mysql&amp;gt; SET GLOBAL time_zone = timezone; TiDB 还可以通过设置 session 变量 time_zone 为每个连接维护各自的时区。默认条件下，这个值取的是全局变量 time_zone 的值。修改 session 使用的时区：
mysql&amp;gt; SET time_zone = timezone; 查看当前使用的时区的值：
mysql&amp;gt; SELECT @@global.time_zone, @@session.time_zone; 设置 time_zone 的值的格式：
 &amp;lsquo;SYSTEM&amp;rsquo; 表明使用系统时间 相对于 UTC 时间的偏移，比如 &amp;lsquo;+10:00&amp;rsquo; 或者 &amp;lsquo;-6:00&amp;rsquo; 某个时区的名字，比如 &amp;lsquo;Europe/Helsinki&amp;rsquo;， &amp;lsquo;US/Eastern&amp;rsquo; 或 &amp;lsquo;MET&amp;rsquo;  NOW() 和 CURTIME() 的返回值都受到时区设置的影响。</description>
    </item>
    
    <item>
      <title>权限管理</title>
      <link>https://pingcap.com/docs-cn/sql/privilege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/privilege/</guid>
      <description>权限管理 权限管理概述 TiDB的权限管理系统是按照 MySQL 的权限管理进行实现，大部分的 MySQL 的语法和权限类型都是支持的。如果发现行为跟 MySQL 不一致的地方，欢迎报告 issue。
示例 用户账户操作 更改密码 set password for &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; = &amp;#39;xxx&amp;#39;; 添加用户 create user &amp;#39;test&amp;#39;@&amp;#39;127.0.0.1&amp;#39; identified by &amp;#39;xxx&amp;#39;; 用户名是大小写敏感的。host则支持模糊匹配，比如：
create user &amp;#39;test&amp;#39;@&amp;#39;192.168.10.%&amp;#39;; 允许 test 用户从 192.168.10 子网的任何一个主机登陆。
如果没有指定 host，则默认是所有 IP 均可登陆。如果没有指定密码，默认为空：
create user &amp;#39;test&amp;#39;; 等价于
create user &amp;#39;test&amp;#39;@&amp;#39;%&amp;#39; identified by &amp;#39;&amp;#39;; 删除用户 drop user &amp;#39;test&amp;#39;@&amp;#39;%&amp;#39;; 这个操作会清除用户在 mysql.user 表里面的记录项，并且清除在授权表里面的相关记录。
忘记root密码 使用一个特殊的启动参数启动 TiDB（需要root权限）：
sudo ./tidb-server -skip-grant-table=true 这个参数启动，TiDB 会跳过权限系统，然后使用 root 登陆以后修改密码：
mysql -h 127.0.0.1 -P 4000 -u root 权限相关操作 授予权限 授予 xxx 用户对数据库 test 的读权限：</description>
    </item>
    
    <item>
      <title>案例</title>
      <link>https://pingcap.com/cases-cn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>注释语法</title>
      <link>https://pingcap.com/docs-cn/sql/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/comment-syntax/</guid>
      <description>注释语法 TiDB 支持三种注释风格：
 用 # 注释一行 用 -- 注释一行，用 -- 注释必须要在其之后留出至少一个空格。 用 /* */ 注释一块，可以注释多行。  例：
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>理解 TiDB 执行计划</title>
      <link>https://pingcap.com/docs-cn/sql/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/understanding-the-query-execution-plan/</guid>
      <description>理解 TiDB 执行计划 TiDB 优化器会根据当前数据表的实际情况来选择最优的执行计划，执行计划由一系列的 operator 构成。本文将详细解释 TiDB 中 EXPLAIN 语句返回的执行计划信息。
使用 EXPLAIN 来优化 SQL 语句 EXPLAIN 语句的返回结果提供了 TiDB 执行 SQL 查询的详细信息：
 EXPLAIN 可以和 SELECT，DELETE，INSERT，REPLACE，以及 UPDATE 语句一起使用； 执行 EXPLAIN，TiDB 会返回被 EXPLAIN 的 SQL 语句经过优化器后的最终物理执行计划。也就是说，EXPLAIN 展示了 TiDB 执行该 SQL 语句的完整信息，比如以什么样的顺序，什么方式 JOIN 两个表，表达式树长什么样等等。详见 EXPLAIN 输出格式； TiDB 目前还不支持 EXPLAIN [options] FOR CONNECTION connection_id，将在未来支持它，详见 #4351；  通过观察 EXPLAIN 的结果，你可以知道如何给数据表添加索引使得执行计划使用索引从而加速 SQL 语句的执行速度；你也可以使用 EXPLAIN 来检查优化器是否选择了最优的顺序来 JOIN 数据表。
EXPLAIN 输出格式 目前 TiDB 的 EXPLAIN 会输出 4 列，分别是：id，count，task，operator info。执行计划中每个 operator 都由这 4 列属性来描述，EXPLAIN 结果中每一行描述一个 operator。每个属性的具体含义如下：</description>
    </item>
    
    <item>
      <title>生成自签名证书</title>
      <link>https://pingcap.com/docs-cn/op-guide/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/generate-self-signed-certificates/</guid>
      <description>生成自签名证书 概述 本文档提供使用 cfssl 生成自签名证书的示例。
假设实例集群拓扑如下：
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    下载 cfssl 假设使用 x86_64 Linux 主机：
mkdir ~/bin curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 curl -s -L -o ~/bin/cfssljson https://pkg.</description>
    </item>
    
    <item>
      <title>用户自定义变量</title>
      <link>https://pingcap.com/docs-cn/sql/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-defined-variables/</guid>
      <description>用户自定义变量 用户自定义变量格式为 @var_name。var_name 目前只支持字母，数字，_$组成。用户自定义变量是大小写不敏感的。
用户自定义变量是跟 session 绑定的，也就是说只有当前连接可以看见设置的用户变量，其他客户端连接无法查看到。
用 SET 语句可以设置用户自定义变量：
SET @var_name = expr [, @var_name = expr] ... 或 SET @var_name := expr 对于 SET 语句，赋值操作符可以是 = 也可以是 :=
例：
mysql&amp;gt; SET @a1=1, @a2=2, @a3:=4; mysql&amp;gt; SELECT @a1, @a2, @t3, @a4 := @a1+@a2+@a3; +------+------+------+--------------------+ | @a1 | @a2 | @a3 | @a4 := @a1+@a2+@a3 | +------+------+------+--------------------+ | 1 | 2 | 4 | 7 | +------+------+------+--------------------+ 如果设置用户变量用了 HEX 或者 BIT 值，TiDB会把它当成二进制字符串。如果你要将其设置成数字，那么需要手动加上 CAST转换: CAST(.</description>
    </item>
    
    <item>
      <title>社区运营</title>
      <link>https://pingcap.com/recruit-cn/market/community-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/market/community-operation/</guid>
      <description>社区运营 岗位职责：
 社区活动的维护运营，包括活动的主题策划、内容统筹、人员沟通、现场执行等运营工作；
 企业自媒体平台的日常运营，包括内容编辑、发布、维护、管理、互动、提高影响力和关注度；
 了解技术社区用户需求，收集反馈，根据运营数据挖掘和分析用户需求；
 资料的搜集与编辑整理。
  任职要求：
 对 ToB 的商业和市场具备一定的感知，了解 ToB 或技术社区类运营的特点和调性；
 有亲和力，具有较强的表达与理解能力以及极强的团队合作意识，善于主动发现问题并及时沟通并解决；
 认真负责，逻辑清晰，有良好的文字和语言表达能力；
 性格开朗，积极热情，能够快速学习。
  待遇：
8K -15K，13薪 + 奖金，优秀者可面议
工作地点：
北京</description>
    </item>
    
    <item>
      <title>离线 TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/offline-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/offline-ansible-deployment/</guid>
      <description>离线 TiDB Ansible 部署方案 准备机器  下载机一台
 该机器需开放外网访问，用于下载 TiDB-Ansible、TiDB 及相关软件安装包。 推荐安装 CentOS 7.3 及以上版本 Linux 操作系统。  部署目标机器若干及部署中控机一台
 系统要求及配置参考准备机器。 可以无法访问外网。   在中控机上安装系统依赖包  下载系统依赖离线安装包，上传至中控机。该离线包仅支持 CentOS 7 系统，包含 pip 及 sshpass。
 # tar -xzvf ansible-system-rpms.el7.tar.gz # cd ansible-system-rpms.el7 # chmod u+x install_ansible_system_rpms.sh # ./install_ansible_system_rpms.sh 安装完成后，可通过 pip -V 验证 pip 是否安装成功：
# pip -V  pip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.7)  如果你的系统已安装 pip，请确认版本 &amp;gt;= 8.1.2，否则离线安装 ansible 及其依赖时，会有兼容问题。</description>
    </item>
    
    <item>
      <title>精度数学</title>
      <link>https://pingcap.com/docs-cn/sql/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/precision-math/</guid>
      <description>精度数学 TiDB 中精度数学计算与 MySQL 中基本一致, 详情请参见: Precision Math.
 数值类型 DECIMAL 数据类型的特性  数值类型 精确数值运算的范围包括精确值数据类型(整型和 DECIMAL 类型), 以及精确值数字字面量. 近似值数据类型和近似值数字字面量被作为浮点数来处理.
精确值数字字面量包含整数部分或小数部分, 或二者都包含. 精确值数字字面量可以包含符号位. 例如: 1, .2, 3.4, -5, -6.78, +9.10.
近似值数字字面量以一个包含尾数和指数的科学计数法表示(基数为 10). 其中尾数和指数可以分别或同时带有符号位. 例如: 1.2E3, 1.2E-3, -1.2E3, -1.2E-3.
两个看起来相似的数字可能会被以不同的方式进行处理. 例如, 2.34 是精确值(定点数), 而 2.3E0 是近似值(浮点数).
DECIMAL 数据类型是定点数类型, 其运算是精确计算. FLOAT 和 DOUBLE 数据类型是浮点类型, 其运算是近似计算.
DECIMAL 数据类型的特性 本节讨论 DECIMAL 数据类型的特性, 主要涉及以下几点:
 最大位数 存储格式 存储要求  DECIMAL 列的声明语法为 DECIMAL(M, D). 其中参数值意义及其范围如下:
 M 表示最大的数字位数 (精度).</description>
    </item>
    
    <item>
      <title>系统变量</title>
      <link>https://pingcap.com/docs-cn/sql/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/variable/</guid>
      <description>系统变量 MySQL 系统变量 (System Variables) 是一些系统参数，用于调整数据库运行时的行为，根据变量的作用范围分为全局范围有效（Global Scope）以及会话级别有效（Session Scope）。TiDB 支持 MySQL5.7 的所有系统变量，大部分变量仅仅是为了兼容性而支持，不会影响运行时行为。
设置系统变量 通过 SET 语句可以修改系统变量的值。进行修改时，还要考虑变量可修改的范围，不是所有的变量都能在全局/会话范围内进行修改。具体的可修改范围参考 MySQL 动态变量文档。
全局范围值  在变量名前加 GLOBAL 关键词或者是使用 @@global. 作为修饰符:  SET GLOBAL autocommit = 1; SET @@global.autocommit = 1; 会话范围值  在变量名前加 SESSION 关键词或者是使用 @@session. 作为修饰符，或者是不加任何修饰符:  SET SESSION autocommit = 1; SET @@session.autocommit = 1; SET @@autocommit = 1;  LOCAL 以及 @@local. 是 SESSION 以及 @@session. 的同义词  TiDB 支持的 MySQL 系统变量 下列系统变量是 TiDB 真正支持并且行为和 MySQL 一致：</description>
    </item>
    
    <item>
      <title>统计信息简介</title>
      <link>https://pingcap.com/docs-cn/sql/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/statistics/</guid>
      <description>统计信息简介 TiDB 优化器会根据统计信息来选择最优的执行计划。统计信息收集了表级别和列级别的信息，表的统计信息包括总行数，以及修改的行数。列的统计信息包括不同值的数量，NULL 的数量，直方图，以及该列的 Count-Min Sketch 信息。
统计信息的收集 手动收集 你可以通过执行 ANALYZE 语句来收集统计信息。
语法：
ANALYZE TABLE TableNameList &amp;gt; 该语句会收集 TableNameList 中所有表的统计信息。 ANALYZE TABLE TableName INDEX [IndexNameList] &amp;gt; 该语句会收集 TableName 中所有的 IndexNameList 中的索引列的统计信息。 &amp;gt; IndexNameList 为空时会收集所有索引列的统计信息。 自动更新 在发生增加，删除以及修改语句时，TiDB 会自动更新表的总行数以及修改的行数。这些信息会定期持久化下来， 更新的周期是 5 * stats-lease, stats-lease 的默认值是 3s，如果将其指定为 0，那么将不会自动更新。
当修改的行数与总行数的比值大于 auto-analyze-ratio 时，TiDB 会自动发起 Analyze 语句。auto-analyze-ratio 可通过配置文件修改，其默认值是 0，即不开启此功能。
在查询语句执行时，TiDB 会以 feedback-probability 的概率收集反馈信息，并将其用于更新直方图和 Count-Min Sketch。feedback-probability 可通过配置文件修改，其默认值是 0。
控制 ANALYZE 并发度 执行 ANALYZE 语句的时候，你可以通过一些参数来调整并发度，以控制对系统的影响。
tidb_build_stats_concurrency 目前 ANALYZE 执行的时候会被切分成一个个小的任务，每个任务只负责某一个列或者索引。tidb_build_stats_concurrency 可以控制同时执行的任务的数量，其默认值是 4。</description>
    </item>
    
    <item>
      <title>行政前台</title>
      <link>https://pingcap.com/recruit-cn/general-administrative/administrative-receptionist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/general-administrative/administrative-receptionist/</guid>
      <description>行政前台 岗位职责：
 负责访客、来宾的登记、接待、引见，对无关人员应阻挡在外或协助保安处理；
 熟练掌握公司概况，能够回答客人提出的一般性问题，提供常规的非保密信息；
 负责电话、邮件、信函的收转发工作，做好工作信息的记录、整理、建档；
 负责公司文件、通知的分发，做好分发记录并保存；
 对工作中出现的各种问题及时汇报，提出工作改进意见；
 完成领导交办的其他工作。
  任职要求:
 有良好的职业形象和气质，懂得基本的前台接待礼仪；
 普通话标准流利，语言表达能力强，善于沟通，有亲和力，较强的保密意识；
 熟悉行政、办公室管理相关工作流程，良好的沟通、协调和组织能力；
 熟练使用办公自动化设备及办公软件；
 良好的团队合作能力，具有高度的责任心，工作积极主动；
 1~2年工作经验，有外企、投行工作经验优先。
  待遇：
4K -8K，13薪 + 奖金，优秀者可面议
联系方式：
hire@pingcap.com
工作地点：
北京</description>
    </item>
    
    <item>
      <title>表达式求值的类型转换</title>
      <link>https://pingcap.com/docs-cn/sql/type-conversion-in-expression-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/type-conversion-in-expression-evaluation/</guid>
      <description>表达式求值的类型转换 TiDB 中表达式求值的类型转换与 MySQL 基本一致，详情参见 MySQL 表达式求值的类型转换。</description>
    </item>
    
    <item>
      <title>表达式语法</title>
      <link>https://pingcap.com/docs-cn/sql/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/expression-syntax/</guid>
      <description>表达式语法 (Expression Syntax) 在 TiDB 中，以下规则是表达式的语法，你可以在 parser/parser.y 中找到定义。TiDB 的语法解析是基于 yacc 的。
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>资深售前技术总监</title>
      <link>https://pingcap.com/recruit-cn/business/presales-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/business/presales-director/</guid>
      <description>资深售前技术总监 岗位职责：
 负责组织制定公司数据库产品、数据库解决方案的技术方案编写、标书的准备、讲解及用户答疑等工作；
 负责用户的技术交流、技术支持、POC 等工作；
 负责合作伙伴厂商的技术交流；
 和产品、社区、市场部门密切配合，负责相关的沟通、技术支持、技术文档撰写等工作。
  任职要求：
 5 年以上 IT 领域售前工作经验；
 熟悉传统商业数据库（如 Oracle）及开源数据库，对云计算、大数据及数据库前沿领域有深入的认识和实践；
 熟悉 1~2个行业，熟悉行业发展方向、技术趋势、商务模式、行业主流 IT 供应商等，熟悉金融行业尤佳；
 丰富的方案设计、标书应答、用户交流经验；
 良好的写作和口才、良好的沟通能力；
 工作条理性强，具有很强的责任心和团队合作精神。
  待遇：
Base 25K - 35K，13薪 + 期权 + 丰厚的业绩奖金，优秀者可面议
工作地点 北京，上海，杭州，广州，深圳</description>
    </item>
    
    <item>
      <title>资深渠道合作总监</title>
      <link>https://pingcap.com/recruit-cn/business/channel-co-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/business/channel-co-director/</guid>
      <description>资深渠道合作总监 岗位职责：
 根据公司产品（分布式数据库）特性，负责相关合作伙伴的建立、维护、发展与管理；
 制定相关合作伙伴的拓展计划；
 执行并完成相关合作伙伴拓展计划和销售任务；
 配合销售及市场部门完成相关工作。
  任职要求：
 本科以上学历，3 年以上软件行业渠道销售经验；
 与主要 IT 系统集成商、行业应用软件开发商具有良好的合作关系，金融行业尤佳；
 具有良好的渠道拓展能力和丰富的渠道资源和渠道管理经验；
 具有数据库软件等基础软件渠道销售经验者优先，有技术背景优先；
 强烈的责任心、良好的沟通能力、团队协作能力。
  待遇：
Base 25K - 35K，期权 + 丰厚的业绩奖金，优秀者可面议
工作地点：
北京</description>
    </item>
    
    <item>
      <title>资深行业销售总监</title>
      <link>https://pingcap.com/recruit-cn/business/sales-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/business/sales-director/</guid>
      <description>资深行业销售总监 岗位职责：
 负责分布式数据库产品的业务拓展、合作及销售；
 深入掌握和分析行业市场信息，把握最新销售信息，为公司提供业务发展战略依据；
 负责目标顾客的开发与维护、项目谈判，调配各种资源达成公司制定销售指标，扩大产品的市场占有率；
 负责拓展新客户和新业务，积极了解客户的需求并进行专业分析和评估，制定合理销售方案；
 完成整体业绩指标，包括销售额和回款额。
  任职要求：
 本科或以上学历，通信、计算机、企业管理、市场营销等相关专业；
 5 年以上 IT 软件产品（通用软件/行业应用软件）销售经验，出色的过往销售业绩；
 有特定行业的客户和渠道资源，比如政府、银行、保险、电信、能源等；
 出众的沟通表达能力、抗压能力、管理能力，具有敬业精神及团队合作意识；
 如有数据库技术经验或售前经验有加分。
  待遇：
Base 25K - 35K，期权 + 丰厚的业绩奖金，优秀者可面议
工作地点：
北京，上海，杭州，广州，深圳</description>
    </item>
    
    <item>
      <title>跨机房部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/location-awareness/</guid>
      <description>跨机房部署方案 概述 PD 能够根据 TiKV 集群的拓扑结构进行调度，使得 TiKV 的容灾能力最大化。
阅读本章前，请先确保阅读 Ansible 部署方案 和 Docker 部署方案。
TiKV 上报拓扑信息 可以通过 TiKV 的启动参数或者配置文件来让 TiKV 上报拓扑信息给 PD。
假设拓扑结构分为三级：zone &amp;gt; rack &amp;gt; host，可以通过 labels 来指定这些信息。
启动参数：
tikv-server --labels zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt; 配置文件：
[server] labels = &amp;#34;zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt;&amp;#34; PD 理解 TiKV 拓扑结构 可以通过 PD 的配置文件让 PD 理解 TiKV 集群的拓扑结构。
[replication] max-replicas = 3 location-labels = [&amp;#34;zone&amp;#34;, &amp;#34;rack&amp;#34;, &amp;#34;host&amp;#34;] 其中 location-labels 需要与 TiKV 的 labels 名字对应，这样 PD 才能知道这些 labels 代表了 TiKV 的拓扑结构。</description>
    </item>
    
    <item>
      <title>连接器和 API</title>
      <link>https://pingcap.com/docs-cn/sql/connection-and-APIs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/connection-and-APIs/</guid>
      <description>连接器和 API 数据库连接器为客户端提供了连接数据库服务端的方式，APIs 提供了使用 MySQL 协议和资源的底层接口。无论是连接器还是 API，都可以用来在不同的语言和环境内连接服务器并执行 sql 语句，包括 odbc、java(jdbc)、Perl、Python、PHP、Ruby 和 C。
TiDB 兼容 MySQL(5.6、5.7) 的所有连接器和 API，包括：
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  使用 MySQL 连接器连接 TiDB Oracle 官方提供了以下 API，TiDB 可以兼容所有这些 API。
 MySQL Connector/C：C 语言的客户端库，是 libmysqlclient 的替代品 MySQL Connector/C++：C++ 语言的客户端库 MySQL Connector/J：Java 语言的客户端库，基于标准 JDBC 接口 MySQL Connector/Net：.</description>
    </item>
    
    <item>
      <title>重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/op-guide/dashboard-overview-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/dashboard-overview-info/</guid>
      <description> 重要监控指标详解 使用 Ansible 部署 TiDB 集群时，一键部署监控系统 (Prometheus/Grafana)，监控架构请看 TiDB 监控框架概述。
目前 Grafana Dashboard 整体分为 PD、TiDB、TiKV、Node_exporter、Overview 等。
对于日常运维，我们单独挑选出重要的 Metrics 放在 Overview 页面，方便日常运维人员观察集群组件 (PD, TiDB, TiKV) 使用状态以及集群使用状态。
以下为 Overview Dashboard 监控说明：
说明  Services Port Status  Services Online：各服务在线节点数量 Services Offline：各服务 Down 掉节点数量  PD  Storage Capacity：TiDB 集群总可用数据库空间大小 Current Storage Size：TiDB 集群目前已用数据库空间大小 Number of Regions：当前集群的 Region 总量 Leader Balance Ratio：Leader 数量最多和最少节点相差的百分比，一般小于 5%，节点重启时会有比较大的波动 Region Balance Ratio：Region 数量最多和最少节点相差的百分比，一般小于 5%，新增/下线节点时相差比较大 Store Status：集群 TiKV 节点的状态  Up Stores：正常运行的 TiKV 节点数量 Disconnect Stores：短时间内通信异常的 TiKV 节点数量 LowSpace Stores：剩余可用空间小于 80% 的 TiKV 节点数量 Down Stores：停止工作的 TiKV 节点数量，如果大于 0，说明有节点不正常 Offline Stores：正在下线的 TiKV 节点数量（正在下线的 TiKV 节点还在提供服务） Tombstone Stores：下线成功的 TiKV 节点数量  99% completed_cmds_duration_seconds：单位时间内，99% 的 pd-server 请求执行时间小于监控曲线的值，一般 &amp;lt;= 5ms handle_requests_duration_seconds：PD 发送请求的网络耗时  TiDB  Statement OPS：SQL 执行数量统计（包含 select、insert、update 等） Duration：SQL 执行的时间 QPS By Instance：每个 TiDB 上的 QPS Failed Query OPM：失败 SQL 的统计，例如语法错误、主键冲突等 Connection count：每个 TiDB 的连接数 Heap Memory Usage：每个 TiDB 使用的堆内存大小 Transaction OPS：事务执行数量统计 Transaction Duration：事务执行的时间 KV Cmd OPS：KV 命令执行数量统计 KV Cmd Duration 99：KV 命令执行的时间 PD TSO OPS：TiDB 从 PD 获取 TSO 的数量 PD TSO Wait Duration：TiDB 从 PD 获取 TS 的时间 TiClient Region Error OPS：TiKV 返回 Region 相关错误信息的数量 Lock Resolve OPS：事务冲突相关的数量 Load Schema Duration：TiDB 从 TiKV 获取 Schema 的时间 KV Backoff OPS：TiKV 返回错误信息的数量（事务冲突等）  TiKV  leader：各个 TiKV 节点上 Leader 的数量分布 region：各个 TiKV 节点上 Region 的数量分布 CPU：各个 TiKV 节点的 CPU 使用率 Memory：各个 TiKV 节点的内存使用量 store size：各个 TiKV 节点存储的数据量 cf size：集群不同 CF 存储的数据量 channel full：正常情况显示 No data，如果有了监控值，说明对应 TiKV 节点的消息处理不过来了 server report failures：正常情况显示 No data，如果出现了 Unreachable，说明 TiKV 之间通信有问题 scheduler pending commands：写入堆积的数量，偶尔出现峰值属于正常现象 coprocessor pending requests：正常情况监控为 0 或者数量很少 coprocessor executor count：不同类型的查询操作数量 coprocessor request duration：TiKV 中查询消耗的时间 raft store CPU：raftstore 线程的 CPU 使用率，目前为单线程，超过 80% 说明使用率很高 Coprocessor CPU：TiKV 查询线程的 CPU 使用率，和业务相关，复杂查询会使用大量的 CPU 资源  System Info  Vcores：CPU 核心数量 Memory：内存总大小 CPU Usage：CPU 使用率，最大为 100% Load [1m]：1 分钟的负载情况 Memory Available：剩余内存大小 Network Traffic：网卡流量统计 TCP Retrans：网络监控，TCP 相关信息统计 IO Util：磁盘使用率，最高为 100%，一般到 80% - 90% 就需要考虑加节点   图例 </description>
    </item>
    
    <item>
      <title>错误码与故障诊断</title>
      <link>https://pingcap.com/docs-cn/sql/error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/error/</guid>
      <description>错误码与故障诊断 本篇文档描述在使用 TiDB 过程中会遇到的问题以及解决方法。
错误码 TiDB 兼容 MySQL 的错误码，在大多数情况下，返回和 MySQL 一样的错误码。另外还有一些特有的错误码：
   错误码 说明     8001 请求使用的内存超过 TiDB 内存使用的阈值限制   8002 带有 SELECT FOR UPDATE 语句的事务，在遇到写入冲突时，为保证一致性无法进行重试，事务将进行回滚并返回该错误   8003 ADMIN CHECK TABLE 命令在遇到行数据跟索引不一致的时候返回该错误   9001 请求 PD 超时，请检查 PD Server 状态/监控/日志以及 TiDB Server 与 PD Server 之间的网络   9002 请求 TiKV 超时，请检查 TiKV Server 状态/监控/日志以及 TiDB Server 与 TiKV Server 之间的网络   9003 TiKV 操作繁忙，一般出现在数据库负载比较高时，请检查 TiKV Server 状态/监控/日志   9004 当数据库上承载的业务存在大量的事务冲突时，会遇到这种错误，请检查业务代码   9005 某个 Raft Group 不可用，如副本数目不足，出现在 TiKV 比较繁忙或者是 TiKV 节点停机的时候，请检查 TiKV Server 状态/监控/日志   9006 GC Life Time 间隔时间过短，长事务本应读到的数据可能被清理了,应增加GC Life Time   9500 单个事务过大，原因及解决方法请参考这里    故障诊断 参见故障诊断文档以及 FAQ。</description>
    </item>
    
    <item>
      <title>首页</title>
      <link>https://pingcap.com/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/</guid>
      <description></description>
    </item>
    
    <item>
      <title>高级数据库支持工程师</title>
      <link>https://pingcap.com/recruit-cn/business/ops-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/business/ops-engineer/</guid>
      <description>高级数据库支持工程师 岗位职责：
 负责对客户进行 TiDB 项目实施、技术支持，包括配置管理、升级、扩容、备份、数据迁移等工作；
 负责用户 TiDB 集群监控、故障响应、问题跟踪及性能分析处理；
 负责与用户进行需求沟通、技术培训，介绍 TiDB 的原理、使用方式、最佳实践等；
 研究 TiDB，对某细分方向，如 TiDB 自动化管理、SQL 优化、故障诊断等有持续产出、贡献。
  任职要求：
 3 年以上 DBA 相关工作经验（MySQL、Oracle、PostgreSQL 等），或者 3 年以上大数据工作经验（Hadoop、HBase、MongoDB 等）；
 精通一种关系型数据库的（如 MySQL ）配置、备份、优化、监控、管理；
 熟悉 Linux 操作系统，如常用命令、文件系统、系统配置等，具有较强的故障定位和问题解决能力，有丰富处理重大故障的经历；
 熟悉 Shell、Python、Perl 等脚本语言，有 DevOPS 工作经验，或对 Ansible、Cloud、Docker、Promethus 等技术领域有一定使用经验；
 丰富的项目管理、项目实施经验，能够独立完成数据库架构设计，标准化建设及 POC 文档编写；
 高度的责任心、良好的沟通技巧和团队合作精神；
 对前沿技术有一定研究者，如分布式系统、ES、RocksDB 等加分，对 Go、Rust、Raft 熟悉者加分。
  待遇：
15K - 30K，14薪 + 奖金，优秀者可面议
工作地点：
北京，上海，杭州，广州，深圳</description>
    </item>
    
  </channel>
</rss>